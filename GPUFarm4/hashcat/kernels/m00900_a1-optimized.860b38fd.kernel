//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: UNKNOWN
// Driver 
// Based on LLVM 3.4svn
//

.version 6.2
.target sm_61, texmode_independent
.address_size 64

	// .globl	gpu_decompress

.entry gpu_decompress(
	.param .u64 .ptr .global .align 4 gpu_decompress_param_0,
	.param .u64 .ptr .global .align 4 gpu_decompress_param_1,
	.param .u64 .ptr .global .align 4 gpu_decompress_param_2,
	.param .u64 gpu_decompress_param_3
)
{
	.local .align 4 .b8 	__local_depot0[260];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<10>;
	.reg .b32 	%r<56>;
	.reg .b64 	%rd<44>;


	mov.u64 	%SPL, __local_depot0;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd5, [gpu_decompress_param_0];
	ld.param.u64 	%rd6, [gpu_decompress_param_1];
	ld.param.u64 	%rd7, [gpu_decompress_param_2];
	ld.param.u64 	%rd8, [gpu_decompress_param_3];
	add.u64 	%rd9, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd9;
	mov.u32 	%r23, %ctaid.x;
	mov.u32 	%r24, %ntid.x;
	mov.b32	%r25, %envreg3;
	mad.lo.s32 	%r26, %r23, %r24, %r25;
	mov.u32 	%r27, %tid.x;
	add.s32 	%r1, %r26, %r27;
	cvt.s64.s32	%rd10, %r1;
	setp.ge.u64	%p1, %rd10, %rd8;
	@%p1 bra 	BB0_12;

	mul.wide.s32 	%rd11, %r1, 12;
	add.s64 	%rd12, %rd5, %rd11;
	ld.global.u32 	%r2, [%rd12];
	ld.global.u32 	%r3, [%rd12+4];
	ld.global.u32 	%r4, [%rd12+8];
	mov.u64 	%rd13, 0;
	st.local.u32 	[%rd1+4], %rd13;
	st.local.u32 	[%rd1], %rd13;
	st.local.u32 	[%rd1+12], %rd13;
	st.local.u32 	[%rd1+8], %rd13;
	st.local.u32 	[%rd1+20], %rd13;
	st.local.u32 	[%rd1+16], %rd13;
	st.local.u32 	[%rd1+28], %rd13;
	st.local.u32 	[%rd1+24], %rd13;
	st.local.u32 	[%rd1+36], %rd13;
	st.local.u32 	[%rd1+32], %rd13;
	st.local.u32 	[%rd1+44], %rd13;
	st.local.u32 	[%rd1+40], %rd13;
	st.local.u32 	[%rd1+52], %rd13;
	st.local.u32 	[%rd1+48], %rd13;
	st.local.u32 	[%rd1+60], %rd13;
	st.local.u32 	[%rd1+56], %rd13;
	st.local.u32 	[%rd1+68], %rd13;
	st.local.u32 	[%rd1+64], %rd13;
	st.local.u32 	[%rd1+76], %rd13;
	st.local.u32 	[%rd1+72], %rd13;
	st.local.u32 	[%rd1+84], %rd13;
	st.local.u32 	[%rd1+80], %rd13;
	st.local.u32 	[%rd1+92], %rd13;
	st.local.u32 	[%rd1+88], %rd13;
	st.local.u32 	[%rd1+100], %rd13;
	st.local.u32 	[%rd1+96], %rd13;
	st.local.u32 	[%rd1+108], %rd13;
	st.local.u32 	[%rd1+104], %rd13;
	st.local.u32 	[%rd1+116], %rd13;
	st.local.u32 	[%rd1+112], %rd13;
	st.local.u32 	[%rd1+124], %rd13;
	st.local.u32 	[%rd1+120], %rd13;
	st.local.u32 	[%rd1+132], %rd13;
	st.local.u32 	[%rd1+128], %rd13;
	st.local.u32 	[%rd1+140], %rd13;
	st.local.u32 	[%rd1+136], %rd13;
	st.local.u32 	[%rd1+148], %rd13;
	st.local.u32 	[%rd1+144], %rd13;
	st.local.u32 	[%rd1+156], %rd13;
	st.local.u32 	[%rd1+152], %rd13;
	st.local.u32 	[%rd1+164], %rd13;
	st.local.u32 	[%rd1+160], %rd13;
	st.local.u32 	[%rd1+172], %rd13;
	st.local.u32 	[%rd1+168], %rd13;
	st.local.u32 	[%rd1+180], %rd13;
	st.local.u32 	[%rd1+176], %rd13;
	st.local.u32 	[%rd1+188], %rd13;
	st.local.u32 	[%rd1+184], %rd13;
	st.local.u32 	[%rd1+196], %rd13;
	st.local.u32 	[%rd1+192], %rd13;
	st.local.u32 	[%rd1+204], %rd13;
	st.local.u32 	[%rd1+200], %rd13;
	st.local.u32 	[%rd1+212], %rd13;
	st.local.u32 	[%rd1+208], %rd13;
	st.local.u32 	[%rd1+220], %rd13;
	st.local.u32 	[%rd1+216], %rd13;
	st.local.u32 	[%rd1+228], %rd13;
	st.local.u32 	[%rd1+224], %rd13;
	st.local.u32 	[%rd1+236], %rd13;
	st.local.u32 	[%rd1+232], %rd13;
	st.local.u32 	[%rd1+244], %rd13;
	st.local.u32 	[%rd1+240], %rd13;
	st.local.u32 	[%rd1+252], %rd13;
	st.local.u32 	[%rd1+248], %rd13;
	setp.eq.s32	%p2, %r3, 0;
	@%p2 bra 	BB0_10;

	and.b32  	%r5, %r3, 3;
	setp.eq.s32	%p3, %r5, 0;
	mov.u32 	%r54, 0;
	@%p3 bra 	BB0_8;

	setp.eq.s32	%p4, %r5, 1;
	mov.u32 	%r50, 0;
	@%p4 bra 	BB0_7;

	setp.eq.s32	%p5, %r5, 2;
	mov.u32 	%r48, 0;
	@%p5 bra 	BB0_6;

	mul.wide.u32 	%rd14, %r2, 4;
	add.s64 	%rd15, %rd6, %rd14;
	ld.global.u32 	%r32, [%rd15];
	st.local.u32 	[%rd1], %r32;
	add.s32 	%r2, %r2, 1;
	mov.u32 	%r48, 1;

BB0_6:
	mul.wide.u32 	%rd16, %r2, 4;
	add.s64 	%rd17, %rd6, %rd16;
	ld.global.u32 	%r33, [%rd17];
	mul.wide.u32 	%rd18, %r48, 4;
	add.s64 	%rd19, %rd1, %rd18;
	st.local.u32 	[%rd19], %r33;
	add.s32 	%r50, %r48, 1;
	add.s32 	%r2, %r2, 1;

BB0_7:
	mul.wide.u32 	%rd20, %r2, 4;
	add.s64 	%rd21, %rd6, %rd20;
	ld.global.u32 	%r34, [%rd21];
	mul.wide.u32 	%rd22, %r50, 4;
	add.s64 	%rd23, %rd1, %rd22;
	st.local.u32 	[%rd23], %r34;
	add.s32 	%r54, %r50, 1;
	add.s32 	%r2, %r2, 1;

BB0_8:
	setp.lt.u32	%p6, %r3, 4;
	@%p6 bra 	BB0_10;

BB0_9:
	mul.wide.u32 	%rd24, %r2, 4;
	add.s64 	%rd25, %rd6, %rd24;
	ld.global.u32 	%r35, [%rd25];
	mul.wide.u32 	%rd26, %r54, 4;
	add.s64 	%rd27, %rd1, %rd26;
	st.local.u32 	[%rd27], %r35;
	add.s32 	%r36, %r2, 1;
	mul.wide.u32 	%rd28, %r36, 4;
	add.s64 	%rd29, %rd6, %rd28;
	ld.global.u32 	%r37, [%rd29];
	add.s32 	%r38, %r54, 1;
	mul.wide.u32 	%rd30, %r38, 4;
	add.s64 	%rd31, %rd1, %rd30;
	st.local.u32 	[%rd31], %r37;
	add.s32 	%r39, %r2, 2;
	mul.wide.u32 	%rd32, %r39, 4;
	add.s64 	%rd33, %rd6, %rd32;
	ld.global.u32 	%r40, [%rd33];
	add.s32 	%r41, %r54, 2;
	mul.wide.u32 	%rd34, %r41, 4;
	add.s64 	%rd35, %rd1, %rd34;
	st.local.u32 	[%rd35], %r40;
	add.s32 	%r42, %r2, 3;
	mul.wide.u32 	%rd36, %r42, 4;
	add.s64 	%rd37, %rd6, %rd36;
	ld.global.u32 	%r43, [%rd37];
	add.s32 	%r44, %r54, 3;
	mul.wide.u32 	%rd38, %r44, 4;
	add.s64 	%rd39, %rd1, %rd38;
	st.local.u32 	[%rd39], %r43;
	add.s32 	%r2, %r2, 4;
	add.s32 	%r54, %r54, 4;
	setp.lt.u32	%p7, %r54, %r3;
	@%p7 bra 	BB0_9;

BB0_10:
	st.local.u32 	[%rd1+256], %r4;
	mul.wide.s32 	%rd40, %r1, 260;
	add.s64 	%rd4, %rd7, %rd40;
	mov.u32 	%r55, 0;
	mov.pred 	%p8, 0;
	@%p8 bra 	BB0_12;

BB0_11:
	mul.wide.s32 	%rd41, %r55, 4;
	add.s64 	%rd42, %rd1, %rd41;
	ld.local.u32 	%r46, [%rd42];
	add.s64 	%rd43, %rd4, %rd41;
	st.global.u32 	[%rd43], %r46;
	add.s32 	%r55, %r55, 1;
	setp.lt.u32	%p9, %r55, 65;
	@%p9 bra 	BB0_11;

BB0_12:
	ret;
}

	// .globl	gpu_memset
.entry gpu_memset(
	.param .u64 .ptr .global .align 16 gpu_memset_param_0,
	.param .u32 gpu_memset_param_1,
	.param .u64 gpu_memset_param_2
)
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<8>;
	.reg .b64 	%rd<6>;


	ld.param.u64 	%rd1, [gpu_memset_param_0];
	ld.param.u32 	%r2, [gpu_memset_param_1];
	ld.param.u64 	%rd2, [gpu_memset_param_2];
	mov.b32	%r3, %envreg3;
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %ntid.x;
	mad.lo.s32 	%r6, %r4, %r5, %r3;
	mov.u32 	%r7, %tid.x;
	add.s32 	%r1, %r6, %r7;
	cvt.s64.s32	%rd3, %r1;
	setp.ge.u64	%p1, %rd3, %rd2;
	@%p1 bra 	BB1_2;

	mul.wide.s32 	%rd4, %r1, 16;
	add.s64 	%rd5, %rd1, %rd4;
	st.global.v4.u32 	[%rd5], {%r2, %r2, %r2, %r2};

BB1_2:
	ret;
}

	// .globl	gpu_atinit
.entry gpu_atinit(
	.param .u64 .ptr .global .align 4 gpu_atinit_param_0,
	.param .u64 gpu_atinit_param_1
)
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<13>;
	.reg .b64 	%rd<7>;


	ld.param.u64 	%rd2, [gpu_atinit_param_0];
	ld.param.u64 	%rd3, [gpu_atinit_param_1];
	mov.b32	%r2, %envreg3;
	mov.u32 	%r3, %ctaid.x;
	mov.u32 	%r4, %ntid.x;
	mad.lo.s32 	%r5, %r3, %r4, %r2;
	mov.u32 	%r6, %tid.x;
	add.s32 	%r1, %r5, %r6;
	cvt.s64.s32	%rd1, %r1;
	setp.ge.u64	%p1, %rd1, %rd3;
	@%p1 bra 	BB2_2;

	cvt.u32.u64	%r7, %rd1;
	shr.u64 	%rd4, %rd1, 32;
	cvt.u32.u64	%r8, %rd4;
	xor.b32  	%r9, %r7, 1549556828;
	xor.b32  	%r10, %r8, 909522486;
	mul.wide.s32 	%rd5, %r1, 260;
	add.s64 	%rd6, %rd2, %rd5;
	st.global.u32 	[%rd6], %r9;
	st.global.u32 	[%rd6+4], %r10;
	mov.u32 	%r11, 0;
	st.global.u32 	[%rd6+8], %r11;
	st.global.u32 	[%rd6+12], %r11;
	st.global.u32 	[%rd6+16], %r11;
	st.global.u32 	[%rd6+20], %r11;
	st.global.u32 	[%rd6+24], %r11;
	st.global.u32 	[%rd6+28], %r11;
	st.global.u32 	[%rd6+32], %r11;
	st.global.u32 	[%rd6+36], %r11;
	st.global.u32 	[%rd6+40], %r11;
	st.global.u32 	[%rd6+44], %r11;
	st.global.u32 	[%rd6+48], %r11;
	st.global.u32 	[%rd6+52], %r11;
	st.global.u32 	[%rd6+56], %r11;
	st.global.u32 	[%rd6+60], %r11;
	st.global.u32 	[%rd6+64], %r11;
	st.global.u32 	[%rd6+68], %r11;
	st.global.u32 	[%rd6+72], %r11;
	st.global.u32 	[%rd6+76], %r11;
	st.global.u32 	[%rd6+80], %r11;
	st.global.u32 	[%rd6+84], %r11;
	st.global.u32 	[%rd6+88], %r11;
	st.global.u32 	[%rd6+92], %r11;
	st.global.u32 	[%rd6+96], %r11;
	st.global.u32 	[%rd6+100], %r11;
	st.global.u32 	[%rd6+104], %r11;
	st.global.u32 	[%rd6+108], %r11;
	st.global.u32 	[%rd6+112], %r11;
	st.global.u32 	[%rd6+116], %r11;
	st.global.u32 	[%rd6+120], %r11;
	st.global.u32 	[%rd6+124], %r11;
	st.global.u32 	[%rd6+128], %r11;
	st.global.u32 	[%rd6+132], %r11;
	st.global.u32 	[%rd6+136], %r11;
	st.global.u32 	[%rd6+140], %r11;
	st.global.u32 	[%rd6+144], %r11;
	st.global.u32 	[%rd6+148], %r11;
	st.global.u32 	[%rd6+152], %r11;
	st.global.u32 	[%rd6+156], %r11;
	st.global.u32 	[%rd6+160], %r11;
	st.global.u32 	[%rd6+164], %r11;
	st.global.u32 	[%rd6+168], %r11;
	st.global.u32 	[%rd6+172], %r11;
	st.global.u32 	[%rd6+176], %r11;
	st.global.u32 	[%rd6+180], %r11;
	st.global.u32 	[%rd6+184], %r11;
	st.global.u32 	[%rd6+188], %r11;
	st.global.u32 	[%rd6+192], %r11;
	st.global.u32 	[%rd6+196], %r11;
	st.global.u32 	[%rd6+200], %r11;
	st.global.u32 	[%rd6+204], %r11;
	st.global.u32 	[%rd6+208], %r11;
	st.global.u32 	[%rd6+212], %r11;
	st.global.u32 	[%rd6+216], %r11;
	st.global.u32 	[%rd6+220], %r11;
	st.global.u32 	[%rd6+224], %r11;
	st.global.u32 	[%rd6+228], %r11;
	st.global.u32 	[%rd6+232], %r11;
	st.global.u32 	[%rd6+236], %r11;
	st.global.u32 	[%rd6+240], %r11;
	st.global.u32 	[%rd6+244], %r11;
	st.global.u32 	[%rd6+248], %r11;
	st.global.u32 	[%rd6+252], %r11;
	mov.u32 	%r12, 7;
	st.global.u32 	[%rd6+256], %r12;

BB2_2:
	ret;
}

	// .globl	m00900_m04
.entry m00900_m04(
	.param .u64 .ptr .global .align 4 m00900_m04_param_0,
	.param .u64 .ptr .global .align 4 m00900_m04_param_1,
	.param .u64 .ptr .global .align 4 m00900_m04_param_2,
	.param .u64 .ptr .global .align 4 m00900_m04_param_3,
	.param .u64 .ptr .global .align 1 m00900_m04_param_4,
	.param .u64 .ptr .global .align 1 m00900_m04_param_5,
	.param .u64 .ptr .global .align 4 m00900_m04_param_6,
	.param .u64 .ptr .global .align 4 m00900_m04_param_7,
	.param .u64 .ptr .global .align 4 m00900_m04_param_8,
	.param .u64 .ptr .global .align 4 m00900_m04_param_9,
	.param .u64 .ptr .global .align 4 m00900_m04_param_10,
	.param .u64 .ptr .global .align 4 m00900_m04_param_11,
	.param .u64 .ptr .global .align 4 m00900_m04_param_12,
	.param .u64 .ptr .global .align 4 m00900_m04_param_13,
	.param .u64 .ptr .global .align 8 m00900_m04_param_14,
	.param .u64 .ptr .global .align 4 m00900_m04_param_15,
	.param .u64 .ptr .global .align 4 m00900_m04_param_16,
	.param .u64 .ptr .global .align 4 m00900_m04_param_17,
	.param .u64 .ptr .global .align 1 m00900_m04_param_18,
	.param .u64 .ptr .global .align 4 m00900_m04_param_19,
	.param .u64 .ptr .global .align 4 m00900_m04_param_20,
	.param .u64 .ptr .global .align 4 m00900_m04_param_21,
	.param .u64 .ptr .global .align 4 m00900_m04_param_22,
	.param .u64 .ptr .global .align 4 m00900_m04_param_23,
	.param .u32 m00900_m04_param_24,
	.param .u32 m00900_m04_param_25,
	.param .u32 m00900_m04_param_26,
	.param .u32 m00900_m04_param_27,
	.param .u32 m00900_m04_param_28,
	.param .u32 m00900_m04_param_29,
	.param .u32 m00900_m04_param_30,
	.param .u32 m00900_m04_param_31,
	.param .u32 m00900_m04_param_32,
	.param .u32 m00900_m04_param_33,
	.param .u64 m00900_m04_param_34
)
{
	.reg .pred 	%p<74>;
	.reg .b32 	%r<1937>;
	.reg .b64 	%rd<59>;


	ld.param.u64 	%rd5, [m00900_m04_param_0];
	ld.param.u64 	%rd18, [m00900_m04_param_19];
	ld.param.u32 	%r268, [m00900_m04_param_24];
	ld.param.u32 	%r269, [m00900_m04_param_25];
	ld.param.u32 	%r270, [m00900_m04_param_26];
	ld.param.u32 	%r272, [m00900_m04_param_30];
	ld.param.u32 	%r273, [m00900_m04_param_31];
	ld.param.u32 	%r274, [m00900_m04_param_32];
	ld.param.u64 	%rd19, [m00900_m04_param_34];
	mov.b32	%r276, %envreg3;
	mov.u32 	%r277, %ctaid.x;
	mov.u32 	%r278, %ntid.x;
	mad.lo.s32 	%r279, %r277, %r278, %r276;
	mov.u32 	%r280, %tid.x;
	add.s32 	%r1, %r279, %r280;
	cvt.s64.s32	%rd1, %r1;
	setp.ge.u64	%p1, %rd1, %rd19;
	@%p1 bra 	BB3_120;

	mul.wide.s32 	%rd20, %r1, 260;
	add.s64 	%rd21, %rd5, %rd20;
	ld.global.u32 	%r2, [%rd21];
	ld.global.u32 	%r3, [%rd21+4];
	ld.global.u32 	%r4, [%rd21+8];
	ld.global.u32 	%r5, [%rd21+12];
	ld.global.u32 	%r6, [%rd21+16];
	ld.global.u32 	%r7, [%rd21+20];
	ld.global.u32 	%r8, [%rd21+24];
	ld.global.u32 	%r9, [%rd21+28];
	ld.global.u32 	%r10, [%rd21+256];
	setp.eq.s32	%p2, %r272, 0;
	@%p2 bra 	BB3_120;

	and.b32  	%r282, %r10, 3;
	mov.u32 	%r283, 4;
	sub.s32 	%r284, %r283, %r282;
	shr.u32 	%r11, %r10, 2;
	shl.b32 	%r285, %r284, 2;
	mov.u32 	%r286, 1985229328;
	shr.u32 	%r287, %r286, %r285;
	and.b32  	%r12, %r287, 65535;
	and.b32  	%r13, %r269, 31;
	and.b32  	%r14, %r270, 31;
	cvt.u64.u32	%rd2, %r274;
	and.b64  	%rd3, %rd1, 4294967295;
	mov.u32 	%r1904, 0;

BB3_3:
	ld.param.u32 	%r1890, [m00900_m04_param_33];
	ld.param.u64 	%rd54, [m00900_m04_param_2];
	mul.wide.u32 	%rd22, %r1904, 260;
	add.s64 	%rd23, %rd54, %rd22;
	ld.global.u32 	%r16, [%rd23+256];
	ld.global.u32 	%r1915, [%rd23];
	ld.global.u32 	%r1916, [%rd23+4];
	ld.global.u32 	%r1917, [%rd23+8];
	ld.global.u32 	%r1918, [%rd23+12];
	ld.global.u32 	%r1908, [%rd23+16];
	ld.global.u32 	%r1907, [%rd23+20];
	ld.global.u32 	%r1906, [%rd23+24];
	ld.global.u32 	%r1905, [%rd23+28];
	setp.eq.s32	%p3, %r1890, 10001;
	@%p3 bra 	BB3_46;
	bra.uni 	BB3_4;

BB3_46:
	mov.u32 	%r1909, 0;
	setp.gt.s32	%p27, %r11, 7;
	@%p27 bra 	BB3_63;

	setp.gt.s32	%p39, %r11, 3;
	@%p39 bra 	BB3_55;

	setp.gt.s32	%p45, %r11, 1;
	@%p45 bra 	BB3_52;

	setp.eq.s32	%p48, %r11, 0;
	@%p48 bra 	BB3_89;
	bra.uni 	BB3_50;

BB3_89:
	mov.u32 	%r1919, 0;
	// inline asm
	prmt.b32 %r1909, %r1919, %r1919, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1912, %r1905, %r1919, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1905, %r1906, %r1905, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1906, %r1907, %r1906, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1907, %r1908, %r1907, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1908, %r1918, %r1908, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1918, %r1917, %r1918, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1917, %r1916, %r1917, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1916, %r1915, %r1916, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1915, %r1919, %r1915, %r12;
	// inline asm
	mov.u32 	%r1910, %r1909;
	mov.u32 	%r1911, %r1909;
	mov.u32 	%r1913, %r1909;
	mov.u32 	%r1914, %r1909;
	bra.uni 	BB3_90;

BB3_4:
	mov.u32 	%r1892, 1985229328;
	mov.u32 	%r1891, 4;
	and.b32  	%r301, %r16, 3;
	sub.s32 	%r303, %r1891, %r301;
	shl.b32 	%r304, %r303, 2;
	shr.u32 	%r306, %r1892, %r304;
	and.b32  	%r25, %r306, 65535;
	shr.u32 	%r300, %r16, 2;
	mov.u32 	%r1909, 0;
	setp.gt.s32	%p4, %r300, 7;
	@%p4 bra 	BB3_20;

	setp.gt.s32	%p16, %r300, 3;
	@%p16 bra 	BB3_13;

	setp.gt.s32	%p22, %r300, 1;
	@%p22 bra 	BB3_10;

	setp.eq.s32	%p25, %r300, 0;
	@%p25 bra 	BB3_45;
	bra.uni 	BB3_8;

BB3_45:
	mov.u32 	%r1909, 0;
	// inline asm
	prmt.b32 %r1919, %r1909, %r1909, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1921, %r9, %r1909, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1928, %r8, %r9, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1927, %r7, %r8, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1926, %r6, %r7, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1925, %r5, %r6, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1932, %r4, %r5, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1931, %r3, %r4, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1930, %r2, %r3, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1929, %r1909, %r2, %r25;
	// inline asm
	mov.u32 	%r1910, %r1909;
	mov.u32 	%r1911, %r1909;
	mov.u32 	%r1912, %r1909;
	mov.u32 	%r1913, %r1909;
	mov.u32 	%r1914, %r1909;
	mov.u32 	%r1920, %r1919;
	mov.u32 	%r1922, %r1919;
	mov.u32 	%r1923, %r1919;
	mov.u32 	%r1924, %r1919;
	bra.uni 	BB3_92;

BB3_63:
	setp.gt.s32	%p28, %r11, 11;
	@%p28 bra 	BB3_71;

	setp.gt.s32	%p34, %r11, 9;
	@%p34 bra 	BB3_68;

	setp.eq.s32	%p37, %r11, 8;
	@%p37 bra 	BB3_85;
	bra.uni 	BB3_66;

BB3_85:
	// inline asm
	prmt.b32 %r1913, %r1908, %r1907, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1914, %r1918, %r1908, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1909, %r1917, %r1918, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1910, %r1916, %r1917, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1911, %r1915, %r1916, %r12;
	// inline asm
	mov.u32 	%r1905, 0;
	// inline asm
	prmt.b32 %r1912, %r1905, %r1915, %r12;
	// inline asm
	mov.u32 	%r1906, %r1905;
	mov.u32 	%r1907, %r1905;
	mov.u32 	%r1908, %r1905;
	bra.uni 	BB3_79;

BB3_20:
	setp.gt.s32	%p5, %r300, 11;
	@%p5 bra 	BB3_28;

	setp.gt.s32	%p11, %r300, 9;
	@%p11 bra 	BB3_25;

	setp.eq.s32	%p14, %r300, 8;
	@%p14 bra 	BB3_41;
	bra.uni 	BB3_23;

BB3_41:
	// inline asm
	prmt.b32 %r1920, %r6, %r7, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1919, %r5, %r6, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1924, %r4, %r5, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1923, %r3, %r4, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1922, %r2, %r3, %r25;
	// inline asm
	mov.u32 	%r1909, 0;
	// inline asm
	prmt.b32 %r1921, %r1909, %r2, %r25;
	// inline asm
	mov.u32 	%r1910, %r1909;
	mov.u32 	%r1911, %r1909;
	mov.u32 	%r1912, %r1909;
	mov.u32 	%r1913, %r1909;
	mov.u32 	%r1914, %r1909;
	bra.uni 	BB3_37;

BB3_55:
	setp.gt.s32	%p40, %r11, 5;
	@%p40 bra 	BB3_60;

	setp.eq.s32	%p43, %r11, 4;
	@%p43 bra 	BB3_87;
	bra.uni 	BB3_57;

BB3_87:
	mov.u32 	%r1919, 0;
	// inline asm
	prmt.b32 %r1913, %r1919, %r1919, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1914, %r1905, %r1919, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1909, %r1906, %r1905, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1910, %r1907, %r1906, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1911, %r1908, %r1907, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1912, %r1918, %r1908, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1905, %r1917, %r1918, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1906, %r1916, %r1917, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1907, %r1915, %r1916, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1908, %r1919, %r1915, %r12;
	// inline asm
	bra.uni 	BB3_59;

BB3_13:
	setp.gt.s32	%p17, %r300, 5;
	@%p17 bra 	BB3_17;

	setp.eq.s32	%p20, %r300, 4;
	@%p20 bra 	BB3_43;
	bra.uni 	BB3_15;

BB3_43:
	mov.u32 	%r1909, 0;
	// inline asm
	prmt.b32 %r1920, %r1909, %r1909, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1919, %r9, %r1909, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1924, %r8, %r9, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1923, %r7, %r8, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1922, %r6, %r7, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1921, %r5, %r6, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1928, %r4, %r5, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1927, %r3, %r4, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1926, %r2, %r3, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1925, %r1909, %r2, %r25;
	// inline asm
	mov.u32 	%r1910, %r1909;
	mov.u32 	%r1911, %r1909;
	mov.u32 	%r1912, %r1909;
	mov.u32 	%r1913, %r1909;
	mov.u32 	%r1914, %r1909;
	bra.uni 	BB3_38;

BB3_71:
	setp.gt.s32	%p29, %r11, 13;
	@%p29 bra 	BB3_75;

	setp.eq.s32	%p32, %r11, 12;
	@%p32 bra 	BB3_80;
	bra.uni 	BB3_73;

BB3_80:
	// inline asm
	prmt.b32 %r1913, %r1915, %r1916, %r12;
	// inline asm
	mov.u32 	%r1905, 0;
	// inline asm
	prmt.b32 %r1914, %r1905, %r1915, %r12;
	// inline asm
	mov.u32 	%r1906, %r1905;
	mov.u32 	%r1907, %r1905;
	mov.u32 	%r1908, %r1905;
	mov.u32 	%r1909, %r1905;
	bra.uni 	BB3_81;

BB3_28:
	setp.gt.s32	%p6, %r300, 13;
	@%p6 bra 	BB3_32;

	setp.eq.s32	%p9, %r300, 12;
	@%p9 bra 	BB3_39;
	bra.uni 	BB3_30;

BB3_39:
	// inline asm
	prmt.b32 %r1920, %r2, %r3, %r25;
	// inline asm
	mov.u32 	%r1909, 0;
	// inline asm
	prmt.b32 %r1919, %r1909, %r2, %r25;
	// inline asm
	mov.u32 	%r1910, %r1909;
	mov.u32 	%r1911, %r1909;
	mov.u32 	%r1912, %r1909;
	mov.u32 	%r1913, %r1909;
	mov.u32 	%r1914, %r1909;
	bra.uni 	BB3_36;

BB3_52:
	setp.eq.s32	%p46, %r11, 2;
	@%p46 bra 	BB3_88;
	bra.uni 	BB3_53;

BB3_88:
	mov.u32 	%r1919, 0;
	// inline asm
	prmt.b32 %r1909, %r1919, %r1919, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1910, %r1905, %r1919, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1911, %r1906, %r1905, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1912, %r1907, %r1906, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1905, %r1908, %r1907, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1906, %r1918, %r1908, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1907, %r1917, %r1918, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1908, %r1916, %r1917, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1918, %r1915, %r1916, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1917, %r1919, %r1915, %r12;
	// inline asm
	mov.u32 	%r1913, %r1909;
	mov.u32 	%r1914, %r1909;
	mov.u32 	%r1915, %r1919;
	mov.u32 	%r1916, %r1919;
	bra.uni 	BB3_90;

BB3_10:
	setp.eq.s32	%p23, %r300, 2;
	@%p23 bra 	BB3_44;
	bra.uni 	BB3_11;

BB3_44:
	mov.u32 	%r1909, 0;
	// inline asm
	prmt.b32 %r1919, %r1909, %r1909, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1923, %r9, %r1909, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1922, %r8, %r9, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1921, %r7, %r8, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1928, %r6, %r7, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1927, %r5, %r6, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1926, %r4, %r5, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1925, %r3, %r4, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1932, %r2, %r3, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1931, %r1909, %r2, %r25;
	// inline asm
	mov.u32 	%r1910, %r1909;
	mov.u32 	%r1911, %r1909;
	mov.u32 	%r1912, %r1909;
	mov.u32 	%r1913, %r1909;
	mov.u32 	%r1914, %r1909;
	mov.u32 	%r1920, %r1919;
	mov.u32 	%r1924, %r1919;
	mov.u32 	%r1929, %r1909;
	mov.u32 	%r1930, %r1909;
	bra.uni 	BB3_92;

BB3_68:
	setp.eq.s32	%p35, %r11, 10;
	@%p35 bra 	BB3_84;
	bra.uni 	BB3_69;

BB3_84:
	// inline asm
	prmt.b32 %r1913, %r1917, %r1918, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1914, %r1916, %r1917, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1909, %r1915, %r1916, %r12;
	// inline asm
	mov.u32 	%r1905, 0;
	// inline asm
	prmt.b32 %r1910, %r1905, %r1915, %r12;
	// inline asm
	mov.u32 	%r1906, %r1905;
	mov.u32 	%r1907, %r1905;
	mov.u32 	%r1908, %r1905;
	bra.uni 	BB3_82;

BB3_25:
	setp.eq.s32	%p12, %r300, 10;
	@%p12 bra 	BB3_40;
	bra.uni 	BB3_26;

BB3_40:
	// inline asm
	prmt.b32 %r1920, %r4, %r5, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1919, %r3, %r4, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1924, %r2, %r3, %r25;
	// inline asm
	mov.u32 	%r1909, 0;
	// inline asm
	prmt.b32 %r1923, %r1909, %r2, %r25;
	// inline asm
	mov.u32 	%r1910, %r1909;
	mov.u32 	%r1911, %r1909;
	mov.u32 	%r1912, %r1909;
	mov.u32 	%r1913, %r1909;
	mov.u32 	%r1914, %r1909;
	mov.u32 	%r1921, %r1909;
	mov.u32 	%r1922, %r1909;
	bra.uni 	BB3_37;

BB3_60:
	setp.eq.s32	%p41, %r11, 6;
	@%p41 bra 	BB3_86;
	bra.uni 	BB3_61;

BB3_86:
	// inline asm
	prmt.b32 %r1913, %r1906, %r1905, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1914, %r1907, %r1906, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1909, %r1908, %r1907, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1910, %r1918, %r1908, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1911, %r1917, %r1918, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1912, %r1916, %r1917, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1905, %r1915, %r1916, %r12;
	// inline asm
	mov.u32 	%r1907, 0;
	// inline asm
	prmt.b32 %r1906, %r1907, %r1915, %r12;
	// inline asm
	mov.u32 	%r1908, %r1907;
	mov.u32 	%r1915, %r1907;
	mov.u32 	%r1916, %r1907;
	mov.u32 	%r1917, %r1907;
	mov.u32 	%r1918, %r1907;
	mov.u32 	%r1919, %r1907;
	mov.u32 	%r1920, %r1907;
	mov.u32 	%r1921, %r1907;
	mov.u32 	%r1922, %r1907;
	mov.u32 	%r1923, %r1907;
	mov.u32 	%r1924, %r1907;
	bra.uni 	BB3_91;

BB3_17:
	setp.eq.s32	%p18, %r300, 6;
	@%p18 bra 	BB3_42;
	bra.uni 	BB3_18;

BB3_42:
	// inline asm
	prmt.b32 %r1920, %r8, %r9, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1919, %r7, %r8, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1924, %r6, %r7, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1923, %r5, %r6, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1922, %r4, %r5, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1921, %r3, %r4, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1928, %r2, %r3, %r25;
	// inline asm
	mov.u32 	%r1909, 0;
	// inline asm
	prmt.b32 %r1927, %r1909, %r2, %r25;
	// inline asm
	mov.u32 	%r1910, %r1909;
	mov.u32 	%r1911, %r1909;
	mov.u32 	%r1912, %r1909;
	mov.u32 	%r1913, %r1909;
	mov.u32 	%r1914, %r1909;
	mov.u32 	%r1925, %r1909;
	mov.u32 	%r1926, %r1909;
	bra.uni 	BB3_38;

BB3_75:
	setp.eq.s32	%p30, %r11, 14;
	@%p30 bra 	BB3_77;

	setp.ne.s32	%p31, %r11, 15;
	mov.u32 	%r1910, %r1909;
	mov.u32 	%r1911, %r1909;
	mov.u32 	%r1912, %r1909;
	mov.u32 	%r1913, %r1909;
	mov.u32 	%r1914, %r1909;
	mov.u32 	%r1919, %r1909;
	mov.u32 	%r1920, %r1909;
	mov.u32 	%r1921, %r1909;
	mov.u32 	%r1922, %r1909;
	mov.u32 	%r1923, %r1909;
	mov.u32 	%r1924, %r1909;
	mov.u32 	%r1925, %r6;
	mov.u32 	%r1926, %r7;
	mov.u32 	%r1927, %r8;
	mov.u32 	%r1928, %r9;
	mov.u32 	%r1929, %r2;
	mov.u32 	%r1930, %r3;
	mov.u32 	%r1931, %r4;
	mov.u32 	%r1932, %r5;
	@%p31 bra 	BB3_92;

BB3_77:
	mov.u32 	%r1905, 0;
	mov.u32 	%r1906, %r1905;
	mov.u32 	%r1907, %r1905;
	mov.u32 	%r1908, %r1905;
	mov.u32 	%r1909, %r1905;
	mov.u32 	%r1910, %r1905;
	mov.u32 	%r1911, %r1905;
	mov.u32 	%r1912, %r1905;
	mov.u32 	%r1913, %r1905;
	bra.uni 	BB3_78;

BB3_32:
	setp.eq.s32	%p7, %r300, 14;
	@%p7 bra 	BB3_35;

	setp.ne.s32	%p8, %r300, 15;
	@%p8 bra 	BB3_34;

BB3_35:
	mov.u32 	%r1909, 0;
	mov.u32 	%r1910, %r1909;
	mov.u32 	%r1911, %r1909;
	mov.u32 	%r1912, %r1909;
	mov.u32 	%r1913, %r1909;
	mov.u32 	%r1914, %r1909;
	mov.u32 	%r1919, %r1909;
	mov.u32 	%r1920, %r1909;
	bra.uni 	BB3_36;

BB3_50:
	setp.eq.s32	%p49, %r11, 1;
	@%p49 bra 	BB3_51;
	bra.uni 	BB3_34;

BB3_51:
	mov.u32 	%r1919, 0;
	// inline asm
	prmt.b32 %r1909, %r1919, %r1919, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1911, %r1905, %r1919, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1912, %r1906, %r1905, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1905, %r1907, %r1906, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1906, %r1908, %r1907, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1907, %r1918, %r1908, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1908, %r1917, %r1918, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1918, %r1916, %r1917, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1917, %r1915, %r1916, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1916, %r1919, %r1915, %r12;
	// inline asm
	mov.u32 	%r1910, %r1909;
	mov.u32 	%r1913, %r1909;
	mov.u32 	%r1914, %r1909;
	mov.u32 	%r1915, %r1919;
	bra.uni 	BB3_90;

BB3_8:
	setp.eq.s32	%p26, %r300, 1;
	@%p26 bra 	BB3_9;
	bra.uni 	BB3_34;

BB3_9:
	mov.u32 	%r1909, 0;
	// inline asm
	prmt.b32 %r1919, %r1909, %r1909, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1922, %r9, %r1909, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1921, %r8, %r9, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1928, %r7, %r8, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1927, %r6, %r7, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1926, %r5, %r6, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1925, %r4, %r5, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1932, %r3, %r4, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1931, %r2, %r3, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1930, %r1909, %r2, %r25;
	// inline asm
	mov.u32 	%r1910, %r1909;
	mov.u32 	%r1911, %r1909;
	mov.u32 	%r1912, %r1909;
	mov.u32 	%r1913, %r1909;
	mov.u32 	%r1914, %r1909;
	mov.u32 	%r1920, %r1919;
	mov.u32 	%r1923, %r1919;
	mov.u32 	%r1924, %r1919;
	mov.u32 	%r1929, %r1909;
	bra.uni 	BB3_92;

BB3_66:
	setp.eq.s32	%p38, %r11, 9;
	@%p38 bra 	BB3_67;
	bra.uni 	BB3_34;

BB3_67:
	// inline asm
	prmt.b32 %r1913, %r1918, %r1908, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1914, %r1917, %r1918, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1909, %r1916, %r1917, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1910, %r1915, %r1916, %r12;
	// inline asm
	mov.u32 	%r1905, 0;
	// inline asm
	prmt.b32 %r1911, %r1905, %r1915, %r12;
	// inline asm
	mov.u32 	%r1906, %r1905;
	mov.u32 	%r1907, %r1905;
	mov.u32 	%r1908, %r1905;
	bra.uni 	BB3_83;

BB3_23:
	setp.eq.s32	%p15, %r300, 9;
	@%p15 bra 	BB3_24;
	bra.uni 	BB3_34;

BB3_24:
	// inline asm
	prmt.b32 %r1920, %r5, %r6, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1919, %r4, %r5, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1924, %r3, %r4, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1923, %r2, %r3, %r25;
	// inline asm
	mov.u32 	%r1909, 0;
	// inline asm
	prmt.b32 %r1922, %r1909, %r2, %r25;
	// inline asm
	mov.u32 	%r1910, %r1909;
	mov.u32 	%r1911, %r1909;
	mov.u32 	%r1912, %r1909;
	mov.u32 	%r1913, %r1909;
	mov.u32 	%r1914, %r1909;
	mov.u32 	%r1921, %r1909;
	bra.uni 	BB3_37;

BB3_57:
	setp.eq.s32	%p44, %r11, 5;
	@%p44 bra 	BB3_58;
	bra.uni 	BB3_34;

BB3_58:
	mov.u32 	%r1919, 0;
	// inline asm
	prmt.b32 %r1913, %r1905, %r1919, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1914, %r1906, %r1905, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1909, %r1907, %r1906, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1910, %r1908, %r1907, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1911, %r1918, %r1908, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1912, %r1917, %r1918, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1905, %r1916, %r1917, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1906, %r1915, %r1916, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1907, %r1919, %r1915, %r12;
	// inline asm
	mov.u32 	%r1908, %r1919;

BB3_59:
	mov.u32 	%r1915, %r1919;
	mov.u32 	%r1916, %r1919;
	mov.u32 	%r1917, %r1919;
	mov.u32 	%r1918, %r1919;
	bra.uni 	BB3_90;

BB3_15:
	setp.eq.s32	%p21, %r300, 5;
	@%p21 bra 	BB3_16;
	bra.uni 	BB3_34;

BB3_16:
	mov.u32 	%r1909, 0;
	// inline asm
	prmt.b32 %r1920, %r9, %r1909, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1919, %r8, %r9, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1924, %r7, %r8, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1923, %r6, %r7, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1922, %r5, %r6, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1921, %r4, %r5, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1928, %r3, %r4, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1927, %r2, %r3, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1926, %r1909, %r2, %r25;
	// inline asm
	mov.u32 	%r1910, %r1909;
	mov.u32 	%r1911, %r1909;
	mov.u32 	%r1912, %r1909;
	mov.u32 	%r1913, %r1909;
	mov.u32 	%r1914, %r1909;
	mov.u32 	%r1925, %r1909;
	bra.uni 	BB3_38;

BB3_73:
	setp.eq.s32	%p33, %r11, 13;
	@%p33 bra 	BB3_74;
	bra.uni 	BB3_34;

BB3_74:
	mov.u32 	%r1905, 0;
	// inline asm
	prmt.b32 %r1913, %r1905, %r1915, %r12;
	// inline asm
	mov.u32 	%r1906, %r1905;
	mov.u32 	%r1907, %r1905;
	mov.u32 	%r1908, %r1905;
	mov.u32 	%r1909, %r1905;
	mov.u32 	%r1910, %r1905;
	mov.u32 	%r1911, %r1905;
	mov.u32 	%r1912, %r1905;

BB3_78:
	mov.u32 	%r1914, %r1905;
	bra.uni 	BB3_79;

BB3_30:
	setp.eq.s32	%p10, %r300, 13;
	@%p10 bra 	BB3_31;
	bra.uni 	BB3_34;

BB3_31:
	mov.u32 	%r1909, 0;
	// inline asm
	prmt.b32 %r1920, %r1909, %r2, %r25;
	// inline asm
	mov.u32 	%r1910, %r1909;
	mov.u32 	%r1911, %r1909;
	mov.u32 	%r1912, %r1909;
	mov.u32 	%r1913, %r1909;
	mov.u32 	%r1914, %r1909;
	mov.u32 	%r1919, %r1909;

BB3_36:
	mov.u32 	%r1921, %r1909;
	mov.u32 	%r1922, %r1909;
	mov.u32 	%r1923, %r1909;
	mov.u32 	%r1924, %r1909;

BB3_37:
	mov.u32 	%r1925, %r1909;
	mov.u32 	%r1926, %r1909;
	mov.u32 	%r1927, %r1909;
	mov.u32 	%r1928, %r1909;

BB3_38:
	mov.u32 	%r1929, %r1909;
	mov.u32 	%r1930, %r1909;
	mov.u32 	%r1931, %r1909;
	mov.u32 	%r1932, %r1909;
	bra.uni 	BB3_92;

BB3_53:
	setp.eq.s32	%p47, %r11, 3;
	@%p47 bra 	BB3_54;
	bra.uni 	BB3_34;

BB3_54:
	mov.u32 	%r1919, 0;
	// inline asm
	prmt.b32 %r1913, %r1919, %r1919, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1909, %r1905, %r1919, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1910, %r1906, %r1905, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1911, %r1907, %r1906, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1912, %r1908, %r1907, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1905, %r1918, %r1908, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1906, %r1917, %r1918, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1907, %r1916, %r1917, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1908, %r1915, %r1916, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1918, %r1919, %r1915, %r12;
	// inline asm
	mov.u32 	%r1914, %r1913;
	mov.u32 	%r1915, %r1919;
	mov.u32 	%r1916, %r1919;
	mov.u32 	%r1917, %r1919;

BB3_90:
	mov.u32 	%r1920, %r1919;
	mov.u32 	%r1921, %r1919;
	mov.u32 	%r1922, %r1919;
	mov.u32 	%r1923, %r1919;
	mov.u32 	%r1924, %r1919;
	bra.uni 	BB3_91;

BB3_11:
	setp.eq.s32	%p24, %r300, 3;
	@%p24 bra 	BB3_12;
	bra.uni 	BB3_34;

BB3_12:
	mov.u32 	%r1909, 0;
	// inline asm
	prmt.b32 %r1919, %r1909, %r1909, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1924, %r9, %r1909, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1923, %r8, %r9, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1922, %r7, %r8, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1921, %r6, %r7, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1928, %r5, %r6, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1927, %r4, %r5, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1926, %r3, %r4, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1925, %r2, %r3, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1932, %r1909, %r2, %r25;
	// inline asm
	mov.u32 	%r1910, %r1909;
	mov.u32 	%r1911, %r1909;
	mov.u32 	%r1912, %r1909;
	mov.u32 	%r1913, %r1909;
	mov.u32 	%r1914, %r1909;
	mov.u32 	%r1920, %r1919;
	mov.u32 	%r1929, %r1909;
	mov.u32 	%r1930, %r1909;
	mov.u32 	%r1931, %r1909;
	bra.uni 	BB3_92;

BB3_69:
	setp.eq.s32	%p36, %r11, 11;
	@%p36 bra 	BB3_70;
	bra.uni 	BB3_34;

BB3_70:
	// inline asm
	prmt.b32 %r1913, %r1916, %r1917, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1914, %r1915, %r1916, %r12;
	// inline asm
	mov.u32 	%r1905, 0;
	// inline asm
	prmt.b32 %r1909, %r1905, %r1915, %r12;
	// inline asm
	mov.u32 	%r1906, %r1905;
	mov.u32 	%r1907, %r1905;
	mov.u32 	%r1908, %r1905;

BB3_81:
	mov.u32 	%r1910, %r1905;

BB3_82:
	mov.u32 	%r1911, %r1905;

BB3_83:
	mov.u32 	%r1912, %r1905;

BB3_79:
	mov.u32 	%r1915, %r1905;
	mov.u32 	%r1916, %r1905;
	mov.u32 	%r1917, %r1905;
	mov.u32 	%r1918, %r1905;
	mov.u32 	%r1919, %r1905;
	mov.u32 	%r1920, %r1905;
	mov.u32 	%r1921, %r1905;
	mov.u32 	%r1922, %r1905;
	mov.u32 	%r1923, %r1905;
	mov.u32 	%r1924, %r1905;
	bra.uni 	BB3_91;

BB3_26:
	setp.eq.s32	%p13, %r300, 11;
	@%p13 bra 	BB3_27;
	bra.uni 	BB3_34;

BB3_27:
	// inline asm
	prmt.b32 %r1920, %r3, %r4, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1919, %r2, %r3, %r25;
	// inline asm
	mov.u32 	%r1909, 0;
	// inline asm
	prmt.b32 %r1924, %r1909, %r2, %r25;
	// inline asm
	mov.u32 	%r1910, %r1909;
	mov.u32 	%r1911, %r1909;
	mov.u32 	%r1912, %r1909;
	mov.u32 	%r1913, %r1909;
	mov.u32 	%r1914, %r1909;
	mov.u32 	%r1921, %r1909;
	mov.u32 	%r1922, %r1909;
	mov.u32 	%r1923, %r1909;
	bra.uni 	BB3_37;

BB3_61:
	setp.eq.s32	%p42, %r11, 7;
	@%p42 bra 	BB3_62;
	bra.uni 	BB3_34;

BB3_62:
	// inline asm
	prmt.b32 %r1913, %r1907, %r1906, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1914, %r1908, %r1907, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1909, %r1918, %r1908, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1910, %r1917, %r1918, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1911, %r1916, %r1917, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1912, %r1915, %r1916, %r12;
	// inline asm
	mov.u32 	%r1906, 0;
	// inline asm
	prmt.b32 %r1905, %r1906, %r1915, %r12;
	// inline asm
	mov.u32 	%r1907, %r1906;
	mov.u32 	%r1908, %r1906;
	mov.u32 	%r1915, %r1906;
	mov.u32 	%r1916, %r1906;
	mov.u32 	%r1917, %r1906;
	mov.u32 	%r1918, %r1906;
	mov.u32 	%r1919, %r1906;
	mov.u32 	%r1920, %r1906;
	mov.u32 	%r1921, %r1906;
	mov.u32 	%r1922, %r1906;
	mov.u32 	%r1923, %r1906;
	mov.u32 	%r1924, %r1906;
	bra.uni 	BB3_91;

BB3_18:
	setp.eq.s32	%p19, %r300, 7;
	@%p19 bra 	BB3_19;
	bra.uni 	BB3_34;

BB3_19:
	// inline asm
	prmt.b32 %r1920, %r7, %r8, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1919, %r6, %r7, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1924, %r5, %r6, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1923, %r4, %r5, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1922, %r3, %r4, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1921, %r2, %r3, %r25;
	// inline asm
	mov.u32 	%r1909, 0;
	// inline asm
	prmt.b32 %r1928, %r1909, %r2, %r25;
	// inline asm
	mov.u32 	%r1910, %r1909;
	mov.u32 	%r1911, %r1909;
	mov.u32 	%r1912, %r1909;
	mov.u32 	%r1913, %r1909;
	mov.u32 	%r1914, %r1909;
	mov.u32 	%r1925, %r1909;
	mov.u32 	%r1926, %r1909;
	mov.u32 	%r1927, %r1909;
	bra.uni 	BB3_38;

BB3_34:
	mov.u32 	%r1910, %r1909;
	mov.u32 	%r1911, %r1909;
	mov.u32 	%r1912, %r1909;
	mov.u32 	%r1913, %r1909;
	mov.u32 	%r1914, %r1909;
	mov.u32 	%r1919, %r1909;
	mov.u32 	%r1920, %r1909;
	mov.u32 	%r1921, %r1909;
	mov.u32 	%r1922, %r1909;
	mov.u32 	%r1923, %r1909;
	mov.u32 	%r1924, %r1909;

BB3_91:
	mov.u32 	%r1925, %r6;
	mov.u32 	%r1926, %r7;
	mov.u32 	%r1927, %r8;
	mov.u32 	%r1928, %r9;
	mov.u32 	%r1929, %r2;
	mov.u32 	%r1930, %r3;
	mov.u32 	%r1931, %r4;
	mov.u32 	%r1932, %r5;

BB3_92:
	ld.param.u64 	%rd55, [m00900_m04_param_6];
	or.b32  	%r1509, %r1929, %r1915;
	add.s32 	%r1510, %r1509, -1;
	shf.l.wrap.b32 	%r1511, %r1510, %r1510, 3;
	and.b32  	%r1512, %r1511, 2004318071;
	xor.b32  	%r1513, %r1512, -1732584194;
	or.b32  	%r1514, %r1930, %r1916;
	add.s32 	%r1515, %r1514, %r1513;
	add.s32 	%r1516, %r1515, 271733878;
	shf.l.wrap.b32 	%r1517, %r1516, %r1516, 7;
	xor.b32  	%r1518, %r1511, -271733879;
	and.b32  	%r1519, %r1518, %r1517;
	xor.b32  	%r1520, %r1519, -271733879;
	or.b32  	%r1521, %r1931, %r1917;
	add.s32 	%r1522, %r1521, %r1520;
	add.s32 	%r1523, %r1522, -1732584194;
	shf.l.wrap.b32 	%r1524, %r1523, %r1523, 11;
	xor.b32  	%r1525, %r1517, %r1511;
	and.b32  	%r1526, %r1525, %r1524;
	xor.b32  	%r1527, %r1526, %r1511;
	or.b32  	%r1528, %r1932, %r1918;
	add.s32 	%r1529, %r1528, %r1527;
	add.s32 	%r1530, %r1529, -271733879;
	shf.l.wrap.b32 	%r1531, %r1530, %r1530, 19;
	xor.b32  	%r1532, %r1524, %r1517;
	and.b32  	%r1533, %r1532, %r1531;
	xor.b32  	%r1534, %r1533, %r1517;
	or.b32  	%r1535, %r1925, %r1908;
	add.s32 	%r1536, %r1511, %r1535;
	add.s32 	%r1537, %r1536, %r1534;
	shf.l.wrap.b32 	%r1538, %r1537, %r1537, 3;
	xor.b32  	%r1539, %r1531, %r1524;
	and.b32  	%r1540, %r1539, %r1538;
	xor.b32  	%r1541, %r1540, %r1524;
	or.b32  	%r1542, %r1926, %r1907;
	add.s32 	%r1543, %r1517, %r1542;
	add.s32 	%r1544, %r1543, %r1541;
	shf.l.wrap.b32 	%r1545, %r1544, %r1544, 7;
	xor.b32  	%r1546, %r1538, %r1531;
	and.b32  	%r1547, %r1546, %r1545;
	xor.b32  	%r1548, %r1547, %r1531;
	or.b32  	%r1549, %r1927, %r1906;
	add.s32 	%r1550, %r1524, %r1549;
	add.s32 	%r1551, %r1550, %r1548;
	shf.l.wrap.b32 	%r1552, %r1551, %r1551, 11;
	xor.b32  	%r1553, %r1545, %r1538;
	and.b32  	%r1554, %r1553, %r1552;
	xor.b32  	%r1555, %r1554, %r1538;
	or.b32  	%r1556, %r1928, %r1905;
	add.s32 	%r1557, %r1531, %r1556;
	add.s32 	%r1558, %r1557, %r1555;
	shf.l.wrap.b32 	%r1559, %r1558, %r1558, 19;
	xor.b32  	%r1560, %r1552, %r1545;
	and.b32  	%r1561, %r1560, %r1559;
	xor.b32  	%r1562, %r1561, %r1545;
	or.b32  	%r1563, %r1921, %r1912;
	add.s32 	%r1564, %r1538, %r1563;
	add.s32 	%r1565, %r1564, %r1562;
	shf.l.wrap.b32 	%r1566, %r1565, %r1565, 3;
	xor.b32  	%r1567, %r1559, %r1552;
	and.b32  	%r1568, %r1567, %r1566;
	xor.b32  	%r1569, %r1568, %r1552;
	or.b32  	%r1570, %r1922, %r1911;
	add.s32 	%r1571, %r1545, %r1570;
	add.s32 	%r1572, %r1571, %r1569;
	shf.l.wrap.b32 	%r1573, %r1572, %r1572, 7;
	xor.b32  	%r1574, %r1566, %r1559;
	and.b32  	%r1575, %r1574, %r1573;
	xor.b32  	%r1576, %r1575, %r1559;
	or.b32  	%r1577, %r1923, %r1910;
	add.s32 	%r1578, %r1552, %r1577;
	add.s32 	%r1579, %r1578, %r1576;
	shf.l.wrap.b32 	%r1580, %r1579, %r1579, 11;
	xor.b32  	%r1581, %r1573, %r1566;
	and.b32  	%r1582, %r1581, %r1580;
	xor.b32  	%r1583, %r1582, %r1566;
	or.b32  	%r1584, %r1924, %r1909;
	add.s32 	%r1585, %r1559, %r1584;
	add.s32 	%r1586, %r1585, %r1583;
	shf.l.wrap.b32 	%r1587, %r1586, %r1586, 19;
	xor.b32  	%r1588, %r1580, %r1573;
	and.b32  	%r1589, %r1588, %r1587;
	xor.b32  	%r1590, %r1589, %r1573;
	or.b32  	%r1591, %r1919, %r1914;
	add.s32 	%r1592, %r1566, %r1591;
	add.s32 	%r1593, %r1592, %r1590;
	shf.l.wrap.b32 	%r1594, %r1593, %r1593, 3;
	xor.b32  	%r1595, %r1587, %r1580;
	and.b32  	%r1596, %r1595, %r1594;
	xor.b32  	%r1597, %r1596, %r1580;
	or.b32  	%r1598, %r1920, %r1913;
	add.s32 	%r1599, %r1573, %r1598;
	add.s32 	%r1600, %r1599, %r1597;
	shf.l.wrap.b32 	%r1601, %r1600, %r1600, 7;
	xor.b32  	%r1602, %r1594, %r1587;
	and.b32  	%r1603, %r1602, %r1601;
	xor.b32  	%r1604, %r1603, %r1587;
	add.s32 	%r1605, %r16, %r10;
	shl.b32 	%r1606, %r1605, 3;
	add.s32 	%r1607, %r1580, %r1606;
	add.s32 	%r1608, %r1607, %r1604;
	shf.l.wrap.b32 	%r1609, %r1608, %r1608, 11;
	xor.b32  	%r1610, %r1601, %r1594;
	and.b32  	%r1611, %r1610, %r1609;
	xor.b32  	%r1612, %r1611, %r1594;
	add.s32 	%r1613, %r1612, %r1587;
	shf.l.wrap.b32 	%r1614, %r1613, %r1613, 19;
	xor.b32  	%r1615, %r1614, %r1601;
	xor.b32  	%r1616, %r1614, %r1609;
	and.b32  	%r1617, %r1616, %r1615;
	xor.b32  	%r1618, %r1617, %r1614;
	add.s32 	%r1619, %r1509, %r1594;
	add.s32 	%r1620, %r1619, %r1618;
	add.s32 	%r1621, %r1620, 1518500249;
	shf.l.wrap.b32 	%r1622, %r1621, %r1621, 3;
	xor.b32  	%r1623, %r1622, %r1609;
	xor.b32  	%r1624, %r1622, %r1614;
	and.b32  	%r1625, %r1624, %r1623;
	xor.b32  	%r1626, %r1625, %r1622;
	add.s32 	%r1627, %r1535, %r1601;
	add.s32 	%r1628, %r1627, %r1626;
	add.s32 	%r1629, %r1628, 1518500249;
	shf.l.wrap.b32 	%r1630, %r1629, %r1629, 5;
	xor.b32  	%r1631, %r1630, %r1614;
	xor.b32  	%r1632, %r1630, %r1622;
	and.b32  	%r1633, %r1632, %r1631;
	xor.b32  	%r1634, %r1633, %r1630;
	add.s32 	%r1635, %r1563, %r1609;
	add.s32 	%r1636, %r1635, %r1634;
	add.s32 	%r1637, %r1636, 1518500249;
	shf.l.wrap.b32 	%r1638, %r1637, %r1637, 9;
	xor.b32  	%r1639, %r1638, %r1622;
	xor.b32  	%r1640, %r1638, %r1630;
	and.b32  	%r1641, %r1640, %r1639;
	xor.b32  	%r1642, %r1641, %r1638;
	add.s32 	%r1643, %r1591, %r1614;
	add.s32 	%r1644, %r1643, %r1642;
	add.s32 	%r1645, %r1644, 1518500249;
	shf.l.wrap.b32 	%r1646, %r1645, %r1645, 13;
	xor.b32  	%r1647, %r1646, %r1630;
	xor.b32  	%r1648, %r1646, %r1638;
	and.b32  	%r1649, %r1648, %r1647;
	xor.b32  	%r1650, %r1649, %r1646;
	add.s32 	%r1651, %r1514, %r1622;
	add.s32 	%r1652, %r1651, %r1650;
	add.s32 	%r1653, %r1652, 1518500249;
	shf.l.wrap.b32 	%r1654, %r1653, %r1653, 3;
	xor.b32  	%r1655, %r1654, %r1638;
	xor.b32  	%r1656, %r1654, %r1646;
	and.b32  	%r1657, %r1656, %r1655;
	xor.b32  	%r1658, %r1657, %r1654;
	add.s32 	%r1659, %r1542, %r1630;
	add.s32 	%r1660, %r1659, %r1658;
	add.s32 	%r1661, %r1660, 1518500249;
	shf.l.wrap.b32 	%r1662, %r1661, %r1661, 5;
	xor.b32  	%r1663, %r1662, %r1646;
	xor.b32  	%r1664, %r1662, %r1654;
	and.b32  	%r1665, %r1664, %r1663;
	xor.b32  	%r1666, %r1665, %r1662;
	add.s32 	%r1667, %r1570, %r1638;
	add.s32 	%r1668, %r1667, %r1666;
	add.s32 	%r1669, %r1668, 1518500249;
	shf.l.wrap.b32 	%r1670, %r1669, %r1669, 9;
	xor.b32  	%r1671, %r1670, %r1654;
	xor.b32  	%r1672, %r1670, %r1662;
	and.b32  	%r1673, %r1672, %r1671;
	xor.b32  	%r1674, %r1673, %r1670;
	add.s32 	%r1675, %r1598, %r1646;
	add.s32 	%r1676, %r1675, %r1674;
	add.s32 	%r1677, %r1676, 1518500249;
	shf.l.wrap.b32 	%r1678, %r1677, %r1677, 13;
	xor.b32  	%r1679, %r1678, %r1662;
	xor.b32  	%r1680, %r1678, %r1670;
	and.b32  	%r1681, %r1680, %r1679;
	xor.b32  	%r1682, %r1681, %r1678;
	add.s32 	%r1683, %r1521, %r1654;
	add.s32 	%r1684, %r1683, %r1682;
	add.s32 	%r1685, %r1684, 1518500249;
	shf.l.wrap.b32 	%r1686, %r1685, %r1685, 3;
	xor.b32  	%r1687, %r1686, %r1670;
	xor.b32  	%r1688, %r1686, %r1678;
	and.b32  	%r1689, %r1688, %r1687;
	xor.b32  	%r1690, %r1689, %r1686;
	add.s32 	%r1691, %r1549, %r1662;
	add.s32 	%r1692, %r1691, %r1690;
	add.s32 	%r1693, %r1692, 1518500249;
	shf.l.wrap.b32 	%r1694, %r1693, %r1693, 5;
	xor.b32  	%r1695, %r1694, %r1678;
	xor.b32  	%r1696, %r1694, %r1686;
	and.b32  	%r1697, %r1696, %r1695;
	xor.b32  	%r1698, %r1697, %r1694;
	add.s32 	%r1699, %r1577, %r1670;
	add.s32 	%r1700, %r1699, %r1698;
	add.s32 	%r1701, %r1700, 1518500249;
	shf.l.wrap.b32 	%r1702, %r1701, %r1701, 9;
	xor.b32  	%r1703, %r1702, %r1686;
	xor.b32  	%r1704, %r1702, %r1694;
	and.b32  	%r1705, %r1704, %r1703;
	xor.b32  	%r1706, %r1705, %r1702;
	add.s32 	%r1707, %r1606, %r1678;
	add.s32 	%r1708, %r1707, %r1706;
	add.s32 	%r1709, %r1708, 1518500249;
	shf.l.wrap.b32 	%r1710, %r1709, %r1709, 13;
	xor.b32  	%r1711, %r1710, %r1694;
	xor.b32  	%r1712, %r1710, %r1702;
	and.b32  	%r1713, %r1712, %r1711;
	xor.b32  	%r1714, %r1713, %r1710;
	add.s32 	%r1715, %r1528, %r1686;
	add.s32 	%r1716, %r1715, %r1714;
	add.s32 	%r1717, %r1716, 1518500249;
	shf.l.wrap.b32 	%r1718, %r1717, %r1717, 3;
	xor.b32  	%r1719, %r1718, %r1702;
	xor.b32  	%r1720, %r1718, %r1710;
	and.b32  	%r1721, %r1720, %r1719;
	xor.b32  	%r1722, %r1721, %r1718;
	add.s32 	%r1723, %r1556, %r1694;
	add.s32 	%r1724, %r1723, %r1722;
	add.s32 	%r1725, %r1724, 1518500249;
	shf.l.wrap.b32 	%r1726, %r1725, %r1725, 5;
	xor.b32  	%r1727, %r1726, %r1710;
	xor.b32  	%r1728, %r1726, %r1718;
	and.b32  	%r1729, %r1728, %r1727;
	xor.b32  	%r1730, %r1729, %r1726;
	add.s32 	%r1731, %r1584, %r1702;
	add.s32 	%r1732, %r1731, %r1730;
	add.s32 	%r1733, %r1732, 1518500249;
	shf.l.wrap.b32 	%r1734, %r1733, %r1733, 9;
	xor.b32  	%r1735, %r1734, %r1718;
	xor.b32  	%r1736, %r1734, %r1726;
	and.b32  	%r1737, %r1736, %r1735;
	xor.b32  	%r1738, %r1737, %r1734;
	add.s32 	%r1739, %r1710, %r1738;
	add.s32 	%r1740, %r1739, 1518500249;
	shf.l.wrap.b32 	%r1741, %r1740, %r1740, 13;
	xor.b32  	%r1742, %r1736, %r1741;
	add.s32 	%r1743, %r1509, %r1718;
	add.s32 	%r1744, %r1743, %r1742;
	add.s32 	%r1745, %r1744, 1859775393;
	shf.l.wrap.b32 	%r1746, %r1745, %r1745, 3;
	xor.b32  	%r1747, %r1741, %r1734;
	xor.b32  	%r1748, %r1747, %r1746;
	add.s32 	%r1749, %r1563, %r1726;
	add.s32 	%r1750, %r1749, %r1748;
	add.s32 	%r1751, %r1750, 1859775393;
	shf.l.wrap.b32 	%r1752, %r1751, %r1751, 9;
	xor.b32  	%r1753, %r1746, %r1741;
	xor.b32  	%r1754, %r1753, %r1752;
	add.s32 	%r1755, %r1535, %r1734;
	add.s32 	%r1756, %r1755, %r1754;
	add.s32 	%r1757, %r1756, 1859775393;
	shf.l.wrap.b32 	%r1758, %r1757, %r1757, 11;
	xor.b32  	%r1759, %r1752, %r1746;
	xor.b32  	%r1760, %r1759, %r1758;
	add.s32 	%r1761, %r1591, %r1741;
	add.s32 	%r1762, %r1761, %r1760;
	add.s32 	%r1763, %r1762, 1859775393;
	shf.l.wrap.b32 	%r1764, %r1763, %r1763, 15;
	xor.b32  	%r1765, %r1758, %r1752;
	xor.b32  	%r1766, %r1765, %r1764;
	add.s32 	%r1767, %r1521, %r1746;
	add.s32 	%r1768, %r1767, %r1766;
	add.s32 	%r1769, %r1768, 1859775393;
	shf.l.wrap.b32 	%r1770, %r1769, %r1769, 3;
	xor.b32  	%r1771, %r1764, %r1758;
	xor.b32  	%r1772, %r1771, %r1770;
	add.s32 	%r1773, %r1577, %r1752;
	add.s32 	%r1774, %r1773, %r1772;
	add.s32 	%r1775, %r1774, 1859775393;
	shf.l.wrap.b32 	%r1776, %r1775, %r1775, 9;
	xor.b32  	%r1777, %r1770, %r1764;
	xor.b32  	%r1778, %r1777, %r1776;
	add.s32 	%r1779, %r1549, %r1758;
	add.s32 	%r1780, %r1779, %r1778;
	add.s32 	%r1781, %r1780, 1859775393;
	shf.l.wrap.b32 	%r1782, %r1781, %r1781, 11;
	xor.b32  	%r1783, %r1776, %r1770;
	xor.b32  	%r1784, %r1783, %r1782;
	add.s32 	%r1785, %r1606, %r1764;
	add.s32 	%r1786, %r1785, %r1784;
	add.s32 	%r1787, %r1786, 1859775393;
	shf.l.wrap.b32 	%r1788, %r1787, %r1787, 15;
	xor.b32  	%r1789, %r1782, %r1776;
	xor.b32  	%r1790, %r1789, %r1788;
	add.s32 	%r1791, %r1514, %r1770;
	add.s32 	%r1792, %r1791, %r1790;
	add.s32 	%r1793, %r1792, 1859775393;
	shf.l.wrap.b32 	%r1794, %r1793, %r1793, 3;
	xor.b32  	%r1795, %r1788, %r1782;
	xor.b32  	%r1796, %r1795, %r1794;
	add.s32 	%r1797, %r1570, %r1776;
	add.s32 	%r1798, %r1797, %r1796;
	add.s32 	%r1799, %r1798, 1859775393;
	shf.l.wrap.b32 	%r1800, %r1799, %r1799, 9;
	xor.b32  	%r1801, %r1794, %r1788;
	xor.b32  	%r1802, %r1801, %r1800;
	add.s32 	%r1803, %r1542, %r1782;
	add.s32 	%r1804, %r1803, %r1802;
	add.s32 	%r1805, %r1804, 1859775393;
	shf.l.wrap.b32 	%r1806, %r1805, %r1805, 11;
	xor.b32  	%r1807, %r1800, %r1794;
	xor.b32  	%r1808, %r1807, %r1806;
	add.s32 	%r1809, %r1598, %r1788;
	add.s32 	%r1810, %r1809, %r1808;
	add.s32 	%r1811, %r1810, 1859775393;
	shf.l.wrap.b32 	%r1812, %r1811, %r1811, 15;
	xor.b32  	%r1813, %r1806, %r1800;
	xor.b32  	%r1814, %r1813, %r1812;
	add.s32 	%r1815, %r1528, %r1794;
	add.s32 	%r1816, %r1815, %r1814;
	add.s32 	%r1817, %r1816, 1859775393;
	shf.l.wrap.b32 	%r244, %r1817, %r1817, 3;
	xor.b32  	%r1818, %r1812, %r1806;
	xor.b32  	%r1819, %r1818, %r244;
	add.s32 	%r1820, %r1584, %r1800;
	add.s32 	%r1821, %r1820, %r1819;
	add.s32 	%r1822, %r1821, 1859775393;
	shf.l.wrap.b32 	%r245, %r1822, %r1822, 9;
	xor.b32  	%r1823, %r244, %r1812;
	xor.b32  	%r1824, %r1823, %r245;
	add.s32 	%r1825, %r1556, %r1806;
	add.s32 	%r1826, %r1825, %r1824;
	add.s32 	%r1827, %r1826, 1859775393;
	shf.l.wrap.b32 	%r246, %r1827, %r1827, 11;
	xor.b32  	%r1828, %r245, %r244;
	xor.b32  	%r1829, %r1828, %r246;
	add.s32 	%r1830, %r1812, %r1829;
	add.s32 	%r1831, %r1830, 1859775393;
	shf.l.wrap.b32 	%r247, %r1831, %r1831, 15;
	shr.u32 	%r1832, %r244, %r13;
	and.b32  	%r1833, %r1832, %r268;
	mul.wide.u32 	%rd24, %r1833, 4;
	add.s64 	%rd25, %rd55, %rd24;
	and.b32  	%r1834, %r244, 31;
	mov.u32 	%r1835, 1;
	shl.b32 	%r248, %r1835, %r1834;
	ld.global.u32 	%r1836, [%rd25];
	and.b32  	%r1837, %r1836, %r248;
	setp.eq.s32	%p50, %r1837, 0;
	@%p50 bra 	BB3_119;

	mov.u32 	%r1897, 1;
	ld.param.u64 	%rd47, [m00900_m04_param_7];
	shr.u32 	%r1838, %r245, %r13;
	and.b32  	%r1839, %r1838, %r268;
	mul.wide.u32 	%rd26, %r1839, 4;
	add.s64 	%rd27, %rd47, %rd26;
	and.b32  	%r1840, %r245, 31;
	shl.b32 	%r249, %r1897, %r1840;
	ld.global.u32 	%r1842, [%rd27];
	and.b32  	%r1843, %r1842, %r249;
	setp.eq.s32	%p51, %r1843, 0;
	@%p51 bra 	BB3_119;

	mov.u32 	%r1898, 1;
	ld.param.u64 	%rd48, [m00900_m04_param_8];
	shr.u32 	%r1844, %r246, %r13;
	and.b32  	%r1845, %r1844, %r268;
	mul.wide.u32 	%rd28, %r1845, 4;
	add.s64 	%rd29, %rd48, %rd28;
	and.b32  	%r1846, %r246, 31;
	shl.b32 	%r250, %r1898, %r1846;
	ld.global.u32 	%r1848, [%rd29];
	and.b32  	%r1849, %r1848, %r250;
	setp.eq.s32	%p52, %r1849, 0;
	@%p52 bra 	BB3_119;

	mov.u32 	%r1899, 1;
	ld.param.u64 	%rd49, [m00900_m04_param_9];
	shr.u32 	%r1850, %r247, %r13;
	and.b32  	%r1851, %r1850, %r268;
	mul.wide.u32 	%rd30, %r1851, 4;
	add.s64 	%rd31, %rd49, %rd30;
	and.b32  	%r1852, %r247, 31;
	shl.b32 	%r251, %r1899, %r1852;
	ld.global.u32 	%r1854, [%rd31];
	and.b32  	%r1855, %r1854, %r251;
	setp.eq.s32	%p53, %r1855, 0;
	@%p53 bra 	BB3_119;

	and.b32  	%r1895, %r244, 31;
	mov.u32 	%r1894, 1;
	shl.b32 	%r1893, %r1894, %r1895;
	ld.param.u64 	%rd50, [m00900_m04_param_10];
	shr.u32 	%r1856, %r244, %r14;
	and.b32  	%r1857, %r1856, %r268;
	mul.wide.u32 	%rd32, %r1857, 4;
	add.s64 	%rd33, %rd50, %rd32;
	ld.global.u32 	%r1858, [%rd33];
	and.b32  	%r1859, %r1858, %r1893;
	setp.eq.s32	%p54, %r1859, 0;
	@%p54 bra 	BB3_119;

	ld.param.u64 	%rd51, [m00900_m04_param_11];
	shr.u32 	%r1860, %r245, %r14;
	and.b32  	%r1861, %r1860, %r268;
	mul.wide.u32 	%rd34, %r1861, 4;
	add.s64 	%rd35, %rd51, %rd34;
	ld.global.u32 	%r1862, [%rd35];
	and.b32  	%r1863, %r1862, %r249;
	setp.eq.s32	%p55, %r1863, 0;
	@%p55 bra 	BB3_119;

	ld.param.u64 	%rd52, [m00900_m04_param_12];
	shr.u32 	%r1864, %r246, %r14;
	and.b32  	%r1865, %r1864, %r268;
	mul.wide.u32 	%rd36, %r1865, 4;
	add.s64 	%rd37, %rd52, %rd36;
	ld.global.u32 	%r1866, [%rd37];
	and.b32  	%r1867, %r1866, %r250;
	setp.eq.s32	%p56, %r1867, 0;
	@%p56 bra 	BB3_119;

	ld.param.u64 	%rd53, [m00900_m04_param_13];
	shr.u32 	%r1868, %r247, %r14;
	and.b32  	%r1869, %r1868, %r268;
	mul.wide.u32 	%rd38, %r1869, 4;
	add.s64 	%rd39, %rd53, %rd38;
	ld.global.u32 	%r1870, [%rd39];
	and.b32  	%r1871, %r1870, %r251;
	setp.eq.s32	%p57, %r1871, 0;
	@%p57 bra 	BB3_119;

	setp.eq.s32	%p58, %r273, 0;
	mov.u32 	%r1934, 0;
	mov.u32 	%r1872, -1;
	mov.u32 	%r1933, %r273;
	@%p58 bra 	BB3_113;

BB3_101:
	mov.u32 	%r1935, 1;
	ld.param.u64 	%rd56, [m00900_m04_param_15];
	shr.u32 	%r254, %r1933, 1;
	add.s32 	%r1936, %r254, %r1934;
	cvt.u64.u32	%rd40, %r1936;
	add.s64 	%rd41, %rd40, %rd2;
	shl.b64 	%rd42, %rd41, 7;
	add.s64 	%rd4, %rd56, %rd42;
	ld.global.u32 	%r256, [%rd4+4];
	setp.gt.u32	%p59, %r247, %r256;
	@%p59 bra 	BB3_111;

	setp.lt.u32	%p60, %r247, %r256;
	mov.u32 	%r1875, -1;
	@%p60 bra 	BB3_103;
	bra.uni 	BB3_104;

BB3_103:
	mov.u32 	%r1935, %r1875;
	bra.uni 	BB3_111;

BB3_104:
	mov.u32 	%r1935, 1;
	ld.global.u32 	%r257, [%rd4+8];
	setp.gt.u32	%p61, %r246, %r257;
	@%p61 bra 	BB3_111;

	setp.lt.u32	%p62, %r246, %r257;
	@%p62 bra 	BB3_106;
	bra.uni 	BB3_107;

BB3_106:
	mov.u32 	%r1935, %r1875;
	bra.uni 	BB3_111;

BB3_107:
	mov.u32 	%r1935, 1;
	ld.global.u32 	%r258, [%rd4+12];
	setp.gt.u32	%p63, %r245, %r258;
	@%p63 bra 	BB3_111;

	setp.lt.u32	%p64, %r245, %r258;
	mov.u32 	%r1935, %r1875;
	@%p64 bra 	BB3_111;

	mov.u32 	%r1935, 1;
	ld.global.u32 	%r259, [%rd4];
	setp.gt.u32	%p65, %r244, %r259;
	@%p65 bra 	BB3_111;

	setp.lt.u32	%p66, %r244, %r259;
	selp.b32	%r1935, -1, 0, %p66;

BB3_111:
	add.s32 	%r1881, %r254, 1;
	setp.gt.s32	%p67, %r1935, 0;
	selp.b32	%r1882, %r1881, 0, %p67;
	add.s32 	%r1934, %r1882, %r1934;
	selp.b32	%r1883, -1, 0, %p67;
	add.s32 	%r1884, %r1883, %r1933;
	shr.u32 	%r1933, %r1884, 1;
	setp.eq.s32	%p68, %r1935, 0;
	@%p68 bra 	BB3_114;

	setp.ne.s32	%p69, %r1933, 0;
	@%p69 bra 	BB3_101;

BB3_113:
	mov.u32 	%r1936, %r1872;

BB3_114:
	setp.eq.s32	%p70, %r1936, -1;
	@%p70 bra 	BB3_119;

	ld.param.u64 	%rd57, [m00900_m04_param_16];
	ld.param.u32 	%r1888, [m00900_m04_param_32];
	add.s32 	%r265, %r1936, %r1888;
	mul.wide.u32 	%rd43, %r265, 4;
	add.s64 	%rd44, %rd57, %rd43;
	atom.global.add.u32 	%r1886, [%rd44], 1;
	setp.ne.s32	%p71, %r1886, 0;
	@%p71 bra 	BB3_119;

	atom.global.add.u32 	%r266, [%rd18], 1;
	setp.lt.u32	%p72, %r266, %r273;
	@%p72 bra 	BB3_118;
	bra.uni 	BB3_117;

BB3_118:
	ld.param.u32 	%r1896, [m00900_m04_param_27];
	ld.param.u64 	%rd58, [m00900_m04_param_14];
	mul.wide.u32 	%rd45, %r266, 32;
	add.s64 	%rd46, %rd58, %rd45;
	st.global.v2.u32 	[%rd46], {%r1896, %r1936};
	st.global.u32 	[%rd46+8], %r265;
	st.global.u32 	[%rd46+24], %r1904;
	st.global.u64 	[%rd46+16], %rd3;
	bra.uni 	BB3_119;

BB3_117:
	atom.global.add.u32 	%r1887, [%rd18], -1;

BB3_119:
	ld.param.u32 	%r1889, [m00900_m04_param_30];
	add.s32 	%r1904, %r1904, 1;
	setp.lt.u32	%p73, %r1904, %r1889;
	@%p73 bra 	BB3_3;

BB3_120:
	ret;
}

	// .globl	m00900_m08
.entry m00900_m08(
	.param .u64 .ptr .global .align 4 m00900_m08_param_0,
	.param .u64 .ptr .global .align 4 m00900_m08_param_1,
	.param .u64 .ptr .global .align 4 m00900_m08_param_2,
	.param .u64 .ptr .global .align 4 m00900_m08_param_3,
	.param .u64 .ptr .global .align 1 m00900_m08_param_4,
	.param .u64 .ptr .global .align 1 m00900_m08_param_5,
	.param .u64 .ptr .global .align 4 m00900_m08_param_6,
	.param .u64 .ptr .global .align 4 m00900_m08_param_7,
	.param .u64 .ptr .global .align 4 m00900_m08_param_8,
	.param .u64 .ptr .global .align 4 m00900_m08_param_9,
	.param .u64 .ptr .global .align 4 m00900_m08_param_10,
	.param .u64 .ptr .global .align 4 m00900_m08_param_11,
	.param .u64 .ptr .global .align 4 m00900_m08_param_12,
	.param .u64 .ptr .global .align 4 m00900_m08_param_13,
	.param .u64 .ptr .global .align 8 m00900_m08_param_14,
	.param .u64 .ptr .global .align 4 m00900_m08_param_15,
	.param .u64 .ptr .global .align 4 m00900_m08_param_16,
	.param .u64 .ptr .global .align 4 m00900_m08_param_17,
	.param .u64 .ptr .global .align 1 m00900_m08_param_18,
	.param .u64 .ptr .global .align 4 m00900_m08_param_19,
	.param .u64 .ptr .global .align 4 m00900_m08_param_20,
	.param .u64 .ptr .global .align 4 m00900_m08_param_21,
	.param .u64 .ptr .global .align 4 m00900_m08_param_22,
	.param .u64 .ptr .global .align 4 m00900_m08_param_23,
	.param .u32 m00900_m08_param_24,
	.param .u32 m00900_m08_param_25,
	.param .u32 m00900_m08_param_26,
	.param .u32 m00900_m08_param_27,
	.param .u32 m00900_m08_param_28,
	.param .u32 m00900_m08_param_29,
	.param .u32 m00900_m08_param_30,
	.param .u32 m00900_m08_param_31,
	.param .u32 m00900_m08_param_32,
	.param .u32 m00900_m08_param_33,
	.param .u64 m00900_m08_param_34
)
{



	ret;
}

	// .globl	m00900_m16
.entry m00900_m16(
	.param .u64 .ptr .global .align 4 m00900_m16_param_0,
	.param .u64 .ptr .global .align 4 m00900_m16_param_1,
	.param .u64 .ptr .global .align 4 m00900_m16_param_2,
	.param .u64 .ptr .global .align 4 m00900_m16_param_3,
	.param .u64 .ptr .global .align 1 m00900_m16_param_4,
	.param .u64 .ptr .global .align 1 m00900_m16_param_5,
	.param .u64 .ptr .global .align 4 m00900_m16_param_6,
	.param .u64 .ptr .global .align 4 m00900_m16_param_7,
	.param .u64 .ptr .global .align 4 m00900_m16_param_8,
	.param .u64 .ptr .global .align 4 m00900_m16_param_9,
	.param .u64 .ptr .global .align 4 m00900_m16_param_10,
	.param .u64 .ptr .global .align 4 m00900_m16_param_11,
	.param .u64 .ptr .global .align 4 m00900_m16_param_12,
	.param .u64 .ptr .global .align 4 m00900_m16_param_13,
	.param .u64 .ptr .global .align 8 m00900_m16_param_14,
	.param .u64 .ptr .global .align 4 m00900_m16_param_15,
	.param .u64 .ptr .global .align 4 m00900_m16_param_16,
	.param .u64 .ptr .global .align 4 m00900_m16_param_17,
	.param .u64 .ptr .global .align 1 m00900_m16_param_18,
	.param .u64 .ptr .global .align 4 m00900_m16_param_19,
	.param .u64 .ptr .global .align 4 m00900_m16_param_20,
	.param .u64 .ptr .global .align 4 m00900_m16_param_21,
	.param .u64 .ptr .global .align 4 m00900_m16_param_22,
	.param .u64 .ptr .global .align 4 m00900_m16_param_23,
	.param .u32 m00900_m16_param_24,
	.param .u32 m00900_m16_param_25,
	.param .u32 m00900_m16_param_26,
	.param .u32 m00900_m16_param_27,
	.param .u32 m00900_m16_param_28,
	.param .u32 m00900_m16_param_29,
	.param .u32 m00900_m16_param_30,
	.param .u32 m00900_m16_param_31,
	.param .u32 m00900_m16_param_32,
	.param .u32 m00900_m16_param_33,
	.param .u64 m00900_m16_param_34
)
{



	ret;
}

	// .globl	m00900_s04
.entry m00900_s04(
	.param .u64 .ptr .global .align 4 m00900_s04_param_0,
	.param .u64 .ptr .global .align 4 m00900_s04_param_1,
	.param .u64 .ptr .global .align 4 m00900_s04_param_2,
	.param .u64 .ptr .global .align 4 m00900_s04_param_3,
	.param .u64 .ptr .global .align 1 m00900_s04_param_4,
	.param .u64 .ptr .global .align 1 m00900_s04_param_5,
	.param .u64 .ptr .global .align 4 m00900_s04_param_6,
	.param .u64 .ptr .global .align 4 m00900_s04_param_7,
	.param .u64 .ptr .global .align 4 m00900_s04_param_8,
	.param .u64 .ptr .global .align 4 m00900_s04_param_9,
	.param .u64 .ptr .global .align 4 m00900_s04_param_10,
	.param .u64 .ptr .global .align 4 m00900_s04_param_11,
	.param .u64 .ptr .global .align 4 m00900_s04_param_12,
	.param .u64 .ptr .global .align 4 m00900_s04_param_13,
	.param .u64 .ptr .global .align 8 m00900_s04_param_14,
	.param .u64 .ptr .global .align 4 m00900_s04_param_15,
	.param .u64 .ptr .global .align 4 m00900_s04_param_16,
	.param .u64 .ptr .global .align 4 m00900_s04_param_17,
	.param .u64 .ptr .global .align 1 m00900_s04_param_18,
	.param .u64 .ptr .global .align 4 m00900_s04_param_19,
	.param .u64 .ptr .global .align 4 m00900_s04_param_20,
	.param .u64 .ptr .global .align 4 m00900_s04_param_21,
	.param .u64 .ptr .global .align 4 m00900_s04_param_22,
	.param .u64 .ptr .global .align 4 m00900_s04_param_23,
	.param .u32 m00900_s04_param_24,
	.param .u32 m00900_s04_param_25,
	.param .u32 m00900_s04_param_26,
	.param .u32 m00900_s04_param_27,
	.param .u32 m00900_s04_param_28,
	.param .u32 m00900_s04_param_29,
	.param .u32 m00900_s04_param_30,
	.param .u32 m00900_s04_param_31,
	.param .u32 m00900_s04_param_32,
	.param .u32 m00900_s04_param_33,
	.param .u64 m00900_s04_param_34
)
{
	.reg .pred 	%p<59>;
	.reg .b32 	%r<1852>;
	.reg .b64 	%rd<23>;


	ld.param.u64 	%rd6, [m00900_s04_param_0];
	ld.param.u64 	%rd9, [m00900_s04_param_15];
	ld.param.u64 	%rd10, [m00900_s04_param_16];
	ld.param.u64 	%rd11, [m00900_s04_param_19];
	ld.param.u32 	%r254, [m00900_s04_param_30];
	ld.param.u32 	%r256, [m00900_s04_param_32];
	ld.param.u64 	%rd12, [m00900_s04_param_34];
	mov.b32	%r258, %envreg3;
	mov.u32 	%r259, %ctaid.x;
	mov.u32 	%r260, %ntid.x;
	mad.lo.s32 	%r261, %r259, %r260, %r258;
	mov.u32 	%r262, %tid.x;
	add.s32 	%r1, %r261, %r262;
	cvt.s64.s32	%rd1, %r1;
	setp.ge.u64	%p1, %rd1, %rd12;
	@%p1 bra 	BB6_101;

	mul.wide.s32 	%rd13, %r1, 260;
	add.s64 	%rd14, %rd6, %rd13;
	ld.global.u32 	%r2, [%rd14];
	ld.global.u32 	%r3, [%rd14+4];
	ld.global.u32 	%r4, [%rd14+8];
	ld.global.u32 	%r5, [%rd14+12];
	ld.global.u32 	%r6, [%rd14+16];
	ld.global.u32 	%r7, [%rd14+20];
	ld.global.u32 	%r8, [%rd14+24];
	ld.global.u32 	%r9, [%rd14+28];
	ld.global.u32 	%r10, [%rd14+256];
	cvt.u64.u32	%rd2, %r256;
	mul.wide.u32 	%rd15, %r256, 128;
	add.s64 	%rd3, %rd9, %rd15;
	ld.global.u32 	%r11, [%rd3];
	setp.eq.s32	%p2, %r254, 0;
	@%p2 bra 	BB6_101;

	ld.global.u32 	%r12, [%rd3+12];
	ld.global.u32 	%r13, [%rd3+8];
	ld.global.u32 	%r14, [%rd3+4];
	and.b32  	%r264, %r10, 3;
	mov.u32 	%r265, 4;
	sub.s32 	%r266, %r265, %r264;
	shr.u32 	%r15, %r10, 2;
	shl.b32 	%r267, %r266, 2;
	mov.u32 	%r268, 1985229328;
	shr.u32 	%r269, %r268, %r267;
	and.b32  	%r16, %r269, 65535;
	shl.b64 	%rd16, %rd2, 2;
	add.s64 	%rd4, %rd10, %rd16;
	and.b64  	%rd5, %rd1, 4294967295;
	mov.u32 	%r1823, 0;

BB6_3:
	ld.param.u32 	%r1817, [m00900_s04_param_33];
	ld.param.u64 	%rd21, [m00900_s04_param_2];
	mul.wide.u32 	%rd17, %r1823, 260;
	add.s64 	%rd18, %rd21, %rd17;
	ld.global.u32 	%r18, [%rd18+256];
	ld.global.u32 	%r1827, [%rd18];
	ld.global.u32 	%r1826, [%rd18+4];
	ld.global.u32 	%r1825, [%rd18+8];
	ld.global.u32 	%r1824, [%rd18+12];
	ld.global.u32 	%r1831, [%rd18+16];
	ld.global.u32 	%r1830, [%rd18+20];
	ld.global.u32 	%r1829, [%rd18+24];
	ld.global.u32 	%r1828, [%rd18+28];
	setp.eq.s32	%p3, %r1817, 10001;
	@%p3 bra 	BB6_46;
	bra.uni 	BB6_4;

BB6_46:
	mov.u32 	%r1832, 0;
	setp.gt.s32	%p27, %r15, 7;
	@%p27 bra 	BB6_62;

	setp.gt.s32	%p39, %r15, 3;
	@%p39 bra 	BB6_55;

	setp.gt.s32	%p45, %r15, 1;
	@%p45 bra 	BB6_52;

	setp.eq.s32	%p48, %r15, 0;
	@%p48 bra 	BB6_90;
	bra.uni 	BB6_50;

BB6_90:
	mov.u32 	%r1838, 0;
	// inline asm
	prmt.b32 %r1832, %r1838, %r1838, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1835, %r1828, %r1838, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1828, %r1829, %r1828, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1829, %r1830, %r1829, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1830, %r1831, %r1830, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1831, %r1824, %r1831, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1824, %r1825, %r1824, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1825, %r1826, %r1825, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1826, %r1827, %r1826, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1827, %r1838, %r1827, %r16;
	// inline asm
	mov.u32 	%r1833, %r1832;
	mov.u32 	%r1834, %r1832;
	bra.uni 	BB6_91;

BB6_4:
	mov.u32 	%r1819, 1985229328;
	mov.u32 	%r1818, 4;
	and.b32  	%r283, %r18, 3;
	sub.s32 	%r285, %r1818, %r283;
	shl.b32 	%r286, %r285, 2;
	shr.u32 	%r288, %r1819, %r286;
	and.b32  	%r27, %r288, 65535;
	shr.u32 	%r282, %r18, 2;
	mov.u32 	%r1832, 0;
	setp.gt.s32	%p4, %r282, 7;
	@%p4 bra 	BB6_20;

	setp.gt.s32	%p16, %r282, 3;
	@%p16 bra 	BB6_13;

	setp.gt.s32	%p22, %r282, 1;
	@%p22 bra 	BB6_10;

	setp.eq.s32	%p25, %r282, 0;
	@%p25 bra 	BB6_45;
	bra.uni 	BB6_8;

BB6_45:
	mov.u32 	%r1832, 0;
	// inline asm
	prmt.b32 %r1838, %r1832, %r1832, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1840, %r9, %r1832, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1847, %r8, %r9, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1846, %r7, %r8, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1845, %r6, %r7, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1844, %r5, %r6, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1851, %r4, %r5, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1850, %r3, %r4, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1849, %r2, %r3, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1848, %r1832, %r2, %r27;
	// inline asm
	mov.u32 	%r1833, %r1832;
	mov.u32 	%r1834, %r1832;
	mov.u32 	%r1835, %r1832;
	mov.u32 	%r1836, %r1832;
	mov.u32 	%r1837, %r1832;
	mov.u32 	%r1839, %r1838;
	mov.u32 	%r1841, %r1838;
	mov.u32 	%r1842, %r1838;
	mov.u32 	%r1843, %r1838;
	bra.uni 	BB6_94;

BB6_62:
	setp.gt.s32	%p28, %r15, 11;
	@%p28 bra 	BB6_70;

	setp.gt.s32	%p34, %r15, 9;
	@%p34 bra 	BB6_67;

	setp.eq.s32	%p37, %r15, 8;
	@%p37 bra 	BB6_84;
	bra.uni 	BB6_65;

BB6_84:
	// inline asm
	prmt.b32 %r1836, %r1831, %r1830, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1837, %r1824, %r1831, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1832, %r1825, %r1824, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1833, %r1826, %r1825, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1834, %r1827, %r1826, %r16;
	// inline asm
	mov.u32 	%r1824, 0;
	// inline asm
	prmt.b32 %r1835, %r1824, %r1827, %r16;
	// inline asm
	mov.u32 	%r1825, %r1824;
	mov.u32 	%r1826, %r1824;
	mov.u32 	%r1827, %r1824;
	mov.u32 	%r1828, %r1824;
	bra.uni 	BB6_85;

BB6_20:
	setp.gt.s32	%p5, %r282, 11;
	@%p5 bra 	BB6_28;

	setp.gt.s32	%p11, %r282, 9;
	@%p11 bra 	BB6_25;

	setp.eq.s32	%p14, %r282, 8;
	@%p14 bra 	BB6_41;
	bra.uni 	BB6_23;

BB6_41:
	// inline asm
	prmt.b32 %r1839, %r6, %r7, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1838, %r5, %r6, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1843, %r4, %r5, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1842, %r3, %r4, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1841, %r2, %r3, %r27;
	// inline asm
	mov.u32 	%r1832, 0;
	// inline asm
	prmt.b32 %r1840, %r1832, %r2, %r27;
	// inline asm
	mov.u32 	%r1833, %r1832;
	mov.u32 	%r1834, %r1832;
	mov.u32 	%r1835, %r1832;
	mov.u32 	%r1836, %r1832;
	mov.u32 	%r1837, %r1832;
	bra.uni 	BB6_37;

BB6_55:
	setp.gt.s32	%p40, %r15, 5;
	@%p40 bra 	BB6_59;

	setp.eq.s32	%p43, %r15, 4;
	@%p43 bra 	BB6_88;
	bra.uni 	BB6_57;

BB6_88:
	mov.u32 	%r1838, 0;
	// inline asm
	prmt.b32 %r1836, %r1838, %r1838, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1837, %r1828, %r1838, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1832, %r1829, %r1828, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1833, %r1830, %r1829, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1834, %r1831, %r1830, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1835, %r1824, %r1831, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1828, %r1825, %r1824, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1829, %r1826, %r1825, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1830, %r1827, %r1826, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1831, %r1838, %r1827, %r16;
	// inline asm
	mov.u32 	%r1824, %r1838;
	mov.u32 	%r1825, %r1838;
	mov.u32 	%r1826, %r1838;
	mov.u32 	%r1827, %r1838;
	bra.uni 	BB6_92;

BB6_13:
	setp.gt.s32	%p17, %r282, 5;
	@%p17 bra 	BB6_17;

	setp.eq.s32	%p20, %r282, 4;
	@%p20 bra 	BB6_43;
	bra.uni 	BB6_15;

BB6_43:
	mov.u32 	%r1832, 0;
	// inline asm
	prmt.b32 %r1839, %r1832, %r1832, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1838, %r9, %r1832, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1843, %r8, %r9, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1842, %r7, %r8, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1841, %r6, %r7, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1840, %r5, %r6, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1847, %r4, %r5, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1846, %r3, %r4, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1845, %r2, %r3, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1844, %r1832, %r2, %r27;
	// inline asm
	mov.u32 	%r1833, %r1832;
	mov.u32 	%r1834, %r1832;
	mov.u32 	%r1835, %r1832;
	mov.u32 	%r1836, %r1832;
	mov.u32 	%r1837, %r1832;
	bra.uni 	BB6_38;

BB6_70:
	setp.gt.s32	%p29, %r15, 13;
	@%p29 bra 	BB6_74;

	setp.eq.s32	%p32, %r15, 12;
	@%p32 bra 	BB6_79;
	bra.uni 	BB6_72;

BB6_79:
	// inline asm
	prmt.b32 %r1836, %r1827, %r1826, %r16;
	// inline asm
	mov.u32 	%r1824, 0;
	// inline asm
	prmt.b32 %r1837, %r1824, %r1827, %r16;
	// inline asm
	mov.u32 	%r1825, %r1824;
	mov.u32 	%r1826, %r1824;
	mov.u32 	%r1827, %r1824;
	mov.u32 	%r1828, %r1824;
	mov.u32 	%r1829, %r1824;
	mov.u32 	%r1830, %r1824;
	mov.u32 	%r1831, %r1824;
	mov.u32 	%r1832, %r1824;
	bra.uni 	BB6_80;

BB6_28:
	setp.gt.s32	%p6, %r282, 13;
	@%p6 bra 	BB6_32;

	setp.eq.s32	%p9, %r282, 12;
	@%p9 bra 	BB6_39;
	bra.uni 	BB6_30;

BB6_39:
	// inline asm
	prmt.b32 %r1839, %r2, %r3, %r27;
	// inline asm
	mov.u32 	%r1832, 0;
	// inline asm
	prmt.b32 %r1838, %r1832, %r2, %r27;
	// inline asm
	mov.u32 	%r1833, %r1832;
	mov.u32 	%r1834, %r1832;
	mov.u32 	%r1835, %r1832;
	mov.u32 	%r1836, %r1832;
	mov.u32 	%r1837, %r1832;
	bra.uni 	BB6_36;

BB6_52:
	setp.eq.s32	%p46, %r15, 2;
	@%p46 bra 	BB6_89;
	bra.uni 	BB6_53;

BB6_89:
	mov.u32 	%r1838, 0;
	// inline asm
	prmt.b32 %r1832, %r1838, %r1838, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1833, %r1828, %r1838, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1834, %r1829, %r1828, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1835, %r1830, %r1829, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1828, %r1831, %r1830, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1829, %r1824, %r1831, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1830, %r1825, %r1824, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1831, %r1826, %r1825, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1824, %r1827, %r1826, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1825, %r1838, %r1827, %r16;
	// inline asm
	mov.u32 	%r1826, %r1838;
	mov.u32 	%r1827, %r1838;
	bra.uni 	BB6_91;

BB6_10:
	setp.eq.s32	%p23, %r282, 2;
	@%p23 bra 	BB6_44;
	bra.uni 	BB6_11;

BB6_44:
	mov.u32 	%r1832, 0;
	// inline asm
	prmt.b32 %r1838, %r1832, %r1832, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1842, %r9, %r1832, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1841, %r8, %r9, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1840, %r7, %r8, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1847, %r6, %r7, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1846, %r5, %r6, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1845, %r4, %r5, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1844, %r3, %r4, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1851, %r2, %r3, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1850, %r1832, %r2, %r27;
	// inline asm
	mov.u32 	%r1833, %r1832;
	mov.u32 	%r1834, %r1832;
	mov.u32 	%r1835, %r1832;
	mov.u32 	%r1836, %r1832;
	mov.u32 	%r1837, %r1832;
	mov.u32 	%r1839, %r1838;
	mov.u32 	%r1843, %r1838;
	mov.u32 	%r1848, %r1832;
	mov.u32 	%r1849, %r1832;
	bra.uni 	BB6_94;

BB6_67:
	setp.eq.s32	%p35, %r15, 10;
	@%p35 bra 	BB6_83;
	bra.uni 	BB6_68;

BB6_83:
	// inline asm
	prmt.b32 %r1836, %r1825, %r1824, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1837, %r1826, %r1825, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1832, %r1827, %r1826, %r16;
	// inline asm
	mov.u32 	%r1824, 0;
	// inline asm
	prmt.b32 %r1833, %r1824, %r1827, %r16;
	// inline asm
	mov.u32 	%r1825, %r1824;
	mov.u32 	%r1826, %r1824;
	mov.u32 	%r1827, %r1824;
	mov.u32 	%r1828, %r1824;
	mov.u32 	%r1829, %r1824;
	mov.u32 	%r1830, %r1824;
	mov.u32 	%r1831, %r1824;
	bra.uni 	BB6_81;

BB6_25:
	setp.eq.s32	%p12, %r282, 10;
	@%p12 bra 	BB6_40;
	bra.uni 	BB6_26;

BB6_40:
	// inline asm
	prmt.b32 %r1839, %r4, %r5, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1838, %r3, %r4, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1843, %r2, %r3, %r27;
	// inline asm
	mov.u32 	%r1832, 0;
	// inline asm
	prmt.b32 %r1842, %r1832, %r2, %r27;
	// inline asm
	mov.u32 	%r1833, %r1832;
	mov.u32 	%r1834, %r1832;
	mov.u32 	%r1835, %r1832;
	mov.u32 	%r1836, %r1832;
	mov.u32 	%r1837, %r1832;
	mov.u32 	%r1840, %r1832;
	mov.u32 	%r1841, %r1832;
	bra.uni 	BB6_37;

BB6_59:
	setp.eq.s32	%p41, %r15, 6;
	@%p41 bra 	BB6_87;
	bra.uni 	BB6_60;

BB6_87:
	// inline asm
	prmt.b32 %r1836, %r1829, %r1828, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1837, %r1830, %r1829, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1832, %r1831, %r1830, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1833, %r1824, %r1831, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1834, %r1825, %r1824, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1835, %r1826, %r1825, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1828, %r1827, %r1826, %r16;
	// inline asm
	mov.u32 	%r1824, 0;
	// inline asm
	prmt.b32 %r1829, %r1824, %r1827, %r16;
	// inline asm
	mov.u32 	%r1825, %r1824;
	mov.u32 	%r1826, %r1824;
	mov.u32 	%r1827, %r1824;
	bra.uni 	BB6_86;

BB6_17:
	setp.eq.s32	%p18, %r282, 6;
	@%p18 bra 	BB6_42;
	bra.uni 	BB6_18;

BB6_42:
	// inline asm
	prmt.b32 %r1839, %r8, %r9, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1838, %r7, %r8, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1843, %r6, %r7, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1842, %r5, %r6, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1841, %r4, %r5, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1840, %r3, %r4, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1847, %r2, %r3, %r27;
	// inline asm
	mov.u32 	%r1832, 0;
	// inline asm
	prmt.b32 %r1846, %r1832, %r2, %r27;
	// inline asm
	mov.u32 	%r1833, %r1832;
	mov.u32 	%r1834, %r1832;
	mov.u32 	%r1835, %r1832;
	mov.u32 	%r1836, %r1832;
	mov.u32 	%r1837, %r1832;
	mov.u32 	%r1844, %r1832;
	mov.u32 	%r1845, %r1832;
	bra.uni 	BB6_38;

BB6_74:
	setp.eq.s32	%p30, %r15, 14;
	@%p30 bra 	BB6_76;

	setp.ne.s32	%p31, %r15, 15;
	mov.u32 	%r1833, %r1832;
	mov.u32 	%r1834, %r1832;
	mov.u32 	%r1835, %r1832;
	mov.u32 	%r1836, %r1832;
	mov.u32 	%r1837, %r1832;
	mov.u32 	%r1838, %r1832;
	mov.u32 	%r1839, %r1832;
	mov.u32 	%r1840, %r1832;
	mov.u32 	%r1841, %r1832;
	mov.u32 	%r1842, %r1832;
	mov.u32 	%r1843, %r1832;
	mov.u32 	%r1844, %r6;
	mov.u32 	%r1845, %r7;
	mov.u32 	%r1846, %r8;
	mov.u32 	%r1847, %r9;
	mov.u32 	%r1848, %r2;
	mov.u32 	%r1849, %r3;
	mov.u32 	%r1850, %r4;
	mov.u32 	%r1851, %r5;
	@%p31 bra 	BB6_94;

BB6_76:
	mov.u32 	%r1824, 0;
	mov.u32 	%r1825, %r1824;
	mov.u32 	%r1826, %r1824;
	mov.u32 	%r1827, %r1824;
	mov.u32 	%r1828, %r1824;
	mov.u32 	%r1829, %r1824;
	mov.u32 	%r1830, %r1824;
	mov.u32 	%r1831, %r1824;
	mov.u32 	%r1832, %r1824;
	mov.u32 	%r1833, %r1824;
	mov.u32 	%r1834, %r1824;
	mov.u32 	%r1835, %r1824;
	mov.u32 	%r1836, %r1824;
	bra.uni 	BB6_77;

BB6_32:
	setp.eq.s32	%p7, %r282, 14;
	@%p7 bra 	BB6_35;

	setp.ne.s32	%p8, %r282, 15;
	@%p8 bra 	BB6_34;

BB6_35:
	mov.u32 	%r1832, 0;
	mov.u32 	%r1833, %r1832;
	mov.u32 	%r1834, %r1832;
	mov.u32 	%r1835, %r1832;
	mov.u32 	%r1836, %r1832;
	mov.u32 	%r1837, %r1832;
	mov.u32 	%r1838, %r1832;
	mov.u32 	%r1839, %r1832;
	bra.uni 	BB6_36;

BB6_50:
	setp.eq.s32	%p49, %r15, 1;
	@%p49 bra 	BB6_51;
	bra.uni 	BB6_34;

BB6_51:
	mov.u32 	%r1838, 0;
	// inline asm
	prmt.b32 %r1832, %r1838, %r1838, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1834, %r1828, %r1838, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1835, %r1829, %r1828, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1828, %r1830, %r1829, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1829, %r1831, %r1830, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1830, %r1824, %r1831, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1831, %r1825, %r1824, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1824, %r1826, %r1825, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1825, %r1827, %r1826, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1826, %r1838, %r1827, %r16;
	// inline asm
	mov.u32 	%r1827, %r1838;
	mov.u32 	%r1833, %r1832;

BB6_91:
	mov.u32 	%r1836, %r1832;
	mov.u32 	%r1837, %r1832;
	bra.uni 	BB6_92;

BB6_8:
	setp.eq.s32	%p26, %r282, 1;
	@%p26 bra 	BB6_9;
	bra.uni 	BB6_34;

BB6_9:
	mov.u32 	%r1832, 0;
	// inline asm
	prmt.b32 %r1838, %r1832, %r1832, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1841, %r9, %r1832, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1840, %r8, %r9, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1847, %r7, %r8, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1846, %r6, %r7, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1845, %r5, %r6, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1844, %r4, %r5, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1851, %r3, %r4, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1850, %r2, %r3, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1849, %r1832, %r2, %r27;
	// inline asm
	mov.u32 	%r1833, %r1832;
	mov.u32 	%r1834, %r1832;
	mov.u32 	%r1835, %r1832;
	mov.u32 	%r1836, %r1832;
	mov.u32 	%r1837, %r1832;
	mov.u32 	%r1839, %r1838;
	mov.u32 	%r1842, %r1838;
	mov.u32 	%r1843, %r1838;
	mov.u32 	%r1848, %r1832;
	bra.uni 	BB6_94;

BB6_65:
	setp.eq.s32	%p38, %r15, 9;
	@%p38 bra 	BB6_66;
	bra.uni 	BB6_34;

BB6_66:
	// inline asm
	prmt.b32 %r1836, %r1824, %r1831, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1837, %r1825, %r1824, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1832, %r1826, %r1825, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1833, %r1827, %r1826, %r16;
	// inline asm
	mov.u32 	%r1824, 0;
	// inline asm
	prmt.b32 %r1834, %r1824, %r1827, %r16;
	// inline asm
	mov.u32 	%r1825, %r1824;
	mov.u32 	%r1826, %r1824;
	mov.u32 	%r1827, %r1824;
	mov.u32 	%r1828, %r1824;
	mov.u32 	%r1829, %r1824;
	mov.u32 	%r1830, %r1824;
	mov.u32 	%r1831, %r1824;
	bra.uni 	BB6_82;

BB6_23:
	setp.eq.s32	%p15, %r282, 9;
	@%p15 bra 	BB6_24;
	bra.uni 	BB6_34;

BB6_24:
	// inline asm
	prmt.b32 %r1839, %r5, %r6, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1838, %r4, %r5, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1843, %r3, %r4, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1842, %r2, %r3, %r27;
	// inline asm
	mov.u32 	%r1832, 0;
	// inline asm
	prmt.b32 %r1841, %r1832, %r2, %r27;
	// inline asm
	mov.u32 	%r1833, %r1832;
	mov.u32 	%r1834, %r1832;
	mov.u32 	%r1835, %r1832;
	mov.u32 	%r1836, %r1832;
	mov.u32 	%r1837, %r1832;
	mov.u32 	%r1840, %r1832;
	bra.uni 	BB6_37;

BB6_57:
	setp.eq.s32	%p44, %r15, 5;
	@%p44 bra 	BB6_58;
	bra.uni 	BB6_34;

BB6_58:
	mov.u32 	%r1838, 0;
	// inline asm
	prmt.b32 %r1836, %r1828, %r1838, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1837, %r1829, %r1828, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1832, %r1830, %r1829, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1833, %r1831, %r1830, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1834, %r1824, %r1831, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1835, %r1825, %r1824, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1828, %r1826, %r1825, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1829, %r1827, %r1826, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1830, %r1838, %r1827, %r16;
	// inline asm
	mov.u32 	%r1824, %r1838;
	mov.u32 	%r1825, %r1838;
	mov.u32 	%r1826, %r1838;
	mov.u32 	%r1827, %r1838;
	mov.u32 	%r1831, %r1838;
	bra.uni 	BB6_92;

BB6_15:
	setp.eq.s32	%p21, %r282, 5;
	@%p21 bra 	BB6_16;
	bra.uni 	BB6_34;

BB6_16:
	mov.u32 	%r1832, 0;
	// inline asm
	prmt.b32 %r1839, %r9, %r1832, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1838, %r8, %r9, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1843, %r7, %r8, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1842, %r6, %r7, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1841, %r5, %r6, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1840, %r4, %r5, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1847, %r3, %r4, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1846, %r2, %r3, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1845, %r1832, %r2, %r27;
	// inline asm
	mov.u32 	%r1833, %r1832;
	mov.u32 	%r1834, %r1832;
	mov.u32 	%r1835, %r1832;
	mov.u32 	%r1836, %r1832;
	mov.u32 	%r1837, %r1832;
	mov.u32 	%r1844, %r1832;
	bra.uni 	BB6_38;

BB6_72:
	setp.eq.s32	%p33, %r15, 13;
	@%p33 bra 	BB6_73;
	bra.uni 	BB6_34;

BB6_73:
	mov.u32 	%r1824, 0;
	// inline asm
	prmt.b32 %r1836, %r1824, %r1827, %r16;
	// inline asm
	mov.u32 	%r1825, %r1824;
	mov.u32 	%r1826, %r1824;
	mov.u32 	%r1827, %r1824;
	mov.u32 	%r1828, %r1824;
	mov.u32 	%r1829, %r1824;
	mov.u32 	%r1830, %r1824;
	mov.u32 	%r1831, %r1824;
	mov.u32 	%r1832, %r1824;
	mov.u32 	%r1833, %r1824;
	mov.u32 	%r1834, %r1824;
	mov.u32 	%r1835, %r1824;

BB6_77:
	mov.u32 	%r1837, %r1824;
	bra.uni 	BB6_78;

BB6_30:
	setp.eq.s32	%p10, %r282, 13;
	@%p10 bra 	BB6_31;
	bra.uni 	BB6_34;

BB6_31:
	mov.u32 	%r1832, 0;
	// inline asm
	prmt.b32 %r1839, %r1832, %r2, %r27;
	// inline asm
	mov.u32 	%r1833, %r1832;
	mov.u32 	%r1834, %r1832;
	mov.u32 	%r1835, %r1832;
	mov.u32 	%r1836, %r1832;
	mov.u32 	%r1837, %r1832;
	mov.u32 	%r1838, %r1832;

BB6_36:
	mov.u32 	%r1840, %r1832;
	mov.u32 	%r1841, %r1832;
	mov.u32 	%r1842, %r1832;
	mov.u32 	%r1843, %r1832;

BB6_37:
	mov.u32 	%r1844, %r1832;
	mov.u32 	%r1845, %r1832;
	mov.u32 	%r1846, %r1832;
	mov.u32 	%r1847, %r1832;

BB6_38:
	mov.u32 	%r1848, %r1832;
	mov.u32 	%r1849, %r1832;
	mov.u32 	%r1850, %r1832;
	mov.u32 	%r1851, %r1832;
	bra.uni 	BB6_94;

BB6_53:
	setp.eq.s32	%p47, %r15, 3;
	@%p47 bra 	BB6_54;
	bra.uni 	BB6_34;

BB6_54:
	mov.u32 	%r1838, 0;
	// inline asm
	prmt.b32 %r1836, %r1838, %r1838, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1832, %r1828, %r1838, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1833, %r1829, %r1828, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1834, %r1830, %r1829, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1835, %r1831, %r1830, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1828, %r1824, %r1831, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1829, %r1825, %r1824, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1830, %r1826, %r1825, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1831, %r1827, %r1826, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1824, %r1838, %r1827, %r16;
	// inline asm
	mov.u32 	%r1825, %r1838;
	mov.u32 	%r1826, %r1838;
	mov.u32 	%r1827, %r1838;
	mov.u32 	%r1837, %r1836;

BB6_92:
	mov.u32 	%r1839, %r1838;
	mov.u32 	%r1840, %r1838;
	mov.u32 	%r1841, %r1838;
	mov.u32 	%r1842, %r1838;
	mov.u32 	%r1843, %r1838;
	bra.uni 	BB6_93;

BB6_11:
	setp.eq.s32	%p24, %r282, 3;
	@%p24 bra 	BB6_12;
	bra.uni 	BB6_34;

BB6_12:
	mov.u32 	%r1832, 0;
	// inline asm
	prmt.b32 %r1838, %r1832, %r1832, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1843, %r9, %r1832, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1842, %r8, %r9, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1841, %r7, %r8, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1840, %r6, %r7, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1847, %r5, %r6, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1846, %r4, %r5, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1845, %r3, %r4, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1844, %r2, %r3, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1851, %r1832, %r2, %r27;
	// inline asm
	mov.u32 	%r1833, %r1832;
	mov.u32 	%r1834, %r1832;
	mov.u32 	%r1835, %r1832;
	mov.u32 	%r1836, %r1832;
	mov.u32 	%r1837, %r1832;
	mov.u32 	%r1839, %r1838;
	mov.u32 	%r1848, %r1832;
	mov.u32 	%r1849, %r1832;
	mov.u32 	%r1850, %r1832;
	bra.uni 	BB6_94;

BB6_68:
	setp.eq.s32	%p36, %r15, 11;
	@%p36 bra 	BB6_69;
	bra.uni 	BB6_34;

BB6_69:
	// inline asm
	prmt.b32 %r1836, %r1826, %r1825, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1837, %r1827, %r1826, %r16;
	// inline asm
	mov.u32 	%r1824, 0;
	// inline asm
	prmt.b32 %r1832, %r1824, %r1827, %r16;
	// inline asm
	mov.u32 	%r1825, %r1824;
	mov.u32 	%r1826, %r1824;
	mov.u32 	%r1827, %r1824;
	mov.u32 	%r1828, %r1824;
	mov.u32 	%r1829, %r1824;
	mov.u32 	%r1830, %r1824;
	mov.u32 	%r1831, %r1824;

BB6_80:
	mov.u32 	%r1833, %r1824;

BB6_81:
	mov.u32 	%r1834, %r1824;

BB6_82:
	mov.u32 	%r1835, %r1824;
	bra.uni 	BB6_78;

BB6_26:
	setp.eq.s32	%p13, %r282, 11;
	@%p13 bra 	BB6_27;
	bra.uni 	BB6_34;

BB6_27:
	// inline asm
	prmt.b32 %r1839, %r3, %r4, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1838, %r2, %r3, %r27;
	// inline asm
	mov.u32 	%r1832, 0;
	// inline asm
	prmt.b32 %r1843, %r1832, %r2, %r27;
	// inline asm
	mov.u32 	%r1833, %r1832;
	mov.u32 	%r1834, %r1832;
	mov.u32 	%r1835, %r1832;
	mov.u32 	%r1836, %r1832;
	mov.u32 	%r1837, %r1832;
	mov.u32 	%r1840, %r1832;
	mov.u32 	%r1841, %r1832;
	mov.u32 	%r1842, %r1832;
	bra.uni 	BB6_37;

BB6_60:
	setp.eq.s32	%p42, %r15, 7;
	@%p42 bra 	BB6_61;
	bra.uni 	BB6_34;

BB6_61:
	// inline asm
	prmt.b32 %r1836, %r1830, %r1829, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1837, %r1831, %r1830, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1832, %r1824, %r1831, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1833, %r1825, %r1824, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1834, %r1826, %r1825, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1835, %r1827, %r1826, %r16;
	// inline asm
	mov.u32 	%r1824, 0;
	// inline asm
	prmt.b32 %r1828, %r1824, %r1827, %r16;
	// inline asm
	mov.u32 	%r1825, %r1824;
	mov.u32 	%r1826, %r1824;
	mov.u32 	%r1827, %r1824;

BB6_85:
	mov.u32 	%r1829, %r1824;

BB6_86:
	mov.u32 	%r1830, %r1824;
	mov.u32 	%r1831, %r1824;

BB6_78:
	mov.u32 	%r1838, %r1824;
	mov.u32 	%r1839, %r1824;
	mov.u32 	%r1840, %r1824;
	mov.u32 	%r1841, %r1824;
	mov.u32 	%r1842, %r1824;
	mov.u32 	%r1843, %r1824;
	bra.uni 	BB6_93;

BB6_18:
	setp.eq.s32	%p19, %r282, 7;
	@%p19 bra 	BB6_19;
	bra.uni 	BB6_34;

BB6_19:
	// inline asm
	prmt.b32 %r1839, %r7, %r8, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1838, %r6, %r7, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1843, %r5, %r6, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1842, %r4, %r5, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1841, %r3, %r4, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1840, %r2, %r3, %r27;
	// inline asm
	mov.u32 	%r1832, 0;
	// inline asm
	prmt.b32 %r1847, %r1832, %r2, %r27;
	// inline asm
	mov.u32 	%r1833, %r1832;
	mov.u32 	%r1834, %r1832;
	mov.u32 	%r1835, %r1832;
	mov.u32 	%r1836, %r1832;
	mov.u32 	%r1837, %r1832;
	mov.u32 	%r1844, %r1832;
	mov.u32 	%r1845, %r1832;
	mov.u32 	%r1846, %r1832;
	bra.uni 	BB6_38;

BB6_34:
	mov.u32 	%r1833, %r1832;
	mov.u32 	%r1834, %r1832;
	mov.u32 	%r1835, %r1832;
	mov.u32 	%r1836, %r1832;
	mov.u32 	%r1837, %r1832;
	mov.u32 	%r1838, %r1832;
	mov.u32 	%r1839, %r1832;
	mov.u32 	%r1840, %r1832;
	mov.u32 	%r1841, %r1832;
	mov.u32 	%r1842, %r1832;
	mov.u32 	%r1843, %r1832;

BB6_93:
	mov.u32 	%r1844, %r6;
	mov.u32 	%r1845, %r7;
	mov.u32 	%r1846, %r8;
	mov.u32 	%r1847, %r9;
	mov.u32 	%r1848, %r2;
	mov.u32 	%r1849, %r3;
	mov.u32 	%r1850, %r4;
	mov.u32 	%r1851, %r5;

BB6_94:
	or.b32  	%r1491, %r1848, %r1827;
	add.s32 	%r1492, %r1491, -1;
	shf.l.wrap.b32 	%r1493, %r1492, %r1492, 3;
	and.b32  	%r1494, %r1493, 2004318071;
	xor.b32  	%r1495, %r1494, -1732584194;
	or.b32  	%r1496, %r1849, %r1826;
	add.s32 	%r1497, %r1496, %r1495;
	add.s32 	%r1498, %r1497, 271733878;
	shf.l.wrap.b32 	%r1499, %r1498, %r1498, 7;
	xor.b32  	%r1500, %r1493, -271733879;
	and.b32  	%r1501, %r1500, %r1499;
	xor.b32  	%r1502, %r1501, -271733879;
	or.b32  	%r1503, %r1850, %r1825;
	add.s32 	%r1504, %r1503, %r1502;
	add.s32 	%r1505, %r1504, -1732584194;
	shf.l.wrap.b32 	%r1506, %r1505, %r1505, 11;
	xor.b32  	%r1507, %r1499, %r1493;
	and.b32  	%r1508, %r1507, %r1506;
	xor.b32  	%r1509, %r1508, %r1493;
	or.b32  	%r1510, %r1851, %r1824;
	add.s32 	%r1511, %r1510, %r1509;
	add.s32 	%r1512, %r1511, -271733879;
	shf.l.wrap.b32 	%r1513, %r1512, %r1512, 19;
	xor.b32  	%r1514, %r1506, %r1499;
	and.b32  	%r1515, %r1514, %r1513;
	xor.b32  	%r1516, %r1515, %r1499;
	or.b32  	%r1517, %r1844, %r1831;
	add.s32 	%r1518, %r1493, %r1517;
	add.s32 	%r1519, %r1518, %r1516;
	shf.l.wrap.b32 	%r1520, %r1519, %r1519, 3;
	xor.b32  	%r1521, %r1513, %r1506;
	and.b32  	%r1522, %r1521, %r1520;
	xor.b32  	%r1523, %r1522, %r1506;
	or.b32  	%r1524, %r1845, %r1830;
	add.s32 	%r1525, %r1499, %r1524;
	add.s32 	%r1526, %r1525, %r1523;
	shf.l.wrap.b32 	%r1527, %r1526, %r1526, 7;
	xor.b32  	%r1528, %r1520, %r1513;
	and.b32  	%r1529, %r1528, %r1527;
	xor.b32  	%r1530, %r1529, %r1513;
	or.b32  	%r1531, %r1846, %r1829;
	add.s32 	%r1532, %r1506, %r1531;
	add.s32 	%r1533, %r1532, %r1530;
	shf.l.wrap.b32 	%r1534, %r1533, %r1533, 11;
	xor.b32  	%r1535, %r1527, %r1520;
	and.b32  	%r1536, %r1535, %r1534;
	xor.b32  	%r1537, %r1536, %r1520;
	or.b32  	%r246, %r1847, %r1828;
	add.s32 	%r1538, %r1513, %r246;
	add.s32 	%r1539, %r1538, %r1537;
	shf.l.wrap.b32 	%r1540, %r1539, %r1539, 19;
	xor.b32  	%r1541, %r1534, %r1527;
	and.b32  	%r1542, %r1541, %r1540;
	xor.b32  	%r1543, %r1542, %r1527;
	or.b32  	%r1544, %r1840, %r1835;
	add.s32 	%r1545, %r1520, %r1544;
	add.s32 	%r1546, %r1545, %r1543;
	shf.l.wrap.b32 	%r1547, %r1546, %r1546, 3;
	xor.b32  	%r1548, %r1540, %r1534;
	and.b32  	%r1549, %r1548, %r1547;
	xor.b32  	%r1550, %r1549, %r1534;
	or.b32  	%r1551, %r1841, %r1834;
	add.s32 	%r1552, %r1527, %r1551;
	add.s32 	%r1553, %r1552, %r1550;
	shf.l.wrap.b32 	%r1554, %r1553, %r1553, 7;
	xor.b32  	%r1555, %r1547, %r1540;
	and.b32  	%r1556, %r1555, %r1554;
	xor.b32  	%r1557, %r1556, %r1540;
	or.b32  	%r1558, %r1842, %r1833;
	add.s32 	%r1559, %r1534, %r1558;
	add.s32 	%r1560, %r1559, %r1557;
	shf.l.wrap.b32 	%r1561, %r1560, %r1560, 11;
	xor.b32  	%r1562, %r1554, %r1547;
	and.b32  	%r1563, %r1562, %r1561;
	xor.b32  	%r1564, %r1563, %r1547;
	or.b32  	%r247, %r1843, %r1832;
	add.s32 	%r1565, %r1540, %r247;
	add.s32 	%r1566, %r1565, %r1564;
	shf.l.wrap.b32 	%r1567, %r1566, %r1566, 19;
	xor.b32  	%r1568, %r1561, %r1554;
	and.b32  	%r1569, %r1568, %r1567;
	xor.b32  	%r1570, %r1569, %r1554;
	or.b32  	%r1571, %r1838, %r1837;
	add.s32 	%r1572, %r1547, %r1571;
	add.s32 	%r1573, %r1572, %r1570;
	shf.l.wrap.b32 	%r1574, %r1573, %r1573, 3;
	xor.b32  	%r1575, %r1567, %r1561;
	and.b32  	%r1576, %r1575, %r1574;
	xor.b32  	%r1577, %r1576, %r1561;
	or.b32  	%r1578, %r1839, %r1836;
	add.s32 	%r1579, %r1554, %r1578;
	add.s32 	%r1580, %r1579, %r1577;
	shf.l.wrap.b32 	%r1581, %r1580, %r1580, 7;
	xor.b32  	%r1582, %r1574, %r1567;
	and.b32  	%r1583, %r1582, %r1581;
	xor.b32  	%r1584, %r1583, %r1567;
	add.s32 	%r1585, %r18, %r10;
	shl.b32 	%r1586, %r1585, 3;
	add.s32 	%r1587, %r1561, %r1586;
	add.s32 	%r1588, %r1587, %r1584;
	shf.l.wrap.b32 	%r1589, %r1588, %r1588, 11;
	xor.b32  	%r1590, %r1581, %r1574;
	and.b32  	%r1591, %r1590, %r1589;
	xor.b32  	%r1592, %r1591, %r1574;
	add.s32 	%r1593, %r1592, %r1567;
	shf.l.wrap.b32 	%r1594, %r1593, %r1593, 19;
	xor.b32  	%r1595, %r1594, %r1581;
	xor.b32  	%r1596, %r1594, %r1589;
	and.b32  	%r1597, %r1596, %r1595;
	xor.b32  	%r1598, %r1597, %r1594;
	add.s32 	%r1599, %r1491, %r1574;
	add.s32 	%r1600, %r1599, %r1598;
	add.s32 	%r1601, %r1600, 1518500249;
	shf.l.wrap.b32 	%r1602, %r1601, %r1601, 3;
	xor.b32  	%r1603, %r1602, %r1589;
	xor.b32  	%r1604, %r1602, %r1594;
	and.b32  	%r1605, %r1604, %r1603;
	xor.b32  	%r1606, %r1605, %r1602;
	add.s32 	%r1607, %r1517, %r1581;
	add.s32 	%r1608, %r1607, %r1606;
	add.s32 	%r1609, %r1608, 1518500249;
	shf.l.wrap.b32 	%r1610, %r1609, %r1609, 5;
	xor.b32  	%r1611, %r1610, %r1594;
	xor.b32  	%r1612, %r1610, %r1602;
	and.b32  	%r1613, %r1612, %r1611;
	xor.b32  	%r1614, %r1613, %r1610;
	add.s32 	%r1615, %r1544, %r1589;
	add.s32 	%r1616, %r1615, %r1614;
	add.s32 	%r1617, %r1616, 1518500249;
	shf.l.wrap.b32 	%r1618, %r1617, %r1617, 9;
	xor.b32  	%r1619, %r1618, %r1602;
	xor.b32  	%r1620, %r1618, %r1610;
	and.b32  	%r1621, %r1620, %r1619;
	xor.b32  	%r1622, %r1621, %r1618;
	add.s32 	%r1623, %r1571, %r1594;
	add.s32 	%r1624, %r1623, %r1622;
	add.s32 	%r1625, %r1624, 1518500249;
	shf.l.wrap.b32 	%r1626, %r1625, %r1625, 13;
	xor.b32  	%r1627, %r1626, %r1610;
	xor.b32  	%r1628, %r1626, %r1618;
	and.b32  	%r1629, %r1628, %r1627;
	xor.b32  	%r1630, %r1629, %r1626;
	add.s32 	%r1631, %r1496, %r1602;
	add.s32 	%r1632, %r1631, %r1630;
	add.s32 	%r1633, %r1632, 1518500249;
	shf.l.wrap.b32 	%r1634, %r1633, %r1633, 3;
	xor.b32  	%r1635, %r1634, %r1618;
	xor.b32  	%r1636, %r1634, %r1626;
	and.b32  	%r1637, %r1636, %r1635;
	xor.b32  	%r1638, %r1637, %r1634;
	add.s32 	%r1639, %r1524, %r1610;
	add.s32 	%r1640, %r1639, %r1638;
	add.s32 	%r1641, %r1640, 1518500249;
	shf.l.wrap.b32 	%r1642, %r1641, %r1641, 5;
	xor.b32  	%r1643, %r1642, %r1626;
	xor.b32  	%r1644, %r1642, %r1634;
	and.b32  	%r1645, %r1644, %r1643;
	xor.b32  	%r1646, %r1645, %r1642;
	add.s32 	%r1647, %r1551, %r1618;
	add.s32 	%r1648, %r1647, %r1646;
	add.s32 	%r1649, %r1648, 1518500249;
	shf.l.wrap.b32 	%r1650, %r1649, %r1649, 9;
	xor.b32  	%r1651, %r1650, %r1634;
	xor.b32  	%r1652, %r1650, %r1642;
	and.b32  	%r1653, %r1652, %r1651;
	xor.b32  	%r1654, %r1653, %r1650;
	add.s32 	%r1655, %r1578, %r1626;
	add.s32 	%r1656, %r1655, %r1654;
	add.s32 	%r1657, %r1656, 1518500249;
	shf.l.wrap.b32 	%r1658, %r1657, %r1657, 13;
	xor.b32  	%r1659, %r1658, %r1642;
	xor.b32  	%r1660, %r1658, %r1650;
	and.b32  	%r1661, %r1660, %r1659;
	xor.b32  	%r1662, %r1661, %r1658;
	add.s32 	%r1663, %r1503, %r1634;
	add.s32 	%r1664, %r1663, %r1662;
	add.s32 	%r1665, %r1664, 1518500249;
	shf.l.wrap.b32 	%r1666, %r1665, %r1665, 3;
	xor.b32  	%r1667, %r1666, %r1650;
	xor.b32  	%r1668, %r1666, %r1658;
	and.b32  	%r1669, %r1668, %r1667;
	xor.b32  	%r1670, %r1669, %r1666;
	add.s32 	%r1671, %r1531, %r1642;
	add.s32 	%r1672, %r1671, %r1670;
	add.s32 	%r1673, %r1672, 1518500249;
	shf.l.wrap.b32 	%r1674, %r1673, %r1673, 5;
	xor.b32  	%r1675, %r1674, %r1658;
	xor.b32  	%r1676, %r1674, %r1666;
	and.b32  	%r1677, %r1676, %r1675;
	xor.b32  	%r1678, %r1677, %r1674;
	add.s32 	%r1679, %r1558, %r1650;
	add.s32 	%r1680, %r1679, %r1678;
	add.s32 	%r1681, %r1680, 1518500249;
	shf.l.wrap.b32 	%r1682, %r1681, %r1681, 9;
	xor.b32  	%r1683, %r1682, %r1666;
	xor.b32  	%r1684, %r1682, %r1674;
	and.b32  	%r1685, %r1684, %r1683;
	xor.b32  	%r1686, %r1685, %r1682;
	add.s32 	%r1687, %r1586, %r1658;
	add.s32 	%r1688, %r1687, %r1686;
	add.s32 	%r1689, %r1688, 1518500249;
	shf.l.wrap.b32 	%r1690, %r1689, %r1689, 13;
	xor.b32  	%r1691, %r1690, %r1674;
	xor.b32  	%r1692, %r1690, %r1682;
	and.b32  	%r1693, %r1692, %r1691;
	xor.b32  	%r1694, %r1693, %r1690;
	add.s32 	%r1695, %r1510, %r1666;
	add.s32 	%r1696, %r1695, %r1694;
	add.s32 	%r1697, %r1696, 1518500249;
	shf.l.wrap.b32 	%r1698, %r1697, %r1697, 3;
	xor.b32  	%r1699, %r1698, %r1682;
	xor.b32  	%r1700, %r1698, %r1690;
	and.b32  	%r1701, %r1700, %r1699;
	xor.b32  	%r1702, %r1701, %r1698;
	add.s32 	%r1703, %r246, %r1674;
	add.s32 	%r1704, %r1703, %r1702;
	add.s32 	%r1705, %r1704, 1518500249;
	shf.l.wrap.b32 	%r1706, %r1705, %r1705, 5;
	xor.b32  	%r1707, %r1706, %r1690;
	xor.b32  	%r1708, %r1706, %r1698;
	and.b32  	%r1709, %r1708, %r1707;
	xor.b32  	%r1710, %r1709, %r1706;
	add.s32 	%r1711, %r247, %r1682;
	add.s32 	%r1712, %r1711, %r1710;
	add.s32 	%r1713, %r1712, 1518500249;
	shf.l.wrap.b32 	%r1714, %r1713, %r1713, 9;
	xor.b32  	%r1715, %r1714, %r1698;
	xor.b32  	%r1716, %r1714, %r1706;
	and.b32  	%r1717, %r1716, %r1715;
	xor.b32  	%r1718, %r1717, %r1714;
	add.s32 	%r1719, %r1690, %r1718;
	add.s32 	%r1720, %r1719, 1518500249;
	shf.l.wrap.b32 	%r1721, %r1720, %r1720, 13;
	xor.b32  	%r1722, %r1716, %r1721;
	add.s32 	%r1723, %r1491, %r1698;
	add.s32 	%r1724, %r1723, %r1722;
	add.s32 	%r1725, %r1724, 1859775393;
	shf.l.wrap.b32 	%r1726, %r1725, %r1725, 3;
	xor.b32  	%r1727, %r1721, %r1714;
	xor.b32  	%r1728, %r1727, %r1726;
	add.s32 	%r1729, %r1544, %r1706;
	add.s32 	%r1730, %r1729, %r1728;
	add.s32 	%r1731, %r1730, 1859775393;
	shf.l.wrap.b32 	%r1732, %r1731, %r1731, 9;
	xor.b32  	%r1733, %r1726, %r1721;
	xor.b32  	%r1734, %r1733, %r1732;
	add.s32 	%r1735, %r1517, %r1714;
	add.s32 	%r1736, %r1735, %r1734;
	add.s32 	%r1737, %r1736, 1859775393;
	shf.l.wrap.b32 	%r1738, %r1737, %r1737, 11;
	xor.b32  	%r1739, %r1732, %r1726;
	xor.b32  	%r1740, %r1739, %r1738;
	add.s32 	%r1741, %r1571, %r1721;
	add.s32 	%r1742, %r1741, %r1740;
	add.s32 	%r1743, %r1742, 1859775393;
	shf.l.wrap.b32 	%r1744, %r1743, %r1743, 15;
	xor.b32  	%r1745, %r1738, %r1732;
	xor.b32  	%r1746, %r1745, %r1744;
	add.s32 	%r1747, %r1503, %r1726;
	add.s32 	%r1748, %r1747, %r1746;
	add.s32 	%r1749, %r1748, 1859775393;
	shf.l.wrap.b32 	%r1750, %r1749, %r1749, 3;
	xor.b32  	%r1751, %r1744, %r1738;
	xor.b32  	%r1752, %r1751, %r1750;
	add.s32 	%r1753, %r1558, %r1732;
	add.s32 	%r1754, %r1753, %r1752;
	add.s32 	%r1755, %r1754, 1859775393;
	shf.l.wrap.b32 	%r1756, %r1755, %r1755, 9;
	xor.b32  	%r1757, %r1750, %r1744;
	xor.b32  	%r1758, %r1757, %r1756;
	add.s32 	%r1759, %r1531, %r1738;
	add.s32 	%r1760, %r1759, %r1758;
	add.s32 	%r1761, %r1760, 1859775393;
	shf.l.wrap.b32 	%r1762, %r1761, %r1761, 11;
	xor.b32  	%r1763, %r1756, %r1750;
	xor.b32  	%r1764, %r1763, %r1762;
	add.s32 	%r1765, %r1586, %r1744;
	add.s32 	%r1766, %r1765, %r1764;
	add.s32 	%r1767, %r1766, 1859775393;
	shf.l.wrap.b32 	%r1768, %r1767, %r1767, 15;
	xor.b32  	%r1769, %r1762, %r1756;
	xor.b32  	%r1770, %r1769, %r1768;
	add.s32 	%r1771, %r1496, %r1750;
	add.s32 	%r1772, %r1771, %r1770;
	add.s32 	%r1773, %r1772, 1859775393;
	shf.l.wrap.b32 	%r1774, %r1773, %r1773, 3;
	xor.b32  	%r1775, %r1768, %r1762;
	xor.b32  	%r1776, %r1775, %r1774;
	add.s32 	%r1777, %r1551, %r1756;
	add.s32 	%r1778, %r1777, %r1776;
	add.s32 	%r1779, %r1778, 1859775393;
	shf.l.wrap.b32 	%r248, %r1779, %r1779, 9;
	xor.b32  	%r1780, %r1774, %r1768;
	xor.b32  	%r1781, %r1780, %r248;
	add.s32 	%r1782, %r1524, %r1762;
	add.s32 	%r1783, %r1782, %r1781;
	add.s32 	%r1784, %r1783, 1859775393;
	shf.l.wrap.b32 	%r249, %r1784, %r1784, 11;
	xor.b32  	%r1785, %r248, %r1774;
	xor.b32  	%r1786, %r1785, %r249;
	add.s32 	%r1787, %r1578, %r1768;
	add.s32 	%r1788, %r1787, %r1786;
	add.s32 	%r1789, %r1788, 1859775393;
	shf.l.wrap.b32 	%r250, %r1789, %r1789, 15;
	xor.b32  	%r1790, %r249, %r248;
	xor.b32  	%r1791, %r1790, %r250;
	add.s32 	%r1792, %r1510, %r1774;
	add.s32 	%r1793, %r1792, %r1791;
	add.s32 	%r1794, %r1793, 1859775393;
	shf.l.wrap.b32 	%r1795, %r1794, %r1794, 3;
	setp.ne.s32	%p50, %r1795, %r11;
	@%p50 bra 	BB6_100;

	xor.b32  	%r1796, %r249, %r11;
	xor.b32  	%r1797, %r1796, %r250;
	add.s32 	%r1798, %r247, %r248;
	add.s32 	%r1799, %r1798, %r1797;
	add.s32 	%r1800, %r1799, 1859775393;
	shf.l.wrap.b32 	%r1801, %r1800, %r1800, 9;
	xor.b32  	%r1802, %r250, %r11;
	xor.b32  	%r1803, %r1802, %r1801;
	add.s32 	%r1804, %r246, %r249;
	add.s32 	%r1805, %r1804, %r1803;
	add.s32 	%r1806, %r1805, 1859775393;
	shf.l.wrap.b32 	%r1807, %r1806, %r1806, 11;
	xor.b32  	%r1808, %r1801, %r11;
	xor.b32  	%r1809, %r1808, %r1807;
	add.s32 	%r1810, %r250, %r1809;
	add.s32 	%r1811, %r1810, 1859775393;
	shf.l.wrap.b32 	%r1812, %r1811, %r1811, 15;
	setp.eq.s32	%p51, %r1801, %r12;
	setp.eq.s32	%p52, %r1807, %r13;
	and.pred  	%p53, %p51, %p52;
	setp.eq.s32	%p54, %r1812, %r14;
	and.pred  	%p55, %p53, %p54;
	@!%p55 bra 	BB6_100;
	bra.uni 	BB6_96;

BB6_96:
	atom.global.add.u32 	%r1813, [%rd4], 1;
	setp.ne.s32	%p56, %r1813, 0;
	@%p56 bra 	BB6_100;

	ld.param.u32 	%r1820, [m00900_s04_param_31];
	atom.global.add.u32 	%r251, [%rd11], 1;
	setp.lt.u32	%p57, %r251, %r1820;
	@%p57 bra 	BB6_99;
	bra.uni 	BB6_98;

BB6_99:
	ld.param.u32 	%r1822, [m00900_s04_param_27];
	ld.param.u64 	%rd22, [m00900_s04_param_14];
	ld.param.u32 	%r1821, [m00900_s04_param_32];
	mul.wide.u32 	%rd19, %r251, 32;
	add.s64 	%rd20, %rd22, %rd19;
	mov.u32 	%r1815, 0;
	st.global.v2.u32 	[%rd20], {%r1822, %r1815};
	st.global.u32 	[%rd20+8], %r1821;
	st.global.u32 	[%rd20+24], %r1823;
	st.global.u64 	[%rd20+16], %rd5;
	bra.uni 	BB6_100;

BB6_98:
	atom.global.add.u32 	%r1814, [%rd11], -1;

BB6_100:
	ld.param.u32 	%r1816, [m00900_s04_param_30];
	add.s32 	%r1823, %r1823, 1;
	setp.lt.u32	%p58, %r1823, %r1816;
	@%p58 bra 	BB6_3;

BB6_101:
	ret;
}

	// .globl	m00900_s08
.entry m00900_s08(
	.param .u64 .ptr .global .align 4 m00900_s08_param_0,
	.param .u64 .ptr .global .align 4 m00900_s08_param_1,
	.param .u64 .ptr .global .align 4 m00900_s08_param_2,
	.param .u64 .ptr .global .align 4 m00900_s08_param_3,
	.param .u64 .ptr .global .align 1 m00900_s08_param_4,
	.param .u64 .ptr .global .align 1 m00900_s08_param_5,
	.param .u64 .ptr .global .align 4 m00900_s08_param_6,
	.param .u64 .ptr .global .align 4 m00900_s08_param_7,
	.param .u64 .ptr .global .align 4 m00900_s08_param_8,
	.param .u64 .ptr .global .align 4 m00900_s08_param_9,
	.param .u64 .ptr .global .align 4 m00900_s08_param_10,
	.param .u64 .ptr .global .align 4 m00900_s08_param_11,
	.param .u64 .ptr .global .align 4 m00900_s08_param_12,
	.param .u64 .ptr .global .align 4 m00900_s08_param_13,
	.param .u64 .ptr .global .align 8 m00900_s08_param_14,
	.param .u64 .ptr .global .align 4 m00900_s08_param_15,
	.param .u64 .ptr .global .align 4 m00900_s08_param_16,
	.param .u64 .ptr .global .align 4 m00900_s08_param_17,
	.param .u64 .ptr .global .align 1 m00900_s08_param_18,
	.param .u64 .ptr .global .align 4 m00900_s08_param_19,
	.param .u64 .ptr .global .align 4 m00900_s08_param_20,
	.param .u64 .ptr .global .align 4 m00900_s08_param_21,
	.param .u64 .ptr .global .align 4 m00900_s08_param_22,
	.param .u64 .ptr .global .align 4 m00900_s08_param_23,
	.param .u32 m00900_s08_param_24,
	.param .u32 m00900_s08_param_25,
	.param .u32 m00900_s08_param_26,
	.param .u32 m00900_s08_param_27,
	.param .u32 m00900_s08_param_28,
	.param .u32 m00900_s08_param_29,
	.param .u32 m00900_s08_param_30,
	.param .u32 m00900_s08_param_31,
	.param .u32 m00900_s08_param_32,
	.param .u32 m00900_s08_param_33,
	.param .u64 m00900_s08_param_34
)
{



	ret;
}

	// .globl	m00900_s16
.entry m00900_s16(
	.param .u64 .ptr .global .align 4 m00900_s16_param_0,
	.param .u64 .ptr .global .align 4 m00900_s16_param_1,
	.param .u64 .ptr .global .align 4 m00900_s16_param_2,
	.param .u64 .ptr .global .align 4 m00900_s16_param_3,
	.param .u64 .ptr .global .align 1 m00900_s16_param_4,
	.param .u64 .ptr .global .align 1 m00900_s16_param_5,
	.param .u64 .ptr .global .align 4 m00900_s16_param_6,
	.param .u64 .ptr .global .align 4 m00900_s16_param_7,
	.param .u64 .ptr .global .align 4 m00900_s16_param_8,
	.param .u64 .ptr .global .align 4 m00900_s16_param_9,
	.param .u64 .ptr .global .align 4 m00900_s16_param_10,
	.param .u64 .ptr .global .align 4 m00900_s16_param_11,
	.param .u64 .ptr .global .align 4 m00900_s16_param_12,
	.param .u64 .ptr .global .align 4 m00900_s16_param_13,
	.param .u64 .ptr .global .align 8 m00900_s16_param_14,
	.param .u64 .ptr .global .align 4 m00900_s16_param_15,
	.param .u64 .ptr .global .align 4 m00900_s16_param_16,
	.param .u64 .ptr .global .align 4 m00900_s16_param_17,
	.param .u64 .ptr .global .align 1 m00900_s16_param_18,
	.param .u64 .ptr .global .align 4 m00900_s16_param_19,
	.param .u64 .ptr .global .align 4 m00900_s16_param_20,
	.param .u64 .ptr .global .align 4 m00900_s16_param_21,
	.param .u64 .ptr .global .align 4 m00900_s16_param_22,
	.param .u64 .ptr .global .align 4 m00900_s16_param_23,
	.param .u32 m00900_s16_param_24,
	.param .u32 m00900_s16_param_25,
	.param .u32 m00900_s16_param_26,
	.param .u32 m00900_s16_param_27,
	.param .u32 m00900_s16_param_28,
	.param .u32 m00900_s16_param_29,
	.param .u32 m00900_s16_param_30,
	.param .u32 m00900_s16_param_31,
	.param .u32 m00900_s16_param_32,
	.param .u32 m00900_s16_param_33,
	.param .u64 m00900_s16_param_34
)
{



	ret;
}


  