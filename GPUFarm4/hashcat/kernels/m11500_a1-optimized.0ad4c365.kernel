//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: UNKNOWN
// Driver 
// Based on LLVM 3.4svn
//

.version 6.1
.target sm_61, texmode_independent
.address_size 64

	// .globl	gpu_memset
.const .align 4 .b8 c_append_helper[4096] = {255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255};
.const .align 8 .b8 crc32tab[1024] = {0, 0, 0, 0, 150, 48, 7, 119, 44, 97, 14, 238, 186, 81, 9, 153, 25, 196, 109, 7, 143, 244, 106, 112, 53, 165, 99, 233, 163, 149, 100, 158, 50, 136, 219, 14, 164, 184, 220, 121, 30, 233, 213, 224, 136, 217, 210, 151, 43, 76, 182, 9, 189, 124, 177, 126, 7, 45, 184, 231, 145, 29, 191, 144, 100, 16, 183, 29, 242, 32, 176, 106, 72, 113, 185, 243, 222, 65, 190, 132, 125, 212, 218, 26, 235, 228, 221, 109, 81, 181, 212, 244, 199, 133, 211, 131, 86, 152, 108, 19, 192, 168, 107, 100, 122, 249, 98, 253, 236, 201, 101, 138, 79, 92, 1, 20, 217, 108, 6, 99, 99, 61, 15, 250, 245, 13, 8, 141, 200, 32, 110, 59, 94, 16, 105, 76, 228, 65, 96, 213, 114, 113, 103, 162, 209, 228, 3, 60, 71, 212, 4, 75, 253, 133, 13, 210, 107, 181, 10, 165, 250, 168, 181, 53, 108, 152, 178, 66, 214, 201, 187, 219, 64, 249, 188, 172, 227, 108, 216, 50, 117, 92, 223, 69, 207, 13, 214, 220, 89, 61, 209, 171, 172, 48, 217, 38, 58, 0, 222, 81, 128, 81, 215, 200, 22, 97, 208, 191, 181, 244, 180, 33, 35, 196, 179, 86, 153, 149, 186, 207, 15, 165, 189, 184, 158, 184, 2, 40, 8, 136, 5, 95, 178, 217, 12, 198, 36, 233, 11, 177, 135, 124, 111, 47, 17, 76, 104, 88, 171, 29, 97, 193, 61, 45, 102, 182, 144, 65, 220, 118, 6, 113, 219, 1, 188, 32, 210, 152, 42, 16, 213, 239, 137, 133, 177, 113, 31, 181, 182, 6, 165, 228, 191, 159, 51, 212, 184, 232, 162, 201, 7, 120, 52, 249, 0, 15, 142, 168, 9, 150, 24, 152, 14, 225, 187, 13, 106, 127, 45, 61, 109, 8, 151, 108, 100, 145, 1, 92, 99, 230, 244, 81, 107, 107, 98, 97, 108, 28, 216, 48, 101, 133, 78, 0, 98, 242, 237, 149, 6, 108, 123, 165, 1, 27, 193, 244, 8, 130, 87, 196, 15, 245, 198, 217, 176, 101, 80, 233, 183, 18, 234, 184, 190, 139, 124, 136, 185, 252, 223, 29, 221, 98, 73, 45, 218, 21, 243, 124, 211, 140, 101, 76, 212, 251, 88, 97, 178, 77, 206, 81, 181, 58, 116, 0, 188, 163, 226, 48, 187, 212, 65, 165, 223, 74, 215, 149, 216, 61, 109, 196, 209, 164, 251, 244, 214, 211, 106, 233, 105, 67, 252, 217, 110, 52, 70, 136, 103, 173, 208, 184, 96, 218, 115, 45, 4, 68, 229, 29, 3, 51, 95, 76, 10, 170, 201, 124, 13, 221, 60, 113, 5, 80, 170, 65, 2, 39, 16, 16, 11, 190, 134, 32, 12, 201, 37, 181, 104, 87, 179, 133, 111, 32, 9, 212, 102, 185, 159, 228, 97, 206, 14, 249, 222, 94, 152, 201, 217, 41, 34, 152, 208, 176, 180, 168, 215, 199, 23, 61, 179, 89, 129, 13, 180, 46, 59, 92, 189, 183, 173, 108, 186, 192, 32, 131, 184, 237, 182, 179, 191, 154, 12, 226, 182, 3, 154, 210, 177, 116, 57, 71, 213, 234, 175, 119, 210, 157, 21, 38, 219, 4, 131, 22, 220, 115, 18, 11, 99, 227, 132, 59, 100, 148, 62, 106, 109, 13, 168, 90, 106, 122, 11, 207, 14, 228, 157, 255, 9, 147, 39, 174, 0, 10, 177, 158, 7, 125, 68, 147, 15, 240, 210, 163, 8, 135, 104, 242, 1, 30, 254, 194, 6, 105, 93, 87, 98, 247, 203, 103, 101, 128, 113, 54, 108, 25, 231, 6, 107, 110, 118, 27, 212, 254, 224, 43, 211, 137, 90, 122, 218, 16, 204, 74, 221, 103, 111, 223, 185, 249, 249, 239, 190, 142, 67, 190, 183, 23, 213, 142, 176, 96, 232, 163, 214, 214, 126, 147, 209, 161, 196, 194, 216, 56, 82, 242, 223, 79, 241, 103, 187, 209, 103, 87, 188, 166, 221, 6, 181, 63, 75, 54, 178, 72, 218, 43, 13, 216, 76, 27, 10, 175, 246, 74, 3, 54, 96, 122, 4, 65, 195, 239, 96, 223, 85, 223, 103, 168, 239, 142, 110, 49, 121, 190, 105, 70, 140, 179, 97, 203, 26, 131, 102, 188, 160, 210, 111, 37, 54, 226, 104, 82, 149, 119, 12, 204, 3, 71, 11, 187, 185, 22, 2, 34, 47, 38, 5, 85, 190, 59, 186, 197, 40, 11, 189, 178, 146, 90, 180, 43, 4, 106, 179, 92, 167, 255, 215, 194, 49, 207, 208, 181, 139, 158, 217, 44, 29, 174, 222, 91, 176, 194, 100, 155, 38, 242, 99, 236, 156, 163, 106, 117, 10, 147, 109, 2, 169, 6, 9, 156, 63, 54, 14, 235, 133, 103, 7, 114, 19, 87, 0, 5, 130, 74, 191, 149, 20, 122, 184, 226, 174, 43, 177, 123, 56, 27, 182, 12, 155, 142, 210, 146, 13, 190, 213, 229, 183, 239, 220, 124, 33, 223, 219, 11, 212, 210, 211, 134, 66, 226, 212, 241, 248, 179, 221, 104, 110, 131, 218, 31, 205, 22, 190, 129, 91, 38, 185, 246, 225, 119, 176, 111, 119, 71, 183, 24, 230, 90, 8, 136, 112, 106, 15, 255, 202, 59, 6, 102, 92, 11, 1, 17, 255, 158, 101, 143, 105, 174, 98, 248, 211, 255, 107, 97, 69, 207, 108, 22, 120, 226, 10, 160, 238, 210, 13, 215, 84, 131, 4, 78, 194, 179, 3, 57, 97, 38, 103, 167, 247, 22, 96, 208, 77, 71, 105, 73, 219, 119, 110, 62, 74, 106, 209, 174, 220, 90, 214, 217, 102, 11, 223, 64, 240, 59, 216, 55, 83, 174, 188, 169, 197, 158, 187, 222, 127, 207, 178, 71, 233, 255, 181, 48, 28, 242, 189, 189, 138, 194, 186, 202, 48, 147, 179, 83, 166, 163, 180, 36, 5, 54, 208, 186, 147, 6, 215, 205, 41, 87, 222, 84, 191, 103, 217, 35, 46, 122, 102, 179, 184, 74, 97, 196, 2, 27, 104, 93, 148, 43, 111, 42, 55, 190, 11, 180, 161, 142, 12, 195, 27, 223, 5, 90, 141, 239, 2, 45};

.entry gpu_memset(
	.param .u64 .ptr .global .align 16 gpu_memset_param_0,
	.param .u32 gpu_memset_param_1,
	.param .u64 gpu_memset_param_2
)
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<8>;
	.reg .b64 	%rd<6>;


	ld.param.u64 	%rd2, [gpu_memset_param_0];
	ld.param.u32 	%r1, [gpu_memset_param_1];
	ld.param.u64 	%rd3, [gpu_memset_param_2];
	mov.b32	%r2, %envreg3;
	mov.u32 	%r3, %ctaid.x;
	mov.u32 	%r4, %ntid.x;
	mad.lo.s32 	%r5, %r3, %r4, %r2;
	mov.u32 	%r6, %tid.x;
	add.s32 	%r7, %r5, %r6;
	cvt.s64.s32	%rd1, %r7;
	setp.ge.u64	%p1, %rd1, %rd3;
	@%p1 bra 	BB0_2;

	shl.b64 	%rd4, %rd1, 4;
	add.s64 	%rd5, %rd2, %rd4;
	st.global.v4.u32 	[%rd5], {%r1, %r1, %r1, %r1};

BB0_2:
	ret;
}

	// .globl	m11500_m04
.entry m11500_m04(
	.param .u64 .ptr .global .align 4 m11500_m04_param_0,
	.param .u64 .ptr .global .align 4 m11500_m04_param_1,
	.param .u64 .ptr .global .align 4 m11500_m04_param_2,
	.param .u64 .ptr .global .align 4 m11500_m04_param_3,
	.param .u64 .ptr .global .align 1 m11500_m04_param_4,
	.param .u64 .ptr .global .align 1 m11500_m04_param_5,
	.param .u64 .ptr .global .align 4 m11500_m04_param_6,
	.param .u64 .ptr .global .align 4 m11500_m04_param_7,
	.param .u64 .ptr .global .align 4 m11500_m04_param_8,
	.param .u64 .ptr .global .align 4 m11500_m04_param_9,
	.param .u64 .ptr .global .align 4 m11500_m04_param_10,
	.param .u64 .ptr .global .align 4 m11500_m04_param_11,
	.param .u64 .ptr .global .align 4 m11500_m04_param_12,
	.param .u64 .ptr .global .align 4 m11500_m04_param_13,
	.param .u64 .ptr .global .align 4 m11500_m04_param_14,
	.param .u64 .ptr .global .align 4 m11500_m04_param_15,
	.param .u64 .ptr .global .align 4 m11500_m04_param_16,
	.param .u64 .ptr .global .align 4 m11500_m04_param_17,
	.param .u64 .ptr .global .align 1 m11500_m04_param_18,
	.param .u64 .ptr .global .align 4 m11500_m04_param_19,
	.param .u64 .ptr .global .align 4 m11500_m04_param_20,
	.param .u64 .ptr .global .align 4 m11500_m04_param_21,
	.param .u64 .ptr .global .align 4 m11500_m04_param_22,
	.param .u64 .ptr .global .align 4 m11500_m04_param_23,
	.param .u32 m11500_m04_param_24,
	.param .u32 m11500_m04_param_25,
	.param .u32 m11500_m04_param_26,
	.param .u32 m11500_m04_param_27,
	.param .u32 m11500_m04_param_28,
	.param .u32 m11500_m04_param_29,
	.param .u32 m11500_m04_param_30,
	.param .u32 m11500_m04_param_31,
	.param .u32 m11500_m04_param_32,
	.param .u32 m11500_m04_param_33,
	.param .u64 m11500_m04_param_34
)
{
	.local .align 16 .b8 	__local_depot1[64];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<81>;
	.reg .b32 	%r<2163>;
	.reg .b64 	%rd<73>;


	mov.u64 	%rd72, __local_depot1;
	cvta.local.u64 	%SP, %rd72;
	ld.param.u64 	%rd6, [m11500_m04_param_0];
	ld.param.u64 	%rd14, [m11500_m04_param_12];
	ld.param.u64 	%rd15, [m11500_m04_param_13];
	ld.param.u64 	%rd16, [m11500_m04_param_14];
	ld.param.u64 	%rd17, [m11500_m04_param_15];
	ld.param.u64 	%rd18, [m11500_m04_param_16];
	ld.param.u64 	%rd19, [m11500_m04_param_17];
	ld.param.u64 	%rd20, [m11500_m04_param_19];
	ld.param.u32 	%r371, [m11500_m04_param_24];
	ld.param.u32 	%r372, [m11500_m04_param_25];
	ld.param.u32 	%r373, [m11500_m04_param_26];
	ld.param.u32 	%r374, [m11500_m04_param_27];
	ld.param.u32 	%r375, [m11500_m04_param_30];
	ld.param.u32 	%r376, [m11500_m04_param_31];
	ld.param.u32 	%r377, [m11500_m04_param_32];
	ld.param.u64 	%rd21, [m11500_m04_param_34];
	add.u64 	%rd22, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd22;
	mov.u32 	%r379, %ctaid.x;
	mov.u32 	%r380, %ntid.x;
	mov.b32	%r381, %envreg3;
	mad.lo.s32 	%r382, %r379, %r380, %r381;
	mov.u32 	%r383, %tid.x;
	add.s32 	%r1, %r382, %r383;
	cvt.s64.s32	%rd2, %r1;
	setp.ge.u64	%p1, %rd2, %rd21;
	@%p1 bra 	BB1_137;

	mul.lo.s64 	%rd23, %rd2, 260;
	add.s64 	%rd24, %rd6, %rd23;
	ld.global.u32 	%r2, [%rd24];
	ld.global.u32 	%r3, [%rd24+4];
	ld.global.u32 	%r4, [%rd24+8];
	ld.global.u32 	%r5, [%rd24+12];
	ld.global.u32 	%r6, [%rd24+16];
	ld.global.u32 	%r7, [%rd24+20];
	ld.global.u32 	%r8, [%rd24+24];
	ld.global.u32 	%r9, [%rd24+28];
	ld.global.u32 	%r10, [%rd24+256];
	setp.eq.s32	%p2, %r375, 0;
	@%p2 bra 	BB1_137;

	mul.wide.u32 	%rd25, %r374, 564;
	add.s64 	%rd26, %rd19, %rd25;
	ld.global.u32 	%r385, [%rd26];
	and.b32  	%r386, %r10, 3;
	mov.u32 	%r387, 4;
	sub.s32 	%r388, %r387, %r386;
	shr.u32 	%r11, %r10, 2;
	shl.b32 	%r389, %r388, 2;
	mov.u32 	%r390, 1985229328;
	shr.u32 	%r391, %r390, %r389;
	and.b32  	%r12, %r391, 65535;
	not.b32 	%r13, %r385;
	and.b32  	%r14, %r372, 31;
	and.b32  	%r15, %r373, 31;
	cvt.u64.u32	%rd3, %r377;
	shr.u32 	%r16, %r13, 8;
	mov.u32 	%r2115, 0;

BB1_3:
	ld.param.u32 	%r2113, [m11500_m04_param_33];
	ld.param.u64 	%rd69, [m11500_m04_param_2];
	mul.wide.u32 	%rd27, %r2115, 260;
	add.s64 	%rd28, %rd69, %rd27;
	ld.global.u32 	%r18, [%rd28+256];
	add.s32 	%r19, %r18, %r10;
	ld.global.u32 	%r2128, [%rd28];
	ld.global.u32 	%r2129, [%rd28+4];
	ld.global.u32 	%r2130, [%rd28+8];
	ld.global.u32 	%r2131, [%rd28+12];
	ld.global.u32 	%r2119, [%rd28+16];
	ld.global.u32 	%r2118, [%rd28+20];
	ld.global.u32 	%r2117, [%rd28+24];
	ld.global.u32 	%r2116, [%rd28+28];
	setp.eq.s32	%p3, %r2113, 10001;
	@%p3 bra 	BB1_47;
	bra.uni 	BB1_4;

BB1_47:
	mov.u32 	%r2120, 0;
	setp.gt.s32	%p27, %r11, 7;
	@%p27 bra 	BB1_66;

	setp.gt.s32	%p39, %r11, 3;
	@%p39 bra 	BB1_56;

	setp.gt.s32	%p45, %r11, 1;
	@%p45 bra 	BB1_53;

	setp.eq.s32	%p48, %r11, 0;
	@%p48 bra 	BB1_94;
	bra.uni 	BB1_51;

BB1_94:
	mov.u32 	%r2132, 0;
	// inline asm
	prmt.b32 %r2124, %r2132, %r2132, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2125, %r2132, %r2132, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2126, %r2132, %r2132, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2127, %r2132, %r2132, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2120, %r2132, %r2132, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2121, %r2132, %r2132, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2122, %r2132, %r2132, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2123, %r2116, %r2132, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2116, %r2117, %r2116, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2117, %r2118, %r2117, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2118, %r2119, %r2118, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2119, %r2131, %r2119, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2131, %r2130, %r2131, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2130, %r2129, %r2130, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2129, %r2128, %r2129, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2128, %r2132, %r2128, %r12;
	// inline asm
	bra.uni 	BB1_95;

BB1_4:
	mov.u32 	%r2112, 1985229328;
	and.b32  	%r409, %r18, 3;
	sub.s32 	%r411, %r387, %r409;
	shl.b32 	%r412, %r411, 2;
	shr.u32 	%r414, %r2112, %r412;
	and.b32  	%r28, %r414, 65535;
	shr.u32 	%r408, %r18, 2;
	mov.u32 	%r2120, 0;
	setp.gt.s32	%p4, %r408, 7;
	@%p4 bra 	BB1_20;

	setp.gt.s32	%p16, %r408, 3;
	@%p16 bra 	BB1_13;

	setp.gt.s32	%p22, %r408, 1;
	@%p22 bra 	BB1_10;

	setp.eq.s32	%p25, %r408, 0;
	@%p25 bra 	BB1_46;
	bra.uni 	BB1_8;

BB1_46:
	mov.u32 	%r2120, 0;
	// inline asm
	prmt.b32 %r2135, %r2120, %r2120, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2134, %r2120, %r2120, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2133, %r2120, %r2120, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2132, %r2120, %r2120, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2139, %r2120, %r2120, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2138, %r2120, %r2120, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2137, %r2120, %r2120, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2136, %r9, %r2120, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2143, %r8, %r9, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2142, %r7, %r8, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2141, %r6, %r7, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2140, %r5, %r6, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2147, %r4, %r5, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2146, %r3, %r4, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2145, %r2, %r3, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2144, %r2120, %r2, %r28;
	// inline asm
	mov.u32 	%r2121, %r2120;
	mov.u32 	%r2122, %r2120;
	mov.u32 	%r2123, %r2120;
	mov.u32 	%r2124, %r2120;
	mov.u32 	%r2125, %r2120;
	mov.u32 	%r2126, %r2120;
	mov.u32 	%r2127, %r2120;
	bra.uni 	BB1_97;

BB1_66:
	setp.gt.s32	%p28, %r11, 11;
	@%p28 bra 	BB1_74;

	setp.gt.s32	%p34, %r11, 9;
	@%p34 bra 	BB1_71;

	setp.eq.s32	%p37, %r11, 8;
	@%p37 bra 	BB1_90;
	bra.uni 	BB1_69;

BB1_90:
	// inline asm
	prmt.b32 %r2124, %r2117, %r2116, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2125, %r2118, %r2117, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2126, %r2119, %r2118, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2127, %r2131, %r2119, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2120, %r2130, %r2131, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2121, %r2129, %r2130, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2122, %r2128, %r2129, %r12;
	// inline asm
	mov.u32 	%r2116, 0;
	// inline asm
	prmt.b32 %r2123, %r2116, %r2128, %r12;
	// inline asm
	mov.u32 	%r2117, %r2116;
	mov.u32 	%r2118, %r2116;
	mov.u32 	%r2119, %r2116;
	bra.uni 	BB1_83;

BB1_20:
	setp.gt.s32	%p5, %r408, 11;
	@%p5 bra 	BB1_28;

	setp.gt.s32	%p11, %r408, 9;
	@%p11 bra 	BB1_25;

	setp.eq.s32	%p14, %r408, 8;
	@%p14 bra 	BB1_42;
	bra.uni 	BB1_23;

BB1_42:
	// inline asm
	prmt.b32 %r2135, %r8, %r9, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2134, %r7, %r8, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2133, %r6, %r7, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2132, %r5, %r6, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2139, %r4, %r5, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2138, %r3, %r4, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2137, %r2, %r3, %r28;
	// inline asm
	mov.u32 	%r2120, 0;
	// inline asm
	prmt.b32 %r2136, %r2120, %r2, %r28;
	// inline asm
	mov.u32 	%r2121, %r2120;
	mov.u32 	%r2122, %r2120;
	mov.u32 	%r2123, %r2120;
	mov.u32 	%r2124, %r2120;
	mov.u32 	%r2125, %r2120;
	mov.u32 	%r2126, %r2120;
	mov.u32 	%r2127, %r2120;
	bra.uni 	BB1_37;

BB1_56:
	setp.gt.s32	%p40, %r11, 5;
	@%p40 bra 	BB1_60;

	setp.eq.s32	%p43, %r11, 4;
	@%p43 bra 	BB1_92;
	bra.uni 	BB1_58;

BB1_92:
	mov.u32 	%r2132, 0;
	// inline asm
	prmt.b32 %r2124, %r2132, %r2132, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2125, %r2132, %r2132, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2126, %r2132, %r2132, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2127, %r2116, %r2132, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2120, %r2117, %r2116, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2121, %r2118, %r2117, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2122, %r2119, %r2118, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2123, %r2131, %r2119, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2116, %r2130, %r2131, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2117, %r2129, %r2130, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2118, %r2128, %r2129, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2119, %r2132, %r2128, %r12;
	// inline asm
	bra.uni 	BB1_65;

BB1_13:
	setp.gt.s32	%p17, %r408, 5;
	@%p17 bra 	BB1_17;

	setp.eq.s32	%p20, %r408, 4;
	@%p20 bra 	BB1_44;
	bra.uni 	BB1_15;

BB1_44:
	mov.u32 	%r2120, 0;
	// inline asm
	prmt.b32 %r2135, %r2120, %r2120, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2134, %r2120, %r2120, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2133, %r2120, %r2120, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2132, %r9, %r2120, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2139, %r8, %r9, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2138, %r7, %r8, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2137, %r6, %r7, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2136, %r5, %r6, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2143, %r4, %r5, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2142, %r3, %r4, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2141, %r2, %r3, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2140, %r2120, %r2, %r28;
	// inline asm
	mov.u32 	%r2121, %r2120;
	mov.u32 	%r2122, %r2120;
	mov.u32 	%r2123, %r2120;
	mov.u32 	%r2124, %r2120;
	mov.u32 	%r2125, %r2120;
	mov.u32 	%r2126, %r2120;
	mov.u32 	%r2127, %r2120;
	bra.uni 	BB1_38;

BB1_74:
	setp.gt.s32	%p29, %r11, 13;
	@%p29 bra 	BB1_78;

	setp.eq.s32	%p32, %r11, 12;
	@%p32 bra 	BB1_85;
	bra.uni 	BB1_76;

BB1_85:
	// inline asm
	prmt.b32 %r2124, %r2130, %r2131, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2125, %r2129, %r2130, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2126, %r2128, %r2129, %r12;
	// inline asm
	mov.u32 	%r2116, 0;
	// inline asm
	prmt.b32 %r2127, %r2116, %r2128, %r12;
	// inline asm
	mov.u32 	%r2117, %r2116;
	mov.u32 	%r2118, %r2116;
	mov.u32 	%r2119, %r2116;
	mov.u32 	%r2120, %r2116;
	bra.uni 	BB1_86;

BB1_28:
	setp.gt.s32	%p6, %r408, 13;
	@%p6 bra 	BB1_32;

	setp.eq.s32	%p9, %r408, 12;
	@%p9 bra 	BB1_40;
	bra.uni 	BB1_30;

BB1_40:
	// inline asm
	prmt.b32 %r2135, %r4, %r5, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2134, %r3, %r4, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2133, %r2, %r3, %r28;
	// inline asm
	mov.u32 	%r2120, 0;
	// inline asm
	prmt.b32 %r2132, %r2120, %r2, %r28;
	// inline asm
	mov.u32 	%r2121, %r2120;
	mov.u32 	%r2122, %r2120;
	mov.u32 	%r2123, %r2120;
	mov.u32 	%r2124, %r2120;
	mov.u32 	%r2125, %r2120;
	mov.u32 	%r2126, %r2120;
	mov.u32 	%r2127, %r2120;
	bra.uni 	BB1_36;

BB1_53:
	setp.eq.s32	%p46, %r11, 2;
	@%p46 bra 	BB1_93;
	bra.uni 	BB1_54;

BB1_93:
	mov.u32 	%r2132, 0;
	// inline asm
	prmt.b32 %r2124, %r2132, %r2132, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2125, %r2132, %r2132, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2126, %r2132, %r2132, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2127, %r2132, %r2132, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2120, %r2132, %r2132, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2121, %r2116, %r2132, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2122, %r2117, %r2116, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2123, %r2118, %r2117, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2116, %r2119, %r2118, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2117, %r2131, %r2119, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2118, %r2130, %r2131, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2119, %r2129, %r2130, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2131, %r2128, %r2129, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2130, %r2132, %r2128, %r12;
	// inline asm
	mov.u32 	%r2128, %r2132;
	mov.u32 	%r2129, %r2132;
	bra.uni 	BB1_95;

BB1_10:
	setp.eq.s32	%p23, %r408, 2;
	@%p23 bra 	BB1_45;
	bra.uni 	BB1_11;

BB1_45:
	mov.u32 	%r2120, 0;
	// inline asm
	prmt.b32 %r2135, %r2120, %r2120, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2134, %r2120, %r2120, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2133, %r2120, %r2120, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2132, %r2120, %r2120, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2139, %r2120, %r2120, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2138, %r9, %r2120, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2137, %r8, %r9, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2136, %r7, %r8, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2143, %r6, %r7, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2142, %r5, %r6, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2141, %r4, %r5, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2140, %r3, %r4, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2147, %r2, %r3, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2146, %r2120, %r2, %r28;
	// inline asm
	mov.u32 	%r2121, %r2120;
	mov.u32 	%r2122, %r2120;
	mov.u32 	%r2123, %r2120;
	mov.u32 	%r2124, %r2120;
	mov.u32 	%r2125, %r2120;
	mov.u32 	%r2126, %r2120;
	mov.u32 	%r2127, %r2120;
	mov.u32 	%r2144, %r2120;
	mov.u32 	%r2145, %r2120;
	bra.uni 	BB1_97;

BB1_71:
	setp.eq.s32	%p35, %r11, 10;
	@%p35 bra 	BB1_89;
	bra.uni 	BB1_72;

BB1_89:
	// inline asm
	prmt.b32 %r2124, %r2119, %r2118, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2125, %r2131, %r2119, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2126, %r2130, %r2131, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2127, %r2129, %r2130, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2120, %r2128, %r2129, %r12;
	// inline asm
	mov.u32 	%r2116, 0;
	// inline asm
	prmt.b32 %r2121, %r2116, %r2128, %r12;
	// inline asm
	mov.u32 	%r2117, %r2116;
	mov.u32 	%r2118, %r2116;
	mov.u32 	%r2119, %r2116;
	bra.uni 	BB1_87;

BB1_25:
	setp.eq.s32	%p12, %r408, 10;
	@%p12 bra 	BB1_41;
	bra.uni 	BB1_26;

BB1_41:
	// inline asm
	prmt.b32 %r2135, %r6, %r7, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2134, %r5, %r6, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2133, %r4, %r5, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2132, %r3, %r4, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2139, %r2, %r3, %r28;
	// inline asm
	mov.u32 	%r2120, 0;
	// inline asm
	prmt.b32 %r2138, %r2120, %r2, %r28;
	// inline asm
	mov.u32 	%r2121, %r2120;
	mov.u32 	%r2122, %r2120;
	mov.u32 	%r2123, %r2120;
	mov.u32 	%r2124, %r2120;
	mov.u32 	%r2125, %r2120;
	mov.u32 	%r2126, %r2120;
	mov.u32 	%r2127, %r2120;
	mov.u32 	%r2136, %r2120;
	mov.u32 	%r2137, %r2120;
	bra.uni 	BB1_37;

BB1_60:
	setp.eq.s32	%p41, %r11, 6;
	@%p41 bra 	BB1_91;
	bra.uni 	BB1_61;

BB1_91:
	mov.u32 	%r2132, 0;
	// inline asm
	prmt.b32 %r2124, %r2132, %r2132, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2125, %r2116, %r2132, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2126, %r2117, %r2116, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2127, %r2118, %r2117, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2120, %r2119, %r2118, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2121, %r2131, %r2119, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2122, %r2130, %r2131, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2123, %r2129, %r2130, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2116, %r2128, %r2129, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2117, %r2132, %r2128, %r12;
	// inline asm
	bra.uni 	BB1_63;

BB1_17:
	setp.eq.s32	%p18, %r408, 6;
	@%p18 bra 	BB1_43;
	bra.uni 	BB1_18;

BB1_43:
	mov.u32 	%r2120, 0;
	// inline asm
	prmt.b32 %r2135, %r2120, %r2120, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2134, %r9, %r2120, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2133, %r8, %r9, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2132, %r7, %r8, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2139, %r6, %r7, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2138, %r5, %r6, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2137, %r4, %r5, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2136, %r3, %r4, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2143, %r2, %r3, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2142, %r2120, %r2, %r28;
	// inline asm
	mov.u32 	%r2121, %r2120;
	mov.u32 	%r2122, %r2120;
	mov.u32 	%r2123, %r2120;
	mov.u32 	%r2124, %r2120;
	mov.u32 	%r2125, %r2120;
	mov.u32 	%r2126, %r2120;
	mov.u32 	%r2127, %r2120;
	mov.u32 	%r2140, %r2120;
	mov.u32 	%r2141, %r2120;
	bra.uni 	BB1_38;

BB1_78:
	setp.eq.s32	%p30, %r11, 14;
	@%p30 bra 	BB1_84;
	bra.uni 	BB1_79;

BB1_84:
	// inline asm
	prmt.b32 %r2124, %r2128, %r2129, %r12;
	// inline asm
	mov.u32 	%r2116, 0;
	// inline asm
	prmt.b32 %r2125, %r2116, %r2128, %r12;
	// inline asm
	mov.u32 	%r2117, %r2116;
	mov.u32 	%r2118, %r2116;
	mov.u32 	%r2119, %r2116;
	mov.u32 	%r2120, %r2116;
	mov.u32 	%r2121, %r2116;
	mov.u32 	%r2122, %r2116;
	mov.u32 	%r2123, %r2116;
	bra.uni 	BB1_81;

BB1_32:
	setp.eq.s32	%p7, %r408, 14;
	@%p7 bra 	BB1_39;
	bra.uni 	BB1_33;

BB1_39:
	// inline asm
	prmt.b32 %r2135, %r2, %r3, %r28;
	// inline asm
	mov.u32 	%r2120, 0;
	// inline asm
	prmt.b32 %r2134, %r2120, %r2, %r28;
	// inline asm
	mov.u32 	%r2121, %r2120;
	mov.u32 	%r2122, %r2120;
	mov.u32 	%r2123, %r2120;
	mov.u32 	%r2124, %r2120;
	mov.u32 	%r2125, %r2120;
	mov.u32 	%r2126, %r2120;
	mov.u32 	%r2127, %r2120;
	mov.u32 	%r2132, %r2120;
	mov.u32 	%r2133, %r2120;
	bra.uni 	BB1_36;

BB1_51:
	setp.eq.s32	%p49, %r11, 1;
	@%p49 bra 	BB1_52;
	bra.uni 	BB1_34;

BB1_52:
	mov.u32 	%r2132, 0;
	// inline asm
	prmt.b32 %r2124, %r2132, %r2132, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2125, %r2132, %r2132, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2126, %r2132, %r2132, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2127, %r2132, %r2132, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2120, %r2132, %r2132, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2121, %r2132, %r2132, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2122, %r2116, %r2132, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2123, %r2117, %r2116, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2116, %r2118, %r2117, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2117, %r2119, %r2118, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2118, %r2131, %r2119, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2119, %r2130, %r2131, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2131, %r2129, %r2130, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2130, %r2128, %r2129, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2129, %r2132, %r2128, %r12;
	// inline asm
	mov.u32 	%r2128, %r2132;
	bra.uni 	BB1_95;

BB1_8:
	setp.eq.s32	%p26, %r408, 1;
	@%p26 bra 	BB1_9;
	bra.uni 	BB1_34;

BB1_9:
	mov.u32 	%r2120, 0;
	// inline asm
	prmt.b32 %r2135, %r2120, %r2120, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2134, %r2120, %r2120, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2133, %r2120, %r2120, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2132, %r2120, %r2120, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2139, %r2120, %r2120, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2138, %r2120, %r2120, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2137, %r9, %r2120, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2136, %r8, %r9, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2143, %r7, %r8, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2142, %r6, %r7, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2141, %r5, %r6, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2140, %r4, %r5, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2147, %r3, %r4, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2146, %r2, %r3, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2145, %r2120, %r2, %r28;
	// inline asm
	mov.u32 	%r2121, %r2120;
	mov.u32 	%r2122, %r2120;
	mov.u32 	%r2123, %r2120;
	mov.u32 	%r2124, %r2120;
	mov.u32 	%r2125, %r2120;
	mov.u32 	%r2126, %r2120;
	mov.u32 	%r2127, %r2120;
	mov.u32 	%r2144, %r2120;
	bra.uni 	BB1_97;

BB1_69:
	setp.eq.s32	%p38, %r11, 9;
	@%p38 bra 	BB1_70;
	bra.uni 	BB1_34;

BB1_70:
	// inline asm
	prmt.b32 %r2124, %r2118, %r2117, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2125, %r2119, %r2118, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2126, %r2131, %r2119, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2127, %r2130, %r2131, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2120, %r2129, %r2130, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2121, %r2128, %r2129, %r12;
	// inline asm
	mov.u32 	%r2116, 0;
	// inline asm
	prmt.b32 %r2122, %r2116, %r2128, %r12;
	// inline asm
	mov.u32 	%r2117, %r2116;
	mov.u32 	%r2118, %r2116;
	mov.u32 	%r2119, %r2116;
	bra.uni 	BB1_88;

BB1_23:
	setp.eq.s32	%p15, %r408, 9;
	@%p15 bra 	BB1_24;
	bra.uni 	BB1_34;

BB1_24:
	// inline asm
	prmt.b32 %r2135, %r7, %r8, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2134, %r6, %r7, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2133, %r5, %r6, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2132, %r4, %r5, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2139, %r3, %r4, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2138, %r2, %r3, %r28;
	// inline asm
	mov.u32 	%r2120, 0;
	// inline asm
	prmt.b32 %r2137, %r2120, %r2, %r28;
	// inline asm
	mov.u32 	%r2121, %r2120;
	mov.u32 	%r2122, %r2120;
	mov.u32 	%r2123, %r2120;
	mov.u32 	%r2124, %r2120;
	mov.u32 	%r2125, %r2120;
	mov.u32 	%r2126, %r2120;
	mov.u32 	%r2127, %r2120;
	mov.u32 	%r2136, %r2120;
	bra.uni 	BB1_37;

BB1_58:
	setp.eq.s32	%p44, %r11, 5;
	@%p44 bra 	BB1_59;
	bra.uni 	BB1_34;

BB1_59:
	mov.u32 	%r2132, 0;
	// inline asm
	prmt.b32 %r2124, %r2132, %r2132, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2125, %r2132, %r2132, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2126, %r2116, %r2132, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2127, %r2117, %r2116, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2120, %r2118, %r2117, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2121, %r2119, %r2118, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2122, %r2131, %r2119, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2123, %r2130, %r2131, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2116, %r2129, %r2130, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2117, %r2128, %r2129, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2118, %r2132, %r2128, %r12;
	// inline asm
	bra.uni 	BB1_64;

BB1_15:
	setp.eq.s32	%p21, %r408, 5;
	@%p21 bra 	BB1_16;
	bra.uni 	BB1_34;

BB1_16:
	mov.u32 	%r2120, 0;
	// inline asm
	prmt.b32 %r2135, %r2120, %r2120, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2134, %r2120, %r2120, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2133, %r9, %r2120, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2132, %r8, %r9, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2139, %r7, %r8, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2138, %r6, %r7, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2137, %r5, %r6, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2136, %r4, %r5, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2143, %r3, %r4, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2142, %r2, %r3, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2141, %r2120, %r2, %r28;
	// inline asm
	mov.u32 	%r2121, %r2120;
	mov.u32 	%r2122, %r2120;
	mov.u32 	%r2123, %r2120;
	mov.u32 	%r2124, %r2120;
	mov.u32 	%r2125, %r2120;
	mov.u32 	%r2126, %r2120;
	mov.u32 	%r2127, %r2120;
	mov.u32 	%r2140, %r2120;
	bra.uni 	BB1_38;

BB1_76:
	setp.eq.s32	%p33, %r11, 13;
	@%p33 bra 	BB1_77;
	bra.uni 	BB1_34;

BB1_77:
	// inline asm
	prmt.b32 %r2124, %r2129, %r2130, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2125, %r2128, %r2129, %r12;
	// inline asm
	mov.u32 	%r2116, 0;
	// inline asm
	prmt.b32 %r2126, %r2116, %r2128, %r12;
	// inline asm
	mov.u32 	%r2117, %r2116;
	mov.u32 	%r2118, %r2116;
	mov.u32 	%r2119, %r2116;
	mov.u32 	%r2120, %r2116;
	mov.u32 	%r2121, %r2116;
	mov.u32 	%r2122, %r2116;
	mov.u32 	%r2123, %r2116;
	bra.uni 	BB1_82;

BB1_30:
	setp.eq.s32	%p10, %r408, 13;
	@%p10 bra 	BB1_31;
	bra.uni 	BB1_34;

BB1_31:
	// inline asm
	prmt.b32 %r2135, %r3, %r4, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2134, %r2, %r3, %r28;
	// inline asm
	mov.u32 	%r2120, 0;
	// inline asm
	prmt.b32 %r2133, %r2120, %r2, %r28;
	// inline asm
	mov.u32 	%r2121, %r2120;
	mov.u32 	%r2122, %r2120;
	mov.u32 	%r2123, %r2120;
	mov.u32 	%r2124, %r2120;
	mov.u32 	%r2125, %r2120;
	mov.u32 	%r2126, %r2120;
	mov.u32 	%r2127, %r2120;
	mov.u32 	%r2132, %r2120;
	bra.uni 	BB1_36;

BB1_54:
	setp.eq.s32	%p47, %r11, 3;
	@%p47 bra 	BB1_55;
	bra.uni 	BB1_34;

BB1_55:
	mov.u32 	%r2132, 0;
	// inline asm
	prmt.b32 %r2124, %r2132, %r2132, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2125, %r2132, %r2132, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2126, %r2132, %r2132, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2127, %r2132, %r2132, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2120, %r2116, %r2132, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2121, %r2117, %r2116, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2122, %r2118, %r2117, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2123, %r2119, %r2118, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2116, %r2131, %r2119, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2117, %r2130, %r2131, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2118, %r2129, %r2130, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2119, %r2128, %r2129, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2131, %r2132, %r2128, %r12;
	// inline asm
	mov.u32 	%r2128, %r2132;
	mov.u32 	%r2129, %r2132;
	mov.u32 	%r2130, %r2132;
	bra.uni 	BB1_95;

BB1_11:
	setp.eq.s32	%p24, %r408, 3;
	@%p24 bra 	BB1_12;
	bra.uni 	BB1_34;

BB1_12:
	mov.u32 	%r2120, 0;
	// inline asm
	prmt.b32 %r2135, %r2120, %r2120, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2134, %r2120, %r2120, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2133, %r2120, %r2120, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2132, %r2120, %r2120, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2139, %r9, %r2120, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2138, %r8, %r9, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2137, %r7, %r8, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2136, %r6, %r7, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2143, %r5, %r6, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2142, %r4, %r5, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2141, %r3, %r4, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2140, %r2, %r3, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2147, %r2120, %r2, %r28;
	// inline asm
	mov.u32 	%r2121, %r2120;
	mov.u32 	%r2122, %r2120;
	mov.u32 	%r2123, %r2120;
	mov.u32 	%r2124, %r2120;
	mov.u32 	%r2125, %r2120;
	mov.u32 	%r2126, %r2120;
	mov.u32 	%r2127, %r2120;
	mov.u32 	%r2144, %r2120;
	mov.u32 	%r2145, %r2120;
	mov.u32 	%r2146, %r2120;
	bra.uni 	BB1_97;

BB1_72:
	setp.eq.s32	%p36, %r11, 11;
	@%p36 bra 	BB1_73;
	bra.uni 	BB1_34;

BB1_73:
	// inline asm
	prmt.b32 %r2124, %r2131, %r2119, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2125, %r2130, %r2131, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2126, %r2129, %r2130, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2127, %r2128, %r2129, %r12;
	// inline asm
	mov.u32 	%r2116, 0;
	// inline asm
	prmt.b32 %r2120, %r2116, %r2128, %r12;
	// inline asm
	mov.u32 	%r2117, %r2116;
	mov.u32 	%r2118, %r2116;
	mov.u32 	%r2119, %r2116;

BB1_86:
	mov.u32 	%r2121, %r2116;

BB1_87:
	mov.u32 	%r2122, %r2116;

BB1_88:
	mov.u32 	%r2123, %r2116;
	bra.uni 	BB1_83;

BB1_26:
	setp.eq.s32	%p13, %r408, 11;
	@%p13 bra 	BB1_27;
	bra.uni 	BB1_34;

BB1_27:
	// inline asm
	prmt.b32 %r2135, %r5, %r6, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2134, %r4, %r5, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2133, %r3, %r4, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2132, %r2, %r3, %r28;
	// inline asm
	mov.u32 	%r2120, 0;
	// inline asm
	prmt.b32 %r2139, %r2120, %r2, %r28;
	// inline asm
	mov.u32 	%r2121, %r2120;
	mov.u32 	%r2122, %r2120;
	mov.u32 	%r2123, %r2120;
	mov.u32 	%r2124, %r2120;
	mov.u32 	%r2125, %r2120;
	mov.u32 	%r2126, %r2120;
	mov.u32 	%r2127, %r2120;
	mov.u32 	%r2136, %r2120;
	mov.u32 	%r2137, %r2120;
	mov.u32 	%r2138, %r2120;
	bra.uni 	BB1_37;

BB1_61:
	setp.eq.s32	%p42, %r11, 7;
	@%p42 bra 	BB1_62;
	bra.uni 	BB1_34;

BB1_62:
	mov.u32 	%r2132, 0;
	// inline asm
	prmt.b32 %r2124, %r2116, %r2132, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2125, %r2117, %r2116, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2126, %r2118, %r2117, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2127, %r2119, %r2118, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2120, %r2131, %r2119, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2121, %r2130, %r2131, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2122, %r2129, %r2130, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2123, %r2128, %r2129, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r2116, %r2132, %r2128, %r12;
	// inline asm
	mov.u32 	%r2117, %r2132;

BB1_63:
	mov.u32 	%r2118, %r2132;

BB1_64:
	mov.u32 	%r2119, %r2132;

BB1_65:
	mov.u32 	%r2128, %r2132;
	mov.u32 	%r2129, %r2132;
	mov.u32 	%r2130, %r2132;
	mov.u32 	%r2131, %r2132;

BB1_95:
	mov.u32 	%r2133, %r2132;
	mov.u32 	%r2134, %r2132;
	mov.u32 	%r2135, %r2132;
	mov.u32 	%r2136, %r2132;
	mov.u32 	%r2137, %r2132;
	mov.u32 	%r2138, %r2132;
	mov.u32 	%r2139, %r2132;
	bra.uni 	BB1_96;

BB1_18:
	setp.eq.s32	%p19, %r408, 7;
	@%p19 bra 	BB1_19;
	bra.uni 	BB1_34;

BB1_19:
	mov.u32 	%r2120, 0;
	// inline asm
	prmt.b32 %r2135, %r9, %r2120, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2134, %r8, %r9, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2133, %r7, %r8, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2132, %r6, %r7, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2139, %r5, %r6, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2138, %r4, %r5, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2137, %r3, %r4, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2136, %r2, %r3, %r28;
	// inline asm
	// inline asm
	prmt.b32 %r2143, %r2120, %r2, %r28;
	// inline asm
	mov.u32 	%r2121, %r2120;
	mov.u32 	%r2122, %r2120;
	mov.u32 	%r2123, %r2120;
	mov.u32 	%r2124, %r2120;
	mov.u32 	%r2125, %r2120;
	mov.u32 	%r2126, %r2120;
	mov.u32 	%r2127, %r2120;
	mov.u32 	%r2140, %r2120;
	mov.u32 	%r2141, %r2120;
	mov.u32 	%r2142, %r2120;
	bra.uni 	BB1_38;

BB1_79:
	setp.ne.s32	%p31, %r11, 15;
	@%p31 bra 	BB1_34;

	mov.u32 	%r2116, 0;
	// inline asm
	prmt.b32 %r2124, %r2116, %r2128, %r12;
	// inline asm
	mov.u32 	%r2117, %r2116;
	mov.u32 	%r2118, %r2116;
	mov.u32 	%r2119, %r2116;
	mov.u32 	%r2120, %r2116;
	mov.u32 	%r2121, %r2116;
	mov.u32 	%r2122, %r2116;
	mov.u32 	%r2123, %r2116;
	mov.u32 	%r2125, %r2116;

BB1_81:
	mov.u32 	%r2126, %r2116;

BB1_82:
	mov.u32 	%r2127, %r2116;

BB1_83:
	mov.u32 	%r2128, %r2116;
	mov.u32 	%r2129, %r2116;
	mov.u32 	%r2130, %r2116;
	mov.u32 	%r2131, %r2116;
	mov.u32 	%r2132, %r2116;
	mov.u32 	%r2133, %r2116;
	mov.u32 	%r2134, %r2116;
	mov.u32 	%r2135, %r2116;
	mov.u32 	%r2136, %r2116;
	mov.u32 	%r2137, %r2116;
	mov.u32 	%r2138, %r2116;
	mov.u32 	%r2139, %r2116;
	bra.uni 	BB1_96;

BB1_33:
	setp.ne.s32	%p8, %r408, 15;
	@%p8 bra 	BB1_34;

	mov.u32 	%r2120, 0;
	// inline asm
	prmt.b32 %r2135, %r2120, %r2, %r28;
	// inline asm
	mov.u32 	%r2121, %r2120;
	mov.u32 	%r2122, %r2120;
	mov.u32 	%r2123, %r2120;
	mov.u32 	%r2124, %r2120;
	mov.u32 	%r2125, %r2120;
	mov.u32 	%r2126, %r2120;
	mov.u32 	%r2127, %r2120;
	mov.u32 	%r2132, %r2120;
	mov.u32 	%r2133, %r2120;
	mov.u32 	%r2134, %r2120;

BB1_36:
	mov.u32 	%r2136, %r2120;
	mov.u32 	%r2137, %r2120;
	mov.u32 	%r2138, %r2120;
	mov.u32 	%r2139, %r2120;

BB1_37:
	mov.u32 	%r2140, %r2120;
	mov.u32 	%r2141, %r2120;
	mov.u32 	%r2142, %r2120;
	mov.u32 	%r2143, %r2120;

BB1_38:
	mov.u32 	%r2144, %r2120;
	mov.u32 	%r2145, %r2120;
	mov.u32 	%r2146, %r2120;
	mov.u32 	%r2147, %r2120;
	bra.uni 	BB1_97;

BB1_34:
	mov.u32 	%r2121, %r2120;
	mov.u32 	%r2122, %r2120;
	mov.u32 	%r2123, %r2120;
	mov.u32 	%r2124, %r2120;
	mov.u32 	%r2125, %r2120;
	mov.u32 	%r2126, %r2120;
	mov.u32 	%r2127, %r2120;
	mov.u32 	%r2132, %r2120;
	mov.u32 	%r2133, %r2120;
	mov.u32 	%r2134, %r2120;
	mov.u32 	%r2135, %r2120;
	mov.u32 	%r2136, %r2120;
	mov.u32 	%r2137, %r2120;
	mov.u32 	%r2138, %r2120;
	mov.u32 	%r2139, %r2120;

BB1_96:
	mov.u32 	%r2140, %r6;
	mov.u32 	%r2141, %r7;
	mov.u32 	%r2142, %r8;
	mov.u32 	%r2143, %r9;
	mov.u32 	%r2144, %r2;
	mov.u32 	%r2145, %r3;
	mov.u32 	%r2146, %r4;
	mov.u32 	%r2147, %r5;

BB1_97:
	or.b32  	%r333, %r2144, %r2128;
	or.b32  	%r2015, %r2147, %r2131;
	or.b32  	%r2016, %r2146, %r2130;
	or.b32  	%r2017, %r2145, %r2129;
	st.local.v4.u32 	[%rd1], {%r333, %r2017, %r2016, %r2015};
	or.b32  	%r2018, %r2143, %r2116;
	or.b32  	%r2019, %r2142, %r2117;
	or.b32  	%r2020, %r2141, %r2118;
	or.b32  	%r2021, %r2140, %r2119;
	st.local.v4.u32 	[%rd1+16], {%r2021, %r2020, %r2019, %r2018};
	or.b32  	%r2022, %r2139, %r2120;
	or.b32  	%r2023, %r2138, %r2121;
	or.b32  	%r2024, %r2137, %r2122;
	or.b32  	%r2025, %r2136, %r2123;
	st.local.v4.u32 	[%rd1+32], {%r2025, %r2024, %r2023, %r2022};
	or.b32  	%r2026, %r2135, %r2124;
	or.b32  	%r2027, %r2134, %r2125;
	or.b32  	%r2028, %r2133, %r2126;
	or.b32  	%r2029, %r2132, %r2127;
	st.local.v4.u32 	[%rd1+48], {%r2029, %r2028, %r2027, %r2026};
	setp.eq.s32	%p50, %r19, 0;
	mov.u32 	%r2154, %r13;
	@%p50 bra 	BB1_99;

	xor.b32  	%r2030, %r333, %r13;
	and.b32  	%r2031, %r2030, 255;
	mul.wide.u32 	%rd29, %r2031, 4;
	mov.u64 	%rd30, crc32tab;
	add.s64 	%rd31, %rd30, %rd29;
	ld.const.u32 	%r2032, [%rd31];
	xor.b32  	%r2154, %r2032, %r16;

BB1_99:
	setp.lt.u32	%p51, %r19, 2;
	@%p51 bra 	BB1_101;

	shr.u32 	%r2033, %r333, 8;
	xor.b32  	%r2034, %r2033, %r2154;
	and.b32  	%r2035, %r2034, 255;
	mul.wide.u32 	%rd32, %r2035, 4;
	mov.u64 	%rd33, crc32tab;
	add.s64 	%rd34, %rd33, %rd32;
	ld.const.u32 	%r2036, [%rd34];
	shr.u32 	%r2037, %r2154, 8;
	xor.b32  	%r2154, %r2036, %r2037;

BB1_101:
	setp.lt.u32	%p52, %r19, 3;
	@%p52 bra 	BB1_103;

	shr.u32 	%r2038, %r333, 16;
	xor.b32  	%r2039, %r2038, %r2154;
	and.b32  	%r2040, %r2039, 255;
	mul.wide.u32 	%rd35, %r2040, 4;
	mov.u64 	%rd36, crc32tab;
	add.s64 	%rd37, %rd36, %rd35;
	ld.const.u32 	%r2041, [%rd37];
	shr.u32 	%r2042, %r2154, 8;
	xor.b32  	%r2154, %r2041, %r2042;

BB1_103:
	setp.lt.u32	%p53, %r19, 4;
	@%p53 bra 	BB1_105;

	shr.u32 	%r2043, %r333, 24;
	and.b32  	%r2044, %r2154, 255;
	xor.b32  	%r2045, %r2043, %r2044;
	mul.wide.u32 	%rd38, %r2045, 4;
	mov.u64 	%rd39, crc32tab;
	add.s64 	%rd40, %rd39, %rd38;
	ld.const.u32 	%r2046, [%rd40];
	shr.u32 	%r2047, %r2154, 8;
	xor.b32  	%r2154, %r2046, %r2047;

BB1_105:
	mov.u32 	%r2152, 1;
	setp.lt.u32	%p54, %r19, 5;
	mov.u32 	%r2153, %r387;
	@%p54 bra 	BB1_115;

BB1_106:
	add.s32 	%r2050, %r2153, 1;
	setp.gt.u32	%p55, %r2050, %r19;
	mul.wide.u32 	%rd41, %r2152, 4;
	add.s64 	%rd4, %rd1, %rd41;
	@%p55 bra 	BB1_108;

	ld.local.u32 	%r2051, [%rd4];
	xor.b32  	%r2052, %r2051, %r2154;
	and.b32  	%r2053, %r2052, 255;
	mul.wide.u32 	%rd42, %r2053, 4;
	mov.u64 	%rd43, crc32tab;
	add.s64 	%rd44, %rd43, %rd42;
	ld.const.u32 	%r2054, [%rd44];
	shr.u32 	%r2055, %r2154, 8;
	xor.b32  	%r2154, %r2054, %r2055;

BB1_108:
	add.s32 	%r2056, %r2153, 2;
	setp.gt.u32	%p56, %r2056, %r19;
	@%p56 bra 	BB1_110;

	ld.local.u32 	%r2057, [%rd4];
	shr.u32 	%r2058, %r2057, 8;
	xor.b32  	%r2059, %r2058, %r2154;
	and.b32  	%r2060, %r2059, 255;
	mul.wide.u32 	%rd45, %r2060, 4;
	mov.u64 	%rd46, crc32tab;
	add.s64 	%rd47, %rd46, %rd45;
	ld.const.u32 	%r2061, [%rd47];
	shr.u32 	%r2062, %r2154, 8;
	xor.b32  	%r2154, %r2061, %r2062;

BB1_110:
	add.s32 	%r2063, %r2153, 3;
	setp.gt.u32	%p57, %r2063, %r19;
	@%p57 bra 	BB1_112;

	ld.local.u16 	%r2064, [%rd4+2];
	xor.b32  	%r2065, %r2064, %r2154;
	and.b32  	%r2066, %r2065, 255;
	mul.wide.u32 	%rd48, %r2066, 4;
	mov.u64 	%rd49, crc32tab;
	add.s64 	%rd50, %rd49, %rd48;
	ld.const.u32 	%r2067, [%rd50];
	shr.u32 	%r2068, %r2154, 8;
	xor.b32  	%r2154, %r2067, %r2068;

BB1_112:
	add.s32 	%r2153, %r2153, 4;
	setp.gt.u32	%p58, %r2153, %r19;
	@%p58 bra 	BB1_114;

	ld.local.u8 	%r2069, [%rd4+3];
	and.b32  	%r2070, %r2154, 255;
	xor.b32  	%r2071, %r2069, %r2070;
	mul.wide.u32 	%rd51, %r2071, 4;
	mov.u64 	%rd52, crc32tab;
	add.s64 	%rd53, %rd52, %rd51;
	ld.const.u32 	%r2072, [%rd53];
	shr.u32 	%r2073, %r2154, 8;
	xor.b32  	%r2154, %r2072, %r2073;

BB1_114:
	add.s32 	%r2152, %r2152, 1;
	setp.lt.u32	%p59, %r2153, %r19;
	@%p59 bra 	BB1_106;

BB1_115:
	ld.param.u64 	%rd65, [m11500_m04_param_6];
	not.b32 	%r356, %r2154;
	shr.u32 	%r2074, %r356, %r14;
	and.b32  	%r2075, %r2074, %r371;
	mul.wide.u32 	%rd54, %r2075, 4;
	add.s64 	%rd55, %rd65, %rd54;
	and.b32  	%r2076, %r356, 31;
	mov.u32 	%r2077, 1;
	shl.b32 	%r357, %r2077, %r2076;
	ld.global.u32 	%r2078, [%rd55];
	and.b32  	%r2079, %r2078, %r357;
	setp.eq.s32	%p60, %r2079, 0;
	@%p60 bra 	BB1_136;

	ld.param.u64 	%rd66, [m11500_m04_param_7];
	ld.global.u32 	%r2080, [%rd66];
	and.b32  	%r2081, %r2080, 1;
	setp.eq.b32	%p61, %r2081, 1;
	@!%p61 bra 	BB1_136;
	bra.uni 	BB1_117;

BB1_117:
	ld.param.u64 	%rd67, [m11500_m04_param_8];
	ld.global.u32 	%r2082, [%rd67];
	and.b32  	%r2083, %r2082, 1;
	setp.eq.b32	%p62, %r2083, 1;
	@!%p62 bra 	BB1_136;
	bra.uni 	BB1_118;

BB1_118:
	ld.param.u64 	%rd68, [m11500_m04_param_9];
	ld.global.u32 	%r2084, [%rd68];
	and.b32  	%r2085, %r2084, 1;
	setp.eq.b32	%p63, %r2085, 1;
	@!%p63 bra 	BB1_136;
	bra.uni 	BB1_119;

BB1_119:
	ld.param.u64 	%rd70, [m11500_m04_param_10];
	shr.u32 	%r2086, %r356, %r15;
	and.b32  	%r2087, %r2086, %r371;
	mul.wide.u32 	%rd56, %r2087, 4;
	add.s64 	%rd57, %rd70, %rd56;
	ld.global.u32 	%r2088, [%rd57];
	and.b32  	%r2089, %r2088, %r357;
	setp.eq.s32	%p64, %r2089, 0;
	@%p64 bra 	BB1_136;

	ld.param.u64 	%rd71, [m11500_m04_param_11];
	ld.global.u32 	%r2090, [%rd71];
	and.b32  	%r2091, %r2090, 1;
	setp.eq.b32	%p65, %r2091, 1;
	@!%p65 bra 	BB1_136;
	bra.uni 	BB1_121;

BB1_121:
	ld.global.u32 	%r2092, [%rd14];
	and.b32  	%r2093, %r2092, 1;
	setp.eq.b32	%p66, %r2093, 1;
	@!%p66 bra 	BB1_136;
	bra.uni 	BB1_122;

BB1_122:
	ld.global.u32 	%r2094, [%rd15];
	and.b32  	%r2095, %r2094, 1;
	setp.eq.b32	%p67, %r2095, 1;
	@!%p67 bra 	BB1_136;
	bra.uni 	BB1_123;

BB1_123:
	setp.eq.s32	%p68, %r376, 0;
	mov.u32 	%r2160, 0;
	mov.u32 	%r2162, -1;
	mov.u32 	%r2159, %r376;
	@%p68 bra 	BB1_131;

BB1_124:
	shr.u32 	%r360, %r2159, 1;
	add.s32 	%r2162, %r360, %r2160;
	cvt.u64.u32	%rd58, %r2162;
	add.s64 	%rd59, %rd58, %rd3;
	shl.b64 	%rd60, %rd59, 4;
	add.s64 	%rd5, %rd17, %rd60;
	ld.global.u32 	%r2099, [%rd5+12];
	mov.u32 	%r2161, -1;
	setp.ne.s32	%p69, %r2099, 0;
	@%p69 bra 	BB1_129;

	ld.global.u32 	%r2101, [%rd5+8];
	setp.ne.s32	%p70, %r2101, 0;
	@%p70 bra 	BB1_129;

	ld.global.u32 	%r2103, [%rd5+4];
	setp.ne.s32	%p71, %r2103, 0;
	@%p71 bra 	BB1_129;

	mov.u32 	%r2161, 1;
	ld.global.u32 	%r362, [%rd5];
	setp.lt.u32	%p72, %r362, %r356;
	@%p72 bra 	BB1_129;

	setp.gt.u32	%p73, %r362, %r356;
	selp.b32	%r2161, -1, 0, %p73;

BB1_129:
	add.s32 	%r2105, %r360, 1;
	setp.gt.s32	%p74, %r2161, 0;
	selp.b32	%r2106, %r2105, 0, %p74;
	add.s32 	%r2160, %r2106, %r2160;
	selp.b32	%r2107, -1, 0, %p74;
	add.s32 	%r2108, %r2107, %r2159;
	shr.u32 	%r2159, %r2108, 1;
	setp.eq.s32	%p75, %r2161, 0;
	@%p75 bra 	BB1_131;

	mov.u32 	%r2162, -1;
	setp.ne.s32	%p76, %r2159, 0;
	@%p76 bra 	BB1_124;

BB1_131:
	setp.eq.s32	%p77, %r2162, -1;
	@%p77 bra 	BB1_136;

	add.s32 	%r368, %r2162, %r377;
	mul.wide.u32 	%rd61, %r368, 4;
	add.s64 	%rd62, %rd18, %rd61;
	atom.global.add.u32 	%r2110, [%rd62], 1;
	setp.ne.s32	%p78, %r2110, 0;
	@%p78 bra 	BB1_136;

	atom.global.add.u32 	%r369, [%rd20], 1;
	setp.lt.u32	%p79, %r369, %r376;
	@%p79 bra 	BB1_135;
	bra.uni 	BB1_134;

BB1_135:
	mul.wide.u32 	%rd63, %r369, 20;
	add.s64 	%rd64, %rd16, %rd63;
	st.global.u32 	[%rd64], %r374;
	st.global.u32 	[%rd64+4], %r2162;
	st.global.u32 	[%rd64+8], %r368;
	st.global.u32 	[%rd64+12], %r1;
	st.global.u32 	[%rd64+16], %r2115;
	bra.uni 	BB1_136;

BB1_134:
	atom.global.add.u32 	%r2111, [%rd20], -1;

BB1_136:
	add.s32 	%r2115, %r2115, 1;
	setp.lt.u32	%p80, %r2115, %r375;
	@%p80 bra 	BB1_3;

BB1_137:
	ret;
}

	// .globl	m11500_m08
.entry m11500_m08(
	.param .u64 .ptr .global .align 4 m11500_m08_param_0,
	.param .u64 .ptr .global .align 4 m11500_m08_param_1,
	.param .u64 .ptr .global .align 4 m11500_m08_param_2,
	.param .u64 .ptr .global .align 4 m11500_m08_param_3,
	.param .u64 .ptr .global .align 1 m11500_m08_param_4,
	.param .u64 .ptr .global .align 1 m11500_m08_param_5,
	.param .u64 .ptr .global .align 4 m11500_m08_param_6,
	.param .u64 .ptr .global .align 4 m11500_m08_param_7,
	.param .u64 .ptr .global .align 4 m11500_m08_param_8,
	.param .u64 .ptr .global .align 4 m11500_m08_param_9,
	.param .u64 .ptr .global .align 4 m11500_m08_param_10,
	.param .u64 .ptr .global .align 4 m11500_m08_param_11,
	.param .u64 .ptr .global .align 4 m11500_m08_param_12,
	.param .u64 .ptr .global .align 4 m11500_m08_param_13,
	.param .u64 .ptr .global .align 4 m11500_m08_param_14,
	.param .u64 .ptr .global .align 4 m11500_m08_param_15,
	.param .u64 .ptr .global .align 4 m11500_m08_param_16,
	.param .u64 .ptr .global .align 4 m11500_m08_param_17,
	.param .u64 .ptr .global .align 1 m11500_m08_param_18,
	.param .u64 .ptr .global .align 4 m11500_m08_param_19,
	.param .u64 .ptr .global .align 4 m11500_m08_param_20,
	.param .u64 .ptr .global .align 4 m11500_m08_param_21,
	.param .u64 .ptr .global .align 4 m11500_m08_param_22,
	.param .u64 .ptr .global .align 4 m11500_m08_param_23,
	.param .u32 m11500_m08_param_24,
	.param .u32 m11500_m08_param_25,
	.param .u32 m11500_m08_param_26,
	.param .u32 m11500_m08_param_27,
	.param .u32 m11500_m08_param_28,
	.param .u32 m11500_m08_param_29,
	.param .u32 m11500_m08_param_30,
	.param .u32 m11500_m08_param_31,
	.param .u32 m11500_m08_param_32,
	.param .u32 m11500_m08_param_33,
	.param .u64 m11500_m08_param_34
)
{



	ret;
}

	// .globl	m11500_m16
.entry m11500_m16(
	.param .u64 .ptr .global .align 4 m11500_m16_param_0,
	.param .u64 .ptr .global .align 4 m11500_m16_param_1,
	.param .u64 .ptr .global .align 4 m11500_m16_param_2,
	.param .u64 .ptr .global .align 4 m11500_m16_param_3,
	.param .u64 .ptr .global .align 1 m11500_m16_param_4,
	.param .u64 .ptr .global .align 1 m11500_m16_param_5,
	.param .u64 .ptr .global .align 4 m11500_m16_param_6,
	.param .u64 .ptr .global .align 4 m11500_m16_param_7,
	.param .u64 .ptr .global .align 4 m11500_m16_param_8,
	.param .u64 .ptr .global .align 4 m11500_m16_param_9,
	.param .u64 .ptr .global .align 4 m11500_m16_param_10,
	.param .u64 .ptr .global .align 4 m11500_m16_param_11,
	.param .u64 .ptr .global .align 4 m11500_m16_param_12,
	.param .u64 .ptr .global .align 4 m11500_m16_param_13,
	.param .u64 .ptr .global .align 4 m11500_m16_param_14,
	.param .u64 .ptr .global .align 4 m11500_m16_param_15,
	.param .u64 .ptr .global .align 4 m11500_m16_param_16,
	.param .u64 .ptr .global .align 4 m11500_m16_param_17,
	.param .u64 .ptr .global .align 1 m11500_m16_param_18,
	.param .u64 .ptr .global .align 4 m11500_m16_param_19,
	.param .u64 .ptr .global .align 4 m11500_m16_param_20,
	.param .u64 .ptr .global .align 4 m11500_m16_param_21,
	.param .u64 .ptr .global .align 4 m11500_m16_param_22,
	.param .u64 .ptr .global .align 4 m11500_m16_param_23,
	.param .u32 m11500_m16_param_24,
	.param .u32 m11500_m16_param_25,
	.param .u32 m11500_m16_param_26,
	.param .u32 m11500_m16_param_27,
	.param .u32 m11500_m16_param_28,
	.param .u32 m11500_m16_param_29,
	.param .u32 m11500_m16_param_30,
	.param .u32 m11500_m16_param_31,
	.param .u32 m11500_m16_param_32,
	.param .u32 m11500_m16_param_33,
	.param .u64 m11500_m16_param_34
)
{



	ret;
}

	// .globl	m11500_s04
.entry m11500_s04(
	.param .u64 .ptr .global .align 4 m11500_s04_param_0,
	.param .u64 .ptr .global .align 4 m11500_s04_param_1,
	.param .u64 .ptr .global .align 4 m11500_s04_param_2,
	.param .u64 .ptr .global .align 4 m11500_s04_param_3,
	.param .u64 .ptr .global .align 1 m11500_s04_param_4,
	.param .u64 .ptr .global .align 1 m11500_s04_param_5,
	.param .u64 .ptr .global .align 4 m11500_s04_param_6,
	.param .u64 .ptr .global .align 4 m11500_s04_param_7,
	.param .u64 .ptr .global .align 4 m11500_s04_param_8,
	.param .u64 .ptr .global .align 4 m11500_s04_param_9,
	.param .u64 .ptr .global .align 4 m11500_s04_param_10,
	.param .u64 .ptr .global .align 4 m11500_s04_param_11,
	.param .u64 .ptr .global .align 4 m11500_s04_param_12,
	.param .u64 .ptr .global .align 4 m11500_s04_param_13,
	.param .u64 .ptr .global .align 4 m11500_s04_param_14,
	.param .u64 .ptr .global .align 4 m11500_s04_param_15,
	.param .u64 .ptr .global .align 4 m11500_s04_param_16,
	.param .u64 .ptr .global .align 4 m11500_s04_param_17,
	.param .u64 .ptr .global .align 1 m11500_s04_param_18,
	.param .u64 .ptr .global .align 4 m11500_s04_param_19,
	.param .u64 .ptr .global .align 4 m11500_s04_param_20,
	.param .u64 .ptr .global .align 4 m11500_s04_param_21,
	.param .u64 .ptr .global .align 4 m11500_s04_param_22,
	.param .u64 .ptr .global .align 4 m11500_s04_param_23,
	.param .u32 m11500_s04_param_24,
	.param .u32 m11500_s04_param_25,
	.param .u32 m11500_s04_param_26,
	.param .u32 m11500_s04_param_27,
	.param .u32 m11500_s04_param_28,
	.param .u32 m11500_s04_param_29,
	.param .u32 m11500_s04_param_30,
	.param .u32 m11500_s04_param_31,
	.param .u32 m11500_s04_param_32,
	.param .u32 m11500_s04_param_33,
	.param .u64 m11500_s04_param_34
)
{
	.local .align 16 .b8 	__local_depot4[64];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<64>;
	.reg .b32 	%r<2105>;
	.reg .b64 	%rd<51>;


	mov.u64 	%rd50, __local_depot4;
	cvta.local.u64 	%SP, %rd50;
	ld.param.u64 	%rd5, [m11500_s04_param_0];
	ld.param.u64 	%rd6, [m11500_s04_param_2];
	ld.param.u64 	%rd7, [m11500_s04_param_14];
	ld.param.u64 	%rd8, [m11500_s04_param_15];
	ld.param.u64 	%rd9, [m11500_s04_param_16];
	ld.param.u64 	%rd10, [m11500_s04_param_17];
	ld.param.u64 	%rd11, [m11500_s04_param_19];
	ld.param.u32 	%r357, [m11500_s04_param_27];
	ld.param.u32 	%r358, [m11500_s04_param_30];
	ld.param.u32 	%r359, [m11500_s04_param_31];
	ld.param.u32 	%r360, [m11500_s04_param_32];
	ld.param.u32 	%r361, [m11500_s04_param_33];
	ld.param.u64 	%rd12, [m11500_s04_param_34];
	add.u64 	%rd13, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd13;
	mov.u32 	%r362, %ctaid.x;
	mov.u32 	%r363, %ntid.x;
	mov.b32	%r364, %envreg3;
	mad.lo.s32 	%r365, %r362, %r363, %r364;
	mov.u32 	%r366, %tid.x;
	add.s32 	%r1, %r365, %r366;
	cvt.s64.s32	%rd2, %r1;
	setp.ge.u64	%p1, %rd2, %rd12;
	@%p1 bra 	BB4_123;

	mul.lo.s64 	%rd14, %rd2, 260;
	add.s64 	%rd15, %rd5, %rd14;
	ld.global.u32 	%r2, [%rd15];
	ld.global.u32 	%r3, [%rd15+4];
	ld.global.u32 	%r4, [%rd15+8];
	ld.global.u32 	%r5, [%rd15+12];
	ld.global.u32 	%r6, [%rd15+16];
	ld.global.u32 	%r7, [%rd15+20];
	ld.global.u32 	%r8, [%rd15+24];
	ld.global.u32 	%r9, [%rd15+28];
	ld.global.u32 	%r10, [%rd15+256];
	setp.eq.s32	%p2, %r358, 0;
	@%p2 bra 	BB4_123;

	mul.wide.u32 	%rd16, %r360, 16;
	add.s64 	%rd17, %rd8, %rd16;
	ld.global.u32 	%r11, [%rd17];
	mul.wide.u32 	%rd18, %r357, 564;
	add.s64 	%rd19, %rd10, %rd18;
	ld.global.u32 	%r368, [%rd19];
	and.b32  	%r369, %r10, 3;
	mov.u32 	%r370, 4;
	sub.s32 	%r371, %r370, %r369;
	shr.u32 	%r12, %r10, 2;
	shl.b32 	%r372, %r371, 2;
	mov.u32 	%r373, 1985229328;
	shr.u32 	%r374, %r373, %r372;
	and.b32  	%r13, %r374, 65535;
	not.b32 	%r14, %r368;
	mul.wide.u32 	%rd20, %r360, 4;
	add.s64 	%rd3, %rd9, %rd20;
	shr.u32 	%r15, %r14, 8;
	mov.u32 	%r2061, 0;

BB4_3:
	mul.wide.u32 	%rd21, %r2061, 260;
	add.s64 	%rd22, %rd6, %rd21;
	ld.global.u32 	%r17, [%rd22+256];
	add.s32 	%r18, %r17, %r10;
	ld.global.u32 	%r2065, [%rd22];
	ld.global.u32 	%r2064, [%rd22+4];
	ld.global.u32 	%r2063, [%rd22+8];
	ld.global.u32 	%r2062, [%rd22+12];
	ld.global.u32 	%r2069, [%rd22+16];
	ld.global.u32 	%r2068, [%rd22+20];
	ld.global.u32 	%r2067, [%rd22+24];
	ld.global.u32 	%r2066, [%rd22+28];
	setp.eq.s32	%p3, %r361, 10001;
	@%p3 bra 	BB4_47;
	bra.uni 	BB4_4;

BB4_47:
	mov.u32 	%r2070, 0;
	setp.gt.s32	%p27, %r12, 7;
	@%p27 bra 	BB4_65;

	setp.gt.s32	%p39, %r12, 3;
	@%p39 bra 	BB4_56;

	setp.gt.s32	%p45, %r12, 1;
	@%p45 bra 	BB4_53;

	setp.eq.s32	%p48, %r12, 0;
	@%p48 bra 	BB4_96;
	bra.uni 	BB4_51;

BB4_96:
	mov.u32 	%r2078, 0;
	// inline asm
	prmt.b32 %r2074, %r2078, %r2078, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2075, %r2078, %r2078, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2076, %r2078, %r2078, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2077, %r2078, %r2078, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2070, %r2078, %r2078, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2071, %r2078, %r2078, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2072, %r2078, %r2078, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2073, %r2066, %r2078, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2066, %r2067, %r2066, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2067, %r2068, %r2067, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2068, %r2069, %r2068, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2069, %r2062, %r2069, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2062, %r2063, %r2062, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2063, %r2064, %r2063, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2064, %r2065, %r2064, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2065, %r2078, %r2065, %r13;
	// inline asm
	bra.uni 	BB4_97;

BB4_4:
	and.b32  	%r392, %r17, 3;
	sub.s32 	%r394, %r370, %r392;
	shl.b32 	%r395, %r394, 2;
	shr.u32 	%r397, %r373, %r395;
	and.b32  	%r27, %r397, 65535;
	shr.u32 	%r391, %r17, 2;
	mov.u32 	%r2070, 0;
	setp.gt.s32	%p4, %r391, 7;
	@%p4 bra 	BB4_20;

	setp.gt.s32	%p16, %r391, 3;
	@%p16 bra 	BB4_13;

	setp.gt.s32	%p22, %r391, 1;
	@%p22 bra 	BB4_10;

	setp.eq.s32	%p25, %r391, 0;
	@%p25 bra 	BB4_46;
	bra.uni 	BB4_8;

BB4_46:
	mov.u32 	%r2070, 0;
	// inline asm
	prmt.b32 %r2081, %r2070, %r2070, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2080, %r2070, %r2070, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2079, %r2070, %r2070, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2078, %r2070, %r2070, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2085, %r2070, %r2070, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2084, %r2070, %r2070, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2083, %r2070, %r2070, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2082, %r9, %r2070, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2089, %r8, %r9, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2088, %r7, %r8, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2087, %r6, %r7, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2086, %r5, %r6, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2093, %r4, %r5, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2092, %r3, %r4, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2091, %r2, %r3, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2090, %r2070, %r2, %r27;
	// inline asm
	mov.u32 	%r2071, %r2070;
	mov.u32 	%r2072, %r2070;
	mov.u32 	%r2073, %r2070;
	mov.u32 	%r2074, %r2070;
	mov.u32 	%r2075, %r2070;
	mov.u32 	%r2076, %r2070;
	mov.u32 	%r2077, %r2070;
	bra.uni 	BB4_99;

BB4_65:
	setp.gt.s32	%p28, %r12, 11;
	@%p28 bra 	BB4_73;

	setp.gt.s32	%p34, %r12, 9;
	@%p34 bra 	BB4_70;

	setp.eq.s32	%p37, %r12, 8;
	@%p37 bra 	BB4_89;
	bra.uni 	BB4_68;

BB4_89:
	// inline asm
	prmt.b32 %r2074, %r2067, %r2066, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2075, %r2068, %r2067, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2076, %r2069, %r2068, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2077, %r2062, %r2069, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2070, %r2063, %r2062, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2071, %r2064, %r2063, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2072, %r2065, %r2064, %r13;
	// inline asm
	mov.u32 	%r2062, 0;
	// inline asm
	prmt.b32 %r2073, %r2062, %r2065, %r13;
	// inline asm
	mov.u32 	%r2063, %r2062;
	mov.u32 	%r2064, %r2062;
	mov.u32 	%r2065, %r2062;
	mov.u32 	%r2066, %r2062;
	mov.u32 	%r2067, %r2062;
	mov.u32 	%r2068, %r2062;
	mov.u32 	%r2069, %r2062;
	bra.uni 	BB4_82;

BB4_20:
	setp.gt.s32	%p5, %r391, 11;
	@%p5 bra 	BB4_28;

	setp.gt.s32	%p11, %r391, 9;
	@%p11 bra 	BB4_25;

	setp.eq.s32	%p14, %r391, 8;
	@%p14 bra 	BB4_42;
	bra.uni 	BB4_23;

BB4_42:
	// inline asm
	prmt.b32 %r2081, %r8, %r9, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2080, %r7, %r8, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2079, %r6, %r7, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2078, %r5, %r6, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2085, %r4, %r5, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2084, %r3, %r4, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2083, %r2, %r3, %r27;
	// inline asm
	mov.u32 	%r2070, 0;
	// inline asm
	prmt.b32 %r2082, %r2070, %r2, %r27;
	// inline asm
	mov.u32 	%r2071, %r2070;
	mov.u32 	%r2072, %r2070;
	mov.u32 	%r2073, %r2070;
	mov.u32 	%r2074, %r2070;
	mov.u32 	%r2075, %r2070;
	mov.u32 	%r2076, %r2070;
	mov.u32 	%r2077, %r2070;
	bra.uni 	BB4_37;

BB4_56:
	setp.gt.s32	%p40, %r12, 5;
	@%p40 bra 	BB4_60;

	setp.eq.s32	%p43, %r12, 4;
	@%p43 bra 	BB4_91;
	bra.uni 	BB4_58;

BB4_91:
	mov.u32 	%r2078, 0;
	// inline asm
	prmt.b32 %r2074, %r2078, %r2078, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2075, %r2078, %r2078, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2076, %r2078, %r2078, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2077, %r2066, %r2078, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2070, %r2067, %r2066, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2071, %r2068, %r2067, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2072, %r2069, %r2068, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2073, %r2062, %r2069, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2066, %r2063, %r2062, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2067, %r2064, %r2063, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2068, %r2065, %r2064, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2069, %r2078, %r2065, %r13;
	// inline asm
	mov.u32 	%r2062, %r2078;
	bra.uni 	BB4_92;

BB4_13:
	setp.gt.s32	%p17, %r391, 5;
	@%p17 bra 	BB4_17;

	setp.eq.s32	%p20, %r391, 4;
	@%p20 bra 	BB4_44;
	bra.uni 	BB4_15;

BB4_44:
	mov.u32 	%r2070, 0;
	// inline asm
	prmt.b32 %r2081, %r2070, %r2070, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2080, %r2070, %r2070, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2079, %r2070, %r2070, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2078, %r9, %r2070, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2085, %r8, %r9, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2084, %r7, %r8, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2083, %r6, %r7, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2082, %r5, %r6, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2089, %r4, %r5, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2088, %r3, %r4, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2087, %r2, %r3, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2086, %r2070, %r2, %r27;
	// inline asm
	mov.u32 	%r2071, %r2070;
	mov.u32 	%r2072, %r2070;
	mov.u32 	%r2073, %r2070;
	mov.u32 	%r2074, %r2070;
	mov.u32 	%r2075, %r2070;
	mov.u32 	%r2076, %r2070;
	mov.u32 	%r2077, %r2070;
	bra.uni 	BB4_38;

BB4_73:
	setp.gt.s32	%p29, %r12, 13;
	@%p29 bra 	BB4_77;

	setp.eq.s32	%p32, %r12, 12;
	@%p32 bra 	BB4_84;
	bra.uni 	BB4_75;

BB4_84:
	// inline asm
	prmt.b32 %r2074, %r2063, %r2062, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2075, %r2064, %r2063, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2076, %r2065, %r2064, %r13;
	// inline asm
	mov.u32 	%r2062, 0;
	// inline asm
	prmt.b32 %r2077, %r2062, %r2065, %r13;
	// inline asm
	mov.u32 	%r2063, %r2062;
	mov.u32 	%r2064, %r2062;
	mov.u32 	%r2065, %r2062;
	mov.u32 	%r2066, %r2062;
	mov.u32 	%r2067, %r2062;
	mov.u32 	%r2068, %r2062;
	mov.u32 	%r2069, %r2062;
	mov.u32 	%r2070, %r2062;
	bra.uni 	BB4_85;

BB4_28:
	setp.gt.s32	%p6, %r391, 13;
	@%p6 bra 	BB4_32;

	setp.eq.s32	%p9, %r391, 12;
	@%p9 bra 	BB4_40;
	bra.uni 	BB4_30;

BB4_40:
	// inline asm
	prmt.b32 %r2081, %r4, %r5, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2080, %r3, %r4, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2079, %r2, %r3, %r27;
	// inline asm
	mov.u32 	%r2070, 0;
	// inline asm
	prmt.b32 %r2078, %r2070, %r2, %r27;
	// inline asm
	mov.u32 	%r2071, %r2070;
	mov.u32 	%r2072, %r2070;
	mov.u32 	%r2073, %r2070;
	mov.u32 	%r2074, %r2070;
	mov.u32 	%r2075, %r2070;
	mov.u32 	%r2076, %r2070;
	mov.u32 	%r2077, %r2070;
	bra.uni 	BB4_36;

BB4_53:
	setp.eq.s32	%p46, %r12, 2;
	@%p46 bra 	BB4_95;
	bra.uni 	BB4_54;

BB4_95:
	mov.u32 	%r2078, 0;
	// inline asm
	prmt.b32 %r2074, %r2078, %r2078, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2075, %r2078, %r2078, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2076, %r2078, %r2078, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2077, %r2078, %r2078, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2070, %r2078, %r2078, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2071, %r2066, %r2078, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2072, %r2067, %r2066, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2073, %r2068, %r2067, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2066, %r2069, %r2068, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2067, %r2062, %r2069, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2068, %r2063, %r2062, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2069, %r2064, %r2063, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2062, %r2065, %r2064, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2063, %r2078, %r2065, %r13;
	// inline asm
	bra.uni 	BB4_93;

BB4_10:
	setp.eq.s32	%p23, %r391, 2;
	@%p23 bra 	BB4_45;
	bra.uni 	BB4_11;

BB4_45:
	mov.u32 	%r2070, 0;
	// inline asm
	prmt.b32 %r2081, %r2070, %r2070, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2080, %r2070, %r2070, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2079, %r2070, %r2070, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2078, %r2070, %r2070, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2085, %r2070, %r2070, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2084, %r9, %r2070, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2083, %r8, %r9, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2082, %r7, %r8, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2089, %r6, %r7, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2088, %r5, %r6, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2087, %r4, %r5, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2086, %r3, %r4, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2093, %r2, %r3, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2092, %r2070, %r2, %r27;
	// inline asm
	mov.u32 	%r2071, %r2070;
	mov.u32 	%r2072, %r2070;
	mov.u32 	%r2073, %r2070;
	mov.u32 	%r2074, %r2070;
	mov.u32 	%r2075, %r2070;
	mov.u32 	%r2076, %r2070;
	mov.u32 	%r2077, %r2070;
	mov.u32 	%r2090, %r2070;
	mov.u32 	%r2091, %r2070;
	bra.uni 	BB4_99;

BB4_70:
	setp.eq.s32	%p35, %r12, 10;
	@%p35 bra 	BB4_88;
	bra.uni 	BB4_71;

BB4_88:
	// inline asm
	prmt.b32 %r2074, %r2069, %r2068, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2075, %r2062, %r2069, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2076, %r2063, %r2062, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2077, %r2064, %r2063, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2070, %r2065, %r2064, %r13;
	// inline asm
	mov.u32 	%r2062, 0;
	// inline asm
	prmt.b32 %r2071, %r2062, %r2065, %r13;
	// inline asm
	mov.u32 	%r2063, %r2062;
	mov.u32 	%r2064, %r2062;
	mov.u32 	%r2065, %r2062;
	mov.u32 	%r2066, %r2062;
	mov.u32 	%r2067, %r2062;
	mov.u32 	%r2068, %r2062;
	mov.u32 	%r2069, %r2062;
	bra.uni 	BB4_86;

BB4_25:
	setp.eq.s32	%p12, %r391, 10;
	@%p12 bra 	BB4_41;
	bra.uni 	BB4_26;

BB4_41:
	// inline asm
	prmt.b32 %r2081, %r6, %r7, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2080, %r5, %r6, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2079, %r4, %r5, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2078, %r3, %r4, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2085, %r2, %r3, %r27;
	// inline asm
	mov.u32 	%r2070, 0;
	// inline asm
	prmt.b32 %r2084, %r2070, %r2, %r27;
	// inline asm
	mov.u32 	%r2071, %r2070;
	mov.u32 	%r2072, %r2070;
	mov.u32 	%r2073, %r2070;
	mov.u32 	%r2074, %r2070;
	mov.u32 	%r2075, %r2070;
	mov.u32 	%r2076, %r2070;
	mov.u32 	%r2077, %r2070;
	mov.u32 	%r2082, %r2070;
	mov.u32 	%r2083, %r2070;
	bra.uni 	BB4_37;

BB4_60:
	setp.eq.s32	%p41, %r12, 6;
	@%p41 bra 	BB4_90;
	bra.uni 	BB4_61;

BB4_90:
	mov.u32 	%r2078, 0;
	// inline asm
	prmt.b32 %r2074, %r2078, %r2078, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2075, %r2066, %r2078, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2076, %r2067, %r2066, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2077, %r2068, %r2067, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2070, %r2069, %r2068, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2071, %r2062, %r2069, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2072, %r2063, %r2062, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2073, %r2064, %r2063, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2066, %r2065, %r2064, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2067, %r2078, %r2065, %r13;
	// inline asm
	mov.u32 	%r2062, %r2078;
	mov.u32 	%r2063, %r2078;
	mov.u32 	%r2064, %r2078;
	mov.u32 	%r2065, %r2078;
	bra.uni 	BB4_63;

BB4_17:
	setp.eq.s32	%p18, %r391, 6;
	@%p18 bra 	BB4_43;
	bra.uni 	BB4_18;

BB4_43:
	mov.u32 	%r2070, 0;
	// inline asm
	prmt.b32 %r2081, %r2070, %r2070, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2080, %r9, %r2070, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2079, %r8, %r9, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2078, %r7, %r8, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2085, %r6, %r7, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2084, %r5, %r6, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2083, %r4, %r5, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2082, %r3, %r4, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2089, %r2, %r3, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2088, %r2070, %r2, %r27;
	// inline asm
	mov.u32 	%r2071, %r2070;
	mov.u32 	%r2072, %r2070;
	mov.u32 	%r2073, %r2070;
	mov.u32 	%r2074, %r2070;
	mov.u32 	%r2075, %r2070;
	mov.u32 	%r2076, %r2070;
	mov.u32 	%r2077, %r2070;
	mov.u32 	%r2086, %r2070;
	mov.u32 	%r2087, %r2070;
	bra.uni 	BB4_38;

BB4_77:
	setp.eq.s32	%p30, %r12, 14;
	@%p30 bra 	BB4_83;
	bra.uni 	BB4_78;

BB4_83:
	// inline asm
	prmt.b32 %r2074, %r2065, %r2064, %r13;
	// inline asm
	mov.u32 	%r2062, 0;
	// inline asm
	prmt.b32 %r2075, %r2062, %r2065, %r13;
	// inline asm
	mov.u32 	%r2063, %r2062;
	mov.u32 	%r2064, %r2062;
	mov.u32 	%r2065, %r2062;
	mov.u32 	%r2066, %r2062;
	mov.u32 	%r2067, %r2062;
	mov.u32 	%r2068, %r2062;
	mov.u32 	%r2069, %r2062;
	mov.u32 	%r2070, %r2062;
	mov.u32 	%r2071, %r2062;
	mov.u32 	%r2072, %r2062;
	mov.u32 	%r2073, %r2062;
	bra.uni 	BB4_80;

BB4_32:
	setp.eq.s32	%p7, %r391, 14;
	@%p7 bra 	BB4_39;
	bra.uni 	BB4_33;

BB4_39:
	// inline asm
	prmt.b32 %r2081, %r2, %r3, %r27;
	// inline asm
	mov.u32 	%r2070, 0;
	// inline asm
	prmt.b32 %r2080, %r2070, %r2, %r27;
	// inline asm
	mov.u32 	%r2071, %r2070;
	mov.u32 	%r2072, %r2070;
	mov.u32 	%r2073, %r2070;
	mov.u32 	%r2074, %r2070;
	mov.u32 	%r2075, %r2070;
	mov.u32 	%r2076, %r2070;
	mov.u32 	%r2077, %r2070;
	mov.u32 	%r2078, %r2070;
	mov.u32 	%r2079, %r2070;
	bra.uni 	BB4_36;

BB4_51:
	setp.eq.s32	%p49, %r12, 1;
	@%p49 bra 	BB4_52;
	bra.uni 	BB4_34;

BB4_52:
	mov.u32 	%r2078, 0;
	// inline asm
	prmt.b32 %r2074, %r2078, %r2078, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2075, %r2078, %r2078, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2076, %r2078, %r2078, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2077, %r2078, %r2078, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2070, %r2078, %r2078, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2071, %r2078, %r2078, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2072, %r2066, %r2078, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2073, %r2067, %r2066, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2066, %r2068, %r2067, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2067, %r2069, %r2068, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2068, %r2062, %r2069, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2069, %r2063, %r2062, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2062, %r2064, %r2063, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2063, %r2065, %r2064, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2064, %r2078, %r2065, %r13;
	// inline asm
	bra.uni 	BB4_94;

BB4_8:
	setp.eq.s32	%p26, %r391, 1;
	@%p26 bra 	BB4_9;
	bra.uni 	BB4_34;

BB4_9:
	mov.u32 	%r2070, 0;
	// inline asm
	prmt.b32 %r2081, %r2070, %r2070, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2080, %r2070, %r2070, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2079, %r2070, %r2070, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2078, %r2070, %r2070, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2085, %r2070, %r2070, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2084, %r2070, %r2070, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2083, %r9, %r2070, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2082, %r8, %r9, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2089, %r7, %r8, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2088, %r6, %r7, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2087, %r5, %r6, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2086, %r4, %r5, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2093, %r3, %r4, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2092, %r2, %r3, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2091, %r2070, %r2, %r27;
	// inline asm
	mov.u32 	%r2071, %r2070;
	mov.u32 	%r2072, %r2070;
	mov.u32 	%r2073, %r2070;
	mov.u32 	%r2074, %r2070;
	mov.u32 	%r2075, %r2070;
	mov.u32 	%r2076, %r2070;
	mov.u32 	%r2077, %r2070;
	mov.u32 	%r2090, %r2070;
	bra.uni 	BB4_99;

BB4_68:
	setp.eq.s32	%p38, %r12, 9;
	@%p38 bra 	BB4_69;
	bra.uni 	BB4_34;

BB4_69:
	// inline asm
	prmt.b32 %r2074, %r2068, %r2067, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2075, %r2069, %r2068, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2076, %r2062, %r2069, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2077, %r2063, %r2062, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2070, %r2064, %r2063, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2071, %r2065, %r2064, %r13;
	// inline asm
	mov.u32 	%r2062, 0;
	// inline asm
	prmt.b32 %r2072, %r2062, %r2065, %r13;
	// inline asm
	mov.u32 	%r2063, %r2062;
	mov.u32 	%r2064, %r2062;
	mov.u32 	%r2065, %r2062;
	mov.u32 	%r2066, %r2062;
	mov.u32 	%r2067, %r2062;
	mov.u32 	%r2068, %r2062;
	mov.u32 	%r2069, %r2062;
	bra.uni 	BB4_87;

BB4_23:
	setp.eq.s32	%p15, %r391, 9;
	@%p15 bra 	BB4_24;
	bra.uni 	BB4_34;

BB4_24:
	// inline asm
	prmt.b32 %r2081, %r7, %r8, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2080, %r6, %r7, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2079, %r5, %r6, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2078, %r4, %r5, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2085, %r3, %r4, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2084, %r2, %r3, %r27;
	// inline asm
	mov.u32 	%r2070, 0;
	// inline asm
	prmt.b32 %r2083, %r2070, %r2, %r27;
	// inline asm
	mov.u32 	%r2071, %r2070;
	mov.u32 	%r2072, %r2070;
	mov.u32 	%r2073, %r2070;
	mov.u32 	%r2074, %r2070;
	mov.u32 	%r2075, %r2070;
	mov.u32 	%r2076, %r2070;
	mov.u32 	%r2077, %r2070;
	mov.u32 	%r2082, %r2070;
	bra.uni 	BB4_37;

BB4_58:
	setp.eq.s32	%p44, %r12, 5;
	@%p44 bra 	BB4_59;
	bra.uni 	BB4_34;

BB4_59:
	mov.u32 	%r2078, 0;
	// inline asm
	prmt.b32 %r2074, %r2078, %r2078, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2075, %r2078, %r2078, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2076, %r2066, %r2078, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2077, %r2067, %r2066, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2070, %r2068, %r2067, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2071, %r2069, %r2068, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2072, %r2062, %r2069, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2073, %r2063, %r2062, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2066, %r2064, %r2063, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2067, %r2065, %r2064, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2068, %r2078, %r2065, %r13;
	// inline asm
	mov.u32 	%r2062, %r2078;
	mov.u32 	%r2063, %r2078;
	mov.u32 	%r2064, %r2078;
	mov.u32 	%r2065, %r2078;
	bra.uni 	BB4_64;

BB4_15:
	setp.eq.s32	%p21, %r391, 5;
	@%p21 bra 	BB4_16;
	bra.uni 	BB4_34;

BB4_16:
	mov.u32 	%r2070, 0;
	// inline asm
	prmt.b32 %r2081, %r2070, %r2070, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2080, %r2070, %r2070, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2079, %r9, %r2070, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2078, %r8, %r9, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2085, %r7, %r8, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2084, %r6, %r7, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2083, %r5, %r6, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2082, %r4, %r5, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2089, %r3, %r4, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2088, %r2, %r3, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2087, %r2070, %r2, %r27;
	// inline asm
	mov.u32 	%r2071, %r2070;
	mov.u32 	%r2072, %r2070;
	mov.u32 	%r2073, %r2070;
	mov.u32 	%r2074, %r2070;
	mov.u32 	%r2075, %r2070;
	mov.u32 	%r2076, %r2070;
	mov.u32 	%r2077, %r2070;
	mov.u32 	%r2086, %r2070;
	bra.uni 	BB4_38;

BB4_75:
	setp.eq.s32	%p33, %r12, 13;
	@%p33 bra 	BB4_76;
	bra.uni 	BB4_34;

BB4_76:
	// inline asm
	prmt.b32 %r2074, %r2064, %r2063, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2075, %r2065, %r2064, %r13;
	// inline asm
	mov.u32 	%r2062, 0;
	// inline asm
	prmt.b32 %r2076, %r2062, %r2065, %r13;
	// inline asm
	mov.u32 	%r2063, %r2062;
	mov.u32 	%r2064, %r2062;
	mov.u32 	%r2065, %r2062;
	mov.u32 	%r2066, %r2062;
	mov.u32 	%r2067, %r2062;
	mov.u32 	%r2068, %r2062;
	mov.u32 	%r2069, %r2062;
	mov.u32 	%r2070, %r2062;
	mov.u32 	%r2071, %r2062;
	mov.u32 	%r2072, %r2062;
	mov.u32 	%r2073, %r2062;
	bra.uni 	BB4_81;

BB4_30:
	setp.eq.s32	%p10, %r391, 13;
	@%p10 bra 	BB4_31;
	bra.uni 	BB4_34;

BB4_31:
	// inline asm
	prmt.b32 %r2081, %r3, %r4, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2080, %r2, %r3, %r27;
	// inline asm
	mov.u32 	%r2070, 0;
	// inline asm
	prmt.b32 %r2079, %r2070, %r2, %r27;
	// inline asm
	mov.u32 	%r2071, %r2070;
	mov.u32 	%r2072, %r2070;
	mov.u32 	%r2073, %r2070;
	mov.u32 	%r2074, %r2070;
	mov.u32 	%r2075, %r2070;
	mov.u32 	%r2076, %r2070;
	mov.u32 	%r2077, %r2070;
	mov.u32 	%r2078, %r2070;
	bra.uni 	BB4_36;

BB4_54:
	setp.eq.s32	%p47, %r12, 3;
	@%p47 bra 	BB4_55;
	bra.uni 	BB4_34;

BB4_55:
	mov.u32 	%r2078, 0;
	// inline asm
	prmt.b32 %r2074, %r2078, %r2078, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2075, %r2078, %r2078, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2076, %r2078, %r2078, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2077, %r2078, %r2078, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2070, %r2066, %r2078, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2071, %r2067, %r2066, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2072, %r2068, %r2067, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2073, %r2069, %r2068, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2066, %r2062, %r2069, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2067, %r2063, %r2062, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2068, %r2064, %r2063, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2069, %r2065, %r2064, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2062, %r2078, %r2065, %r13;
	// inline asm

BB4_92:
	mov.u32 	%r2063, %r2078;

BB4_93:
	mov.u32 	%r2064, %r2078;

BB4_94:
	mov.u32 	%r2065, %r2078;
	bra.uni 	BB4_97;

BB4_11:
	setp.eq.s32	%p24, %r391, 3;
	@%p24 bra 	BB4_12;
	bra.uni 	BB4_34;

BB4_12:
	mov.u32 	%r2070, 0;
	// inline asm
	prmt.b32 %r2081, %r2070, %r2070, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2080, %r2070, %r2070, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2079, %r2070, %r2070, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2078, %r2070, %r2070, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2085, %r9, %r2070, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2084, %r8, %r9, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2083, %r7, %r8, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2082, %r6, %r7, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2089, %r5, %r6, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2088, %r4, %r5, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2087, %r3, %r4, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2086, %r2, %r3, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2093, %r2070, %r2, %r27;
	// inline asm
	mov.u32 	%r2071, %r2070;
	mov.u32 	%r2072, %r2070;
	mov.u32 	%r2073, %r2070;
	mov.u32 	%r2074, %r2070;
	mov.u32 	%r2075, %r2070;
	mov.u32 	%r2076, %r2070;
	mov.u32 	%r2077, %r2070;
	mov.u32 	%r2090, %r2070;
	mov.u32 	%r2091, %r2070;
	mov.u32 	%r2092, %r2070;
	bra.uni 	BB4_99;

BB4_71:
	setp.eq.s32	%p36, %r12, 11;
	@%p36 bra 	BB4_72;
	bra.uni 	BB4_34;

BB4_72:
	// inline asm
	prmt.b32 %r2074, %r2062, %r2069, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2075, %r2063, %r2062, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2076, %r2064, %r2063, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2077, %r2065, %r2064, %r13;
	// inline asm
	mov.u32 	%r2062, 0;
	// inline asm
	prmt.b32 %r2070, %r2062, %r2065, %r13;
	// inline asm
	mov.u32 	%r2063, %r2062;
	mov.u32 	%r2064, %r2062;
	mov.u32 	%r2065, %r2062;
	mov.u32 	%r2066, %r2062;
	mov.u32 	%r2067, %r2062;
	mov.u32 	%r2068, %r2062;
	mov.u32 	%r2069, %r2062;

BB4_85:
	mov.u32 	%r2071, %r2062;

BB4_86:
	mov.u32 	%r2072, %r2062;

BB4_87:
	mov.u32 	%r2073, %r2062;
	bra.uni 	BB4_82;

BB4_26:
	setp.eq.s32	%p13, %r391, 11;
	@%p13 bra 	BB4_27;
	bra.uni 	BB4_34;

BB4_27:
	// inline asm
	prmt.b32 %r2081, %r5, %r6, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2080, %r4, %r5, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2079, %r3, %r4, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2078, %r2, %r3, %r27;
	// inline asm
	mov.u32 	%r2070, 0;
	// inline asm
	prmt.b32 %r2085, %r2070, %r2, %r27;
	// inline asm
	mov.u32 	%r2071, %r2070;
	mov.u32 	%r2072, %r2070;
	mov.u32 	%r2073, %r2070;
	mov.u32 	%r2074, %r2070;
	mov.u32 	%r2075, %r2070;
	mov.u32 	%r2076, %r2070;
	mov.u32 	%r2077, %r2070;
	mov.u32 	%r2082, %r2070;
	mov.u32 	%r2083, %r2070;
	mov.u32 	%r2084, %r2070;
	bra.uni 	BB4_37;

BB4_61:
	setp.eq.s32	%p42, %r12, 7;
	@%p42 bra 	BB4_62;
	bra.uni 	BB4_34;

BB4_62:
	mov.u32 	%r2078, 0;
	// inline asm
	prmt.b32 %r2074, %r2066, %r2078, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2075, %r2067, %r2066, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2076, %r2068, %r2067, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2077, %r2069, %r2068, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2070, %r2062, %r2069, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2071, %r2063, %r2062, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2072, %r2064, %r2063, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2073, %r2065, %r2064, %r13;
	// inline asm
	// inline asm
	prmt.b32 %r2066, %r2078, %r2065, %r13;
	// inline asm
	mov.u32 	%r2062, %r2078;
	mov.u32 	%r2063, %r2078;
	mov.u32 	%r2064, %r2078;
	mov.u32 	%r2065, %r2078;
	mov.u32 	%r2067, %r2078;

BB4_63:
	mov.u32 	%r2068, %r2078;

BB4_64:
	mov.u32 	%r2069, %r2078;

BB4_97:
	mov.u32 	%r2079, %r2078;
	mov.u32 	%r2080, %r2078;
	mov.u32 	%r2081, %r2078;
	mov.u32 	%r2082, %r2078;
	mov.u32 	%r2083, %r2078;
	mov.u32 	%r2084, %r2078;
	mov.u32 	%r2085, %r2078;
	bra.uni 	BB4_98;

BB4_18:
	setp.eq.s32	%p19, %r391, 7;
	@%p19 bra 	BB4_19;
	bra.uni 	BB4_34;

BB4_19:
	mov.u32 	%r2070, 0;
	// inline asm
	prmt.b32 %r2081, %r9, %r2070, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2080, %r8, %r9, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2079, %r7, %r8, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2078, %r6, %r7, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2085, %r5, %r6, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2084, %r4, %r5, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2083, %r3, %r4, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2082, %r2, %r3, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r2089, %r2070, %r2, %r27;
	// inline asm
	mov.u32 	%r2071, %r2070;
	mov.u32 	%r2072, %r2070;
	mov.u32 	%r2073, %r2070;
	mov.u32 	%r2074, %r2070;
	mov.u32 	%r2075, %r2070;
	mov.u32 	%r2076, %r2070;
	mov.u32 	%r2077, %r2070;
	mov.u32 	%r2086, %r2070;
	mov.u32 	%r2087, %r2070;
	mov.u32 	%r2088, %r2070;
	bra.uni 	BB4_38;

BB4_78:
	setp.ne.s32	%p31, %r12, 15;
	@%p31 bra 	BB4_34;

	mov.u32 	%r2062, 0;
	// inline asm
	prmt.b32 %r2074, %r2062, %r2065, %r13;
	// inline asm
	mov.u32 	%r2063, %r2062;
	mov.u32 	%r2064, %r2062;
	mov.u32 	%r2065, %r2062;
	mov.u32 	%r2066, %r2062;
	mov.u32 	%r2067, %r2062;
	mov.u32 	%r2068, %r2062;
	mov.u32 	%r2069, %r2062;
	mov.u32 	%r2070, %r2062;
	mov.u32 	%r2071, %r2062;
	mov.u32 	%r2072, %r2062;
	mov.u32 	%r2073, %r2062;
	mov.u32 	%r2075, %r2062;

BB4_80:
	mov.u32 	%r2076, %r2062;

BB4_81:
	mov.u32 	%r2077, %r2062;

BB4_82:
	mov.u32 	%r2078, %r2062;
	mov.u32 	%r2079, %r2062;
	mov.u32 	%r2080, %r2062;
	mov.u32 	%r2081, %r2062;
	mov.u32 	%r2082, %r2062;
	mov.u32 	%r2083, %r2062;
	mov.u32 	%r2084, %r2062;
	mov.u32 	%r2085, %r2062;
	bra.uni 	BB4_98;

BB4_33:
	setp.ne.s32	%p8, %r391, 15;
	@%p8 bra 	BB4_34;

	mov.u32 	%r2070, 0;
	// inline asm
	prmt.b32 %r2081, %r2070, %r2, %r27;
	// inline asm
	mov.u32 	%r2071, %r2070;
	mov.u32 	%r2072, %r2070;
	mov.u32 	%r2073, %r2070;
	mov.u32 	%r2074, %r2070;
	mov.u32 	%r2075, %r2070;
	mov.u32 	%r2076, %r2070;
	mov.u32 	%r2077, %r2070;
	mov.u32 	%r2078, %r2070;
	mov.u32 	%r2079, %r2070;
	mov.u32 	%r2080, %r2070;

BB4_36:
	mov.u32 	%r2082, %r2070;
	mov.u32 	%r2083, %r2070;
	mov.u32 	%r2084, %r2070;
	mov.u32 	%r2085, %r2070;

BB4_37:
	mov.u32 	%r2086, %r2070;
	mov.u32 	%r2087, %r2070;
	mov.u32 	%r2088, %r2070;
	mov.u32 	%r2089, %r2070;

BB4_38:
	mov.u32 	%r2090, %r2070;
	mov.u32 	%r2091, %r2070;
	mov.u32 	%r2092, %r2070;
	mov.u32 	%r2093, %r2070;
	bra.uni 	BB4_99;

BB4_34:
	mov.u32 	%r2071, %r2070;
	mov.u32 	%r2072, %r2070;
	mov.u32 	%r2073, %r2070;
	mov.u32 	%r2074, %r2070;
	mov.u32 	%r2075, %r2070;
	mov.u32 	%r2076, %r2070;
	mov.u32 	%r2077, %r2070;
	mov.u32 	%r2078, %r2070;
	mov.u32 	%r2079, %r2070;
	mov.u32 	%r2080, %r2070;
	mov.u32 	%r2081, %r2070;
	mov.u32 	%r2082, %r2070;
	mov.u32 	%r2083, %r2070;
	mov.u32 	%r2084, %r2070;
	mov.u32 	%r2085, %r2070;

BB4_98:
	mov.u32 	%r2086, %r6;
	mov.u32 	%r2087, %r7;
	mov.u32 	%r2088, %r8;
	mov.u32 	%r2089, %r9;
	mov.u32 	%r2090, %r2;
	mov.u32 	%r2091, %r3;
	mov.u32 	%r2092, %r4;
	mov.u32 	%r2093, %r5;

BB4_99:
	or.b32  	%r332, %r2090, %r2065;
	or.b32  	%r1998, %r2093, %r2062;
	or.b32  	%r1999, %r2092, %r2063;
	or.b32  	%r2000, %r2091, %r2064;
	st.local.v4.u32 	[%rd1], {%r332, %r2000, %r1999, %r1998};
	or.b32  	%r2001, %r2089, %r2066;
	or.b32  	%r2002, %r2088, %r2067;
	or.b32  	%r2003, %r2087, %r2068;
	or.b32  	%r2004, %r2086, %r2069;
	st.local.v4.u32 	[%rd1+16], {%r2004, %r2003, %r2002, %r2001};
	or.b32  	%r2005, %r2085, %r2070;
	or.b32  	%r2006, %r2084, %r2071;
	or.b32  	%r2007, %r2083, %r2072;
	or.b32  	%r2008, %r2082, %r2073;
	st.local.v4.u32 	[%rd1+32], {%r2008, %r2007, %r2006, %r2005};
	or.b32  	%r2009, %r2081, %r2074;
	or.b32  	%r2010, %r2080, %r2075;
	or.b32  	%r2011, %r2079, %r2076;
	or.b32  	%r2012, %r2078, %r2077;
	st.local.v4.u32 	[%rd1+48], {%r2012, %r2011, %r2010, %r2009};
	setp.eq.s32	%p50, %r18, 0;
	mov.u32 	%r2100, %r14;
	@%p50 bra 	BB4_101;

	xor.b32  	%r2013, %r332, %r14;
	and.b32  	%r2014, %r2013, 255;
	mul.wide.u32 	%rd23, %r2014, 4;
	mov.u64 	%rd24, crc32tab;
	add.s64 	%rd25, %rd24, %rd23;
	ld.const.u32 	%r2015, [%rd25];
	xor.b32  	%r2100, %r2015, %r15;

BB4_101:
	setp.lt.u32	%p51, %r18, 2;
	@%p51 bra 	BB4_103;

	shr.u32 	%r2016, %r332, 8;
	xor.b32  	%r2017, %r2016, %r2100;
	and.b32  	%r2018, %r2017, 255;
	mul.wide.u32 	%rd26, %r2018, 4;
	mov.u64 	%rd27, crc32tab;
	add.s64 	%rd28, %rd27, %rd26;
	ld.const.u32 	%r2019, [%rd28];
	shr.u32 	%r2020, %r2100, 8;
	xor.b32  	%r2100, %r2019, %r2020;

BB4_103:
	setp.lt.u32	%p52, %r18, 3;
	@%p52 bra 	BB4_105;

	shr.u32 	%r2021, %r332, 16;
	xor.b32  	%r2022, %r2021, %r2100;
	and.b32  	%r2023, %r2022, 255;
	mul.wide.u32 	%rd29, %r2023, 4;
	mov.u64 	%rd30, crc32tab;
	add.s64 	%rd31, %rd30, %rd29;
	ld.const.u32 	%r2024, [%rd31];
	shr.u32 	%r2025, %r2100, 8;
	xor.b32  	%r2100, %r2024, %r2025;

BB4_105:
	setp.lt.u32	%p53, %r18, 4;
	@%p53 bra 	BB4_107;

	shr.u32 	%r2026, %r332, 24;
	and.b32  	%r2027, %r2100, 255;
	xor.b32  	%r2028, %r2026, %r2027;
	mul.wide.u32 	%rd32, %r2028, 4;
	mov.u64 	%rd33, crc32tab;
	add.s64 	%rd34, %rd33, %rd32;
	ld.const.u32 	%r2029, [%rd34];
	shr.u32 	%r2030, %r2100, 8;
	xor.b32  	%r2100, %r2029, %r2030;

BB4_107:
	mov.u32 	%r2098, 1;
	setp.lt.u32	%p54, %r18, 5;
	mov.u32 	%r2099, %r370;
	@%p54 bra 	BB4_117;

BB4_108:
	add.s32 	%r2033, %r2099, 1;
	setp.gt.u32	%p55, %r2033, %r18;
	mul.wide.u32 	%rd35, %r2098, 4;
	add.s64 	%rd4, %rd1, %rd35;
	@%p55 bra 	BB4_110;

	ld.local.u32 	%r2034, [%rd4];
	xor.b32  	%r2035, %r2034, %r2100;
	and.b32  	%r2036, %r2035, 255;
	mul.wide.u32 	%rd36, %r2036, 4;
	mov.u64 	%rd37, crc32tab;
	add.s64 	%rd38, %rd37, %rd36;
	ld.const.u32 	%r2037, [%rd38];
	shr.u32 	%r2038, %r2100, 8;
	xor.b32  	%r2100, %r2037, %r2038;

BB4_110:
	add.s32 	%r2039, %r2099, 2;
	setp.gt.u32	%p56, %r2039, %r18;
	@%p56 bra 	BB4_112;

	ld.local.u32 	%r2040, [%rd4];
	shr.u32 	%r2041, %r2040, 8;
	xor.b32  	%r2042, %r2041, %r2100;
	and.b32  	%r2043, %r2042, 255;
	mul.wide.u32 	%rd39, %r2043, 4;
	mov.u64 	%rd40, crc32tab;
	add.s64 	%rd41, %rd40, %rd39;
	ld.const.u32 	%r2044, [%rd41];
	shr.u32 	%r2045, %r2100, 8;
	xor.b32  	%r2100, %r2044, %r2045;

BB4_112:
	add.s32 	%r2046, %r2099, 3;
	setp.gt.u32	%p57, %r2046, %r18;
	@%p57 bra 	BB4_114;

	ld.local.u16 	%r2047, [%rd4+2];
	xor.b32  	%r2048, %r2047, %r2100;
	and.b32  	%r2049, %r2048, 255;
	mul.wide.u32 	%rd42, %r2049, 4;
	mov.u64 	%rd43, crc32tab;
	add.s64 	%rd44, %rd43, %rd42;
	ld.const.u32 	%r2050, [%rd44];
	shr.u32 	%r2051, %r2100, 8;
	xor.b32  	%r2100, %r2050, %r2051;

BB4_114:
	add.s32 	%r2099, %r2099, 4;
	setp.gt.u32	%p58, %r2099, %r18;
	@%p58 bra 	BB4_116;

	ld.local.u8 	%r2052, [%rd4+3];
	and.b32  	%r2053, %r2100, 255;
	xor.b32  	%r2054, %r2052, %r2053;
	mul.wide.u32 	%rd45, %r2054, 4;
	mov.u64 	%rd46, crc32tab;
	add.s64 	%rd47, %rd46, %rd45;
	ld.const.u32 	%r2055, [%rd47];
	shr.u32 	%r2056, %r2100, 8;
	xor.b32  	%r2100, %r2055, %r2056;

BB4_116:
	add.s32 	%r2098, %r2098, 1;
	setp.lt.u32	%p59, %r2099, %r18;
	@%p59 bra 	BB4_108;

BB4_117:
	not.b32 	%r2057, %r2100;
	setp.ne.s32	%p60, %r11, %r2057;
	@%p60 bra 	BB4_122;

	atom.global.add.u32 	%r2058, [%rd3], 1;
	setp.ne.s32	%p61, %r2058, 0;
	@%p61 bra 	BB4_122;

	atom.global.add.u32 	%r355, [%rd11], 1;
	setp.lt.u32	%p62, %r355, %r359;
	@%p62 bra 	BB4_121;
	bra.uni 	BB4_120;

BB4_121:
	mul.wide.u32 	%rd48, %r355, 20;
	add.s64 	%rd49, %rd7, %rd48;
	st.global.u32 	[%rd49], %r357;
	mov.u32 	%r2060, 0;
	st.global.u32 	[%rd49+4], %r2060;
	st.global.u32 	[%rd49+8], %r360;
	st.global.u32 	[%rd49+12], %r1;
	st.global.u32 	[%rd49+16], %r2061;
	bra.uni 	BB4_122;

BB4_120:
	atom.global.add.u32 	%r2059, [%rd11], -1;

BB4_122:
	add.s32 	%r2061, %r2061, 1;
	setp.lt.u32	%p63, %r2061, %r358;
	@%p63 bra 	BB4_3;

BB4_123:
	ret;
}

	// .globl	m11500_s08
.entry m11500_s08(
	.param .u64 .ptr .global .align 4 m11500_s08_param_0,
	.param .u64 .ptr .global .align 4 m11500_s08_param_1,
	.param .u64 .ptr .global .align 4 m11500_s08_param_2,
	.param .u64 .ptr .global .align 4 m11500_s08_param_3,
	.param .u64 .ptr .global .align 1 m11500_s08_param_4,
	.param .u64 .ptr .global .align 1 m11500_s08_param_5,
	.param .u64 .ptr .global .align 4 m11500_s08_param_6,
	.param .u64 .ptr .global .align 4 m11500_s08_param_7,
	.param .u64 .ptr .global .align 4 m11500_s08_param_8,
	.param .u64 .ptr .global .align 4 m11500_s08_param_9,
	.param .u64 .ptr .global .align 4 m11500_s08_param_10,
	.param .u64 .ptr .global .align 4 m11500_s08_param_11,
	.param .u64 .ptr .global .align 4 m11500_s08_param_12,
	.param .u64 .ptr .global .align 4 m11500_s08_param_13,
	.param .u64 .ptr .global .align 4 m11500_s08_param_14,
	.param .u64 .ptr .global .align 4 m11500_s08_param_15,
	.param .u64 .ptr .global .align 4 m11500_s08_param_16,
	.param .u64 .ptr .global .align 4 m11500_s08_param_17,
	.param .u64 .ptr .global .align 1 m11500_s08_param_18,
	.param .u64 .ptr .global .align 4 m11500_s08_param_19,
	.param .u64 .ptr .global .align 4 m11500_s08_param_20,
	.param .u64 .ptr .global .align 4 m11500_s08_param_21,
	.param .u64 .ptr .global .align 4 m11500_s08_param_22,
	.param .u64 .ptr .global .align 4 m11500_s08_param_23,
	.param .u32 m11500_s08_param_24,
	.param .u32 m11500_s08_param_25,
	.param .u32 m11500_s08_param_26,
	.param .u32 m11500_s08_param_27,
	.param .u32 m11500_s08_param_28,
	.param .u32 m11500_s08_param_29,
	.param .u32 m11500_s08_param_30,
	.param .u32 m11500_s08_param_31,
	.param .u32 m11500_s08_param_32,
	.param .u32 m11500_s08_param_33,
	.param .u64 m11500_s08_param_34
)
{



	ret;
}

	// .globl	m11500_s16
.entry m11500_s16(
	.param .u64 .ptr .global .align 4 m11500_s16_param_0,
	.param .u64 .ptr .global .align 4 m11500_s16_param_1,
	.param .u64 .ptr .global .align 4 m11500_s16_param_2,
	.param .u64 .ptr .global .align 4 m11500_s16_param_3,
	.param .u64 .ptr .global .align 1 m11500_s16_param_4,
	.param .u64 .ptr .global .align 1 m11500_s16_param_5,
	.param .u64 .ptr .global .align 4 m11500_s16_param_6,
	.param .u64 .ptr .global .align 4 m11500_s16_param_7,
	.param .u64 .ptr .global .align 4 m11500_s16_param_8,
	.param .u64 .ptr .global .align 4 m11500_s16_param_9,
	.param .u64 .ptr .global .align 4 m11500_s16_param_10,
	.param .u64 .ptr .global .align 4 m11500_s16_param_11,
	.param .u64 .ptr .global .align 4 m11500_s16_param_12,
	.param .u64 .ptr .global .align 4 m11500_s16_param_13,
	.param .u64 .ptr .global .align 4 m11500_s16_param_14,
	.param .u64 .ptr .global .align 4 m11500_s16_param_15,
	.param .u64 .ptr .global .align 4 m11500_s16_param_16,
	.param .u64 .ptr .global .align 4 m11500_s16_param_17,
	.param .u64 .ptr .global .align 1 m11500_s16_param_18,
	.param .u64 .ptr .global .align 4 m11500_s16_param_19,
	.param .u64 .ptr .global .align 4 m11500_s16_param_20,
	.param .u64 .ptr .global .align 4 m11500_s16_param_21,
	.param .u64 .ptr .global .align 4 m11500_s16_param_22,
	.param .u64 .ptr .global .align 4 m11500_s16_param_23,
	.param .u32 m11500_s16_param_24,
	.param .u32 m11500_s16_param_25,
	.param .u32 m11500_s16_param_26,
	.param .u32 m11500_s16_param_27,
	.param .u32 m11500_s16_param_28,
	.param .u32 m11500_s16_param_29,
	.param .u32 m11500_s16_param_30,
	.param .u32 m11500_s16_param_31,
	.param .u32 m11500_s16_param_32,
	.param .u32 m11500_s16_param_33,
	.param .u64 m11500_s16_param_34
)
{



	ret;
}


  