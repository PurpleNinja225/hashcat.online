//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: UNKNOWN
// Driver 
// Based on LLVM 3.4svn
//

.version 6.1
.target sm_50, texmode_independent
.address_size 64

	// .globl	amp

.entry amp(
	.param .u64 .ptr .global .align 4 amp_param_0,
	.param .u64 .ptr .global .align 4 amp_param_1,
	.param .u64 .ptr .global .align 4 amp_param_2,
	.param .u64 .ptr .global .align 4 amp_param_3,
	.param .u64 .ptr .global .align 4 amp_param_4,
	.param .u32 amp_param_5,
	.param .u32 amp_param_6
)
{
	.local .align 16 .b8 	__local_depot0[64];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<1032>;
	.reg .b16 	%rs<377>;
	.reg .b32 	%r<8959>;
	.reg .b64 	%rd<44>;


	mov.u64 	%rd43, __local_depot0;
	cvta.local.u64 	%SP, %rd43;
	ld.param.u64 	%rd8, [amp_param_0];
	ld.param.u64 	%rd9, [amp_param_1];
	ld.param.u64 	%rd10, [amp_param_2];
	ld.param.u32 	%r1779, [amp_param_6];
	mov.u32 	%r1780, %ctaid.x;
	mov.u32 	%r1781, %ntid.x;
	mov.b32	%r1782, %envreg3;
	mad.lo.s32 	%r1783, %r1780, %r1781, %r1782;
	mov.u32 	%r1784, %tid.x;
	add.s32 	%r1, %r1783, %r1784;
	setp.ge.u32	%p1, %r1, %r1779;
	@%p1 bra 	BB0_1557;

	mul.wide.u32 	%rd11, %r1, 80;
	add.s64 	%rd12, %rd8, %rd11;
	add.s64 	%rd1, %rd12, 64;
	ld.global.u32 	%r8949, [%rd12+64];
	ld.global.u32 	%r8773, [%rd10];
	add.s64 	%rd3, %rd9, %rd11;
	setp.ne.s32	%p2, %r8773, 58;
	@%p2 bra 	BB0_3;

	ld.global.u32 	%r1785, [%rd10+4];
	setp.eq.s32	%p3, %r1785, 0;
	@%p3 bra 	BB0_1556;

BB0_3:
	ld.global.u32 	%r8944, [%rd1+-64];
	ld.global.u32 	%r8943, [%rd1+-60];
	ld.global.u32 	%r8942, [%rd1+-56];
	ld.global.u32 	%r8941, [%rd1+-52];
	ld.global.u32 	%r8948, [%rd1+-48];
	ld.global.u32 	%r8947, [%rd1+-44];
	ld.global.u32 	%r8946, [%rd1+-40];
	ld.global.u32 	%r8945, [%rd1+-36];
	setp.eq.s32	%p4, %r8773, 0;
	@%p4 bra 	BB0_1555;

	add.u64 	%rd13, %SP, 32;
	cvta.to.local.u64 	%rd6, %rd13;
	add.u64 	%rd14, %SP, 0;
	cvta.to.local.u64 	%rd7, %rd14;
	mov.u32 	%r8774, 0;
	bra.uni 	BB0_5;

BB0_1556:
	ld.global.u32 	%r8751, [%rd1+-64];
	st.global.u32 	[%rd3], %r8751;
	ld.global.u32 	%r8752, [%rd1+-60];
	st.global.u32 	[%rd3+4], %r8752;
	ld.global.u32 	%r8753, [%rd1+-56];
	st.global.u32 	[%rd3+8], %r8753;
	ld.global.u32 	%r8754, [%rd1+-52];
	st.global.u32 	[%rd3+12], %r8754;
	ld.global.u32 	%r8755, [%rd1+-48];
	st.global.u32 	[%rd3+16], %r8755;
	ld.global.u32 	%r8756, [%rd1+-44];
	st.global.u32 	[%rd3+20], %r8756;
	ld.global.u32 	%r8757, [%rd1+-40];
	st.global.u32 	[%rd3+24], %r8757;
	ld.global.u32 	%r8758, [%rd1+-36];
	st.global.u32 	[%rd3+28], %r8758;
	ld.global.u32 	%r8759, [%rd1+-32];
	st.global.u32 	[%rd3+32], %r8759;
	ld.global.u32 	%r8760, [%rd1+-28];
	st.global.u32 	[%rd3+36], %r8760;
	ld.global.u32 	%r8761, [%rd1+-24];
	st.global.u32 	[%rd3+40], %r8761;
	ld.global.u32 	%r8762, [%rd1+-20];
	st.global.u32 	[%rd3+44], %r8762;
	ld.global.u32 	%r8763, [%rd1+-16];
	st.global.u32 	[%rd3+48], %r8763;
	ld.global.u32 	%r8764, [%rd1+-12];
	st.global.u32 	[%rd3+52], %r8764;
	ld.global.u32 	%r8765, [%rd1+-8];
	st.global.u32 	[%rd3+56], %r8765;
	ld.global.u32 	%r8766, [%rd1+-4];
	st.global.u32 	[%rd3+60], %r8766;
	ld.global.u32 	%r8767, [%rd1];
	st.global.u32 	[%rd3+64], %r8767;
	bra.uni 	BB0_1557;

BB0_196:
	setp.ne.s32	%p132, %r24, 31;
	mov.u32 	%r8784, %r8787;
	mov.u32 	%r8785, %r8787;
	mov.u32 	%r8786, %r8787;
	mov.u32 	%r8788, %r8787;
	mov.u32 	%r8789, %r8787;
	mov.u32 	%r8790, %r8787;
	mov.u32 	%r8791, %r8787;
	@%p132 bra 	BB0_215;

	mov.u32 	%r8784, 0;
	mov.u32 	%r2363, 8;
	// inline asm
	shf.r.wrap.b32 %r8788, %r8784, %r19, %r2363;
	// inline asm

BB0_198:
	mov.u32 	%r8785, %r8784;
	mov.u32 	%r8786, %r8784;
	mov.u32 	%r8787, %r8784;
	mov.u32 	%r8789, %r8784;

BB0_190:
	mov.u32 	%r8790, %r8784;
	mov.u32 	%r8791, %r8784;

BB0_215:
	and.b32  	%r2905, %r14, 3;
	shl.b32 	%r2906, %r2905, 3;
	mov.u32 	%r2907, -1;
	shl.b32 	%r160, %r2907, %r2906;
	shr.u32 	%r2904, %r14, 2;
	setp.gt.s32	%p174, %r2904, 3;
	@%p174 bra 	BB0_223;

	setp.gt.s32	%p180, %r2904, 1;
	@%p180 bra 	BB0_220;

	setp.eq.s32	%p183, %r2904, 0;
	@%p183 bra 	BB0_234;
	bra.uni 	BB0_218;

BB0_234:
	and.b32  	%r8787, %r8787, %r160;
	bra.uni 	BB0_235;

BB0_223:
	setp.gt.s32	%p175, %r2904, 5;
	@%p175 bra 	BB0_227;

	setp.eq.s32	%p178, %r2904, 4;
	@%p178 bra 	BB0_232;
	bra.uni 	BB0_225;

BB0_232:
	and.b32  	%r8791, %r8791, %r160;
	mov.u32 	%r8784, 0;
	mov.u32 	%r8785, %r8784;
	mov.u32 	%r8786, %r8784;
	mov.u32 	%r8787, %r8784;
	bra.uni 	BB0_235;

BB0_220:
	setp.eq.s32	%p181, %r2904, 2;
	@%p181 bra 	BB0_233;
	bra.uni 	BB0_221;

BB0_233:
	and.b32  	%r8785, %r8785, %r160;
	mov.u32 	%r8786, 0;
	mov.u32 	%r8787, %r8786;
	bra.uni 	BB0_235;

BB0_227:
	setp.eq.s32	%p176, %r2904, 6;
	@%p176 bra 	BB0_230;
	bra.uni 	BB0_228;

BB0_230:
	and.b32  	%r8789, %r8789, %r160;
	mov.u32 	%r8784, 0;
	mov.u32 	%r8785, %r8784;
	mov.u32 	%r8786, %r8784;
	mov.u32 	%r8787, %r8784;
	bra.uni 	BB0_231;

BB0_218:
	setp.eq.s32	%p184, %r2904, 1;
	@%p184 bra 	BB0_219;
	bra.uni 	BB0_235;

BB0_219:
	and.b32  	%r8786, %r8786, %r160;
	mov.u32 	%r8787, 0;
	bra.uni 	BB0_235;

BB0_225:
	setp.eq.s32	%p179, %r2904, 5;
	@%p179 bra 	BB0_226;
	bra.uni 	BB0_235;

BB0_226:
	and.b32  	%r8790, %r8790, %r160;
	mov.u32 	%r8784, 0;
	mov.u32 	%r8785, %r8784;
	mov.u32 	%r8786, %r8784;
	mov.u32 	%r8787, %r8784;
	mov.u32 	%r8791, %r8784;
	bra.uni 	BB0_235;

BB0_221:
	setp.eq.s32	%p182, %r2904, 3;
	@%p182 bra 	BB0_222;
	bra.uni 	BB0_235;

BB0_222:
	and.b32  	%r8784, %r8784, %r160;
	mov.u32 	%r8785, 0;
	mov.u32 	%r8786, %r8785;
	mov.u32 	%r8787, %r8785;
	bra.uni 	BB0_235;

BB0_228:
	setp.ne.s32	%p177, %r2904, 7;
	@%p177 bra 	BB0_235;

	and.b32  	%r8788, %r8788, %r160;
	mov.u32 	%r8784, 0;
	mov.u32 	%r8785, %r8784;
	mov.u32 	%r8786, %r8784;
	mov.u32 	%r8787, %r8784;
	mov.u32 	%r8789, %r8784;

BB0_231:
	mov.u32 	%r8790, %r8784;
	mov.u32 	%r8791, %r8784;

BB0_235:
	or.b32  	%r8944, %r8787, %r19;
	or.b32  	%r8943, %r8786, %r20;
	or.b32  	%r8942, %r8785, %r21;
	or.b32  	%r8941, %r8784, %r22;
	or.b32  	%r8948, %r8791, %r15;
	or.b32  	%r8947, %r8790, %r16;
	or.b32  	%r8946, %r8789, %r17;
	or.b32  	%r8945, %r8788, %r18;
	bra.uni 	BB0_1554;

BB0_290:
	setp.eq.s32	%p220, %r24, 19;
	@%p220 bra 	BB0_321;
	bra.uni 	BB0_291;

BB0_321:
	mov.u32 	%r3117, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r21, %r22, %r3117;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r20, %r21, %r3117;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r19, %r20, %r3117;
	// inline asm
	mov.u32 	%r8808, 0;
	// inline asm
	shf.r.wrap.b32 %r19, %r8808, %r19, %r3117;
	// inline asm

BB0_322:
	mov.u32 	%r8809, %r8808;
	mov.u32 	%r8810, %r8808;
	mov.u32 	%r8811, %r8808;
	bra.uni 	BB0_338;

BB0_274:
	setp.eq.s32	%p232, %r24, 11;
	@%p232 bra 	BB0_275;
	bra.uni 	BB0_291;

BB0_275:
	mov.u32 	%r3261, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r15, %r16, %r3261;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r22, %r15, %r3261;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r21, %r22, %r3261;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3250, %r20, %r21, %r3261;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8808, %r19, %r20, %r3261;
	// inline asm
	mov.u32 	%r8810, 0;
	// inline asm
	shf.r.wrap.b32 %r8809, %r8810, %r19, %r3261;
	// inline asm
	mov.u32 	%r8811, %r8810;
	mov.u32 	%r19, %r3250;
	bra.uni 	BB0_338;

BB0_306:
	setp.eq.s32	%p209, %r24, 27;
	@%p209 bra 	BB0_307;
	bra.uni 	BB0_291;

BB0_307:
	mov.u32 	%r3005, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r19, %r20, %r3005;
	// inline asm
	mov.u32 	%r8808, 0;
	// inline asm
	shf.r.wrap.b32 %r17, %r8808, %r19, %r3005;
	// inline asm

BB0_308:
	mov.u32 	%r8809, %r8808;
	mov.u32 	%r8810, %r8808;
	mov.u32 	%r8811, %r8808;
	bra.uni 	BB0_336;

BB0_266:
	setp.eq.s32	%p238, %r24, 7;
	@%p238 bra 	BB0_267;
	bra.uni 	BB0_291;

BB0_267:
	mov.u32 	%r3345, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r16, %r17, %r3345;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r15, %r16, %r3345;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r22, %r15, %r3345;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3330, %r21, %r22, %r3345;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8808, %r20, %r21, %r3345;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8809, %r19, %r20, %r3345;
	// inline asm
	mov.u32 	%r8811, 0;
	// inline asm
	shf.r.wrap.b32 %r8810, %r8811, %r19, %r3345;
	// inline asm
	mov.u32 	%r19, %r3330;
	bra.uni 	BB0_338;

BB0_297:
	setp.eq.s32	%p215, %r24, 23;
	@%p215 bra 	BB0_298;
	bra.uni 	BB0_291;

BB0_298:
	mov.u32 	%r3057, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r20, %r21, %r3057;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r19, %r20, %r3057;
	// inline asm
	mov.u32 	%r8808, 0;
	// inline asm
	shf.r.wrap.b32 %r16, %r8808, %r19, %r3057;
	// inline asm

BB0_299:
	mov.u32 	%r8809, %r8808;
	mov.u32 	%r8810, %r8808;
	mov.u32 	%r8811, %r8808;
	bra.uni 	BB0_337;

BB0_281:
	setp.eq.s32	%p227, %r24, 15;
	@%p227 bra 	BB0_282;
	bra.uni 	BB0_291;

BB0_282:
	mov.u32 	%r3185, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r22, %r15, %r3185;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r21, %r22, %r3185;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r20, %r21, %r3185;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3178, %r19, %r20, %r3185;
	// inline asm
	mov.u32 	%r8809, 0;
	// inline asm
	shf.r.wrap.b32 %r8808, %r8809, %r19, %r3185;
	// inline asm
	mov.u32 	%r8810, %r8809;
	mov.u32 	%r8811, %r8809;
	mov.u32 	%r19, %r3178;
	bra.uni 	BB0_338;

BB0_314:
	setp.ne.s32	%p204, %r24, 30;
	@%p204 bra 	BB0_291;

	mov.u32 	%r8808, 0;
	mov.u32 	%r2972, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r8808, %r19, %r2972;
	// inline asm

BB0_334:
	mov.u32 	%r8809, %r8808;
	mov.u32 	%r8810, %r8808;
	mov.u32 	%r8811, %r8808;

BB0_335:
	mov.u32 	%r17, %r8808;

BB0_336:
	mov.u32 	%r16, %r8808;

BB0_337:
	mov.u32 	%r19, %r8808;
	bra.uni 	BB0_338;

BB0_291:
	mov.u32 	%r8808, %r22;
	mov.u32 	%r8809, %r21;
	mov.u32 	%r8810, %r20;
	mov.u32 	%r8811, %r19;
	mov.u32 	%r19, %r15;

BB0_338:
	or.b32  	%r8944, %r8811, %r8803;
	or.b32  	%r8943, %r8810, %r8802;
	or.b32  	%r8942, %r8809, %r8801;
	or.b32  	%r8941, %r8808, %r8800;
	or.b32  	%r8948, %r19, %r8807;
	or.b32  	%r8947, %r16, %r8806;
	or.b32  	%r8946, %r17, %r8805;
	or.b32  	%r8945, %r18, %r8804;
	bra.uni 	BB0_1554;

BB0_1314:
	setp.eq.s32	%p935, %r6470, 1;
	mov.u32 	%r8891, %r8899;
	mov.u32 	%r8892, %r8899;
	mov.u32 	%r8893, %r8899;
	mov.u32 	%r8894, %r8899;
	mov.u32 	%r8895, %r8899;
	mov.u32 	%r8896, %r8899;
	mov.u32 	%r8897, %r8899;
	mov.u32 	%r8898, %r8899;
	@%p935 bra 	BB0_1315;
	bra.uni 	BB0_1394;

BB0_1315:
	mov.u32 	%r7015, 24;
	// inline asm
	shf.r.wrap.b32 %r8895, %r17, %r18, %r7015;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8896, %r16, %r17, %r7015;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8897, %r15, %r16, %r7015;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8898, %r22, %r15, %r7015;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8891, %r21, %r22, %r7015;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8892, %r20, %r21, %r7015;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8893, %r19, %r20, %r7015;
	// inline asm
	mov.u32 	%r7013, 0;
	// inline asm
	shf.r.wrap.b32 %r8894, %r7013, %r19, %r7015;
	// inline asm
	bra.uni 	BB0_1394;

BB0_1346:
	setp.eq.s32	%p912, %r6470, 17;
	mov.u32 	%r8891, %r8899;
	mov.u32 	%r8892, %r8899;
	mov.u32 	%r8893, %r8899;
	mov.u32 	%r8894, %r8899;
	mov.u32 	%r8895, %r8899;
	mov.u32 	%r8896, %r8899;
	mov.u32 	%r8897, %r8899;
	mov.u32 	%r8898, %r8899;
	@%p912 bra 	BB0_1347;
	bra.uni 	BB0_1394;

BB0_1347:
	mov.u32 	%r6671, 24;
	// inline asm
	shf.r.wrap.b32 %r8895, %r21, %r22, %r6671;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8896, %r20, %r21, %r6671;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8897, %r19, %r20, %r6671;
	// inline asm
	mov.u32 	%r8891, 0;
	// inline asm
	shf.r.wrap.b32 %r8898, %r8891, %r19, %r6671;
	// inline asm
	bra.uni 	BB0_1351;

BB0_1329:
	setp.eq.s32	%p924, %r6470, 9;
	mov.u32 	%r8891, %r8899;
	mov.u32 	%r8892, %r8899;
	mov.u32 	%r8893, %r8899;
	mov.u32 	%r8894, %r8899;
	mov.u32 	%r8895, %r8899;
	mov.u32 	%r8896, %r8899;
	mov.u32 	%r8897, %r8899;
	mov.u32 	%r8898, %r8899;
	@%p924 bra 	BB0_1330;
	bra.uni 	BB0_1394;

BB0_1330:
	mov.u32 	%r6827, 24;
	// inline asm
	shf.r.wrap.b32 %r8895, %r15, %r16, %r6827;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8896, %r22, %r15, %r6827;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8897, %r21, %r22, %r6827;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8898, %r20, %r21, %r6827;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8891, %r19, %r20, %r6827;
	// inline asm
	mov.u32 	%r8893, 0;
	// inline asm
	shf.r.wrap.b32 %r8892, %r8893, %r19, %r6827;
	// inline asm
	mov.u32 	%r8894, %r8893;
	bra.uni 	BB0_1394;

BB0_1363:
	setp.eq.s32	%p901, %r6470, 25;
	mov.u32 	%r8891, %r8899;
	mov.u32 	%r8892, %r8899;
	mov.u32 	%r8893, %r8899;
	mov.u32 	%r8894, %r8899;
	mov.u32 	%r8895, %r8899;
	mov.u32 	%r8896, %r8899;
	mov.u32 	%r8897, %r8899;
	mov.u32 	%r8898, %r8899;
	@%p901 bra 	BB0_1364;
	bra.uni 	BB0_1394;

BB0_1364:
	mov.u32 	%r6547, 24;
	// inline asm
	shf.r.wrap.b32 %r8895, %r19, %r20, %r6547;
	// inline asm
	mov.u32 	%r8891, 0;
	// inline asm
	shf.r.wrap.b32 %r8896, %r8891, %r19, %r6547;
	// inline asm
	bra.uni 	BB0_1368;

BB0_1321:
	setp.eq.s32	%p930, %r6470, 5;
	mov.u32 	%r8891, %r8899;
	mov.u32 	%r8892, %r8899;
	mov.u32 	%r8893, %r8899;
	mov.u32 	%r8894, %r8899;
	mov.u32 	%r8895, %r8899;
	mov.u32 	%r8896, %r8899;
	mov.u32 	%r8897, %r8899;
	mov.u32 	%r8898, %r8899;
	@%p930 bra 	BB0_1322;
	bra.uni 	BB0_1394;

BB0_1322:
	mov.u32 	%r6917, 24;
	// inline asm
	shf.r.wrap.b32 %r8895, %r16, %r17, %r6917;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8896, %r15, %r16, %r6917;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8897, %r22, %r15, %r6917;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8898, %r21, %r22, %r6917;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8891, %r20, %r21, %r6917;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8892, %r19, %r20, %r6917;
	// inline asm
	mov.u32 	%r8894, 0;
	// inline asm
	shf.r.wrap.b32 %r8893, %r8894, %r19, %r6917;
	// inline asm
	bra.uni 	BB0_1394;

BB0_1354:
	setp.eq.s32	%p907, %r6470, 21;
	mov.u32 	%r8891, %r8899;
	mov.u32 	%r8892, %r8899;
	mov.u32 	%r8893, %r8899;
	mov.u32 	%r8894, %r8899;
	mov.u32 	%r8895, %r8899;
	mov.u32 	%r8896, %r8899;
	mov.u32 	%r8897, %r8899;
	mov.u32 	%r8898, %r8899;
	@%p907 bra 	BB0_1355;
	bra.uni 	BB0_1394;

BB0_1355:
	mov.u32 	%r6605, 24;
	// inline asm
	shf.r.wrap.b32 %r8895, %r20, %r21, %r6605;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8896, %r19, %r20, %r6605;
	// inline asm
	mov.u32 	%r8891, 0;
	// inline asm
	shf.r.wrap.b32 %r8897, %r8891, %r19, %r6605;
	// inline asm
	bra.uni 	BB0_1359;

BB0_1336:
	setp.eq.s32	%p919, %r6470, 13;
	mov.u32 	%r8891, %r8899;
	mov.u32 	%r8892, %r8899;
	mov.u32 	%r8893, %r8899;
	mov.u32 	%r8894, %r8899;
	mov.u32 	%r8895, %r8899;
	mov.u32 	%r8896, %r8899;
	mov.u32 	%r8897, %r8899;
	mov.u32 	%r8898, %r8899;
	@%p919 bra 	BB0_1337;
	bra.uni 	BB0_1394;

BB0_1337:
	mov.u32 	%r6745, 24;
	// inline asm
	shf.r.wrap.b32 %r8895, %r22, %r15, %r6745;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8896, %r21, %r22, %r6745;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8897, %r20, %r21, %r6745;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8898, %r19, %r20, %r6745;
	// inline asm
	mov.u32 	%r8892, 0;
	// inline asm
	shf.r.wrap.b32 %r8891, %r8892, %r19, %r6745;
	// inline asm
	bra.uni 	BB0_1341;

BB0_1372:
	setp.eq.s32	%p896, %r6470, 29;
	mov.u32 	%r8891, %r8899;
	mov.u32 	%r8892, %r8899;
	mov.u32 	%r8893, %r8899;
	mov.u32 	%r8894, %r8899;
	mov.u32 	%r8895, %r8899;
	mov.u32 	%r8896, %r8899;
	mov.u32 	%r8897, %r8899;
	mov.u32 	%r8898, %r8899;
	@%p896 bra 	BB0_1373;
	bra.uni 	BB0_1394;

BB0_1373:
	mov.u32 	%r8891, 0;
	mov.u32 	%r6497, 24;
	// inline asm
	shf.r.wrap.b32 %r8895, %r8891, %r19, %r6497;
	// inline asm
	bra.uni 	BB0_1377;

BB0_1317:
	setp.eq.s32	%p933, %r6470, 3;
	mov.u32 	%r8891, %r8899;
	mov.u32 	%r8892, %r8899;
	mov.u32 	%r8893, %r8899;
	mov.u32 	%r8894, %r8899;
	mov.u32 	%r8895, %r8899;
	mov.u32 	%r8896, %r8899;
	mov.u32 	%r8897, %r8899;
	mov.u32 	%r8898, %r8899;
	@%p933 bra 	BB0_1318;
	bra.uni 	BB0_1394;

BB0_1318:
	mov.u32 	%r6951, 8;
	// inline asm
	shf.r.wrap.b32 %r8895, %r17, %r18, %r6951;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8896, %r16, %r17, %r6951;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8897, %r15, %r16, %r6951;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8898, %r22, %r15, %r6951;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8891, %r21, %r22, %r6951;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8892, %r20, %r21, %r6951;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8893, %r19, %r20, %r6951;
	// inline asm
	mov.u32 	%r6949, 0;
	// inline asm
	shf.r.wrap.b32 %r8894, %r6949, %r19, %r6951;
	// inline asm
	bra.uni 	BB0_1394;

BB0_1349:
	setp.eq.s32	%p910, %r6470, 19;
	mov.u32 	%r8891, %r8899;
	mov.u32 	%r8892, %r8899;
	mov.u32 	%r8893, %r8899;
	mov.u32 	%r8894, %r8899;
	mov.u32 	%r8895, %r8899;
	mov.u32 	%r8896, %r8899;
	mov.u32 	%r8897, %r8899;
	mov.u32 	%r8898, %r8899;
	@%p910 bra 	BB0_1350;
	bra.uni 	BB0_1394;

BB0_1350:
	mov.u32 	%r6631, 8;
	// inline asm
	shf.r.wrap.b32 %r8895, %r21, %r22, %r6631;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8896, %r20, %r21, %r6631;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8897, %r19, %r20, %r6631;
	// inline asm
	mov.u32 	%r8891, 0;
	// inline asm
	shf.r.wrap.b32 %r8898, %r8891, %r19, %r6631;
	// inline asm

BB0_1351:
	mov.u32 	%r8892, %r8891;
	mov.u32 	%r8893, %r8891;
	mov.u32 	%r8894, %r8891;
	bra.uni 	BB0_1394;

BB0_1332:
	setp.eq.s32	%p922, %r6470, 11;
	mov.u32 	%r8891, %r8899;
	mov.u32 	%r8892, %r8899;
	mov.u32 	%r8893, %r8899;
	mov.u32 	%r8894, %r8899;
	mov.u32 	%r8895, %r8899;
	mov.u32 	%r8896, %r8899;
	mov.u32 	%r8897, %r8899;
	mov.u32 	%r8898, %r8899;
	@%p922 bra 	BB0_1333;
	bra.uni 	BB0_1394;

BB0_1333:
	mov.u32 	%r6775, 8;
	// inline asm
	shf.r.wrap.b32 %r8895, %r15, %r16, %r6775;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8896, %r22, %r15, %r6775;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8897, %r21, %r22, %r6775;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8898, %r20, %r21, %r6775;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8891, %r19, %r20, %r6775;
	// inline asm
	mov.u32 	%r8893, 0;
	// inline asm
	shf.r.wrap.b32 %r8892, %r8893, %r19, %r6775;
	// inline asm
	mov.u32 	%r8894, %r8893;
	bra.uni 	BB0_1394;

BB0_1366:
	setp.eq.s32	%p899, %r6470, 27;
	mov.u32 	%r8891, %r8899;
	mov.u32 	%r8892, %r8899;
	mov.u32 	%r8893, %r8899;
	mov.u32 	%r8894, %r8899;
	mov.u32 	%r8895, %r8899;
	mov.u32 	%r8896, %r8899;
	mov.u32 	%r8897, %r8899;
	mov.u32 	%r8898, %r8899;
	@%p899 bra 	BB0_1367;
	bra.uni 	BB0_1394;

BB0_1367:
	mov.u32 	%r6519, 8;
	// inline asm
	shf.r.wrap.b32 %r8895, %r19, %r20, %r6519;
	// inline asm
	mov.u32 	%r8891, 0;
	// inline asm
	shf.r.wrap.b32 %r8896, %r8891, %r19, %r6519;
	// inline asm

BB0_1368:
	mov.u32 	%r8892, %r8891;
	mov.u32 	%r8893, %r8891;
	mov.u32 	%r8894, %r8891;
	bra.uni 	BB0_1369;

BB0_1324:
	setp.eq.s32	%p928, %r6470, 7;
	mov.u32 	%r8891, %r8899;
	mov.u32 	%r8892, %r8899;
	mov.u32 	%r8893, %r8899;
	mov.u32 	%r8894, %r8899;
	mov.u32 	%r8895, %r8899;
	mov.u32 	%r8896, %r8899;
	mov.u32 	%r8897, %r8899;
	mov.u32 	%r8898, %r8899;
	@%p928 bra 	BB0_1325;
	bra.uni 	BB0_1394;

BB0_1325:
	mov.u32 	%r6859, 8;
	// inline asm
	shf.r.wrap.b32 %r8895, %r16, %r17, %r6859;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8896, %r15, %r16, %r6859;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8897, %r22, %r15, %r6859;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8898, %r21, %r22, %r6859;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8891, %r20, %r21, %r6859;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8892, %r19, %r20, %r6859;
	// inline asm
	mov.u32 	%r8894, 0;
	// inline asm
	shf.r.wrap.b32 %r8893, %r8894, %r19, %r6859;
	// inline asm
	bra.uni 	BB0_1394;

BB0_1357:
	setp.eq.s32	%p905, %r6470, 23;
	mov.u32 	%r8891, %r8899;
	mov.u32 	%r8892, %r8899;
	mov.u32 	%r8893, %r8899;
	mov.u32 	%r8894, %r8899;
	mov.u32 	%r8895, %r8899;
	mov.u32 	%r8896, %r8899;
	mov.u32 	%r8897, %r8899;
	mov.u32 	%r8898, %r8899;
	@%p905 bra 	BB0_1358;
	bra.uni 	BB0_1394;

BB0_1358:
	mov.u32 	%r6571, 8;
	// inline asm
	shf.r.wrap.b32 %r8895, %r20, %r21, %r6571;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8896, %r19, %r20, %r6571;
	// inline asm
	mov.u32 	%r8891, 0;
	// inline asm
	shf.r.wrap.b32 %r8897, %r8891, %r19, %r6571;
	// inline asm

BB0_1359:
	mov.u32 	%r8892, %r8891;
	mov.u32 	%r8893, %r8891;
	mov.u32 	%r8894, %r8891;
	mov.u32 	%r8898, %r8891;
	bra.uni 	BB0_1394;

BB0_1339:
	setp.eq.s32	%p917, %r6470, 15;
	mov.u32 	%r8891, %r8899;
	mov.u32 	%r8892, %r8899;
	mov.u32 	%r8893, %r8899;
	mov.u32 	%r8894, %r8899;
	mov.u32 	%r8895, %r8899;
	mov.u32 	%r8896, %r8899;
	mov.u32 	%r8897, %r8899;
	mov.u32 	%r8898, %r8899;
	@%p917 bra 	BB0_1340;
	bra.uni 	BB0_1394;

BB0_1340:
	mov.u32 	%r6699, 8;
	// inline asm
	shf.r.wrap.b32 %r8895, %r22, %r15, %r6699;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8896, %r21, %r22, %r6699;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8897, %r20, %r21, %r6699;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8898, %r19, %r20, %r6699;
	// inline asm
	mov.u32 	%r8892, 0;
	// inline asm
	shf.r.wrap.b32 %r8891, %r8892, %r19, %r6699;
	// inline asm

BB0_1341:
	mov.u32 	%r8893, %r8892;
	mov.u32 	%r8894, %r8892;
	bra.uni 	BB0_1394;

BB0_1375:
	setp.ne.s32	%p894, %r6470, 31;
	mov.u32 	%r8891, %r8899;
	mov.u32 	%r8892, %r8899;
	mov.u32 	%r8893, %r8899;
	mov.u32 	%r8894, %r8899;
	mov.u32 	%r8895, %r8899;
	mov.u32 	%r8896, %r8899;
	mov.u32 	%r8897, %r8899;
	mov.u32 	%r8898, %r8899;
	@%p894 bra 	BB0_1394;

	mov.u32 	%r8891, 0;
	mov.u32 	%r6475, 8;
	// inline asm
	shf.r.wrap.b32 %r8895, %r8891, %r19, %r6475;
	// inline asm

BB0_1377:
	mov.u32 	%r8892, %r8891;
	mov.u32 	%r8893, %r8891;
	mov.u32 	%r8894, %r8891;
	mov.u32 	%r8896, %r8891;

BB0_1369:
	mov.u32 	%r8897, %r8891;
	mov.u32 	%r8898, %r8891;

BB0_1394:
	// inline asm
	prmt.b32 %r7016, %r8895, 0, 0x0123;
	// inline asm
	// inline asm
	prmt.b32 %r7018, %r8896, 0, 0x0123;
	// inline asm
	// inline asm
	prmt.b32 %r7020, %r8897, 0, 0x0123;
	// inline asm
	// inline asm
	prmt.b32 %r7022, %r8898, 0, 0x0123;
	// inline asm
	// inline asm
	prmt.b32 %r7024, %r8891, 0, 0x0123;
	// inline asm
	// inline asm
	prmt.b32 %r7026, %r8892, 0, 0x0123;
	// inline asm
	// inline asm
	prmt.b32 %r7028, %r8893, 0, 0x0123;
	// inline asm
	and.b32  	%r7039, %r14, 3;
	mov.u32 	%r7040, 4;
	sub.s32 	%r7041, %r7040, %r7039;
	shl.b32 	%r7042, %r7041, 2;
	mov.u32 	%r7043, 1985229328;
	shr.u32 	%r7044, %r7043, %r7042;
	and.b32  	%r1414, %r7044, 65535;
	shr.u32 	%r7038, %r14, 2;
	setp.gt.s32	%p936, %r7038, 3;
	@%p936 bra 	BB0_1402;

	setp.gt.s32	%p942, %r7038, 1;
	@%p942 bra 	BB0_1399;

	setp.eq.s32	%p945, %r7038, 0;
	@%p945 bra 	BB0_1412;
	bra.uni 	BB0_1397;

BB0_1412:
	// inline asm
	prmt.b32 %r7185, %r8894, 0, 0x0123;
	// inline asm
	// inline asm
	prmt.b32 %r8906, %r7028, %r7185, %r1414;
	// inline asm
	// inline asm
	prmt.b32 %r8905, %r7026, %r7028, %r1414;
	// inline asm
	// inline asm
	prmt.b32 %r8904, %r7024, %r7026, %r1414;
	// inline asm
	// inline asm
	prmt.b32 %r8903, %r7022, %r7024, %r1414;
	// inline asm
	// inline asm
	prmt.b32 %r8902, %r7020, %r7022, %r1414;
	// inline asm
	// inline asm
	prmt.b32 %r8901, %r7018, %r7020, %r1414;
	// inline asm
	// inline asm
	prmt.b32 %r8900, %r7016, %r7018, %r1414;
	// inline asm
	mov.u32 	%r7216, 0;
	// inline asm
	prmt.b32 %r8899, %r7216, %r7016, %r1414;
	// inline asm
	bra.uni 	BB0_1413;

BB0_1402:
	setp.gt.s32	%p937, %r7038, 5;
	@%p937 bra 	BB0_1406;

	setp.eq.s32	%p940, %r7038, 4;
	@%p940 bra 	BB0_1410;
	bra.uni 	BB0_1404;

BB0_1410:
	// inline asm
	prmt.b32 %r8906, %r7020, %r7022, %r1414;
	// inline asm
	// inline asm
	prmt.b32 %r8905, %r7018, %r7020, %r1414;
	// inline asm
	// inline asm
	prmt.b32 %r8904, %r7016, %r7018, %r1414;
	// inline asm
	mov.u32 	%r8899, 0;
	// inline asm
	prmt.b32 %r8903, %r8899, %r7016, %r1414;
	// inline asm
	mov.u32 	%r8900, %r8899;
	mov.u32 	%r8901, %r8899;
	mov.u32 	%r8902, %r8899;
	bra.uni 	BB0_1413;

BB0_1399:
	setp.eq.s32	%p943, %r7038, 2;
	@%p943 bra 	BB0_1411;
	bra.uni 	BB0_1400;

BB0_1411:
	// inline asm
	prmt.b32 %r8906, %r7024, %r7026, %r1414;
	// inline asm
	// inline asm
	prmt.b32 %r8905, %r7022, %r7024, %r1414;
	// inline asm
	// inline asm
	prmt.b32 %r8904, %r7020, %r7022, %r1414;
	// inline asm
	// inline asm
	prmt.b32 %r8903, %r7018, %r7020, %r1414;
	// inline asm
	// inline asm
	prmt.b32 %r8902, %r7016, %r7018, %r1414;
	// inline asm
	mov.u32 	%r8899, 0;
	// inline asm
	prmt.b32 %r8901, %r8899, %r7016, %r1414;
	// inline asm
	mov.u32 	%r8900, %r8899;
	bra.uni 	BB0_1413;

BB0_1406:
	setp.eq.s32	%p938, %r7038, 6;
	@%p938 bra 	BB0_1409;
	bra.uni 	BB0_1407;

BB0_1409:
	// inline asm
	prmt.b32 %r8906, %r7016, %r7018, %r1414;
	// inline asm
	mov.u32 	%r8899, 0;
	// inline asm
	prmt.b32 %r8905, %r8899, %r7016, %r1414;
	// inline asm
	mov.u32 	%r8900, %r8899;
	mov.u32 	%r8901, %r8899;
	mov.u32 	%r8902, %r8899;
	mov.u32 	%r8903, %r8899;
	mov.u32 	%r8904, %r8899;
	bra.uni 	BB0_1413;

BB0_1397:
	setp.eq.s32	%p946, %r7038, 1;
	mov.u32 	%r8900, %r8899;
	mov.u32 	%r8901, %r8899;
	mov.u32 	%r8902, %r8899;
	mov.u32 	%r8903, %r8899;
	mov.u32 	%r8904, %r8899;
	mov.u32 	%r8905, %r8899;
	mov.u32 	%r8906, %r8899;
	@%p946 bra 	BB0_1398;
	bra.uni 	BB0_1413;

BB0_1398:
	// inline asm
	prmt.b32 %r8906, %r7026, %r7028, %r1414;
	// inline asm
	// inline asm
	prmt.b32 %r8905, %r7024, %r7026, %r1414;
	// inline asm
	// inline asm
	prmt.b32 %r8904, %r7022, %r7024, %r1414;
	// inline asm
	// inline asm
	prmt.b32 %r8903, %r7020, %r7022, %r1414;
	// inline asm
	// inline asm
	prmt.b32 %r8902, %r7018, %r7020, %r1414;
	// inline asm
	// inline asm
	prmt.b32 %r8901, %r7016, %r7018, %r1414;
	// inline asm
	mov.u32 	%r8899, 0;
	// inline asm
	prmt.b32 %r8900, %r8899, %r7016, %r1414;
	// inline asm
	bra.uni 	BB0_1413;

BB0_1404:
	setp.eq.s32	%p941, %r7038, 5;
	mov.u32 	%r8900, %r8899;
	mov.u32 	%r8901, %r8899;
	mov.u32 	%r8902, %r8899;
	mov.u32 	%r8903, %r8899;
	mov.u32 	%r8904, %r8899;
	mov.u32 	%r8905, %r8899;
	mov.u32 	%r8906, %r8899;
	@%p941 bra 	BB0_1405;
	bra.uni 	BB0_1413;

BB0_1405:
	// inline asm
	prmt.b32 %r8906, %r7018, %r7020, %r1414;
	// inline asm
	// inline asm
	prmt.b32 %r8905, %r7016, %r7018, %r1414;
	// inline asm
	mov.u32 	%r8899, 0;
	// inline asm
	prmt.b32 %r8904, %r8899, %r7016, %r1414;
	// inline asm
	mov.u32 	%r8900, %r8899;
	mov.u32 	%r8901, %r8899;
	mov.u32 	%r8902, %r8899;
	mov.u32 	%r8903, %r8899;
	bra.uni 	BB0_1413;

BB0_1400:
	setp.eq.s32	%p944, %r7038, 3;
	mov.u32 	%r8900, %r8899;
	mov.u32 	%r8901, %r8899;
	mov.u32 	%r8902, %r8899;
	mov.u32 	%r8903, %r8899;
	mov.u32 	%r8904, %r8899;
	mov.u32 	%r8905, %r8899;
	mov.u32 	%r8906, %r8899;
	@%p944 bra 	BB0_1401;
	bra.uni 	BB0_1413;

BB0_1401:
	// inline asm
	prmt.b32 %r8906, %r7022, %r7024, %r1414;
	// inline asm
	// inline asm
	prmt.b32 %r8905, %r7020, %r7022, %r1414;
	// inline asm
	// inline asm
	prmt.b32 %r8904, %r7018, %r7020, %r1414;
	// inline asm
	// inline asm
	prmt.b32 %r8903, %r7016, %r7018, %r1414;
	// inline asm
	mov.u32 	%r8899, 0;
	// inline asm
	prmt.b32 %r8902, %r8899, %r7016, %r1414;
	// inline asm
	mov.u32 	%r8900, %r8899;
	mov.u32 	%r8901, %r8899;
	bra.uni 	BB0_1413;

BB0_1407:
	setp.ne.s32	%p939, %r7038, 7;
	mov.u32 	%r8900, %r8899;
	mov.u32 	%r8901, %r8899;
	mov.u32 	%r8902, %r8899;
	mov.u32 	%r8903, %r8899;
	mov.u32 	%r8904, %r8899;
	mov.u32 	%r8905, %r8899;
	mov.u32 	%r8906, %r8899;
	@%p939 bra 	BB0_1413;

	mov.u32 	%r8899, 0;
	// inline asm
	prmt.b32 %r8906, %r8899, %r7016, %r1414;
	// inline asm
	mov.u32 	%r8900, %r8899;
	mov.u32 	%r8901, %r8899;
	mov.u32 	%r8902, %r8899;
	mov.u32 	%r8903, %r8899;
	mov.u32 	%r8904, %r8899;
	mov.u32 	%r8905, %r8899;

BB0_1413:
	or.b32  	%r8944, %r8899, %r19;
	or.b32  	%r8943, %r8900, %r20;
	or.b32  	%r8942, %r8901, %r21;
	or.b32  	%r8941, %r8902, %r22;
	or.b32  	%r8948, %r8903, %r15;
	or.b32  	%r8947, %r8904, %r16;
	or.b32  	%r8946, %r8905, %r17;
	or.b32  	%r8945, %r8906, %r18;
	bra.uni 	BB0_1554;

BB0_5:
	mov.u32 	%r22, %r8941;
	mov.u32 	%r21, %r8942;
	mov.u32 	%r20, %r8943;
	mov.u32 	%r19, %r8944;
	mov.u32 	%r18, %r8945;
	mov.u32 	%r17, %r8946;
	mov.u32 	%r16, %r8947;
	mov.u32 	%r15, %r8948;
	mov.u32 	%r14, %r8949;
	shr.u32 	%r23, %r8773, 8;
	bfe.u32 	%r24, %r8773, 8, 8;
	shr.u32 	%r25, %r8773, 16;
	bfe.u32 	%r26, %r8773, 16, 8;
	and.b32  	%r1787, %r8773, 255;
	setp.gt.s32	%p5, %r1787, 93;
	@%p5 bra 	BB0_73;

	setp.gt.s32	%p33, %r1787, 68;
	@%p33 bra 	BB0_39;

	setp.gt.s32	%p47, %r1787, 44;
	@%p47 bra 	BB0_23;

	setp.gt.s32	%p54, %r1787, 41;
	@%p54 bra 	BB0_19;

	setp.eq.s32	%p58, %r1787, 36;
	@%p58 bra 	BB0_1312;
	bra.uni 	BB0_10;

BB0_1312:
	add.s32 	%r8949, %r14, 1;
	setp.gt.u32	%p879, %r8949, 31;
	@%p879 bra 	BB0_978;

	and.b32  	%r6450, %r14, 3;
	shl.b32 	%r6451, %r6450, 3;
	shl.b32 	%r6452, %r24, %r6451;
	setp.lt.u32	%p880, %r14, 4;
	selp.b32	%r6453, %r6452, 0, %p880;
	or.b32  	%r8944, %r6453, %r19;
	and.b32  	%r6454, %r14, -4;
	setp.eq.s32	%p881, %r6454, 4;
	selp.b32	%r6455, %r6452, 0, %p881;
	or.b32  	%r8943, %r6455, %r20;
	setp.eq.s32	%p882, %r6454, 8;
	selp.b32	%r6456, %r6452, 0, %p882;
	or.b32  	%r8942, %r6456, %r21;
	setp.eq.s32	%p883, %r6454, 12;
	selp.b32	%r6457, %r6452, 0, %p883;
	or.b32  	%r8941, %r6457, %r22;
	setp.eq.s32	%p884, %r6454, 16;
	selp.b32	%r6458, %r6452, 0, %p884;
	or.b32  	%r8948, %r6458, %r15;
	setp.eq.s32	%p885, %r6454, 20;
	selp.b32	%r6459, %r6452, 0, %p885;
	or.b32  	%r8947, %r6459, %r16;
	setp.eq.s32	%p886, %r6454, 24;
	selp.b32	%r6460, %r6452, 0, %p886;
	or.b32  	%r8946, %r6460, %r17;
	setp.gt.u32	%p887, %r14, 27;
	selp.b32	%r6461, %r6452, 0, %p887;
	or.b32  	%r8945, %r6461, %r18;
	bra.uni 	BB0_1554;

BB0_73:
	setp.gt.s32	%p6, %r1787, 112;
	@%p6 bra 	BB0_102;

	setp.gt.s32	%p20, %r1787, 104;
	@%p20 bra 	BB0_89;

	setp.gt.s32	%p27, %r1787, 99;
	@%p27 bra 	BB0_79;

	setp.eq.s32	%p31, %r1787, 94;
	@%p31 bra 	BB0_1310;
	bra.uni 	BB0_77;

BB0_1310:
	add.s32 	%r8949, %r14, 1;
	setp.gt.u32	%p878, %r8949, 31;
	@%p878 bra 	BB0_978;

	mov.u32 	%r6449, 24;
	// inline asm
	shf.r.wrap.b32 %r8945, %r17, %r18, %r6449;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8946, %r16, %r17, %r6449;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8947, %r15, %r16, %r6449;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8948, %r22, %r15, %r6449;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8941, %r21, %r22, %r6449;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8942, %r20, %r21, %r6449;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r19, %r20, %r6449;
	// inline asm
	mov.u32 	%r6447, 0;
	// inline asm
	shf.r.wrap.b32 %r6446, %r6447, %r19, %r6449;
	// inline asm
	or.b32  	%r8944, %r6446, %r24;
	bra.uni 	BB0_1554;

BB0_39:
	setp.gt.s32	%p34, %r1787, 83;
	@%p34 bra 	BB0_58;

	setp.gt.s32	%p41, %r1787, 75;
	@%p41 bra 	BB0_50;

	setp.eq.s32	%p45, %r1787, 69;
	@%p45 bra 	BB0_133;
	bra.uni 	BB0_42;

BB0_133:
	and.b32  	%r1820, %r19, 1077952576;
	shr.u32 	%r1821, %r1820, 1;
	and.b32  	%r1822, %r19, -2139062144;
	shr.u32 	%r1823, %r1822, 2;
	not.b32 	%r1824, %r1823;
	and.b32  	%r1825, %r1821, %r1824;
	and.b32  	%r1826, %r19, 522133279;
	add.s32 	%r1827, %r1826, 522133279;
	mov.u32 	%r1828, -84215046;
	sub.s32 	%r1829, %r1828, %r1826;
	and.b32  	%r1830, %r1825, %r1829;
	and.b32  	%r1831, %r1830, %r1827;
	or.b32  	%r1832, %r1831, %r19;
	and.b32  	%r1833, %r20, 1077952576;
	shr.u32 	%r1834, %r1833, 1;
	and.b32  	%r1835, %r20, -2139062144;
	shr.u32 	%r1836, %r1835, 2;
	not.b32 	%r1837, %r1836;
	and.b32  	%r1838, %r1834, %r1837;
	and.b32  	%r1839, %r20, 522133279;
	add.s32 	%r1840, %r1839, 522133279;
	sub.s32 	%r1841, %r1828, %r1839;
	and.b32  	%r1842, %r1838, %r1841;
	and.b32  	%r1843, %r1842, %r1840;
	or.b32  	%r1844, %r1843, %r20;
	and.b32  	%r1845, %r21, 1077952576;
	shr.u32 	%r1846, %r1845, 1;
	and.b32  	%r1847, %r21, -2139062144;
	shr.u32 	%r1848, %r1847, 2;
	not.b32 	%r1849, %r1848;
	and.b32  	%r1850, %r1846, %r1849;
	and.b32  	%r1851, %r21, 522133279;
	add.s32 	%r1852, %r1851, 522133279;
	sub.s32 	%r1853, %r1828, %r1851;
	and.b32  	%r1854, %r1850, %r1853;
	and.b32  	%r1855, %r1854, %r1852;
	or.b32  	%r1856, %r1855, %r21;
	and.b32  	%r1857, %r22, 1077952576;
	shr.u32 	%r1858, %r1857, 1;
	and.b32  	%r1859, %r22, -2139062144;
	shr.u32 	%r1860, %r1859, 2;
	not.b32 	%r1861, %r1860;
	and.b32  	%r1862, %r1858, %r1861;
	and.b32  	%r1863, %r22, 522133279;
	add.s32 	%r1864, %r1863, 522133279;
	sub.s32 	%r1865, %r1828, %r1863;
	and.b32  	%r1866, %r1862, %r1865;
	and.b32  	%r1867, %r1866, %r1864;
	or.b32  	%r1868, %r1867, %r22;
	and.b32  	%r1869, %r15, 1077952576;
	shr.u32 	%r1870, %r1869, 1;
	and.b32  	%r1871, %r15, -2139062144;
	shr.u32 	%r1872, %r1871, 2;
	not.b32 	%r1873, %r1872;
	and.b32  	%r1874, %r1870, %r1873;
	and.b32  	%r1875, %r15, 522133279;
	add.s32 	%r1876, %r1875, 522133279;
	sub.s32 	%r1877, %r1828, %r1875;
	and.b32  	%r1878, %r1874, %r1877;
	and.b32  	%r1879, %r1878, %r1876;
	or.b32  	%r1880, %r1879, %r15;
	and.b32  	%r1881, %r16, 1077952576;
	shr.u32 	%r1882, %r1881, 1;
	and.b32  	%r1883, %r16, -2139062144;
	shr.u32 	%r1884, %r1883, 2;
	not.b32 	%r1885, %r1884;
	and.b32  	%r1886, %r1882, %r1885;
	and.b32  	%r1887, %r16, 522133279;
	add.s32 	%r1888, %r1887, 522133279;
	sub.s32 	%r1889, %r1828, %r1887;
	and.b32  	%r1890, %r1886, %r1889;
	and.b32  	%r1891, %r1890, %r1888;
	or.b32  	%r1892, %r1891, %r16;
	and.b32  	%r1893, %r17, 1077952576;
	shr.u32 	%r1894, %r1893, 1;
	and.b32  	%r1895, %r17, -2139062144;
	shr.u32 	%r1896, %r1895, 2;
	not.b32 	%r1897, %r1896;
	and.b32  	%r1898, %r1894, %r1897;
	and.b32  	%r1899, %r17, 522133279;
	add.s32 	%r1900, %r1899, 522133279;
	sub.s32 	%r1901, %r1828, %r1899;
	and.b32  	%r1902, %r1898, %r1901;
	and.b32  	%r1903, %r1902, %r1900;
	or.b32  	%r1904, %r1903, %r17;
	and.b32  	%r1905, %r18, 1077952576;
	shr.u32 	%r1906, %r1905, 1;
	and.b32  	%r1907, %r18, -2139062144;
	shr.u32 	%r1908, %r1907, 2;
	not.b32 	%r1909, %r1908;
	and.b32  	%r1910, %r1906, %r1909;
	and.b32  	%r1911, %r18, 522133279;
	add.s32 	%r1912, %r1911, 522133279;
	sub.s32 	%r1913, %r1828, %r1911;
	and.b32  	%r1914, %r1910, %r1913;
	and.b32  	%r1915, %r1914, %r1912;
	or.b32  	%r1916, %r1915, %r18;
	mov.b32	{%rs10, %rs11}, %r1832;
	shr.u16 	%rs12, %rs11, 8;
	setp.eq.s16	%p60, %rs12, 32;
	and.b16  	%rs13, %rs11, 255;
	setp.eq.s16	%p61, %rs13, 32;
	shr.u16 	%rs14, %rs10, 8;
	setp.eq.s16	%p62, %rs14, 32;
	and.b16  	%rs15, %rs10, 255;
	setp.eq.s16	%p63, %rs15, 32;
	selp.b16	%rs16, -1, 0, %p63;
	selp.b16	%rs17, -1, 0, %p62;
	selp.b16	%rs18, -1, 0, %p61;
	selp.b16	%rs19, -1, 0, %p60;
	shr.u16 	%rs20, %rs17, 7;
	cvt.u32.u16	%r1917, %rs20;
	shr.u16 	%rs21, %rs16, 7;
	and.b16  	%rs22, %rs21, 255;
	cvt.u32.u16	%r1918, %rs22;
	prmt.b32 	%r1919, %r1917, %r1918, 30212;
	shr.u16 	%rs23, %rs19, 7;
	cvt.u32.u16	%r1920, %rs23;
	shr.u16 	%rs24, %rs18, 7;
	and.b16  	%rs25, %rs24, 255;
	cvt.u32.u16	%r1921, %rs25;
	prmt.b32 	%r1922, %r1920, %r1921, 30212;
	prmt.b32 	%r1813, %r1922, %r1919, 4180;
	mov.b32	{%rs26, %rs27}, %r1844;
	shr.u16 	%rs28, %rs27, 8;
	setp.eq.s16	%p64, %rs28, 32;
	and.b16  	%rs29, %rs27, 255;
	setp.eq.s16	%p65, %rs29, 32;
	shr.u16 	%rs30, %rs26, 8;
	setp.eq.s16	%p66, %rs30, 32;
	and.b16  	%rs31, %rs26, 255;
	setp.eq.s16	%p67, %rs31, 32;
	selp.b16	%rs32, -1, 0, %p67;
	selp.b16	%rs33, -1, 0, %p66;
	selp.b16	%rs34, -1, 0, %p65;
	selp.b16	%rs35, -1, 0, %p64;
	shr.u16 	%rs36, %rs33, 7;
	cvt.u32.u16	%r1923, %rs36;
	shr.u16 	%rs37, %rs32, 7;
	and.b16  	%rs38, %rs37, 255;
	cvt.u32.u16	%r1924, %rs38;
	prmt.b32 	%r1925, %r1923, %r1924, 30212;
	shr.u16 	%rs39, %rs35, 7;
	cvt.u32.u16	%r1926, %rs39;
	shr.u16 	%rs40, %rs34, 7;
	and.b16  	%rs41, %rs40, 255;
	cvt.u32.u16	%r1927, %rs41;
	prmt.b32 	%r1928, %r1926, %r1927, 30212;
	prmt.b32 	%r1809, %r1928, %r1925, 4180;
	mov.b32	{%rs42, %rs43}, %r1856;
	shr.u16 	%rs44, %rs43, 8;
	setp.eq.s16	%p68, %rs44, 32;
	and.b16  	%rs45, %rs43, 255;
	setp.eq.s16	%p69, %rs45, 32;
	shr.u16 	%rs46, %rs42, 8;
	setp.eq.s16	%p70, %rs46, 32;
	and.b16  	%rs47, %rs42, 255;
	setp.eq.s16	%p71, %rs47, 32;
	selp.b16	%rs48, -1, 0, %p71;
	selp.b16	%rs49, -1, 0, %p70;
	selp.b16	%rs50, -1, 0, %p69;
	selp.b16	%rs51, -1, 0, %p68;
	shr.u16 	%rs52, %rs49, 7;
	cvt.u32.u16	%r1929, %rs52;
	shr.u16 	%rs53, %rs48, 7;
	and.b16  	%rs54, %rs53, 255;
	cvt.u32.u16	%r1930, %rs54;
	prmt.b32 	%r1931, %r1929, %r1930, 30212;
	shr.u16 	%rs55, %rs51, 7;
	cvt.u32.u16	%r1932, %rs55;
	shr.u16 	%rs56, %rs50, 7;
	and.b16  	%rs57, %rs56, 255;
	cvt.u32.u16	%r1933, %rs57;
	prmt.b32 	%r1934, %r1932, %r1933, 30212;
	prmt.b32 	%r1805, %r1934, %r1931, 4180;
	mov.b32	{%rs58, %rs59}, %r1868;
	shr.u16 	%rs60, %rs59, 8;
	setp.eq.s16	%p72, %rs60, 32;
	and.b16  	%rs61, %rs59, 255;
	setp.eq.s16	%p73, %rs61, 32;
	shr.u16 	%rs62, %rs58, 8;
	setp.eq.s16	%p74, %rs62, 32;
	and.b16  	%rs63, %rs58, 255;
	setp.eq.s16	%p75, %rs63, 32;
	selp.b16	%rs64, -1, 0, %p75;
	selp.b16	%rs65, -1, 0, %p74;
	selp.b16	%rs66, -1, 0, %p73;
	selp.b16	%rs67, -1, 0, %p72;
	shr.u16 	%rs68, %rs65, 7;
	cvt.u32.u16	%r1935, %rs68;
	shr.u16 	%rs69, %rs64, 7;
	and.b16  	%rs70, %rs69, 255;
	cvt.u32.u16	%r1936, %rs70;
	prmt.b32 	%r1937, %r1935, %r1936, 30212;
	shr.u16 	%rs71, %rs67, 7;
	cvt.u32.u16	%r1938, %rs71;
	shr.u16 	%rs72, %rs66, 7;
	and.b16  	%rs73, %rs72, 255;
	cvt.u32.u16	%r1939, %rs73;
	prmt.b32 	%r1940, %r1938, %r1939, 30212;
	prmt.b32 	%r1801, %r1940, %r1937, 4180;
	mov.b32	{%rs74, %rs75}, %r1880;
	shr.u16 	%rs76, %rs75, 8;
	setp.eq.s16	%p76, %rs76, 32;
	and.b16  	%rs77, %rs75, 255;
	setp.eq.s16	%p77, %rs77, 32;
	shr.u16 	%rs78, %rs74, 8;
	setp.eq.s16	%p78, %rs78, 32;
	and.b16  	%rs79, %rs74, 255;
	setp.eq.s16	%p79, %rs79, 32;
	selp.b16	%rs80, -1, 0, %p79;
	selp.b16	%rs81, -1, 0, %p78;
	selp.b16	%rs82, -1, 0, %p77;
	selp.b16	%rs83, -1, 0, %p76;
	shr.u16 	%rs84, %rs81, 7;
	cvt.u32.u16	%r1941, %rs84;
	shr.u16 	%rs85, %rs80, 7;
	and.b16  	%rs86, %rs85, 255;
	cvt.u32.u16	%r1942, %rs86;
	prmt.b32 	%r1943, %r1941, %r1942, 30212;
	shr.u16 	%rs87, %rs83, 7;
	cvt.u32.u16	%r1944, %rs87;
	shr.u16 	%rs88, %rs82, 7;
	and.b16  	%rs89, %rs88, 255;
	cvt.u32.u16	%r1945, %rs89;
	prmt.b32 	%r1946, %r1944, %r1945, 30212;
	prmt.b32 	%r1797, %r1946, %r1943, 4180;
	mov.b32	{%rs90, %rs91}, %r1892;
	shr.u16 	%rs92, %rs91, 8;
	setp.eq.s16	%p80, %rs92, 32;
	and.b16  	%rs93, %rs91, 255;
	setp.eq.s16	%p81, %rs93, 32;
	shr.u16 	%rs94, %rs90, 8;
	setp.eq.s16	%p82, %rs94, 32;
	and.b16  	%rs95, %rs90, 255;
	setp.eq.s16	%p83, %rs95, 32;
	selp.b16	%rs96, -1, 0, %p83;
	selp.b16	%rs97, -1, 0, %p82;
	selp.b16	%rs98, -1, 0, %p81;
	selp.b16	%rs99, -1, 0, %p80;
	shr.u16 	%rs100, %rs97, 7;
	cvt.u32.u16	%r1947, %rs100;
	shr.u16 	%rs101, %rs96, 7;
	and.b16  	%rs102, %rs101, 255;
	cvt.u32.u16	%r1948, %rs102;
	prmt.b32 	%r1949, %r1947, %r1948, 30212;
	shr.u16 	%rs103, %rs99, 7;
	cvt.u32.u16	%r1950, %rs103;
	shr.u16 	%rs104, %rs98, 7;
	and.b16  	%rs105, %rs104, 255;
	cvt.u32.u16	%r1951, %rs105;
	prmt.b32 	%r1952, %r1950, %r1951, 30212;
	prmt.b32 	%r1793, %r1952, %r1949, 4180;
	mov.b32	{%rs106, %rs107}, %r1904;
	shr.u16 	%rs108, %rs107, 8;
	setp.eq.s16	%p84, %rs108, 32;
	and.b16  	%rs109, %rs107, 255;
	setp.eq.s16	%p85, %rs109, 32;
	shr.u16 	%rs110, %rs106, 8;
	setp.eq.s16	%p86, %rs110, 32;
	and.b16  	%rs111, %rs106, 255;
	setp.eq.s16	%p87, %rs111, 32;
	selp.b16	%rs112, -1, 0, %p87;
	selp.b16	%rs113, -1, 0, %p86;
	selp.b16	%rs114, -1, 0, %p85;
	selp.b16	%rs115, -1, 0, %p84;
	shr.u16 	%rs116, %rs113, 7;
	cvt.u32.u16	%r1953, %rs116;
	shr.u16 	%rs117, %rs112, 7;
	and.b16  	%rs118, %rs117, 255;
	cvt.u32.u16	%r1954, %rs118;
	prmt.b32 	%r1955, %r1953, %r1954, 30212;
	shr.u16 	%rs119, %rs115, 7;
	cvt.u32.u16	%r1956, %rs119;
	shr.u16 	%rs120, %rs114, 7;
	and.b16  	%rs121, %rs120, 255;
	cvt.u32.u16	%r1957, %rs121;
	prmt.b32 	%r1958, %r1956, %r1957, 30212;
	prmt.b32 	%r1789, %r1958, %r1955, 4180;
	mov.b32	{%rs122, %rs123}, %r1916;
	shr.u16 	%rs124, %rs123, 8;
	setp.eq.s16	%p88, %rs124, 32;
	and.b16  	%rs125, %rs123, 255;
	setp.eq.s16	%p89, %rs125, 32;
	shr.u16 	%rs126, %rs122, 8;
	setp.eq.s16	%p90, %rs126, 32;
	and.b16  	%rs127, %rs122, 255;
	setp.eq.s16	%p91, %rs127, 32;
	selp.b16	%rs128, -1, 0, %p91;
	selp.b16	%rs129, -1, 0, %p90;
	selp.b16	%rs130, -1, 0, %p89;
	selp.b16	%rs131, -1, 0, %p88;
	shr.u16 	%rs132, %rs129, 7;
	cvt.u32.u16	%r1959, %rs132;
	shr.u16 	%rs133, %rs128, 7;
	and.b16  	%rs134, %rs133, 255;
	cvt.u32.u16	%r1960, %rs134;
	prmt.b32 	%r1961, %r1959, %r1960, 30212;
	shr.u16 	%rs135, %rs131, 7;
	cvt.u32.u16	%r1962, %rs135;
	shr.u16 	%rs136, %rs130, 7;
	and.b16  	%rs137, %rs136, 255;
	cvt.u32.u16	%r1963, %rs137;
	prmt.b32 	%r1964, %r1962, %r1963, 30212;
	prmt.b32 	%r1790, %r1964, %r1961, 4180;
	mov.u32 	%r1819, 24;
	// inline asm
	shf.r.wrap.b32 %r1788, %r1789, %r1790, %r1819;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1792, %r1793, %r1789, %r1819;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1796, %r1797, %r1793, %r1819;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1800, %r1801, %r1797, %r1819;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1804, %r1805, %r1801, %r1819;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1808, %r1809, %r1805, %r1819;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1812, %r1813, %r1809, %r1819;
	// inline asm
	mov.u32 	%r1817, 0;
	// inline asm
	shf.r.wrap.b32 %r1816, %r1817, %r1813, %r1819;
	// inline asm
	or.b32  	%r1965, %r1816, 255;
	and.b32  	%r1966, %r1832, 1077952576;
	shr.u32 	%r1967, %r1966, 1;
	and.b32  	%r1968, %r1832, -2139062144;
	shr.u32 	%r1969, %r1968, 2;
	not.b32 	%r1970, %r1969;
	and.b32  	%r1971, %r1967, %r1970;
	and.b32  	%r1972, %r1832, 522133279;
	add.s32 	%r1973, %r1972, 522133279;
	sub.s32 	%r1974, %r1828, %r1972;
	and.b32  	%r1975, %r1971, %r1974;
	and.b32  	%r1976, %r1975, %r1973;
	and.b32  	%r1977, %r1976, %r1965;
	not.b32 	%r1978, %r1977;
	and.b32  	%r8944, %r1832, %r1978;
	and.b32  	%r1979, %r1844, 1077952576;
	shr.u32 	%r1980, %r1979, 1;
	and.b32  	%r1981, %r1844, -2139062144;
	shr.u32 	%r1982, %r1981, 2;
	not.b32 	%r1983, %r1982;
	and.b32  	%r1984, %r1980, %r1983;
	and.b32  	%r1985, %r1844, 522133279;
	add.s32 	%r1986, %r1985, 522133279;
	sub.s32 	%r1987, %r1828, %r1985;
	and.b32  	%r1988, %r1984, %r1987;
	and.b32  	%r1989, %r1988, %r1986;
	and.b32  	%r1990, %r1989, %r1812;
	not.b32 	%r1991, %r1990;
	and.b32  	%r8943, %r1844, %r1991;
	and.b32  	%r1992, %r1856, 1077952576;
	shr.u32 	%r1993, %r1992, 1;
	and.b32  	%r1994, %r1856, -2139062144;
	shr.u32 	%r1995, %r1994, 2;
	not.b32 	%r1996, %r1995;
	and.b32  	%r1997, %r1993, %r1996;
	and.b32  	%r1998, %r1856, 522133279;
	add.s32 	%r1999, %r1998, 522133279;
	sub.s32 	%r2000, %r1828, %r1998;
	and.b32  	%r2001, %r1997, %r2000;
	and.b32  	%r2002, %r2001, %r1999;
	and.b32  	%r2003, %r2002, %r1808;
	not.b32 	%r2004, %r2003;
	and.b32  	%r8942, %r1856, %r2004;
	and.b32  	%r2005, %r1868, 1077952576;
	shr.u32 	%r2006, %r2005, 1;
	and.b32  	%r2007, %r1868, -2139062144;
	shr.u32 	%r2008, %r2007, 2;
	not.b32 	%r2009, %r2008;
	and.b32  	%r2010, %r2006, %r2009;
	and.b32  	%r2011, %r1868, 522133279;
	add.s32 	%r2012, %r2011, 522133279;
	sub.s32 	%r2013, %r1828, %r2011;
	and.b32  	%r2014, %r2010, %r2013;
	and.b32  	%r2015, %r2014, %r2012;
	and.b32  	%r2016, %r2015, %r1804;
	not.b32 	%r2017, %r2016;
	and.b32  	%r8941, %r1868, %r2017;
	and.b32  	%r2018, %r1880, 1077952576;
	shr.u32 	%r2019, %r2018, 1;
	and.b32  	%r2020, %r1880, -2139062144;
	shr.u32 	%r2021, %r2020, 2;
	not.b32 	%r2022, %r2021;
	and.b32  	%r2023, %r2019, %r2022;
	and.b32  	%r2024, %r1880, 522133279;
	add.s32 	%r2025, %r2024, 522133279;
	sub.s32 	%r2026, %r1828, %r2024;
	and.b32  	%r2027, %r2023, %r2026;
	and.b32  	%r2028, %r2027, %r2025;
	and.b32  	%r2029, %r2028, %r1800;
	not.b32 	%r2030, %r2029;
	and.b32  	%r8948, %r1880, %r2030;
	and.b32  	%r2031, %r1892, 1077952576;
	shr.u32 	%r2032, %r2031, 1;
	and.b32  	%r2033, %r1892, -2139062144;
	shr.u32 	%r2034, %r2033, 2;
	not.b32 	%r2035, %r2034;
	and.b32  	%r2036, %r2032, %r2035;
	and.b32  	%r2037, %r1892, 522133279;
	add.s32 	%r2038, %r2037, 522133279;
	sub.s32 	%r2039, %r1828, %r2037;
	and.b32  	%r2040, %r2036, %r2039;
	and.b32  	%r2041, %r2040, %r2038;
	and.b32  	%r2042, %r2041, %r1796;
	not.b32 	%r2043, %r2042;
	and.b32  	%r8947, %r1892, %r2043;
	and.b32  	%r2044, %r1904, 1077952576;
	shr.u32 	%r2045, %r2044, 1;
	and.b32  	%r2046, %r1904, -2139062144;
	shr.u32 	%r2047, %r2046, 2;
	not.b32 	%r2048, %r2047;
	and.b32  	%r2049, %r2045, %r2048;
	and.b32  	%r2050, %r1904, 522133279;
	add.s32 	%r2051, %r2050, 522133279;
	sub.s32 	%r2052, %r1828, %r2050;
	and.b32  	%r2053, %r2049, %r2052;
	and.b32  	%r2054, %r2053, %r2051;
	and.b32  	%r2055, %r2054, %r1792;
	not.b32 	%r2056, %r2055;
	and.b32  	%r8946, %r1904, %r2056;
	and.b32  	%r2057, %r1916, 1077952576;
	shr.u32 	%r2058, %r2057, 1;
	and.b32  	%r2059, %r1916, -2139062144;
	shr.u32 	%r2060, %r2059, 2;
	not.b32 	%r2061, %r2060;
	and.b32  	%r2062, %r2058, %r2061;
	and.b32  	%r2063, %r1916, 522133279;
	add.s32 	%r2064, %r2063, 522133279;
	sub.s32 	%r2065, %r1828, %r2063;
	and.b32  	%r2066, %r2062, %r2065;
	and.b32  	%r2067, %r2066, %r2064;
	and.b32  	%r2068, %r2067, %r1788;
	not.b32 	%r2069, %r2068;
	and.b32  	%r8945, %r1916, %r2069;
	mov.u32 	%r8949, %r14;
	bra.uni 	BB0_1554;

BB0_102:
	setp.gt.s32	%p7, %r1787, 119;
	@%p7 bra 	BB0_116;

	setp.gt.s32	%p14, %r1787, 114;
	@%p14 bra 	BB0_112;

	setp.eq.s32	%p18, %r1787, 113;
	@%p18 bra 	BB0_783;
	bra.uni 	BB0_105;

BB0_783:
	setp.eq.s32	%p507, %r14, 0;
	add.s32 	%r8949, %r14, %r14;
	setp.gt.u32	%p508, %r8949, 31;
	or.pred  	%p509, %p507, %p508;
	@%p509 bra 	BB0_11;

	and.b32  	%r4023, %r19, 255;
	and.b32  	%r4024, %r19, 65280;
	prmt.b32 	%r4025, %r4024, %r4023, 8452;
	bfe.u32 	%r4026, %r19, 16, 8;
	and.b32  	%r4027, %r19, -16777216;
	shr.u32 	%r4028, %r4027, 8;
	or.b32  	%r4029, %r4026, %r4028;
	and.b32  	%r4030, %r20, 65280;
	and.b32  	%r4031, %r20, 255;
	prmt.b32 	%r4032, %r4030, %r4031, 8452;
	bfe.u32 	%r4033, %r20, 16, 8;
	and.b32  	%r4034, %r20, -16777216;
	shr.u32 	%r4035, %r4034, 8;
	or.b32  	%r4036, %r4033, %r4035;
	and.b32  	%r4037, %r21, 65280;
	and.b32  	%r4038, %r21, 255;
	prmt.b32 	%r4039, %r4037, %r4038, 8452;
	bfe.u32 	%r4040, %r21, 16, 8;
	and.b32  	%r4041, %r21, -16777216;
	shr.u32 	%r4042, %r4041, 8;
	or.b32  	%r4043, %r4040, %r4042;
	and.b32  	%r4044, %r22, 65280;
	and.b32  	%r4045, %r22, 255;
	prmt.b32 	%r4046, %r4044, %r4045, 8452;
	bfe.u32 	%r4047, %r22, 16, 8;
	and.b32  	%r4048, %r22, -16777216;
	shr.u32 	%r4049, %r4048, 8;
	or.b32  	%r4050, %r4047, %r4049;
	shl.b32 	%r4051, %r4025, 8;
	or.b32  	%r8944, %r4051, %r4025;
	shl.b32 	%r4052, %r4029, 8;
	or.b32  	%r8943, %r4052, %r4029;
	shl.b32 	%r4053, %r4032, 8;
	or.b32  	%r8942, %r4053, %r4032;
	shl.b32 	%r4054, %r4036, 8;
	or.b32  	%r8941, %r4054, %r4036;
	shl.b32 	%r4055, %r4039, 8;
	or.b32  	%r8948, %r4055, %r4039;
	shl.b32 	%r4056, %r4043, 8;
	or.b32  	%r8947, %r4056, %r4043;
	shl.b32 	%r4057, %r4046, 8;
	or.b32  	%r8946, %r4057, %r4046;
	shl.b32 	%r4058, %r4050, 8;
	or.b32  	%r8945, %r4058, %r4050;
	bra.uni 	BB0_1554;

BB0_23:
	setp.gt.s32	%p48, %r1787, 63;
	@%p48 bra 	BB0_31;

	setp.eq.s32	%p52, %r1787, 45;
	@%p52 bra 	BB0_373;
	bra.uni 	BB0_25;

BB0_373:
	setp.ge.u32	%p270, %r24, %r14;
	@%p270 bra 	BB0_11;

	and.b32  	%r3619, %r23, 3;
	shl.b32 	%r3620, %r3619, 3;
	mov.u32 	%r3621, 255;
	shl.b32 	%r361, %r3621, %r3620;
	not.b32 	%r362, %r361;
	and.b32  	%r363, %r361, 16843009;
	shr.u32 	%r3618, %r24, 2;
	setp.gt.s32	%p271, %r3618, 3;
	@%p271 bra 	BB0_382;

	setp.gt.s32	%p277, %r3618, 1;
	@%p277 bra 	BB0_379;

	setp.eq.s32	%p280, %r3618, 0;
	@%p280 bra 	BB0_392;
	bra.uni 	BB0_377;

BB0_392:
	and.b32  	%r3650, %r19, %r362;
	and.b32  	%r3651, %r361, %r19;
	sub.s32 	%r3652, %r3651, %r363;
	and.b32  	%r3653, %r3652, %r361;
	or.b32  	%r8944, %r3653, %r3650;
	bra.uni 	BB0_617;

BB0_89:
	setp.gt.s32	%p21, %r1787, 107;
	@%p21 bra 	BB0_94;

	setp.eq.s32	%p25, %r1787, 105;
	@%p25 bra 	BB0_1029;
	bra.uni 	BB0_91;

BB0_1029:
	setp.gt.u32	%p693, %r24, %r14;
	add.s32 	%r8949, %r14, 1;
	setp.gt.u32	%p694, %r8949, 31;
	or.pred  	%p695, %p693, %p694;
	@%p695 bra 	BB0_978;

	mov.u32 	%r4996, 24;
	// inline asm
	shf.r.wrap.b32 %r8945, %r17, %r18, %r4996;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8946, %r16, %r17, %r4996;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8947, %r15, %r16, %r4996;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8948, %r22, %r15, %r4996;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8941, %r21, %r22, %r4996;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8942, %r20, %r21, %r4996;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r19, %r20, %r4996;
	// inline asm
	and.b32  	%r4998, %r23, 3;
	shl.b32 	%r4999, %r4998, 3;
	shl.b32 	%r931, %r26, %r4999;
	mov.u32 	%r5000, 1;
	shl.b32 	%r5001, %r5000, %r4999;
	add.s32 	%r932, %r5001, -1;
	mov.u32 	%r5002, -256;
	shl.b32 	%r933, %r5002, %r4999;
	shr.u32 	%r4997, %r24, 2;
	setp.gt.s32	%p696, %r4997, 3;
	@%p696 bra 	BB0_1038;

	setp.gt.s32	%p702, %r4997, 1;
	@%p702 bra 	BB0_1035;

	setp.eq.s32	%p705, %r4997, 0;
	@%p705 bra 	BB0_1051;
	bra.uni 	BB0_1033;

BB0_1051:
	mov.u32 	%r8772, 24;
	mov.u32 	%r5025, 0;
	// inline asm
	shf.r.wrap.b32 %r5024, %r5025, %r19, %r8772;
	// inline asm
	and.b32  	%r5028, %r932, %r19;
	or.b32  	%r5029, %r5028, %r931;
	and.b32  	%r5030, %r5024, %r933;
	or.b32  	%r8944, %r5029, %r5030;
	bra.uni 	BB0_1554;

BB0_58:
	setp.gt.s32	%p35, %r1787, 89;
	@%p35 bra 	BB0_68;

	setp.eq.s32	%p39, %r1787, 84;
	@%p39 bra 	BB0_1530;
	bra.uni 	BB0_60;

BB0_1530:
	setp.ge.u32	%p1019, %r24, %r14;
	@%p1019 bra 	BB0_978;

	and.b32  	%r8158, %r23, 3;
	shl.b32 	%r8159, %r8158, 3;
	mov.u32 	%r8160, 32;
	shl.b32 	%r1710, %r8160, %r8159;
	shr.u32 	%r8157, %r24, 2;
	setp.gt.s32	%p1020, %r8157, 3;
	@%p1020 bra 	BB0_1539;

	setp.gt.s32	%p1026, %r8157, 1;
	@%p1026 bra 	BB0_1536;

	setp.eq.s32	%p1029, %r8157, 0;
	@%p1029 bra 	BB0_1549;
	bra.uni 	BB0_1534;

BB0_1549:
	and.b32  	%r8252, %r19, 1077952576;
	shr.u32 	%r8253, %r8252, 1;
	and.b32  	%r8254, %r19, -2139062144;
	shr.u32 	%r8255, %r8254, 2;
	not.b32 	%r8256, %r8255;
	and.b32  	%r8257, %r8253, %r8256;
	and.b32  	%r8258, %r19, 522133279;
	add.s32 	%r8259, %r8258, 522133279;
	mov.u32 	%r8260, -84215046;
	sub.s32 	%r8261, %r8260, %r8258;
	and.b32  	%r8262, %r8257, %r8261;
	and.b32  	%r8263, %r8262, %r8259;
	and.b32  	%r8264, %r8263, %r1710;
	xor.b32  	%r8944, %r8264, %r19;
	bra.uni 	BB0_1028;

BB0_116:
	setp.gt.s32	%p8, %r1787, 121;
	@%p8 bra 	BB0_124;

	setp.eq.s32	%p12, %r1787, 120;
	@%p12 bra 	BB0_1162;
	bra.uni 	BB0_118;

BB0_1162:
	setp.ge.u32	%p768, %r24, %r14;
	add.s32 	%r5605, %r24, %r26;
	setp.gt.u32	%p769, %r5605, %r14;
	or.pred  	%p770, %p768, %p769;
	@%p770 bra 	BB0_978;

	setp.gt.s32	%p771, %r24, 15;
	@%p771 bra 	BB0_1192;

	setp.gt.s32	%p795, %r24, 7;
	@%p795 bra 	BB0_1177;

	setp.gt.s32	%p807, %r24, 3;
	@%p807 bra 	BB0_1170;

	setp.eq.s32	%p813, %r24, 1;
	@%p813 bra 	BB0_1241;

	setp.eq.s32	%p814, %r24, 2;
	@%p814 bra 	BB0_1240;
	bra.uni 	BB0_1168;

BB0_1240:
	mov.u32 	%r6106, 16;
	// inline asm
	shf.r.wrap.b32 %r6075, %r19, %r20, %r6106;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r20, %r21, %r6106;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8942, %r21, %r22, %r6106;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8941, %r22, %r15, %r6106;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6091, %r15, %r16, %r6106;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8947, %r16, %r17, %r6106;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8946, %r17, %r18, %r6106;
	// inline asm
	mov.u32 	%r6105, 0;
	// inline asm
	shf.r.wrap.b32 %r8945, %r18, %r6105, %r6106;
	// inline asm
	mov.u32 	%r22, %r6075;
	mov.u32 	%r18, %r6091;
	bra.uni 	BB0_1245;

BB0_19:
	setp.eq.s32	%p55, %r1787, 42;
	@%p55 bra 	BB0_448;

	setp.eq.s32	%p56, %r1787, 43;
	@%p56 bra 	BB0_393;
	bra.uni 	BB0_21;

BB0_393:
	setp.ge.u32	%p282, %r24, %r14;
	@%p282 bra 	BB0_11;

	and.b32  	%r3655, %r23, 3;
	shl.b32 	%r3656, %r3655, 3;
	mov.u32 	%r3657, 255;
	shl.b32 	%r372, %r3657, %r3656;
	not.b32 	%r373, %r372;
	and.b32  	%r374, %r372, 16843009;
	shr.u32 	%r3654, %r24, 2;
	setp.gt.s32	%p283, %r3654, 3;
	@%p283 bra 	BB0_402;

	setp.gt.s32	%p289, %r3654, 1;
	@%p289 bra 	BB0_399;

	setp.eq.s32	%p292, %r3654, 0;
	@%p292 bra 	BB0_412;
	bra.uni 	BB0_397;

BB0_412:
	and.b32  	%r3686, %r19, %r373;
	and.b32  	%r3687, %r372, %r19;
	add.s32 	%r3688, %r3687, %r374;
	and.b32  	%r3689, %r3688, %r372;
	or.b32  	%r8944, %r3689, %r3686;
	bra.uni 	BB0_617;

BB0_79:
	setp.eq.s32	%p28, %r1787, 100;
	@%p28 bra 	BB0_1430;

	setp.eq.s32	%p29, %r1787, 101;
	@%p29 bra 	BB0_134;
	bra.uni 	BB0_81;

BB0_134:
	and.b32  	%r2102, %r19, 1077952576;
	shr.u32 	%r2103, %r2102, 1;
	and.b32  	%r2104, %r19, -2139062144;
	shr.u32 	%r2105, %r2104, 2;
	not.b32 	%r2106, %r2105;
	and.b32  	%r2107, %r2103, %r2106;
	and.b32  	%r2108, %r19, 522133279;
	add.s32 	%r2109, %r2108, 522133279;
	mov.u32 	%r2110, -84215046;
	sub.s32 	%r2111, %r2110, %r2108;
	and.b32  	%r2112, %r2107, %r2111;
	and.b32  	%r2113, %r2112, %r2109;
	or.b32  	%r2114, %r2113, %r19;
	and.b32  	%r2115, %r20, 1077952576;
	shr.u32 	%r2116, %r2115, 1;
	and.b32  	%r2117, %r20, -2139062144;
	shr.u32 	%r2118, %r2117, 2;
	not.b32 	%r2119, %r2118;
	and.b32  	%r2120, %r2116, %r2119;
	and.b32  	%r2121, %r20, 522133279;
	add.s32 	%r2122, %r2121, 522133279;
	sub.s32 	%r2123, %r2110, %r2121;
	and.b32  	%r2124, %r2120, %r2123;
	and.b32  	%r2125, %r2124, %r2122;
	or.b32  	%r2126, %r2125, %r20;
	and.b32  	%r2127, %r21, 1077952576;
	shr.u32 	%r2128, %r2127, 1;
	and.b32  	%r2129, %r21, -2139062144;
	shr.u32 	%r2130, %r2129, 2;
	not.b32 	%r2131, %r2130;
	and.b32  	%r2132, %r2128, %r2131;
	and.b32  	%r2133, %r21, 522133279;
	add.s32 	%r2134, %r2133, 522133279;
	sub.s32 	%r2135, %r2110, %r2133;
	and.b32  	%r2136, %r2132, %r2135;
	and.b32  	%r2137, %r2136, %r2134;
	or.b32  	%r2138, %r2137, %r21;
	and.b32  	%r2139, %r22, 1077952576;
	shr.u32 	%r2140, %r2139, 1;
	and.b32  	%r2141, %r22, -2139062144;
	shr.u32 	%r2142, %r2141, 2;
	not.b32 	%r2143, %r2142;
	and.b32  	%r2144, %r2140, %r2143;
	and.b32  	%r2145, %r22, 522133279;
	add.s32 	%r2146, %r2145, 522133279;
	sub.s32 	%r2147, %r2110, %r2145;
	and.b32  	%r2148, %r2144, %r2147;
	and.b32  	%r2149, %r2148, %r2146;
	or.b32  	%r2150, %r2149, %r22;
	and.b32  	%r2151, %r15, 1077952576;
	shr.u32 	%r2152, %r2151, 1;
	and.b32  	%r2153, %r15, -2139062144;
	shr.u32 	%r2154, %r2153, 2;
	not.b32 	%r2155, %r2154;
	and.b32  	%r2156, %r2152, %r2155;
	and.b32  	%r2157, %r15, 522133279;
	add.s32 	%r2158, %r2157, 522133279;
	sub.s32 	%r2159, %r2110, %r2157;
	and.b32  	%r2160, %r2156, %r2159;
	and.b32  	%r2161, %r2160, %r2158;
	or.b32  	%r2162, %r2161, %r15;
	and.b32  	%r2163, %r16, 1077952576;
	shr.u32 	%r2164, %r2163, 1;
	and.b32  	%r2165, %r16, -2139062144;
	shr.u32 	%r2166, %r2165, 2;
	not.b32 	%r2167, %r2166;
	and.b32  	%r2168, %r2164, %r2167;
	and.b32  	%r2169, %r16, 522133279;
	add.s32 	%r2170, %r2169, 522133279;
	sub.s32 	%r2171, %r2110, %r2169;
	and.b32  	%r2172, %r2168, %r2171;
	and.b32  	%r2173, %r2172, %r2170;
	or.b32  	%r2174, %r2173, %r16;
	and.b32  	%r2175, %r17, 1077952576;
	shr.u32 	%r2176, %r2175, 1;
	and.b32  	%r2177, %r17, -2139062144;
	shr.u32 	%r2178, %r2177, 2;
	not.b32 	%r2179, %r2178;
	and.b32  	%r2180, %r2176, %r2179;
	and.b32  	%r2181, %r17, 522133279;
	add.s32 	%r2182, %r2181, 522133279;
	sub.s32 	%r2183, %r2110, %r2181;
	and.b32  	%r2184, %r2180, %r2183;
	and.b32  	%r2185, %r2184, %r2182;
	or.b32  	%r2186, %r2185, %r17;
	and.b32  	%r2187, %r18, 1077952576;
	shr.u32 	%r2188, %r2187, 1;
	and.b32  	%r2189, %r18, -2139062144;
	shr.u32 	%r2190, %r2189, 2;
	not.b32 	%r2191, %r2190;
	and.b32  	%r2192, %r2188, %r2191;
	and.b32  	%r2193, %r18, 522133279;
	add.s32 	%r2194, %r2193, 522133279;
	sub.s32 	%r2195, %r2110, %r2193;
	and.b32  	%r2196, %r2192, %r2195;
	and.b32  	%r2197, %r2196, %r2194;
	or.b32  	%r2198, %r2197, %r18;
	mov.b32	{%rs138, %rs139}, %r2114;
	shr.u16 	%rs140, %rs139, 8;
	cvt.u16.u32	%rs141, %r23;
	and.b16  	%rs142, %rs141, 255;
	setp.eq.s16	%p92, %rs140, %rs142;
	and.b16  	%rs143, %rs139, 255;
	setp.eq.s16	%p93, %rs143, %rs142;
	shr.u16 	%rs144, %rs138, 8;
	setp.eq.s16	%p94, %rs144, %rs142;
	and.b16  	%rs145, %rs138, 255;
	setp.eq.s16	%p95, %rs145, %rs142;
	selp.b16	%rs146, -1, 0, %p95;
	selp.b16	%rs147, -1, 0, %p94;
	selp.b16	%rs148, -1, 0, %p93;
	selp.b16	%rs149, -1, 0, %p92;
	shr.u16 	%rs150, %rs147, 7;
	cvt.u32.u16	%r2199, %rs150;
	shr.u16 	%rs151, %rs146, 7;
	and.b16  	%rs152, %rs151, 255;
	cvt.u32.u16	%r2200, %rs152;
	prmt.b32 	%r2201, %r2199, %r2200, 30212;
	shr.u16 	%rs153, %rs149, 7;
	cvt.u32.u16	%r2202, %rs153;
	shr.u16 	%rs154, %rs148, 7;
	and.b16  	%rs155, %rs154, 255;
	cvt.u32.u16	%r2203, %rs155;
	prmt.b32 	%r2204, %r2202, %r2203, 30212;
	prmt.b32 	%r2095, %r2204, %r2201, 4180;
	mov.b32	{%rs156, %rs157}, %r2126;
	shr.u16 	%rs158, %rs157, 8;
	setp.eq.s16	%p96, %rs158, %rs142;
	and.b16  	%rs159, %rs157, 255;
	setp.eq.s16	%p97, %rs159, %rs142;
	shr.u16 	%rs160, %rs156, 8;
	setp.eq.s16	%p98, %rs160, %rs142;
	and.b16  	%rs161, %rs156, 255;
	setp.eq.s16	%p99, %rs161, %rs142;
	selp.b16	%rs162, -1, 0, %p99;
	selp.b16	%rs163, -1, 0, %p98;
	selp.b16	%rs164, -1, 0, %p97;
	selp.b16	%rs165, -1, 0, %p96;
	shr.u16 	%rs166, %rs163, 7;
	cvt.u32.u16	%r2205, %rs166;
	shr.u16 	%rs167, %rs162, 7;
	and.b16  	%rs168, %rs167, 255;
	cvt.u32.u16	%r2206, %rs168;
	prmt.b32 	%r2207, %r2205, %r2206, 30212;
	shr.u16 	%rs169, %rs165, 7;
	cvt.u32.u16	%r2208, %rs169;
	shr.u16 	%rs170, %rs164, 7;
	and.b16  	%rs171, %rs170, 255;
	cvt.u32.u16	%r2209, %rs171;
	prmt.b32 	%r2210, %r2208, %r2209, 30212;
	prmt.b32 	%r2091, %r2210, %r2207, 4180;
	mov.b32	{%rs172, %rs173}, %r2138;
	shr.u16 	%rs174, %rs173, 8;
	setp.eq.s16	%p100, %rs174, %rs142;
	and.b16  	%rs175, %rs173, 255;
	setp.eq.s16	%p101, %rs175, %rs142;
	shr.u16 	%rs176, %rs172, 8;
	setp.eq.s16	%p102, %rs176, %rs142;
	and.b16  	%rs177, %rs172, 255;
	setp.eq.s16	%p103, %rs177, %rs142;
	selp.b16	%rs178, -1, 0, %p103;
	selp.b16	%rs179, -1, 0, %p102;
	selp.b16	%rs180, -1, 0, %p101;
	selp.b16	%rs181, -1, 0, %p100;
	shr.u16 	%rs182, %rs179, 7;
	cvt.u32.u16	%r2211, %rs182;
	shr.u16 	%rs183, %rs178, 7;
	and.b16  	%rs184, %rs183, 255;
	cvt.u32.u16	%r2212, %rs184;
	prmt.b32 	%r2213, %r2211, %r2212, 30212;
	shr.u16 	%rs185, %rs181, 7;
	cvt.u32.u16	%r2214, %rs185;
	shr.u16 	%rs186, %rs180, 7;
	and.b16  	%rs187, %rs186, 255;
	cvt.u32.u16	%r2215, %rs187;
	prmt.b32 	%r2216, %r2214, %r2215, 30212;
	prmt.b32 	%r2087, %r2216, %r2213, 4180;
	mov.b32	{%rs188, %rs189}, %r2150;
	shr.u16 	%rs190, %rs189, 8;
	setp.eq.s16	%p104, %rs190, %rs142;
	and.b16  	%rs191, %rs189, 255;
	setp.eq.s16	%p105, %rs191, %rs142;
	shr.u16 	%rs192, %rs188, 8;
	setp.eq.s16	%p106, %rs192, %rs142;
	and.b16  	%rs193, %rs188, 255;
	setp.eq.s16	%p107, %rs193, %rs142;
	selp.b16	%rs194, -1, 0, %p107;
	selp.b16	%rs195, -1, 0, %p106;
	selp.b16	%rs196, -1, 0, %p105;
	selp.b16	%rs197, -1, 0, %p104;
	shr.u16 	%rs198, %rs195, 7;
	cvt.u32.u16	%r2217, %rs198;
	shr.u16 	%rs199, %rs194, 7;
	and.b16  	%rs200, %rs199, 255;
	cvt.u32.u16	%r2218, %rs200;
	prmt.b32 	%r2219, %r2217, %r2218, 30212;
	shr.u16 	%rs201, %rs197, 7;
	cvt.u32.u16	%r2220, %rs201;
	shr.u16 	%rs202, %rs196, 7;
	and.b16  	%rs203, %rs202, 255;
	cvt.u32.u16	%r2221, %rs203;
	prmt.b32 	%r2222, %r2220, %r2221, 30212;
	prmt.b32 	%r2083, %r2222, %r2219, 4180;
	mov.b32	{%rs204, %rs205}, %r2162;
	shr.u16 	%rs206, %rs205, 8;
	setp.eq.s16	%p108, %rs206, %rs142;
	and.b16  	%rs207, %rs205, 255;
	setp.eq.s16	%p109, %rs207, %rs142;
	shr.u16 	%rs208, %rs204, 8;
	setp.eq.s16	%p110, %rs208, %rs142;
	and.b16  	%rs209, %rs204, 255;
	setp.eq.s16	%p111, %rs209, %rs142;
	selp.b16	%rs210, -1, 0, %p111;
	selp.b16	%rs211, -1, 0, %p110;
	selp.b16	%rs212, -1, 0, %p109;
	selp.b16	%rs213, -1, 0, %p108;
	shr.u16 	%rs214, %rs211, 7;
	cvt.u32.u16	%r2223, %rs214;
	shr.u16 	%rs215, %rs210, 7;
	and.b16  	%rs216, %rs215, 255;
	cvt.u32.u16	%r2224, %rs216;
	prmt.b32 	%r2225, %r2223, %r2224, 30212;
	shr.u16 	%rs217, %rs213, 7;
	cvt.u32.u16	%r2226, %rs217;
	shr.u16 	%rs218, %rs212, 7;
	and.b16  	%rs219, %rs218, 255;
	cvt.u32.u16	%r2227, %rs219;
	prmt.b32 	%r2228, %r2226, %r2227, 30212;
	prmt.b32 	%r2079, %r2228, %r2225, 4180;
	mov.b32	{%rs220, %rs221}, %r2174;
	shr.u16 	%rs222, %rs221, 8;
	setp.eq.s16	%p112, %rs222, %rs142;
	and.b16  	%rs223, %rs221, 255;
	setp.eq.s16	%p113, %rs223, %rs142;
	shr.u16 	%rs224, %rs220, 8;
	setp.eq.s16	%p114, %rs224, %rs142;
	and.b16  	%rs225, %rs220, 255;
	setp.eq.s16	%p115, %rs225, %rs142;
	selp.b16	%rs226, -1, 0, %p115;
	selp.b16	%rs227, -1, 0, %p114;
	selp.b16	%rs228, -1, 0, %p113;
	selp.b16	%rs229, -1, 0, %p112;
	shr.u16 	%rs230, %rs227, 7;
	cvt.u32.u16	%r2229, %rs230;
	shr.u16 	%rs231, %rs226, 7;
	and.b16  	%rs232, %rs231, 255;
	cvt.u32.u16	%r2230, %rs232;
	prmt.b32 	%r2231, %r2229, %r2230, 30212;
	shr.u16 	%rs233, %rs229, 7;
	cvt.u32.u16	%r2232, %rs233;
	shr.u16 	%rs234, %rs228, 7;
	and.b16  	%rs235, %rs234, 255;
	cvt.u32.u16	%r2233, %rs235;
	prmt.b32 	%r2234, %r2232, %r2233, 30212;
	prmt.b32 	%r2075, %r2234, %r2231, 4180;
	mov.b32	{%rs236, %rs237}, %r2186;
	shr.u16 	%rs238, %rs237, 8;
	setp.eq.s16	%p116, %rs238, %rs142;
	and.b16  	%rs239, %rs237, 255;
	setp.eq.s16	%p117, %rs239, %rs142;
	shr.u16 	%rs240, %rs236, 8;
	setp.eq.s16	%p118, %rs240, %rs142;
	and.b16  	%rs241, %rs236, 255;
	setp.eq.s16	%p119, %rs241, %rs142;
	selp.b16	%rs242, -1, 0, %p119;
	selp.b16	%rs243, -1, 0, %p118;
	selp.b16	%rs244, -1, 0, %p117;
	selp.b16	%rs245, -1, 0, %p116;
	shr.u16 	%rs246, %rs243, 7;
	cvt.u32.u16	%r2235, %rs246;
	shr.u16 	%rs247, %rs242, 7;
	and.b16  	%rs248, %rs247, 255;
	cvt.u32.u16	%r2236, %rs248;
	prmt.b32 	%r2237, %r2235, %r2236, 30212;
	shr.u16 	%rs249, %rs245, 7;
	cvt.u32.u16	%r2238, %rs249;
	shr.u16 	%rs250, %rs244, 7;
	and.b16  	%rs251, %rs250, 255;
	cvt.u32.u16	%r2239, %rs251;
	prmt.b32 	%r2240, %r2238, %r2239, 30212;
	prmt.b32 	%r2071, %r2240, %r2237, 4180;
	mov.b32	{%rs252, %rs253}, %r2198;
	shr.u16 	%rs254, %rs253, 8;
	setp.eq.s16	%p120, %rs254, %rs142;
	and.b16  	%rs255, %rs253, 255;
	setp.eq.s16	%p121, %rs255, %rs142;
	shr.u16 	%rs256, %rs252, 8;
	setp.eq.s16	%p122, %rs256, %rs142;
	and.b16  	%rs257, %rs252, 255;
	setp.eq.s16	%p123, %rs257, %rs142;
	selp.b16	%rs258, -1, 0, %p123;
	selp.b16	%rs259, -1, 0, %p122;
	selp.b16	%rs260, -1, 0, %p121;
	selp.b16	%rs261, -1, 0, %p120;
	shr.u16 	%rs262, %rs259, 7;
	cvt.u32.u16	%r2241, %rs262;
	shr.u16 	%rs263, %rs258, 7;
	and.b16  	%rs264, %rs263, 255;
	cvt.u32.u16	%r2242, %rs264;
	prmt.b32 	%r2243, %r2241, %r2242, 30212;
	shr.u16 	%rs265, %rs261, 7;
	cvt.u32.u16	%r2244, %rs265;
	shr.u16 	%rs266, %rs260, 7;
	and.b16  	%rs267, %rs266, 255;
	cvt.u32.u16	%r2245, %rs267;
	prmt.b32 	%r2246, %r2244, %r2245, 30212;
	prmt.b32 	%r2072, %r2246, %r2243, 4180;
	mov.u32 	%r2101, 24;
	// inline asm
	shf.r.wrap.b32 %r2070, %r2071, %r2072, %r2101;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2074, %r2075, %r2071, %r2101;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2078, %r2079, %r2075, %r2101;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2082, %r2083, %r2079, %r2101;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2086, %r2087, %r2083, %r2101;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2090, %r2091, %r2087, %r2101;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2094, %r2095, %r2091, %r2101;
	// inline asm
	mov.u32 	%r2099, 0;
	// inline asm
	shf.r.wrap.b32 %r2098, %r2099, %r2095, %r2101;
	// inline asm
	or.b32  	%r2247, %r2098, 255;
	and.b32  	%r2248, %r2114, 1077952576;
	shr.u32 	%r2249, %r2248, 1;
	and.b32  	%r2250, %r2114, -2139062144;
	shr.u32 	%r2251, %r2250, 2;
	not.b32 	%r2252, %r2251;
	and.b32  	%r2253, %r2249, %r2252;
	and.b32  	%r2254, %r2114, 522133279;
	add.s32 	%r2255, %r2254, 522133279;
	sub.s32 	%r2256, %r2110, %r2254;
	and.b32  	%r2257, %r2253, %r2256;
	and.b32  	%r2258, %r2257, %r2255;
	and.b32  	%r2259, %r2258, %r2247;
	not.b32 	%r2260, %r2259;
	and.b32  	%r8944, %r2114, %r2260;
	and.b32  	%r2261, %r2126, 1077952576;
	shr.u32 	%r2262, %r2261, 1;
	and.b32  	%r2263, %r2126, -2139062144;
	shr.u32 	%r2264, %r2263, 2;
	not.b32 	%r2265, %r2264;
	and.b32  	%r2266, %r2262, %r2265;
	and.b32  	%r2267, %r2126, 522133279;
	add.s32 	%r2268, %r2267, 522133279;
	sub.s32 	%r2269, %r2110, %r2267;
	and.b32  	%r2270, %r2266, %r2269;
	and.b32  	%r2271, %r2270, %r2268;
	and.b32  	%r2272, %r2271, %r2094;
	not.b32 	%r2273, %r2272;
	and.b32  	%r8943, %r2126, %r2273;
	and.b32  	%r2274, %r2138, 1077952576;
	shr.u32 	%r2275, %r2274, 1;
	and.b32  	%r2276, %r2138, -2139062144;
	shr.u32 	%r2277, %r2276, 2;
	not.b32 	%r2278, %r2277;
	and.b32  	%r2279, %r2275, %r2278;
	and.b32  	%r2280, %r2138, 522133279;
	add.s32 	%r2281, %r2280, 522133279;
	sub.s32 	%r2282, %r2110, %r2280;
	and.b32  	%r2283, %r2279, %r2282;
	and.b32  	%r2284, %r2283, %r2281;
	and.b32  	%r2285, %r2284, %r2090;
	not.b32 	%r2286, %r2285;
	and.b32  	%r8942, %r2138, %r2286;
	and.b32  	%r2287, %r2150, 1077952576;
	shr.u32 	%r2288, %r2287, 1;
	and.b32  	%r2289, %r2150, -2139062144;
	shr.u32 	%r2290, %r2289, 2;
	not.b32 	%r2291, %r2290;
	and.b32  	%r2292, %r2288, %r2291;
	and.b32  	%r2293, %r2150, 522133279;
	add.s32 	%r2294, %r2293, 522133279;
	sub.s32 	%r2295, %r2110, %r2293;
	and.b32  	%r2296, %r2292, %r2295;
	and.b32  	%r2297, %r2296, %r2294;
	and.b32  	%r2298, %r2297, %r2086;
	not.b32 	%r2299, %r2298;
	and.b32  	%r8941, %r2150, %r2299;
	and.b32  	%r2300, %r2162, 1077952576;
	shr.u32 	%r2301, %r2300, 1;
	and.b32  	%r2302, %r2162, -2139062144;
	shr.u32 	%r2303, %r2302, 2;
	not.b32 	%r2304, %r2303;
	and.b32  	%r2305, %r2301, %r2304;
	and.b32  	%r2306, %r2162, 522133279;
	add.s32 	%r2307, %r2306, 522133279;
	sub.s32 	%r2308, %r2110, %r2306;
	and.b32  	%r2309, %r2305, %r2308;
	and.b32  	%r2310, %r2309, %r2307;
	and.b32  	%r2311, %r2310, %r2082;
	not.b32 	%r2312, %r2311;
	and.b32  	%r8948, %r2162, %r2312;
	and.b32  	%r2313, %r2174, 1077952576;
	shr.u32 	%r2314, %r2313, 1;
	and.b32  	%r2315, %r2174, -2139062144;
	shr.u32 	%r2316, %r2315, 2;
	not.b32 	%r2317, %r2316;
	and.b32  	%r2318, %r2314, %r2317;
	and.b32  	%r2319, %r2174, 522133279;
	add.s32 	%r2320, %r2319, 522133279;
	sub.s32 	%r2321, %r2110, %r2319;
	and.b32  	%r2322, %r2318, %r2321;
	and.b32  	%r2323, %r2322, %r2320;
	and.b32  	%r2324, %r2323, %r2078;
	not.b32 	%r2325, %r2324;
	and.b32  	%r8947, %r2174, %r2325;
	and.b32  	%r2326, %r2186, 1077952576;
	shr.u32 	%r2327, %r2326, 1;
	and.b32  	%r2328, %r2186, -2139062144;
	shr.u32 	%r2329, %r2328, 2;
	not.b32 	%r2330, %r2329;
	and.b32  	%r2331, %r2327, %r2330;
	and.b32  	%r2332, %r2186, 522133279;
	add.s32 	%r2333, %r2332, 522133279;
	sub.s32 	%r2334, %r2110, %r2332;
	and.b32  	%r2335, %r2331, %r2334;
	and.b32  	%r2336, %r2335, %r2333;
	and.b32  	%r2337, %r2336, %r2074;
	not.b32 	%r2338, %r2337;
	and.b32  	%r8946, %r2186, %r2338;
	and.b32  	%r2339, %r2198, 1077952576;
	shr.u32 	%r2340, %r2339, 1;
	and.b32  	%r2341, %r2198, -2139062144;
	shr.u32 	%r2342, %r2341, 2;
	not.b32 	%r2343, %r2342;
	and.b32  	%r2344, %r2340, %r2343;
	and.b32  	%r2345, %r2198, 522133279;
	add.s32 	%r2346, %r2345, 522133279;
	sub.s32 	%r2347, %r2110, %r2345;
	and.b32  	%r2348, %r2344, %r2347;
	and.b32  	%r2349, %r2348, %r2346;
	and.b32  	%r2350, %r2349, %r2070;
	not.b32 	%r2351, %r2350;
	and.b32  	%r8945, %r2198, %r2351;
	mov.u32 	%r8949, %r14;
	bra.uni 	BB0_1554;

BB0_50:
	setp.eq.s32	%p42, %r1787, 76;
	@%p42 bra 	BB0_428;

	setp.eq.s32	%p43, %r1787, 79;
	@%p43 bra 	BB0_1052;
	bra.uni 	BB0_52;

BB0_1052:
	setp.ge.u32	%p707, %r24, %r14;
	add.s32 	%r5031, %r24, %r26;
	setp.gt.u32	%p708, %r5031, %r14;
	or.pred  	%p709, %p707, %p708;
	@%p709 bra 	BB0_978;

	mov.u32 	%r8945, 0;
	setp.gt.s32	%p710, %r26, 15;
	@%p710 bra 	BB0_1086;

	setp.gt.s32	%p734, %r26, 7;
	@%p734 bra 	BB0_1070;

	setp.gt.s32	%p746, %r26, 3;
	@%p746 bra 	BB0_1063;

	setp.gt.s32	%p752, %r26, 1;
	@%p752 bra 	BB0_1060;

	setp.eq.s32	%p755, %r26, 0;
	@%p755 bra 	BB0_1136;
	bra.uni 	BB0_1058;

BB0_1136:
	mov.u32 	%r8941, %r22;
	mov.u32 	%r8942, %r21;
	mov.u32 	%r8943, %r20;
	mov.u32 	%r8862, %r19;
	mov.u32 	%r8945, %r18;
	mov.u32 	%r8946, %r17;
	mov.u32 	%r8947, %r16;
	mov.u32 	%r8948, %r15;
	bra.uni 	BB0_1137;

BB0_112:
	setp.eq.s32	%p15, %r1787, 115;
	@%p15 bra 	BB0_976;

	setp.eq.s32	%p16, %r1787, 116;
	@%p16 bra 	BB0_1550;
	bra.uni 	BB0_114;

BB0_1550:
	and.b32  	%r8265, %r19, 1077952576;
	shr.u32 	%r8266, %r8265, 1;
	and.b32  	%r8267, %r19, -2139062144;
	shr.u32 	%r8268, %r8267, 2;
	not.b32 	%r8269, %r8268;
	and.b32  	%r8270, %r8266, %r8269;
	and.b32  	%r8271, %r19, 522133279;
	add.s32 	%r8272, %r8271, 522133279;
	mov.u32 	%r8273, -84215046;
	sub.s32 	%r8274, %r8273, %r8271;
	and.b32  	%r8275, %r8270, %r8274;
	and.b32  	%r8276, %r8275, %r8272;
	xor.b32  	%r8944, %r8276, %r19;
	and.b32  	%r8277, %r20, 1077952576;
	shr.u32 	%r8278, %r8277, 1;
	and.b32  	%r8279, %r20, -2139062144;
	shr.u32 	%r8280, %r8279, 2;
	not.b32 	%r8281, %r8280;
	and.b32  	%r8282, %r8278, %r8281;
	and.b32  	%r8283, %r20, 522133279;
	add.s32 	%r8284, %r8283, 522133279;
	sub.s32 	%r8285, %r8273, %r8283;
	and.b32  	%r8286, %r8282, %r8285;
	and.b32  	%r8287, %r8286, %r8284;
	xor.b32  	%r8943, %r8287, %r20;
	and.b32  	%r8288, %r21, 1077952576;
	shr.u32 	%r8289, %r8288, 1;
	and.b32  	%r8290, %r21, -2139062144;
	shr.u32 	%r8291, %r8290, 2;
	not.b32 	%r8292, %r8291;
	and.b32  	%r8293, %r8289, %r8292;
	and.b32  	%r8294, %r21, 522133279;
	add.s32 	%r8295, %r8294, 522133279;
	sub.s32 	%r8296, %r8273, %r8294;
	and.b32  	%r8297, %r8293, %r8296;
	and.b32  	%r8298, %r8297, %r8295;
	xor.b32  	%r8942, %r8298, %r21;
	and.b32  	%r8299, %r22, 1077952576;
	shr.u32 	%r8300, %r8299, 1;
	and.b32  	%r8301, %r22, -2139062144;
	shr.u32 	%r8302, %r8301, 2;
	not.b32 	%r8303, %r8302;
	and.b32  	%r8304, %r8300, %r8303;
	and.b32  	%r8305, %r22, 522133279;
	add.s32 	%r8306, %r8305, 522133279;
	sub.s32 	%r8307, %r8273, %r8305;
	and.b32  	%r8308, %r8304, %r8307;
	and.b32  	%r8309, %r8308, %r8306;
	xor.b32  	%r8941, %r8309, %r22;
	and.b32  	%r8310, %r15, 1077952576;
	shr.u32 	%r8311, %r8310, 1;
	and.b32  	%r8312, %r15, -2139062144;
	shr.u32 	%r8313, %r8312, 2;
	not.b32 	%r8314, %r8313;
	and.b32  	%r8315, %r8311, %r8314;
	and.b32  	%r8316, %r15, 522133279;
	add.s32 	%r8317, %r8316, 522133279;
	sub.s32 	%r8318, %r8273, %r8316;
	and.b32  	%r8319, %r8315, %r8318;
	and.b32  	%r8320, %r8319, %r8317;
	xor.b32  	%r8948, %r8320, %r15;
	and.b32  	%r8321, %r16, 1077952576;
	shr.u32 	%r8322, %r8321, 1;
	and.b32  	%r8323, %r16, -2139062144;
	shr.u32 	%r8324, %r8323, 2;
	not.b32 	%r8325, %r8324;
	and.b32  	%r8326, %r8322, %r8325;
	and.b32  	%r8327, %r16, 522133279;
	add.s32 	%r8328, %r8327, 522133279;
	sub.s32 	%r8329, %r8273, %r8327;
	and.b32  	%r8330, %r8326, %r8329;
	and.b32  	%r8331, %r8330, %r8328;
	xor.b32  	%r8947, %r8331, %r16;
	and.b32  	%r8332, %r17, 1077952576;
	shr.u32 	%r8333, %r8332, 1;
	and.b32  	%r8334, %r17, -2139062144;
	shr.u32 	%r8335, %r8334, 2;
	not.b32 	%r8336, %r8335;
	and.b32  	%r8337, %r8333, %r8336;
	and.b32  	%r8338, %r17, 522133279;
	add.s32 	%r8339, %r8338, 522133279;
	sub.s32 	%r8340, %r8273, %r8338;
	and.b32  	%r8341, %r8337, %r8340;
	and.b32  	%r8342, %r8341, %r8339;
	xor.b32  	%r8946, %r8342, %r17;
	and.b32  	%r8343, %r18, 1077952576;
	shr.u32 	%r8344, %r8343, 1;
	and.b32  	%r8345, %r18, -2139062144;
	shr.u32 	%r8346, %r8345, 2;
	not.b32 	%r8347, %r8346;
	and.b32  	%r8348, %r8344, %r8347;
	and.b32  	%r8349, %r18, 522133279;
	add.s32 	%r8350, %r8349, 522133279;
	sub.s32 	%r8351, %r8273, %r8349;
	and.b32  	%r8352, %r8348, %r8351;
	and.b32  	%r8353, %r8352, %r8350;
	xor.b32  	%r8945, %r8353, %r18;
	bra.uni 	BB0_1553;

BB0_31:
	setp.eq.s32	%p49, %r1787, 64;
	@%p49 bra 	BB0_951;

	setp.eq.s32	%p50, %r1787, 67;
	@%p50 bra 	BB0_1551;
	bra.uni 	BB0_33;

BB0_1551:
	and.b32  	%r8354, %r19, 1077952576;
	shr.u32 	%r8355, %r8354, 1;
	and.b32  	%r8356, %r19, -2139062144;
	shr.u32 	%r8357, %r8356, 2;
	not.b32 	%r8358, %r8357;
	and.b32  	%r8359, %r8355, %r8358;
	and.b32  	%r8360, %r19, 522133279;
	add.s32 	%r8361, %r8360, 522133279;
	mov.u32 	%r8362, -84215046;
	sub.s32 	%r8363, %r8362, %r8360;
	and.b32  	%r8364, %r8359, %r8363;
	and.b32  	%r8365, %r8364, %r8361;
	not.b32 	%r8366, %r8365;
	and.b32  	%r8367, %r20, 1077952576;
	shr.u32 	%r8368, %r8367, 1;
	and.b32  	%r8369, %r20, -2139062144;
	shr.u32 	%r8370, %r8369, 2;
	not.b32 	%r8371, %r8370;
	and.b32  	%r8372, %r8368, %r8371;
	and.b32  	%r8373, %r20, 522133279;
	add.s32 	%r8374, %r8373, 522133279;
	sub.s32 	%r8375, %r8362, %r8373;
	and.b32  	%r8376, %r8372, %r8375;
	and.b32  	%r8377, %r8376, %r8374;
	not.b32 	%r8378, %r8377;
	and.b32  	%r8943, %r20, %r8378;
	and.b32  	%r8379, %r21, 1077952576;
	shr.u32 	%r8380, %r8379, 1;
	and.b32  	%r8381, %r21, -2139062144;
	shr.u32 	%r8382, %r8381, 2;
	not.b32 	%r8383, %r8382;
	and.b32  	%r8384, %r8380, %r8383;
	and.b32  	%r8385, %r21, 522133279;
	add.s32 	%r8386, %r8385, 522133279;
	sub.s32 	%r8387, %r8362, %r8385;
	and.b32  	%r8388, %r8384, %r8387;
	and.b32  	%r8389, %r8388, %r8386;
	not.b32 	%r8390, %r8389;
	and.b32  	%r8942, %r21, %r8390;
	and.b32  	%r8391, %r22, 1077952576;
	shr.u32 	%r8392, %r8391, 1;
	and.b32  	%r8393, %r22, -2139062144;
	shr.u32 	%r8394, %r8393, 2;
	not.b32 	%r8395, %r8394;
	and.b32  	%r8396, %r8392, %r8395;
	and.b32  	%r8397, %r22, 522133279;
	add.s32 	%r8398, %r8397, 522133279;
	sub.s32 	%r8399, %r8362, %r8397;
	and.b32  	%r8400, %r8396, %r8399;
	and.b32  	%r8401, %r8400, %r8398;
	not.b32 	%r8402, %r8401;
	and.b32  	%r8941, %r22, %r8402;
	and.b32  	%r8403, %r15, 1077952576;
	shr.u32 	%r8404, %r8403, 1;
	and.b32  	%r8405, %r15, -2139062144;
	shr.u32 	%r8406, %r8405, 2;
	not.b32 	%r8407, %r8406;
	and.b32  	%r8408, %r8404, %r8407;
	and.b32  	%r8409, %r15, 522133279;
	add.s32 	%r8410, %r8409, 522133279;
	sub.s32 	%r8411, %r8362, %r8409;
	and.b32  	%r8412, %r8408, %r8411;
	and.b32  	%r8413, %r8412, %r8410;
	not.b32 	%r8414, %r8413;
	and.b32  	%r8948, %r15, %r8414;
	and.b32  	%r8415, %r16, 1077952576;
	shr.u32 	%r8416, %r8415, 1;
	and.b32  	%r8417, %r16, -2139062144;
	shr.u32 	%r8418, %r8417, 2;
	not.b32 	%r8419, %r8418;
	and.b32  	%r8420, %r8416, %r8419;
	and.b32  	%r8421, %r16, 522133279;
	add.s32 	%r8422, %r8421, 522133279;
	sub.s32 	%r8423, %r8362, %r8421;
	and.b32  	%r8424, %r8420, %r8423;
	and.b32  	%r8425, %r8424, %r8422;
	not.b32 	%r8426, %r8425;
	and.b32  	%r8947, %r16, %r8426;
	and.b32  	%r8427, %r17, 1077952576;
	shr.u32 	%r8428, %r8427, 1;
	and.b32  	%r8429, %r17, -2139062144;
	shr.u32 	%r8430, %r8429, 2;
	not.b32 	%r8431, %r8430;
	and.b32  	%r8432, %r8428, %r8431;
	and.b32  	%r8433, %r17, 522133279;
	add.s32 	%r8434, %r8433, 522133279;
	sub.s32 	%r8435, %r8362, %r8433;
	and.b32  	%r8436, %r8432, %r8435;
	and.b32  	%r8437, %r8436, %r8434;
	not.b32 	%r8438, %r8437;
	and.b32  	%r8946, %r17, %r8438;
	and.b32  	%r8439, %r18, 1077952576;
	shr.u32 	%r8440, %r8439, 1;
	and.b32  	%r8441, %r18, -2139062144;
	shr.u32 	%r8442, %r8441, 2;
	not.b32 	%r8443, %r8442;
	and.b32  	%r8444, %r8440, %r8443;
	and.b32  	%r8445, %r18, 522133279;
	add.s32 	%r8446, %r8445, 522133279;
	sub.s32 	%r8447, %r8362, %r8445;
	and.b32  	%r8448, %r8444, %r8447;
	and.b32  	%r8449, %r8448, %r8446;
	not.b32 	%r8450, %r8449;
	and.b32  	%r8945, %r18, %r8450;
	and.b32  	%r8451, %r19, %r8366;
	and.b32  	%r8452, %r8451, 64;
	shr.u32 	%r8453, %r8452, 1;
	shr.u32 	%r8454, %r8451, 2;
	and.b32  	%r8455, %r8451, 522133279;
	add.s32 	%r8456, %r8455, 31;
	sub.s32 	%r8457, %r8362, %r8455;
	not.b32 	%r8458, %r8454;
	and.b32  	%r8459, %r8458, %r8453;
	and.b32  	%r8460, %r8459, %r8457;
	and.b32  	%r8461, %r8460, %r8456;
	or.b32  	%r8944, %r8461, %r8451;
	bra.uni 	BB0_1553;

BB0_94:
	setp.eq.s32	%p22, %r1787, 108;
	@%p22 bra 	BB0_1552;

	setp.eq.s32	%p23, %r1787, 111;
	@%p23 bra 	BB0_1003;
	bra.uni 	BB0_96;

BB0_1003:
	setp.ge.u32	%p681, %r24, %r14;
	@%p681 bra 	BB0_978;

	and.b32  	%r4957, %r23, 3;
	shl.b32 	%r4958, %r4957, 3;
	shl.b32 	%r913, %r26, %r4958;
	mov.u32 	%r4959, 255;
	shl.b32 	%r4960, %r4959, %r4958;
	not.b32 	%r914, %r4960;
	shr.u32 	%r4956, %r24, 2;
	setp.gt.s32	%p682, %r4956, 3;
	@%p682 bra 	BB0_1013;

	setp.gt.s32	%p688, %r4956, 1;
	@%p688 bra 	BB0_1010;

	setp.eq.s32	%p691, %r4956, 0;
	@%p691 bra 	BB0_1027;
	bra.uni 	BB0_1007;

BB0_1027:
	and.b32  	%r4968, %r19, %r914;
	or.b32  	%r8944, %r4968, %r913;

BB0_1028:
	mov.u32 	%r8941, %r22;
	mov.u32 	%r8942, %r21;
	mov.u32 	%r8943, %r20;
	bra.uni 	BB0_15;

BB0_68:
	setp.eq.s32	%p36, %r1787, 90;
	@%p36 bra 	BB0_785;

	setp.eq.s32	%p37, %r1787, 91;
	@%p37 bra 	BB0_1290;
	bra.uni 	BB0_70;

BB0_1290:
	setp.eq.s32	%p848, %r14, 0;
	mov.u32 	%r8949, 0;
	@%p848 bra 	BB0_1034;

	add.s32 	%r8949, %r14, -1;
	mov.u32 	%r6283, 8;
	// inline asm
	shf.r.wrap.b32 %r8944, %r19, %r20, %r6283;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r20, %r21, %r6283;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8942, %r21, %r22, %r6283;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8941, %r22, %r15, %r6283;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8948, %r15, %r16, %r6283;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8947, %r16, %r17, %r6283;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8946, %r17, %r18, %r6283;
	// inline asm
	mov.u32 	%r6282, 0;
	// inline asm
	shf.r.wrap.b32 %r8945, %r18, %r6282, %r6283;
	// inline asm
	bra.uni 	BB0_1554;

BB0_124:
	setp.eq.s32	%p9, %r1787, 122;
	@%p9 bra 	BB0_788;

	setp.eq.s32	%p10, %r1787, 123;
	@%p10 bra 	BB0_1308;
	bra.uni 	BB0_126;

BB0_1308:
	setp.eq.s32	%p869, %r14, 0;
	mov.u32 	%r8949, 0;
	@%p869 bra 	BB0_1034;

	add.s32 	%r6404, %r14, -1;
	and.b32  	%r6405, %r6404, 3;
	shl.b32 	%r6406, %r6405, 3;
	and.b32  	%r6407, %r19, 255;
	shl.b32 	%r6408, %r6407, %r6406;
	mov.u32 	%r6403, 8;
	// inline asm
	shf.r.wrap.b32 %r6372, %r19, %r20, %r6403;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6376, %r20, %r21, %r6403;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6380, %r21, %r22, %r6403;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6384, %r22, %r15, %r6403;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6388, %r15, %r16, %r6403;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6392, %r16, %r17, %r6403;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6396, %r17, %r18, %r6403;
	// inline asm
	mov.u32 	%r6402, 0;
	// inline asm
	shf.r.wrap.b32 %r6400, %r18, %r6402, %r6403;
	// inline asm
	setp.lt.u32	%p870, %r6404, 4;
	selp.b32	%r6409, %r6408, 0, %p870;
	or.b32  	%r8944, %r6372, %r6409;
	and.b32  	%r6410, %r6404, -4;
	setp.eq.s32	%p871, %r6410, 4;
	selp.b32	%r6411, %r6408, 0, %p871;
	or.b32  	%r8943, %r6376, %r6411;
	setp.eq.s32	%p872, %r6410, 8;
	selp.b32	%r6412, %r6408, 0, %p872;
	or.b32  	%r8942, %r6380, %r6412;
	setp.eq.s32	%p873, %r6410, 12;
	selp.b32	%r6413, %r6408, 0, %p873;
	or.b32  	%r8941, %r6384, %r6413;
	setp.eq.s32	%p874, %r6410, 16;
	selp.b32	%r6414, %r6408, 0, %p874;
	or.b32  	%r8948, %r6388, %r6414;
	setp.eq.s32	%p875, %r6410, 20;
	selp.b32	%r6415, %r6408, 0, %p875;
	or.b32  	%r8947, %r6392, %r6415;
	setp.eq.s32	%p876, %r6410, 24;
	selp.b32	%r6416, %r6408, 0, %p876;
	or.b32  	%r8946, %r6396, %r6416;
	setp.gt.u32	%p877, %r6404, 27;
	selp.b32	%r6417, %r6408, 0, %p877;
	or.b32  	%r8945, %r6400, %r6417;
	bra.uni 	BB0_1553;

BB0_10:
	setp.eq.s32	%p59, %r1787, 39;
	@%p59 bra 	BB0_977;
	bra.uni 	BB0_11;

BB0_977:
	setp.ge.u32	%p669, %r24, %r14;
	@%p669 bra 	BB0_978;

	and.b32  	%r4924, %r23, 3;
	shl.b32 	%r4925, %r4924, 3;
	mov.u32 	%r4926, 1;
	shl.b32 	%r4927, %r4926, %r4925;
	add.s32 	%r904, %r4927, -1;
	shr.u32 	%r4923, %r24, 2;
	setp.gt.s32	%p670, %r4923, 3;
	@%p670 bra 	BB0_987;

	setp.gt.s32	%p676, %r4923, 1;
	@%p676 bra 	BB0_984;

	setp.eq.s32	%p679, %r4923, 0;
	@%p679 bra 	BB0_1002;
	bra.uni 	BB0_982;

BB0_1002:
	and.b32  	%r8944, %r904, %r19;
	mov.u32 	%r8941, 0;
	mov.u32 	%r8942, %r8941;
	mov.u32 	%r8943, %r8941;
	bra.uni 	BB0_1000;

BB0_77:
	setp.eq.s32	%p32, %r1787, 99;
	@%p32 bra 	BB0_78;
	bra.uni 	BB0_11;

BB0_78:
	and.b32  	%r8462, %r19, 1077952576;
	shr.u32 	%r8463, %r8462, 1;
	and.b32  	%r8464, %r19, -2139062144;
	shr.u32 	%r8465, %r8464, 2;
	not.b32 	%r8466, %r8465;
	and.b32  	%r8467, %r8463, %r8466;
	and.b32  	%r8468, %r19, 522133279;
	add.s32 	%r8469, %r8468, 522133279;
	mov.u32 	%r8470, -84215046;
	sub.s32 	%r8471, %r8470, %r8468;
	and.b32  	%r8472, %r8467, %r8471;
	and.b32  	%r8473, %r8472, %r8469;
	or.b32  	%r8474, %r8473, %r19;
	and.b32  	%r8475, %r20, 1077952576;
	shr.u32 	%r8476, %r8475, 1;
	and.b32  	%r8477, %r20, -2139062144;
	shr.u32 	%r8478, %r8477, 2;
	not.b32 	%r8479, %r8478;
	and.b32  	%r8480, %r8476, %r8479;
	and.b32  	%r8481, %r20, 522133279;
	add.s32 	%r8482, %r8481, 522133279;
	sub.s32 	%r8483, %r8470, %r8481;
	and.b32  	%r8484, %r8480, %r8483;
	and.b32  	%r8485, %r8484, %r8482;
	or.b32  	%r8943, %r8485, %r20;
	and.b32  	%r8486, %r21, 1077952576;
	shr.u32 	%r8487, %r8486, 1;
	and.b32  	%r8488, %r21, -2139062144;
	shr.u32 	%r8489, %r8488, 2;
	not.b32 	%r8490, %r8489;
	and.b32  	%r8491, %r8487, %r8490;
	and.b32  	%r8492, %r21, 522133279;
	add.s32 	%r8493, %r8492, 522133279;
	sub.s32 	%r8494, %r8470, %r8492;
	and.b32  	%r8495, %r8491, %r8494;
	and.b32  	%r8496, %r8495, %r8493;
	or.b32  	%r8942, %r8496, %r21;
	and.b32  	%r8497, %r22, 1077952576;
	shr.u32 	%r8498, %r8497, 1;
	and.b32  	%r8499, %r22, -2139062144;
	shr.u32 	%r8500, %r8499, 2;
	not.b32 	%r8501, %r8500;
	and.b32  	%r8502, %r8498, %r8501;
	and.b32  	%r8503, %r22, 522133279;
	add.s32 	%r8504, %r8503, 522133279;
	sub.s32 	%r8505, %r8470, %r8503;
	and.b32  	%r8506, %r8502, %r8505;
	and.b32  	%r8507, %r8506, %r8504;
	or.b32  	%r8941, %r8507, %r22;
	and.b32  	%r8508, %r15, 1077952576;
	shr.u32 	%r8509, %r8508, 1;
	and.b32  	%r8510, %r15, -2139062144;
	shr.u32 	%r8511, %r8510, 2;
	not.b32 	%r8512, %r8511;
	and.b32  	%r8513, %r8509, %r8512;
	and.b32  	%r8514, %r15, 522133279;
	add.s32 	%r8515, %r8514, 522133279;
	sub.s32 	%r8516, %r8470, %r8514;
	and.b32  	%r8517, %r8513, %r8516;
	and.b32  	%r8518, %r8517, %r8515;
	or.b32  	%r8948, %r8518, %r15;
	and.b32  	%r8519, %r16, 1077952576;
	shr.u32 	%r8520, %r8519, 1;
	and.b32  	%r8521, %r16, -2139062144;
	shr.u32 	%r8522, %r8521, 2;
	not.b32 	%r8523, %r8522;
	and.b32  	%r8524, %r8520, %r8523;
	and.b32  	%r8525, %r16, 522133279;
	add.s32 	%r8526, %r8525, 522133279;
	sub.s32 	%r8527, %r8470, %r8525;
	and.b32  	%r8528, %r8524, %r8527;
	and.b32  	%r8529, %r8528, %r8526;
	or.b32  	%r8947, %r8529, %r16;
	and.b32  	%r8530, %r17, 1077952576;
	shr.u32 	%r8531, %r8530, 1;
	and.b32  	%r8532, %r17, -2139062144;
	shr.u32 	%r8533, %r8532, 2;
	not.b32 	%r8534, %r8533;
	and.b32  	%r8535, %r8531, %r8534;
	and.b32  	%r8536, %r17, 522133279;
	add.s32 	%r8537, %r8536, 522133279;
	sub.s32 	%r8538, %r8470, %r8536;
	and.b32  	%r8539, %r8535, %r8538;
	and.b32  	%r8540, %r8539, %r8537;
	or.b32  	%r8946, %r8540, %r17;
	and.b32  	%r8541, %r18, 1077952576;
	shr.u32 	%r8542, %r8541, 1;
	and.b32  	%r8543, %r18, -2139062144;
	shr.u32 	%r8544, %r8543, 2;
	not.b32 	%r8545, %r8544;
	and.b32  	%r8546, %r8542, %r8545;
	and.b32  	%r8547, %r18, 522133279;
	add.s32 	%r8548, %r8547, 522133279;
	sub.s32 	%r8549, %r8470, %r8547;
	and.b32  	%r8550, %r8546, %r8549;
	and.b32  	%r8551, %r8550, %r8548;
	or.b32  	%r8945, %r8551, %r18;
	and.b32  	%r8552, %r8474, 64;
	shr.u32 	%r8553, %r8552, 1;
	and.b32  	%r8554, %r8474, 128;
	shr.u32 	%r8555, %r8554, 2;
	not.b32 	%r8556, %r8555;
	and.b32  	%r8557, %r8553, %r8556;
	and.b32  	%r8558, %r8474, 522133279;
	add.s32 	%r8559, %r8558, 31;
	sub.s32 	%r8560, %r8470, %r8558;
	and.b32  	%r8561, %r8557, %r8560;
	and.b32  	%r8562, %r8561, %r8559;
	not.b32 	%r8563, %r8562;
	or.b32  	%r8564, %r8563, -33;
	and.b32  	%r8944, %r8564, %r8474;
	bra.uni 	BB0_1553;

BB0_42:
	setp.eq.s32	%p46, %r1787, 75;
	@%p46 bra 	BB0_43;
	bra.uni 	BB0_11;

BB0_43:
	setp.lt.u32	%p462, %r14, 2;
	@%p462 bra 	BB0_11;

	setp.gt.s32	%p463, %r14, 16;
	@%p463 bra 	BB0_724;

	setp.gt.s32	%p485, %r14, 8;
	@%p485 bra 	BB0_709;

	setp.gt.s32	%p497, %r14, 4;
	@%p497 bra 	BB0_702;

	setp.eq.s32	%p503, %r14, 2;
	@%p503 bra 	BB0_781;

	setp.eq.s32	%p504, %r14, 3;
	@%p504 bra 	BB0_49;
	bra.uni 	BB0_700;

BB0_49:
	and.b32  	%r4008, %r19, 255;
	shl.b32 	%r4009, %r19, 8;
	and.b32  	%r4010, %r4009, 16711680;
	or.b32  	%r4011, %r4010, %r4008;
	shr.u32 	%r4012, %r19, 8;
	and.b32  	%r4013, %r4012, 65280;
	or.b32  	%r8944, %r4011, %r4013;
	mov.u32 	%r8949, 3;
	bra.uni 	BB0_782;

BB0_105:
	setp.eq.s32	%p19, %r1787, 114;
	@%p19 bra 	BB0_106;
	bra.uni 	BB0_11;

BB0_106:
	mov.u32 	%r7596, 32;
	sub.s32 	%r7595, %r7596, %r14;
	setp.gt.s32	%p974, %r7595, 15;
	@%p974 bra 	BB0_1475;

	setp.gt.s32	%p998, %r7595, 7;
	@%p998 bra 	BB0_1460;

	setp.gt.s32	%p1010, %r7595, 3;
	@%p1010 bra 	BB0_1453;

	setp.eq.s32	%p1016, %r7595, 1;
	@%p1016 bra 	BB0_1523;

	setp.eq.s32	%p1017, %r7595, 2;
	@%p1017 bra 	BB0_111;
	bra.uni 	BB0_1451;

BB0_111:
	mov.u32 	%r8097, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r17, %r18, %r8097;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r16, %r17, %r8097;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r15, %r16, %r8097;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8078, %r22, %r15, %r8097;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8933, %r21, %r22, %r8097;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8934, %r20, %r21, %r8097;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8935, %r19, %r20, %r8097;
	// inline asm
	mov.u32 	%r8095, 0;
	// inline asm
	shf.r.wrap.b32 %r8936, %r8095, %r19, %r8097;
	// inline asm
	mov.u32 	%r19, %r8078;
	bra.uni 	BB0_1529;

BB0_25:
	setp.eq.s32	%p53, %r1787, 46;
	@%p53 bra 	BB0_26;
	bra.uni 	BB0_11;

BB0_26:
	add.s32 	%r3565, %r24, 1;
	setp.ge.u32	%p258, %r3565, %r14;
	@%p258 bra 	BB0_11;

	mov.u32 	%r3593, 8;
	// inline asm
	shf.r.wrap.b32 %r3566, %r19, %r20, %r3593;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3570, %r20, %r21, %r3593;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3574, %r21, %r22, %r3593;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3578, %r22, %r15, %r3593;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3582, %r15, %r16, %r3593;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3586, %r16, %r17, %r3593;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3590, %r17, %r18, %r3593;
	// inline asm
	and.b32  	%r3595, %r23, 3;
	shl.b32 	%r3596, %r3595, 3;
	mov.u32 	%r3597, 255;
	shl.b32 	%r351, %r3597, %r3596;
	not.b32 	%r352, %r351;
	shr.u32 	%r3594, %r24, 2;
	setp.gt.s32	%p259, %r3594, 3;
	@%p259 bra 	BB0_363;

	setp.gt.s32	%p265, %r3594, 1;
	@%p265 bra 	BB0_360;

	setp.eq.s32	%p268, %r3594, 0;
	@%p268 bra 	BB0_30;
	bra.uni 	BB0_358;

BB0_30:
	and.b32  	%r3616, %r19, %r352;
	and.b32  	%r3617, %r3566, %r351;
	or.b32  	%r8944, %r3617, %r3616;
	bra.uni 	BB0_617;

BB0_91:
	setp.eq.s32	%p26, %r1787, 107;
	@%p26 bra 	BB0_92;
	bra.uni 	BB0_11;

BB0_92:
	setp.lt.u32	%p506, %r14, 2;
	@%p506 bra 	BB0_11;

	and.b32  	%r4018, %r19, -65536;
	shl.b32 	%r4019, %r19, 8;
	and.b32  	%r4020, %r4019, 65280;
	or.b32  	%r4021, %r4020, %r4018;
	bfe.u32 	%r4022, %r19, 8, 8;
	or.b32  	%r8944, %r4021, %r4022;

BB0_617:
	mov.u32 	%r8941, %r22;
	mov.u32 	%r8942, %r21;
	mov.u32 	%r8943, %r20;
	bra.uni 	BB0_645;

BB0_60:
	setp.eq.s32	%p40, %r1787, 89;
	@%p40 bra 	BB0_61;
	bra.uni 	BB0_11;

BB0_61:
	setp.gt.u32	%p124, %r24, %r14;
	add.s32 	%r8949, %r24, %r14;
	setp.gt.u32	%p125, %r8949, 31;
	or.pred  	%p126, %p124, %p125;
	@%p126 bra 	BB0_11;

	mov.u32 	%r8787, 0;
	setp.gt.s32	%p127, %r24, 15;
	@%p127 bra 	BB0_163;

	setp.gt.s32	%p151, %r24, 7;
	@%p151 bra 	BB0_147;

	setp.gt.s32	%p163, %r24, 3;
	@%p163 bra 	BB0_140;

	setp.gt.s32	%p169, %r24, 1;
	@%p169 bra 	BB0_137;

	setp.eq.s32	%p172, %r24, 0;
	@%p172 bra 	BB0_67;
	bra.uni 	BB0_135;

BB0_67:
	mov.u32 	%r8784, %r22;
	mov.u32 	%r8785, %r21;
	mov.u32 	%r8786, %r20;
	mov.u32 	%r8787, %r19;
	mov.u32 	%r8788, %r18;
	mov.u32 	%r8789, %r17;
	mov.u32 	%r8790, %r16;
	mov.u32 	%r8791, %r15;
	bra.uni 	BB0_215;

BB0_118:
	setp.eq.s32	%p13, %r1787, 121;
	@%p13 bra 	BB0_119;
	bra.uni 	BB0_11;

BB0_119:
	setp.gt.u32	%p185, %r24, %r14;
	add.s32 	%r8949, %r24, %r14;
	setp.gt.u32	%p186, %r8949, 31;
	or.pred  	%p187, %p185, %p186;
	@%p187 bra 	BB0_11;

	and.b32  	%r2937, %r23, 3;
	shl.b32 	%r2938, %r2937, 3;
	mov.u32 	%r2939, 1;
	shl.b32 	%r2940, %r2939, %r2938;
	add.s32 	%r186, %r2940, -1;
	shr.u32 	%r2936, %r24, 2;
	setp.gt.s32	%p188, %r2936, 3;
	@%p188 bra 	BB0_241;

	setp.gt.s32	%p194, %r2936, 1;
	@%p194 bra 	BB0_238;

	setp.eq.s32	%p197, %r2936, 0;
	@%p197 bra 	BB0_123;
	bra.uni 	BB0_236;

BB0_123:
	and.b32  	%r8803, %r186, %r19;
	mov.u32 	%r8800, 0;
	mov.u32 	%r8801, %r8800;
	mov.u32 	%r8802, %r8800;
	bra.uni 	BB0_253;

BB0_448:
	setp.lt.u32	%p318, %r24, %r14;
	setp.gt.u32	%p319, %r14, %r26;
	and.pred  	%p320, %p318, %p319;
	mov.u32 	%r8941, %r22;
	mov.u32 	%r8942, %r21;
	mov.u32 	%r8943, %r20;
	mov.u32 	%r8944, %r19;
	mov.u32 	%r8945, %r18;
	mov.u32 	%r8946, %r17;
	mov.u32 	%r8947, %r16;
	mov.u32 	%r8948, %r15;
	mov.u32 	%r8949, %r14;
	@!%p320 bra 	BB0_1554;
	bra.uni 	BB0_449;

BB0_449:
	mov.u32 	%r8825, 0;
	setp.gt.s32	%p321, %r24, 15;
	@%p321 bra 	BB0_481;

	setp.gt.s32	%p345, %r24, 7;
	@%p345 bra 	BB0_466;

	setp.gt.s32	%p357, %r24, 3;
	@%p357 bra 	BB0_459;

	setp.gt.s32	%p363, %r24, 1;
	@%p363 bra 	BB0_456;

	setp.eq.s32	%p366, %r24, 0;
	@%p366 bra 	BB0_527;
	bra.uni 	BB0_454;

BB0_527:
	and.b32  	%r8816, %r19, 255;
	bra.uni 	BB0_528;

BB0_21:
	setp.eq.s32	%p57, %r1787, 44;
	@%p57 bra 	BB0_22;
	bra.uni 	BB0_11;

BB0_22:
	setp.ne.s32	%p244, %r24, 0;
	setp.lt.u32	%p245, %r24, %r14;
	and.pred  	%p246, %p244, %p245;
	mov.u32 	%r8941, %r22;
	mov.u32 	%r8942, %r21;
	mov.u32 	%r8943, %r20;
	mov.u32 	%r8944, %r19;
	mov.u32 	%r8945, %r18;
	mov.u32 	%r8946, %r17;
	mov.u32 	%r8947, %r16;
	mov.u32 	%r8948, %r15;
	mov.u32 	%r8949, %r14;
	@!%p246 bra 	BB0_1554;
	bra.uni 	BB0_339;

BB0_339:
	mov.u32 	%r3540, 24;
	// inline asm
	shf.r.wrap.b32 %r3513, %r17, %r18, %r3540;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3517, %r16, %r17, %r3540;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3521, %r15, %r16, %r3540;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3525, %r22, %r15, %r3540;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3529, %r21, %r22, %r3540;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3533, %r20, %r21, %r3540;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3537, %r19, %r20, %r3540;
	// inline asm
	and.b32  	%r3542, %r23, 3;
	shl.b32 	%r3543, %r3542, 3;
	mov.u32 	%r3544, 255;
	shl.b32 	%r334, %r3544, %r3543;
	not.b32 	%r335, %r334;
	shr.u32 	%r3541, %r24, 2;
	setp.gt.s32	%p247, %r3541, 3;
	@%p247 bra 	BB0_347;

	setp.gt.s32	%p253, %r3541, 1;
	@%p253 bra 	BB0_344;

	setp.eq.s32	%p256, %r3541, 0;
	@%p256 bra 	BB0_357;
	bra.uni 	BB0_342;

BB0_357:
	mov.u32 	%r3560, 0;
	// inline asm
	shf.r.wrap.b32 %r3559, %r3560, %r19, %r3540;
	// inline asm
	and.b32  	%r3563, %r3559, %r334;
	and.b32  	%r3564, %r19, %r335;
	or.b32  	%r8944, %r3563, %r3564;
	bra.uni 	BB0_617;

BB0_1430:
	add.s32 	%r8949, %r14, %r14;
	setp.gt.u32	%p962, %r8949, 31;
	@%p962 bra 	BB0_978;

	and.b32  	%r7417, %r14, 3;
	mov.u32 	%r7418, 4;
	sub.s32 	%r7419, %r7418, %r7417;
	shl.b32 	%r7420, %r7419, 2;
	mov.u32 	%r7421, 1985229328;
	shr.u32 	%r7422, %r7421, %r7420;
	and.b32  	%r1533, %r7422, 65535;
	shr.u32 	%r7416, %r14, 2;
	mov.u32 	%r8925, 0;
	setp.gt.s32	%p963, %r7416, 3;
	@%p963 bra 	BB0_1439;

	setp.gt.s32	%p969, %r7416, 1;
	@%p969 bra 	BB0_1436;

	setp.eq.s32	%p972, %r7416, 0;
	@%p972 bra 	BB0_1449;
	bra.uni 	BB0_1434;

BB0_1449:
	// inline asm
	prmt.b32 %r8932, %r17, %r18, %r1533;
	// inline asm
	// inline asm
	prmt.b32 %r8931, %r16, %r17, %r1533;
	// inline asm
	// inline asm
	prmt.b32 %r8930, %r15, %r16, %r1533;
	// inline asm
	// inline asm
	prmt.b32 %r8929, %r22, %r15, %r1533;
	// inline asm
	// inline asm
	prmt.b32 %r8928, %r21, %r22, %r1533;
	// inline asm
	// inline asm
	prmt.b32 %r8927, %r20, %r21, %r1533;
	// inline asm
	// inline asm
	prmt.b32 %r8926, %r19, %r20, %r1533;
	// inline asm
	mov.u32 	%r7592, 0;
	// inline asm
	prmt.b32 %r8925, %r7592, %r19, %r1533;
	// inline asm
	bra.uni 	BB0_1450;

BB0_81:
	setp.eq.s32	%p30, %r1787, 102;
	@%p30 bra 	BB0_82;
	bra.uni 	BB0_11;

BB0_82:
	add.s32 	%r8949, %r14, %r14;
	setp.gt.u32	%p888, %r8949, 31;
	@%p888 bra 	BB0_978;

	mov.u32 	%r6471, 32;
	sub.s32 	%r6470, %r6471, %r14;
	mov.u32 	%r8899, 0;
	setp.gt.s32	%p889, %r6470, 15;
	@%p889 bra 	BB0_1342;

	setp.gt.s32	%p913, %r6470, 7;
	@%p913 bra 	BB0_1326;

	setp.gt.s32	%p925, %r6470, 3;
	@%p925 bra 	BB0_1319;

	setp.gt.s32	%p931, %r6470, 1;
	@%p931 bra 	BB0_1316;

	setp.eq.s32	%p934, %r6470, 0;
	@%p934 bra 	BB0_88;
	bra.uni 	BB0_1314;

BB0_88:
	mov.u32 	%r8891, %r22;
	mov.u32 	%r8892, %r21;
	mov.u32 	%r8893, %r20;
	mov.u32 	%r8894, %r19;
	mov.u32 	%r8895, %r18;
	mov.u32 	%r8896, %r17;
	mov.u32 	%r8897, %r16;
	mov.u32 	%r8898, %r15;
	bra.uni 	BB0_1394;

BB0_428:
	setp.ge.u32	%p306, %r24, %r14;
	@%p306 bra 	BB0_11;

	and.b32  	%r3727, %r23, 3;
	shl.b32 	%r3728, %r3727, 3;
	mov.u32 	%r3729, 255;
	shl.b32 	%r393, %r3729, %r3728;
	not.b32 	%r394, %r393;
	shr.u32 	%r3726, %r24, 2;
	setp.gt.s32	%p307, %r3726, 3;
	@%p307 bra 	BB0_437;

	setp.gt.s32	%p313, %r3726, 1;
	@%p313 bra 	BB0_434;

	setp.eq.s32	%p316, %r3726, 0;
	@%p316 bra 	BB0_447;
	bra.uni 	BB0_432;

BB0_447:
	and.b32  	%r3758, %r19, %r394;
	and.b32  	%r3759, %r393, %r19;
	shl.b32 	%r3760, %r3759, 1;
	and.b32  	%r3761, %r3760, %r393;
	or.b32  	%r8944, %r3761, %r3758;
	bra.uni 	BB0_617;

BB0_52:
	setp.eq.s32	%p44, %r1787, 82;
	@%p44 bra 	BB0_53;
	bra.uni 	BB0_11;

BB0_53:
	setp.ge.u32	%p294, %r24, %r14;
	@%p294 bra 	BB0_11;

	and.b32  	%r3691, %r23, 3;
	shl.b32 	%r3692, %r3691, 3;
	mov.u32 	%r3693, 255;
	shl.b32 	%r383, %r3693, %r3692;
	not.b32 	%r384, %r383;
	shr.u32 	%r3690, %r24, 2;
	setp.gt.s32	%p295, %r3690, 3;
	@%p295 bra 	BB0_418;

	setp.gt.s32	%p301, %r3690, 1;
	@%p301 bra 	BB0_415;

	setp.eq.s32	%p304, %r3690, 0;
	@%p304 bra 	BB0_57;
	bra.uni 	BB0_413;

BB0_57:
	and.b32  	%r3722, %r19, %r384;
	and.b32  	%r3723, %r383, %r19;
	shr.u32 	%r3724, %r3723, 1;
	and.b32  	%r3725, %r3724, %r383;
	or.b32  	%r8944, %r3725, %r3722;
	bra.uni 	BB0_617;

BB0_976:
	mov.b32	{%rs277, %rs278}, %r19;
	shr.u16 	%rs279, %rs278, 8;
	and.b16  	%rs280, %rs278, 255;
	shr.u16 	%rs281, %rs277, 8;
	cvt.u16.u32	%rs282, %r23;
	and.b16  	%rs283, %rs282, 255;
	and.b16  	%rs284, %rs277, 255;
	setp.eq.s16	%p637, %rs284, %rs283;
	cvt.u16.u32	%rs285, %r25;
	setp.eq.s16	%p638, %rs281, %rs283;
	setp.eq.s16	%p639, %rs280, %rs283;
	setp.eq.s16	%p640, %rs279, %rs283;
	selp.b16	%rs286, %rs285, %rs281, %p638;
	cvt.u32.u16	%r4875, %rs286;
	selp.b16	%rs287, %rs285, %rs277, %p637;
	and.b16  	%rs288, %rs287, 255;
	cvt.u32.u16	%r4876, %rs288;
	prmt.b32 	%r4877, %r4875, %r4876, 30212;
	selp.b16	%rs289, %rs285, %rs279, %p640;
	cvt.u32.u16	%r4878, %rs289;
	selp.b16	%rs290, %rs285, %rs278, %p639;
	and.b16  	%rs291, %rs290, 255;
	cvt.u32.u16	%r4879, %rs291;
	prmt.b32 	%r4880, %r4878, %r4879, 30212;
	prmt.b32 	%r8944, %r4880, %r4877, 4180;
	mov.b32	{%rs292, %rs293}, %r20;
	shr.u16 	%rs294, %rs293, 8;
	and.b16  	%rs295, %rs293, 255;
	shr.u16 	%rs296, %rs292, 8;
	and.b16  	%rs297, %rs292, 255;
	setp.eq.s16	%p641, %rs297, %rs283;
	setp.eq.s16	%p642, %rs296, %rs283;
	setp.eq.s16	%p643, %rs295, %rs283;
	setp.eq.s16	%p644, %rs294, %rs283;
	selp.b16	%rs298, %rs285, %rs296, %p642;
	cvt.u32.u16	%r4881, %rs298;
	selp.b16	%rs299, %rs285, %rs292, %p641;
	and.b16  	%rs300, %rs299, 255;
	cvt.u32.u16	%r4882, %rs300;
	prmt.b32 	%r4883, %r4881, %r4882, 30212;
	selp.b16	%rs301, %rs285, %rs294, %p644;
	cvt.u32.u16	%r4884, %rs301;
	selp.b16	%rs302, %rs285, %rs293, %p643;
	and.b16  	%rs303, %rs302, 255;
	cvt.u32.u16	%r4885, %rs303;
	prmt.b32 	%r4886, %r4884, %r4885, 30212;
	prmt.b32 	%r8943, %r4886, %r4883, 4180;
	mov.b32	{%rs304, %rs305}, %r21;
	shr.u16 	%rs306, %rs305, 8;
	and.b16  	%rs307, %rs305, 255;
	shr.u16 	%rs308, %rs304, 8;
	and.b16  	%rs309, %rs304, 255;
	setp.eq.s16	%p645, %rs309, %rs283;
	setp.eq.s16	%p646, %rs308, %rs283;
	setp.eq.s16	%p647, %rs307, %rs283;
	setp.eq.s16	%p648, %rs306, %rs283;
	selp.b16	%rs310, %rs285, %rs308, %p646;
	cvt.u32.u16	%r4887, %rs310;
	selp.b16	%rs311, %rs285, %rs304, %p645;
	and.b16  	%rs312, %rs311, 255;
	cvt.u32.u16	%r4888, %rs312;
	prmt.b32 	%r4889, %r4887, %r4888, 30212;
	selp.b16	%rs313, %rs285, %rs306, %p648;
	cvt.u32.u16	%r4890, %rs313;
	selp.b16	%rs314, %rs285, %rs305, %p647;
	and.b16  	%rs315, %rs314, 255;
	cvt.u32.u16	%r4891, %rs315;
	prmt.b32 	%r4892, %r4890, %r4891, 30212;
	prmt.b32 	%r8942, %r4892, %r4889, 4180;
	mov.b32	{%rs316, %rs317}, %r22;
	shr.u16 	%rs318, %rs317, 8;
	and.b16  	%rs319, %rs317, 255;
	shr.u16 	%rs320, %rs316, 8;
	and.b16  	%rs321, %rs316, 255;
	setp.eq.s16	%p649, %rs321, %rs283;
	setp.eq.s16	%p650, %rs320, %rs283;
	setp.eq.s16	%p651, %rs319, %rs283;
	setp.eq.s16	%p652, %rs318, %rs283;
	selp.b16	%rs322, %rs285, %rs320, %p650;
	cvt.u32.u16	%r4893, %rs322;
	selp.b16	%rs323, %rs285, %rs316, %p649;
	and.b16  	%rs324, %rs323, 255;
	cvt.u32.u16	%r4894, %rs324;
	prmt.b32 	%r4895, %r4893, %r4894, 30212;
	selp.b16	%rs325, %rs285, %rs318, %p652;
	cvt.u32.u16	%r4896, %rs325;
	selp.b16	%rs326, %rs285, %rs317, %p651;
	and.b16  	%rs327, %rs326, 255;
	cvt.u32.u16	%r4897, %rs327;
	prmt.b32 	%r4898, %r4896, %r4897, 30212;
	prmt.b32 	%r8941, %r4898, %r4895, 4180;
	mov.b32	{%rs328, %rs329}, %r15;
	shr.u16 	%rs330, %rs329, 8;
	and.b16  	%rs331, %rs329, 255;
	shr.u16 	%rs332, %rs328, 8;
	and.b16  	%rs333, %rs328, 255;
	setp.eq.s16	%p653, %rs333, %rs283;
	setp.eq.s16	%p654, %rs332, %rs283;
	setp.eq.s16	%p655, %rs331, %rs283;
	setp.eq.s16	%p656, %rs330, %rs283;
	selp.b16	%rs334, %rs285, %rs332, %p654;
	cvt.u32.u16	%r4899, %rs334;
	selp.b16	%rs335, %rs285, %rs328, %p653;
	and.b16  	%rs336, %rs335, 255;
	cvt.u32.u16	%r4900, %rs336;
	prmt.b32 	%r4901, %r4899, %r4900, 30212;
	selp.b16	%rs337, %rs285, %rs330, %p656;
	cvt.u32.u16	%r4902, %rs337;
	selp.b16	%rs338, %rs285, %rs329, %p655;
	and.b16  	%rs339, %rs338, 255;
	cvt.u32.u16	%r4903, %rs339;
	prmt.b32 	%r4904, %r4902, %r4903, 30212;
	prmt.b32 	%r8948, %r4904, %r4901, 4180;
	mov.b32	{%rs340, %rs341}, %r16;
	shr.u16 	%rs342, %rs341, 8;
	and.b16  	%rs343, %rs341, 255;
	shr.u16 	%rs344, %rs340, 8;
	and.b16  	%rs345, %rs340, 255;
	setp.eq.s16	%p657, %rs345, %rs283;
	setp.eq.s16	%p658, %rs344, %rs283;
	setp.eq.s16	%p659, %rs343, %rs283;
	setp.eq.s16	%p660, %rs342, %rs283;
	selp.b16	%rs346, %rs285, %rs344, %p658;
	cvt.u32.u16	%r4905, %rs346;
	selp.b16	%rs347, %rs285, %rs340, %p657;
	and.b16  	%rs348, %rs347, 255;
	cvt.u32.u16	%r4906, %rs348;
	prmt.b32 	%r4907, %r4905, %r4906, 30212;
	selp.b16	%rs349, %rs285, %rs342, %p660;
	cvt.u32.u16	%r4908, %rs349;
	selp.b16	%rs350, %rs285, %rs341, %p659;
	and.b16  	%rs351, %rs350, 255;
	cvt.u32.u16	%r4909, %rs351;
	prmt.b32 	%r4910, %r4908, %r4909, 30212;
	prmt.b32 	%r8947, %r4910, %r4907, 4180;
	mov.b32	{%rs352, %rs353}, %r17;
	shr.u16 	%rs354, %rs353, 8;
	and.b16  	%rs355, %rs353, 255;
	shr.u16 	%rs356, %rs352, 8;
	and.b16  	%rs357, %rs352, 255;
	setp.eq.s16	%p661, %rs357, %rs283;
	setp.eq.s16	%p662, %rs356, %rs283;
	setp.eq.s16	%p663, %rs355, %rs283;
	setp.eq.s16	%p664, %rs354, %rs283;
	selp.b16	%rs358, %rs285, %rs356, %p662;
	cvt.u32.u16	%r4911, %rs358;
	selp.b16	%rs359, %rs285, %rs352, %p661;
	and.b16  	%rs360, %rs359, 255;
	cvt.u32.u16	%r4912, %rs360;
	prmt.b32 	%r4913, %r4911, %r4912, 30212;
	selp.b16	%rs361, %rs285, %rs354, %p664;
	cvt.u32.u16	%r4914, %rs361;
	selp.b16	%rs362, %rs285, %rs353, %p663;
	and.b16  	%rs363, %rs362, 255;
	cvt.u32.u16	%r4915, %rs363;
	prmt.b32 	%r4916, %r4914, %r4915, 30212;
	prmt.b32 	%r8946, %r4916, %r4913, 4180;
	mov.b32	{%rs364, %rs365}, %r18;
	shr.u16 	%rs366, %rs365, 8;
	and.b16  	%rs367, %rs365, 255;
	shr.u16 	%rs368, %rs364, 8;
	and.b16  	%rs369, %rs364, 255;
	setp.eq.s16	%p665, %rs369, %rs283;
	setp.eq.s16	%p666, %rs368, %rs283;
	setp.eq.s16	%p667, %rs367, %rs283;
	setp.eq.s16	%p668, %rs366, %rs283;
	selp.b16	%rs370, %rs285, %rs368, %p666;
	cvt.u32.u16	%r4917, %rs370;
	selp.b16	%rs371, %rs285, %rs364, %p665;
	and.b16  	%rs372, %rs371, 255;
	cvt.u32.u16	%r4918, %rs372;
	prmt.b32 	%r4919, %r4917, %r4918, 30212;
	selp.b16	%rs373, %rs285, %rs366, %p668;
	cvt.u32.u16	%r4920, %rs373;
	selp.b16	%rs374, %rs285, %rs365, %p667;
	and.b16  	%rs375, %rs374, 255;
	cvt.u32.u16	%r4921, %rs375;
	prmt.b32 	%r4922, %r4920, %r4921, 30212;
	prmt.b32 	%r8945, %r4922, %r4919, 4180;
	mov.u32 	%r8949, %r14;
	bra.uni 	BB0_1554;

BB0_114:
	setp.eq.s32	%p17, %r1787, 117;
	@%p17 bra 	BB0_115;
	bra.uni 	BB0_11;

BB0_115:
	and.b32  	%r8565, %r19, 1077952576;
	shr.u32 	%r8566, %r8565, 1;
	and.b32  	%r8567, %r19, -2139062144;
	shr.u32 	%r8568, %r8567, 2;
	not.b32 	%r8569, %r8568;
	and.b32  	%r8570, %r8566, %r8569;
	and.b32  	%r8571, %r19, 522133279;
	add.s32 	%r8572, %r8571, 522133279;
	mov.u32 	%r8573, -84215046;
	sub.s32 	%r8574, %r8573, %r8571;
	and.b32  	%r8575, %r8570, %r8574;
	and.b32  	%r8576, %r8575, %r8572;
	not.b32 	%r8577, %r8576;
	and.b32  	%r8944, %r19, %r8577;
	and.b32  	%r8578, %r20, 1077952576;
	shr.u32 	%r8579, %r8578, 1;
	and.b32  	%r8580, %r20, -2139062144;
	shr.u32 	%r8581, %r8580, 2;
	not.b32 	%r8582, %r8581;
	and.b32  	%r8583, %r8579, %r8582;
	and.b32  	%r8584, %r20, 522133279;
	add.s32 	%r8585, %r8584, 522133279;
	sub.s32 	%r8586, %r8573, %r8584;
	and.b32  	%r8587, %r8583, %r8586;
	and.b32  	%r8588, %r8587, %r8585;
	not.b32 	%r8589, %r8588;
	and.b32  	%r8943, %r20, %r8589;
	and.b32  	%r8590, %r21, 1077952576;
	shr.u32 	%r8591, %r8590, 1;
	and.b32  	%r8592, %r21, -2139062144;
	shr.u32 	%r8593, %r8592, 2;
	not.b32 	%r8594, %r8593;
	and.b32  	%r8595, %r8591, %r8594;
	and.b32  	%r8596, %r21, 522133279;
	add.s32 	%r8597, %r8596, 522133279;
	sub.s32 	%r8598, %r8573, %r8596;
	and.b32  	%r8599, %r8595, %r8598;
	and.b32  	%r8600, %r8599, %r8597;
	not.b32 	%r8601, %r8600;
	and.b32  	%r8942, %r21, %r8601;
	and.b32  	%r8602, %r22, 1077952576;
	shr.u32 	%r8603, %r8602, 1;
	and.b32  	%r8604, %r22, -2139062144;
	shr.u32 	%r8605, %r8604, 2;
	not.b32 	%r8606, %r8605;
	and.b32  	%r8607, %r8603, %r8606;
	and.b32  	%r8608, %r22, 522133279;
	add.s32 	%r8609, %r8608, 522133279;
	sub.s32 	%r8610, %r8573, %r8608;
	and.b32  	%r8611, %r8607, %r8610;
	and.b32  	%r8612, %r8611, %r8609;
	not.b32 	%r8613, %r8612;
	and.b32  	%r8941, %r22, %r8613;
	and.b32  	%r8614, %r15, 1077952576;
	shr.u32 	%r8615, %r8614, 1;
	and.b32  	%r8616, %r15, -2139062144;
	shr.u32 	%r8617, %r8616, 2;
	not.b32 	%r8618, %r8617;
	and.b32  	%r8619, %r8615, %r8618;
	and.b32  	%r8620, %r15, 522133279;
	add.s32 	%r8621, %r8620, 522133279;
	sub.s32 	%r8622, %r8573, %r8620;
	and.b32  	%r8623, %r8619, %r8622;
	and.b32  	%r8624, %r8623, %r8621;
	not.b32 	%r8625, %r8624;
	and.b32  	%r8948, %r15, %r8625;
	and.b32  	%r8626, %r16, 1077952576;
	shr.u32 	%r8627, %r8626, 1;
	and.b32  	%r8628, %r16, -2139062144;
	shr.u32 	%r8629, %r8628, 2;
	not.b32 	%r8630, %r8629;
	and.b32  	%r8631, %r8627, %r8630;
	and.b32  	%r8632, %r16, 522133279;
	add.s32 	%r8633, %r8632, 522133279;
	sub.s32 	%r8634, %r8573, %r8632;
	and.b32  	%r8635, %r8631, %r8634;
	and.b32  	%r8636, %r8635, %r8633;
	not.b32 	%r8637, %r8636;
	and.b32  	%r8947, %r16, %r8637;
	and.b32  	%r8638, %r17, 1077952576;
	shr.u32 	%r8639, %r8638, 1;
	and.b32  	%r8640, %r17, -2139062144;
	shr.u32 	%r8641, %r8640, 2;
	not.b32 	%r8642, %r8641;
	and.b32  	%r8643, %r8639, %r8642;
	and.b32  	%r8644, %r17, 522133279;
	add.s32 	%r8645, %r8644, 522133279;
	sub.s32 	%r8646, %r8573, %r8644;
	and.b32  	%r8647, %r8643, %r8646;
	and.b32  	%r8648, %r8647, %r8645;
	not.b32 	%r8649, %r8648;
	and.b32  	%r8946, %r17, %r8649;
	and.b32  	%r8650, %r18, 1077952576;
	shr.u32 	%r8651, %r8650, 1;
	and.b32  	%r8652, %r18, -2139062144;
	shr.u32 	%r8653, %r8652, 2;
	not.b32 	%r8654, %r8653;
	and.b32  	%r8655, %r8651, %r8654;
	and.b32  	%r8656, %r18, 522133279;
	add.s32 	%r8657, %r8656, 522133279;
	sub.s32 	%r8658, %r8573, %r8656;
	and.b32  	%r8659, %r8655, %r8658;
	and.b32  	%r8660, %r8659, %r8657;
	not.b32 	%r8661, %r8660;
	and.b32  	%r8945, %r18, %r8661;
	bra.uni 	BB0_1553;

BB0_951:
	st.local.v4.u32 	[%rd7], {%r19, %r20, %r21, %r22};
	st.local.v4.u32 	[%rd7+16], {%r15, %r16, %r17, %r18};
	mov.u64 	%rd15, 0;
	st.local.v2.u64 	[%rd6], {%rd15, %rd15};
	st.local.v2.u64 	[%rd6+16], {%rd15, %rd15};
	cvt.u16.u32	%rs376, %r19;
	setp.eq.s32	%p624, %r14, 0;
	mov.u32 	%r8949, 0;
	@%p624 bra 	BB0_975;

	cvt.u16.u32	%rs2, %r23;
	and.b32  	%r863, %r14, 3;
	setp.eq.s32	%p625, %r863, 0;
	mov.u32 	%r8852, 0;
	mov.u32 	%r8949, %r8852;
	@%p625 bra 	BB0_965;

	setp.eq.s32	%p626, %r863, 1;
	mov.u32 	%r8847, 0;
	@%p626 bra 	BB0_954;
	bra.uni 	BB0_955;

BB0_954:
	mov.u32 	%r8949, %r8847;
	bra.uni 	BB0_962;

BB0_33:
	setp.eq.s32	%p51, %r1787, 68;
	@%p51 bra 	BB0_34;
	bra.uni 	BB0_11;

BB0_34:
	setp.ge.u32	%p827, %r24, %r14;
	@%p827 bra 	BB0_978;

	mov.u32 	%r6214, 8;
	// inline asm
	shf.r.wrap.b32 %r6183, %r19, %r20, %r6214;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r20, %r21, %r6214;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8942, %r21, %r22, %r6214;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8941, %r22, %r15, %r6214;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8948, %r15, %r16, %r6214;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8947, %r16, %r17, %r6214;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8946, %r17, %r18, %r6214;
	// inline asm
	mov.u32 	%r6213, 0;
	// inline asm
	shf.r.wrap.b32 %r8945, %r18, %r6213, %r6214;
	// inline asm
	and.b32  	%r6216, %r23, 3;
	shl.b32 	%r6217, %r6216, 3;
	mov.u32 	%r6218, 1;
	shl.b32 	%r6219, %r6218, %r6217;
	add.s32 	%r1210, %r6219, -1;
	neg.s32 	%r1211, %r6219;
	shr.u32 	%r6215, %r24, 2;
	setp.gt.s32	%p828, %r6215, 3;
	@%p828 bra 	BB0_1273;

	setp.gt.s32	%p834, %r6215, 1;
	@%p834 bra 	BB0_1270;

	setp.eq.s32	%p837, %r6215, 0;
	@%p837 bra 	BB0_38;
	bra.uni 	BB0_1268;

BB0_38:
	and.b32  	%r6234, %r1210, %r19;
	and.b32  	%r6235, %r6183, %r1211;
	or.b32  	%r8944, %r6235, %r6234;
	bra.uni 	BB0_1278;

BB0_1552:
	and.b32  	%r8662, %r19, 1077952576;
	shr.u32 	%r8663, %r8662, 1;
	and.b32  	%r8664, %r19, -2139062144;
	shr.u32 	%r8665, %r8664, 2;
	not.b32 	%r8666, %r8665;
	and.b32  	%r8667, %r8663, %r8666;
	and.b32  	%r8668, %r19, 522133279;
	add.s32 	%r8669, %r8668, 522133279;
	mov.u32 	%r8670, -84215046;
	sub.s32 	%r8671, %r8670, %r8668;
	and.b32  	%r8672, %r8667, %r8671;
	and.b32  	%r8673, %r8672, %r8669;
	or.b32  	%r8944, %r8673, %r19;
	and.b32  	%r8674, %r20, 1077952576;
	shr.u32 	%r8675, %r8674, 1;
	and.b32  	%r8676, %r20, -2139062144;
	shr.u32 	%r8677, %r8676, 2;
	not.b32 	%r8678, %r8677;
	and.b32  	%r8679, %r8675, %r8678;
	and.b32  	%r8680, %r20, 522133279;
	add.s32 	%r8681, %r8680, 522133279;
	sub.s32 	%r8682, %r8670, %r8680;
	and.b32  	%r8683, %r8679, %r8682;
	and.b32  	%r8684, %r8683, %r8681;
	or.b32  	%r8943, %r8684, %r20;
	and.b32  	%r8685, %r21, 1077952576;
	shr.u32 	%r8686, %r8685, 1;
	and.b32  	%r8687, %r21, -2139062144;
	shr.u32 	%r8688, %r8687, 2;
	not.b32 	%r8689, %r8688;
	and.b32  	%r8690, %r8686, %r8689;
	and.b32  	%r8691, %r21, 522133279;
	add.s32 	%r8692, %r8691, 522133279;
	sub.s32 	%r8693, %r8670, %r8691;
	and.b32  	%r8694, %r8690, %r8693;
	and.b32  	%r8695, %r8694, %r8692;
	or.b32  	%r8942, %r8695, %r21;
	and.b32  	%r8696, %r22, 1077952576;
	shr.u32 	%r8697, %r8696, 1;
	and.b32  	%r8698, %r22, -2139062144;
	shr.u32 	%r8699, %r8698, 2;
	not.b32 	%r8700, %r8699;
	and.b32  	%r8701, %r8697, %r8700;
	and.b32  	%r8702, %r22, 522133279;
	add.s32 	%r8703, %r8702, 522133279;
	sub.s32 	%r8704, %r8670, %r8702;
	and.b32  	%r8705, %r8701, %r8704;
	and.b32  	%r8706, %r8705, %r8703;
	or.b32  	%r8941, %r8706, %r22;
	and.b32  	%r8707, %r15, 1077952576;
	shr.u32 	%r8708, %r8707, 1;
	and.b32  	%r8709, %r15, -2139062144;
	shr.u32 	%r8710, %r8709, 2;
	not.b32 	%r8711, %r8710;
	and.b32  	%r8712, %r8708, %r8711;
	and.b32  	%r8713, %r15, 522133279;
	add.s32 	%r8714, %r8713, 522133279;
	sub.s32 	%r8715, %r8670, %r8713;
	and.b32  	%r8716, %r8712, %r8715;
	and.b32  	%r8717, %r8716, %r8714;
	or.b32  	%r8948, %r8717, %r15;
	and.b32  	%r8718, %r16, 1077952576;
	shr.u32 	%r8719, %r8718, 1;
	and.b32  	%r8720, %r16, -2139062144;
	shr.u32 	%r8721, %r8720, 2;
	not.b32 	%r8722, %r8721;
	and.b32  	%r8723, %r8719, %r8722;
	and.b32  	%r8724, %r16, 522133279;
	add.s32 	%r8725, %r8724, 522133279;
	sub.s32 	%r8726, %r8670, %r8724;
	and.b32  	%r8727, %r8723, %r8726;
	and.b32  	%r8728, %r8727, %r8725;
	or.b32  	%r8947, %r8728, %r16;
	and.b32  	%r8729, %r17, 1077952576;
	shr.u32 	%r8730, %r8729, 1;
	and.b32  	%r8731, %r17, -2139062144;
	shr.u32 	%r8732, %r8731, 2;
	not.b32 	%r8733, %r8732;
	and.b32  	%r8734, %r8730, %r8733;
	and.b32  	%r8735, %r17, 522133279;
	add.s32 	%r8736, %r8735, 522133279;
	sub.s32 	%r8737, %r8670, %r8735;
	and.b32  	%r8738, %r8734, %r8737;
	and.b32  	%r8739, %r8738, %r8736;
	or.b32  	%r8946, %r8739, %r17;
	and.b32  	%r8740, %r18, 1077952576;
	shr.u32 	%r8741, %r8740, 1;
	and.b32  	%r8742, %r18, -2139062144;
	shr.u32 	%r8743, %r8742, 2;
	not.b32 	%r8744, %r8743;
	and.b32  	%r8745, %r8741, %r8744;
	and.b32  	%r8746, %r18, 522133279;
	add.s32 	%r8747, %r8746, 522133279;
	sub.s32 	%r8748, %r8670, %r8746;
	and.b32  	%r8749, %r8745, %r8748;
	and.b32  	%r8750, %r8749, %r8747;
	or.b32  	%r8945, %r8750, %r18;
	bra.uni 	BB0_1553;

BB0_96:
	setp.eq.s32	%p24, %r1787, 112;
	@%p24 bra 	BB0_97;
	bra.uni 	BB0_11;

BB0_97:
	mad.lo.s32 	%r7220, %r24, %r14, %r14;
	setp.gt.u32	%p947, %r7220, 31;
	setp.eq.s32	%p948, %r24, 0;
	or.pred  	%p949, %p947, %p948;
	mov.u32 	%r8907, 0;
	mov.u32 	%r8949, %r14;
	mov.u32 	%r8948, %r15;
	mov.u32 	%r8947, %r16;
	mov.u32 	%r8946, %r17;
	mov.u32 	%r8945, %r18;
	mov.u32 	%r8944, %r19;
	mov.u32 	%r8943, %r20;
	mov.u32 	%r8942, %r21;
	mov.u32 	%r8941, %r22;
	@%p949 bra 	BB0_978;

BB0_98:
	and.b32  	%r7230, %r8949, 3;
	mov.u32 	%r7231, 4;
	sub.s32 	%r7232, %r7231, %r7230;
	shl.b32 	%r7233, %r7232, 2;
	mov.u32 	%r7234, 1985229328;
	shr.u32 	%r7235, %r7234, %r7233;
	and.b32  	%r1477, %r7235, 65535;
	shr.u32 	%r7229, %r8949, 2;
	setp.gt.s32	%p950, %r7229, 3;
	@%p950 bra 	BB0_1419;

	setp.gt.s32	%p956, %r7229, 1;
	@%p956 bra 	BB0_1416;

	setp.eq.s32	%p959, %r7229, 0;
	@%p959 bra 	BB0_101;
	bra.uni 	BB0_1414;

BB0_101:
	// inline asm
	prmt.b32 %r8924, %r17, %r18, %r1477;
	// inline asm
	// inline asm
	prmt.b32 %r8923, %r16, %r17, %r1477;
	// inline asm
	// inline asm
	prmt.b32 %r8922, %r15, %r16, %r1477;
	// inline asm
	// inline asm
	prmt.b32 %r8921, %r22, %r15, %r1477;
	// inline asm
	// inline asm
	prmt.b32 %r8920, %r21, %r22, %r1477;
	// inline asm
	// inline asm
	prmt.b32 %r8919, %r20, %r21, %r1477;
	// inline asm
	// inline asm
	prmt.b32 %r8918, %r19, %r20, %r1477;
	// inline asm
	mov.u32 	%r7405, 0;
	// inline asm
	prmt.b32 %r8917, %r7405, %r19, %r1477;
	// inline asm
	bra.uni 	BB0_1429;

BB0_1419:
	setp.gt.s32	%p951, %r7229, 5;
	@%p951 bra 	BB0_1423;

	setp.eq.s32	%p954, %r7229, 4;
	@%p954 bra 	BB0_1427;
	bra.uni 	BB0_1421;

BB0_1427:
	// inline asm
	prmt.b32 %r8924, %r21, %r22, %r1477;
	// inline asm
	// inline asm
	prmt.b32 %r8923, %r20, %r21, %r1477;
	// inline asm
	// inline asm
	prmt.b32 %r8922, %r19, %r20, %r1477;
	// inline asm
	mov.u32 	%r8917, 0;
	// inline asm
	prmt.b32 %r8921, %r8917, %r19, %r1477;
	// inline asm
	mov.u32 	%r8918, %r8917;
	mov.u32 	%r8919, %r8917;
	mov.u32 	%r8920, %r8917;
	bra.uni 	BB0_1429;

BB0_1416:
	setp.eq.s32	%p957, %r7229, 2;
	@%p957 bra 	BB0_1428;
	bra.uni 	BB0_1417;

BB0_1428:
	// inline asm
	prmt.b32 %r8924, %r15, %r16, %r1477;
	// inline asm
	// inline asm
	prmt.b32 %r8923, %r22, %r15, %r1477;
	// inline asm
	// inline asm
	prmt.b32 %r8922, %r21, %r22, %r1477;
	// inline asm
	// inline asm
	prmt.b32 %r8921, %r20, %r21, %r1477;
	// inline asm
	// inline asm
	prmt.b32 %r8920, %r19, %r20, %r1477;
	// inline asm
	mov.u32 	%r8917, 0;
	// inline asm
	prmt.b32 %r8919, %r8917, %r19, %r1477;
	// inline asm
	mov.u32 	%r8918, %r8917;
	bra.uni 	BB0_1429;

BB0_1423:
	setp.eq.s32	%p952, %r7229, 6;
	@%p952 bra 	BB0_1426;
	bra.uni 	BB0_1424;

BB0_1426:
	// inline asm
	prmt.b32 %r8924, %r19, %r20, %r1477;
	// inline asm
	mov.u32 	%r8917, 0;
	// inline asm
	prmt.b32 %r8923, %r8917, %r19, %r1477;
	// inline asm
	mov.u32 	%r8918, %r8917;
	mov.u32 	%r8919, %r8917;
	mov.u32 	%r8920, %r8917;
	mov.u32 	%r8921, %r8917;
	mov.u32 	%r8922, %r8917;
	bra.uni 	BB0_1429;

BB0_1414:
	mov.u32 	%r8917, 0;
	setp.eq.s32	%p960, %r7229, 1;
	mov.u32 	%r8918, %r8917;
	mov.u32 	%r8919, %r8917;
	mov.u32 	%r8920, %r8917;
	mov.u32 	%r8921, %r8917;
	mov.u32 	%r8922, %r8917;
	mov.u32 	%r8923, %r8917;
	mov.u32 	%r8924, %r8917;
	@%p960 bra 	BB0_1415;
	bra.uni 	BB0_1429;

BB0_1415:
	// inline asm
	prmt.b32 %r8924, %r16, %r17, %r1477;
	// inline asm
	// inline asm
	prmt.b32 %r8923, %r15, %r16, %r1477;
	// inline asm
	// inline asm
	prmt.b32 %r8922, %r22, %r15, %r1477;
	// inline asm
	// inline asm
	prmt.b32 %r8921, %r21, %r22, %r1477;
	// inline asm
	// inline asm
	prmt.b32 %r8920, %r20, %r21, %r1477;
	// inline asm
	// inline asm
	prmt.b32 %r8919, %r19, %r20, %r1477;
	// inline asm
	mov.u32 	%r8917, 0;
	// inline asm
	prmt.b32 %r8918, %r8917, %r19, %r1477;
	// inline asm
	bra.uni 	BB0_1429;

BB0_1421:
	mov.u32 	%r8917, 0;
	setp.eq.s32	%p955, %r7229, 5;
	mov.u32 	%r8918, %r8917;
	mov.u32 	%r8919, %r8917;
	mov.u32 	%r8920, %r8917;
	mov.u32 	%r8921, %r8917;
	mov.u32 	%r8922, %r8917;
	mov.u32 	%r8923, %r8917;
	mov.u32 	%r8924, %r8917;
	@%p955 bra 	BB0_1422;
	bra.uni 	BB0_1429;

BB0_1422:
	// inline asm
	prmt.b32 %r8924, %r20, %r21, %r1477;
	// inline asm
	// inline asm
	prmt.b32 %r8923, %r19, %r20, %r1477;
	// inline asm
	mov.u32 	%r8917, 0;
	// inline asm
	prmt.b32 %r8922, %r8917, %r19, %r1477;
	// inline asm
	mov.u32 	%r8918, %r8917;
	mov.u32 	%r8919, %r8917;
	mov.u32 	%r8920, %r8917;
	mov.u32 	%r8921, %r8917;
	bra.uni 	BB0_1429;

BB0_1417:
	mov.u32 	%r8917, 0;
	setp.eq.s32	%p958, %r7229, 3;
	mov.u32 	%r8918, %r8917;
	mov.u32 	%r8919, %r8917;
	mov.u32 	%r8920, %r8917;
	mov.u32 	%r8921, %r8917;
	mov.u32 	%r8922, %r8917;
	mov.u32 	%r8923, %r8917;
	mov.u32 	%r8924, %r8917;
	@%p958 bra 	BB0_1418;
	bra.uni 	BB0_1429;

BB0_1418:
	// inline asm
	prmt.b32 %r8924, %r22, %r15, %r1477;
	// inline asm
	// inline asm
	prmt.b32 %r8923, %r21, %r22, %r1477;
	// inline asm
	// inline asm
	prmt.b32 %r8922, %r20, %r21, %r1477;
	// inline asm
	// inline asm
	prmt.b32 %r8921, %r19, %r20, %r1477;
	// inline asm
	mov.u32 	%r8917, 0;
	// inline asm
	prmt.b32 %r8920, %r8917, %r19, %r1477;
	// inline asm
	mov.u32 	%r8918, %r8917;
	mov.u32 	%r8919, %r8917;
	bra.uni 	BB0_1429;

BB0_1424:
	mov.u32 	%r8917, 0;
	setp.ne.s32	%p953, %r7229, 7;
	mov.u32 	%r8918, %r8917;
	mov.u32 	%r8919, %r8917;
	mov.u32 	%r8920, %r8917;
	mov.u32 	%r8921, %r8917;
	mov.u32 	%r8922, %r8917;
	mov.u32 	%r8923, %r8917;
	mov.u32 	%r8924, %r8917;
	@%p953 bra 	BB0_1429;

	mov.u32 	%r8917, 0;
	// inline asm
	prmt.b32 %r8924, %r8917, %r19, %r1477;
	// inline asm
	mov.u32 	%r8918, %r8917;
	mov.u32 	%r8919, %r8917;
	mov.u32 	%r8920, %r8917;
	mov.u32 	%r8921, %r8917;
	mov.u32 	%r8922, %r8917;
	mov.u32 	%r8923, %r8917;

BB0_1429:
	or.b32  	%r8944, %r8917, %r8944;
	or.b32  	%r8943, %r8918, %r8943;
	or.b32  	%r8942, %r8919, %r8942;
	or.b32  	%r8941, %r8920, %r8941;
	or.b32  	%r8948, %r8921, %r8948;
	or.b32  	%r8947, %r8922, %r8947;
	or.b32  	%r8946, %r8923, %r8946;
	or.b32  	%r8945, %r8924, %r8945;
	add.s32 	%r8949, %r8949, %r14;
	add.s32 	%r8907, %r8907, 1;
	setp.lt.u32	%p961, %r8907, %r24;
	@%p961 bra 	BB0_98;
	bra.uni 	BB0_1554;

BB0_785:
	setp.eq.s32	%p510, %r14, 0;
	add.s32 	%r4059, %r24, %r14;
	setp.gt.u32	%p511, %r4059, 31;
	or.pred  	%p512, %p510, %p511;
	@%p512 bra 	BB0_11;

	add.s32 	%r4061, %r14, -1;
	and.b32  	%r4062, %r4061, 3;
	shl.b32 	%r4063, %r4062, 3;
	setp.lt.u32	%p513, %r4061, 4;
	selp.b32	%r4064, %r19, 0, %p513;
	and.b32  	%r4065, %r4061, -4;
	setp.eq.s32	%p514, %r4065, 4;
	selp.b32	%r4066, %r20, 0, %p514;
	setp.eq.s32	%p515, %r4065, 8;
	selp.b32	%r4067, %r21, 0, %p515;
	setp.eq.s32	%p516, %r4065, 12;
	selp.b32	%r4068, %r22, 0, %p516;
	setp.eq.s32	%p517, %r4065, 16;
	selp.b32	%r4069, %r15, 0, %p517;
	setp.eq.s32	%p518, %r4065, 20;
	selp.b32	%r4070, %r16, 0, %p518;
	setp.eq.s32	%p519, %r4065, 24;
	selp.b32	%r4071, %r17, 0, %p519;
	setp.gt.u32	%p520, %r4061, 27;
	selp.b32	%r4072, %r18, 0, %p520;
	or.b32  	%r4073, %r4072, %r4064;
	or.b32  	%r4074, %r4073, %r4066;
	or.b32  	%r4075, %r4074, %r4067;
	or.b32  	%r4076, %r4075, %r4068;
	or.b32  	%r4077, %r4076, %r4069;
	or.b32  	%r4078, %r4077, %r4070;
	or.b32  	%r4079, %r4078, %r4071;
	shr.u32 	%r4080, %r4079, %r4063;
	and.b32  	%r588, %r4080, 255;
	setp.eq.s32	%p521, %r24, 0;
	mov.u32 	%r8826, 0;
	mov.u32 	%r8949, %r14;
	mov.u32 	%r8948, %r15;
	mov.u32 	%r8947, %r16;
	mov.u32 	%r8946, %r17;
	mov.u32 	%r8945, %r18;
	mov.u32 	%r8944, %r19;
	mov.u32 	%r8943, %r20;
	mov.u32 	%r8942, %r21;
	mov.u32 	%r8941, %r22;
	@%p521 bra 	BB0_1554;

BB0_787:
	and.b32  	%r4081, %r8949, 3;
	shl.b32 	%r4082, %r4081, 3;
	shl.b32 	%r4083, %r588, %r4082;
	setp.lt.u32	%p522, %r8949, 4;
	selp.b32	%r4084, %r4083, 0, %p522;
	or.b32  	%r8944, %r4084, %r8944;
	and.b32  	%r4085, %r8949, -4;
	setp.eq.s32	%p523, %r4085, 4;
	selp.b32	%r4086, %r4083, 0, %p523;
	or.b32  	%r8943, %r4086, %r8943;
	setp.eq.s32	%p524, %r4085, 8;
	selp.b32	%r4087, %r4083, 0, %p524;
	or.b32  	%r8942, %r4087, %r8942;
	setp.eq.s32	%p525, %r4085, 12;
	selp.b32	%r4088, %r4083, 0, %p525;
	or.b32  	%r8941, %r4088, %r8941;
	setp.eq.s32	%p526, %r4085, 16;
	selp.b32	%r4089, %r4083, 0, %p526;
	or.b32  	%r8948, %r4089, %r8948;
	setp.eq.s32	%p527, %r4085, 20;
	selp.b32	%r4090, %r4083, 0, %p527;
	or.b32  	%r8947, %r4090, %r8947;
	setp.eq.s32	%p528, %r4085, 24;
	selp.b32	%r4091, %r4083, 0, %p528;
	or.b32  	%r8946, %r4091, %r8946;
	setp.gt.u32	%p529, %r8949, 27;
	selp.b32	%r4092, %r4083, 0, %p529;
	or.b32  	%r8945, %r4092, %r8945;
	add.s32 	%r8949, %r8949, 1;
	add.s32 	%r8826, %r8826, 1;
	setp.lt.u32	%p530, %r8826, %r24;
	@%p530 bra 	BB0_787;
	bra.uni 	BB0_1554;

BB0_70:
	setp.eq.s32	%p38, %r1787, 93;
	@%p38 bra 	BB0_71;
	bra.uni 	BB0_11;

BB0_71:
	setp.eq.s32	%p839, %r14, 0;
	mov.u32 	%r8949, 0;
	@%p839 bra 	BB0_1034;

	add.s32 	%r8949, %r14, -1;
	and.b32  	%r6237, %r8949, 3;
	shl.b32 	%r6238, %r6237, 3;
	mov.u32 	%r6239, 1;
	shl.b32 	%r6240, %r6239, %r6238;
	add.s32 	%r6241, %r6240, -1;
	setp.lt.u32	%p840, %r8949, 4;
	selp.b32	%r6242, %r6241, -1, %p840;
	and.b32  	%r8944, %r6242, %r19;
	and.b32  	%r6243, %r8949, -4;
	setp.eq.s32	%p841, %r6243, 4;
	selp.b32	%r6244, %r6241, -1, %p841;
	and.b32  	%r8943, %r6244, %r20;
	setp.eq.s32	%p842, %r6243, 8;
	selp.b32	%r6245, %r6241, -1, %p842;
	and.b32  	%r8942, %r6245, %r21;
	setp.eq.s32	%p843, %r6243, 12;
	selp.b32	%r6246, %r6241, -1, %p843;
	and.b32  	%r8941, %r6246, %r22;
	setp.eq.s32	%p844, %r6243, 16;
	selp.b32	%r6247, %r6241, -1, %p844;
	and.b32  	%r8948, %r6247, %r15;
	setp.eq.s32	%p845, %r6243, 20;
	selp.b32	%r6248, %r6241, -1, %p845;
	and.b32  	%r8947, %r6248, %r16;
	setp.eq.s32	%p846, %r6243, 24;
	selp.b32	%r6249, %r6241, -1, %p846;
	and.b32  	%r8946, %r6249, %r17;
	setp.gt.u32	%p847, %r8949, 27;
	selp.b32	%r6250, %r6241, -1, %p847;
	and.b32  	%r8945, %r6250, %r18;
	bra.uni 	BB0_1554;

BB0_788:
	setp.eq.s32	%p531, %r14, 0;
	add.s32 	%r8949, %r24, %r14;
	setp.gt.u32	%p532, %r8949, 31;
	or.pred  	%p533, %p531, %p532;
	@%p533 bra 	BB0_11;

	and.b32  	%r610, %r19, 255;
	setp.gt.s32	%p534, %r24, 15;
	@%p534 bra 	BB0_819;

	setp.gt.s32	%p558, %r24, 7;
	@%p558 bra 	BB0_803;

	setp.gt.s32	%p570, %r24, 3;
	@%p570 bra 	BB0_796;

	setp.eq.s32	%p576, %r24, 1;
	@%p576 bra 	BB0_868;

	setp.eq.s32	%p577, %r24, 2;
	@%p577 bra 	BB0_867;
	bra.uni 	BB0_794;

BB0_867:
	mov.u32 	%r4593, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r17, %r18, %r4593;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r16, %r17, %r4593;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r15, %r16, %r4593;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r15, %r22, %r15, %r4593;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8941, %r21, %r22, %r4593;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8942, %r20, %r21, %r4593;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r19, %r20, %r4593;
	// inline asm
	mov.u32 	%r4591, 0;
	// inline asm
	shf.r.wrap.b32 %r8944, %r4591, %r19, %r4593;
	// inline asm
	bra.uni 	BB0_874;

BB0_126:
	setp.eq.s32	%p11, %r1787, 125;
	@%p11 bra 	BB0_127;
	bra.uni 	BB0_11;

BB0_127:
	setp.eq.s32	%p849, %r14, 0;
	mov.u32 	%r8949, 0;
	@%p849 bra 	BB0_1034;

	add.s32 	%r6318, %r14, -1;
	shl.b32 	%r6319, %r6318, 3;
	and.b32  	%r6320, %r6319, 24;
	setp.lt.u32	%p850, %r6318, 4;
	selp.b32	%r6321, %r19, 0, %p850;
	and.b32  	%r6322, %r6318, -4;
	setp.eq.s32	%p851, %r6322, 4;
	selp.b32	%r6323, %r20, 0, %p851;
	setp.eq.s32	%p852, %r6322, 8;
	selp.b32	%r6324, %r21, 0, %p852;
	setp.eq.s32	%p853, %r6322, 12;
	selp.b32	%r6325, %r22, 0, %p853;
	setp.eq.s32	%p854, %r6322, 16;
	selp.b32	%r6326, %r15, 0, %p854;
	setp.eq.s32	%p855, %r6322, 20;
	selp.b32	%r6327, %r16, 0, %p855;
	setp.eq.s32	%p856, %r6322, 24;
	selp.b32	%r6328, %r17, 0, %p856;
	setp.gt.u32	%p857, %r6318, 27;
	selp.b32	%r6329, %r18, 0, %p857;
	or.b32  	%r6330, %r6329, %r6321;
	or.b32  	%r6331, %r6330, %r6323;
	or.b32  	%r6332, %r6331, %r6324;
	or.b32  	%r6333, %r6332, %r6325;
	or.b32  	%r6334, %r6333, %r6326;
	or.b32  	%r6335, %r6334, %r6327;
	or.b32  	%r6336, %r6335, %r6328;
	shr.u32 	%r6337, %r6336, %r6320;
	and.b32  	%r6338, %r6337, 255;
	mov.u32 	%r6316, 24;
	// inline asm
	shf.r.wrap.b32 %r6285, %r17, %r18, %r6316;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8946, %r16, %r17, %r6316;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8947, %r15, %r16, %r6316;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8948, %r22, %r15, %r6316;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8941, %r21, %r22, %r6316;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8942, %r20, %r21, %r6316;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r19, %r20, %r6316;
	// inline asm
	mov.u32 	%r8945, 0;
	// inline asm
	shf.r.wrap.b32 %r6313, %r8945, %r19, %r6316;
	// inline asm
	or.b32  	%r8944, %r6313, %r6338;
	shl.b32 	%r6339, %r14, 3;
	and.b32  	%r6340, %r6339, 24;
	mov.u32 	%r6341, 1;
	shl.b32 	%r6342, %r6341, %r6340;
	add.s32 	%r1255, %r6342, -1;
	shr.u32 	%r6317, %r14, 2;
	setp.gt.s32	%p858, %r6317, 3;
	@%p858 bra 	BB0_1295;

	setp.gt.s32	%p864, %r6317, 1;
	@%p864 bra 	BB0_1292;

	setp.eq.s32	%p867, %r6317, 0;
	@%p867 bra 	BB0_1307;
	bra.uni 	BB0_131;

BB0_1307:
	and.b32  	%r8944, %r8944, %r1255;
	mov.u32 	%r8941, 0;
	mov.u32 	%r8942, %r8941;
	mov.u32 	%r8943, %r8941;
	bra.uni 	BB0_1305;

BB0_382:
	setp.gt.s32	%p272, %r3618, 5;
	@%p272 bra 	BB0_386;

	setp.eq.s32	%p275, %r3618, 4;
	@%p275 bra 	BB0_390;
	bra.uni 	BB0_384;

BB0_390:
	and.b32  	%r3634, %r15, %r362;
	and.b32  	%r3635, %r361, %r15;
	sub.s32 	%r3636, %r3635, %r363;
	and.b32  	%r3637, %r3636, %r361;
	or.b32  	%r8948, %r3637, %r3634;
	bra.uni 	BB0_658;

BB0_1038:
	setp.gt.s32	%p697, %r4997, 5;
	@%p697 bra 	BB0_1042;

	setp.eq.s32	%p700, %r4997, 4;
	@%p700 bra 	BB0_1046;
	bra.uni 	BB0_1040;

BB0_1046:
	and.b32  	%r5012, %r932, %r15;
	or.b32  	%r5013, %r5012, %r931;
	and.b32  	%r5014, %r8948, %r933;
	or.b32  	%r8948, %r5013, %r5014;
	mov.u32 	%r8941, %r22;
	bra.uni 	BB0_1047;

BB0_1539:
	setp.gt.s32	%p1021, %r8157, 5;
	@%p1021 bra 	BB0_1543;

	setp.eq.s32	%p1024, %r8157, 4;
	@%p1024 bra 	BB0_1547;
	bra.uni 	BB0_1541;

BB0_1547:
	and.b32  	%r8200, %r15, 1077952576;
	shr.u32 	%r8201, %r8200, 1;
	and.b32  	%r8202, %r15, -2139062144;
	shr.u32 	%r8203, %r8202, 2;
	not.b32 	%r8204, %r8203;
	and.b32  	%r8205, %r8201, %r8204;
	and.b32  	%r8206, %r15, 522133279;
	add.s32 	%r8207, %r8206, 522133279;
	mov.u32 	%r8208, -84215046;
	sub.s32 	%r8209, %r8208, %r8206;
	and.b32  	%r8210, %r8205, %r8209;
	and.b32  	%r8211, %r8210, %r8207;
	and.b32  	%r8212, %r8211, %r1710;
	xor.b32  	%r8948, %r8212, %r15;
	bra.uni 	BB0_658;

BB0_1192:
	setp.gt.s32	%p772, %r24, 23;
	@%p772 bra 	BB0_1208;

	setp.gt.s32	%p784, %r24, 19;
	@%p784 bra 	BB0_1201;

	setp.gt.s32	%p790, %r24, 17;
	@%p790 bra 	BB0_1198;

	setp.eq.s32	%p793, %r24, 16;
	@%p793 bra 	BB0_1230;
	bra.uni 	BB0_1196;

BB0_1230:
	mov.u32 	%r8945, 0;
	mov.u32 	%r8941, %r18;
	mov.u32 	%r8942, %r17;
	mov.u32 	%r8943, %r16;
	mov.u32 	%r22, %r15;
	bra.uni 	BB0_1231;

BB0_1475:
	setp.gt.s32	%p975, %r7595, 23;
	@%p975 bra 	BB0_1492;

	setp.gt.s32	%p987, %r7595, 19;
	@%p987 bra 	BB0_1484;

	setp.gt.s32	%p993, %r7595, 17;
	@%p993 bra 	BB0_1481;

	setp.eq.s32	%p996, %r7595, 16;
	@%p996 bra 	BB0_1516;
	bra.uni 	BB0_1479;

BB0_1516:
	mov.u32 	%r8933, 0;
	mov.u32 	%r8934, %r8933;
	mov.u32 	%r8935, %r8933;
	mov.u32 	%r8936, %r8933;
	mov.u32 	%r18, %r22;
	mov.u32 	%r17, %r21;
	mov.u32 	%r16, %r20;
	bra.uni 	BB0_1529;

BB0_402:
	setp.gt.s32	%p284, %r3654, 5;
	@%p284 bra 	BB0_406;

	setp.eq.s32	%p287, %r3654, 4;
	@%p287 bra 	BB0_410;
	bra.uni 	BB0_404;

BB0_410:
	and.b32  	%r3670, %r15, %r373;
	and.b32  	%r3671, %r372, %r15;
	add.s32 	%r3672, %r3671, %r374;
	and.b32  	%r3673, %r3672, %r372;
	or.b32  	%r8948, %r3673, %r3670;
	bra.uni 	BB0_658;

BB0_1086:
	setp.gt.s32	%p711, %r26, 23;
	@%p711 bra 	BB0_1102;

	setp.gt.s32	%p723, %r26, 19;
	@%p723 bra 	BB0_1095;

	setp.gt.s32	%p729, %r26, 17;
	@%p729 bra 	BB0_1092;

	setp.eq.s32	%p732, %r26, 16;
	@%p732 bra 	BB0_1128;
	bra.uni 	BB0_1090;

BB0_1128:
	mov.u32 	%r8941, %r18;
	mov.u32 	%r8942, %r17;
	mov.u32 	%r8943, %r16;
	mov.u32 	%r8862, %r15;
	bra.uni 	BB0_1122;

BB0_1013:
	setp.gt.s32	%p683, %r4956, 5;
	@%p683 bra 	BB0_1018;

	setp.eq.s32	%p686, %r4956, 4;
	@%p686 bra 	BB0_1024;
	bra.uni 	BB0_1015;

BB0_1024:
	and.b32  	%r4964, %r15, %r914;
	or.b32  	%r8948, %r4964, %r913;
	bra.uni 	BB0_658;

BB0_481:
	setp.gt.s32	%p322, %r24, 23;
	@%p322 bra 	BB0_497;

	setp.gt.s32	%p334, %r24, 19;
	@%p334 bra 	BB0_490;

	setp.gt.s32	%p340, %r24, 17;
	@%p340 bra 	BB0_487;

	setp.eq.s32	%p343, %r24, 16;
	@%p343 bra 	BB0_519;
	bra.uni 	BB0_485;

BB0_519:
	and.b32  	%r8816, %r15, 255;
	bra.uni 	BB0_528;

BB0_1439:
	setp.gt.s32	%p964, %r7416, 5;
	@%p964 bra 	BB0_1443;

	setp.eq.s32	%p967, %r7416, 4;
	@%p967 bra 	BB0_1447;
	bra.uni 	BB0_1441;

BB0_1447:
	// inline asm
	prmt.b32 %r8932, %r21, %r22, %r1533;
	// inline asm
	// inline asm
	prmt.b32 %r8931, %r20, %r21, %r1533;
	// inline asm
	// inline asm
	prmt.b32 %r8930, %r19, %r20, %r1533;
	// inline asm
	mov.u32 	%r8925, 0;
	// inline asm
	prmt.b32 %r8929, %r8925, %r19, %r1533;
	// inline asm
	mov.u32 	%r8926, %r8925;
	mov.u32 	%r8927, %r8925;
	mov.u32 	%r8928, %r8925;
	bra.uni 	BB0_1450;

BB0_437:
	setp.gt.s32	%p308, %r3726, 5;
	@%p308 bra 	BB0_441;

	setp.eq.s32	%p311, %r3726, 4;
	@%p311 bra 	BB0_445;
	bra.uni 	BB0_439;

BB0_445:
	and.b32  	%r3742, %r15, %r394;
	and.b32  	%r3743, %r393, %r15;
	shl.b32 	%r3744, %r3743, 1;
	and.b32  	%r3745, %r3744, %r393;
	or.b32  	%r8948, %r3745, %r3742;
	bra.uni 	BB0_658;

BB0_819:
	setp.gt.s32	%p535, %r24, 23;
	@%p535 bra 	BB0_836;

	setp.gt.s32	%p547, %r24, 19;
	@%p547 bra 	BB0_828;

	setp.gt.s32	%p553, %r24, 17;
	@%p553 bra 	BB0_825;

	setp.eq.s32	%p556, %r24, 16;
	@%p556 bra 	BB0_860;
	bra.uni 	BB0_823;

BB0_860:
	mov.u32 	%r8941, 0;
	mov.u32 	%r8942, %r8941;
	mov.u32 	%r8943, %r8941;
	mov.u32 	%r8944, %r8941;
	mov.u32 	%r18, %r22;
	mov.u32 	%r17, %r21;
	mov.u32 	%r16, %r20;
	mov.u32 	%r15, %r19;
	bra.uni 	BB0_874;

BB0_379:
	setp.eq.s32	%p278, %r3618, 2;
	@%p278 bra 	BB0_391;
	bra.uni 	BB0_380;

BB0_391:
	and.b32  	%r3642, %r21, %r362;
	and.b32  	%r3643, %r361, %r21;
	sub.s32 	%r3644, %r3643, %r363;
	and.b32  	%r3645, %r3644, %r361;
	or.b32  	%r8942, %r3645, %r3642;
	bra.uni 	BB0_634;

BB0_1035:
	setp.eq.s32	%p703, %r4997, 2;
	@%p703 bra 	BB0_1049;
	bra.uni 	BB0_1036;

BB0_1049:
	and.b32  	%r5018, %r932, %r21;
	or.b32  	%r5019, %r5018, %r931;
	and.b32  	%r5020, %r8942, %r933;
	or.b32  	%r8942, %r5019, %r5020;
	bra.uni 	BB0_1048;

BB0_1536:
	setp.eq.s32	%p1027, %r8157, 2;
	@%p1027 bra 	BB0_1548;
	bra.uni 	BB0_1537;

BB0_1548:
	and.b32  	%r8226, %r21, 1077952576;
	shr.u32 	%r8227, %r8226, 1;
	and.b32  	%r8228, %r21, -2139062144;
	shr.u32 	%r8229, %r8228, 2;
	not.b32 	%r8230, %r8229;
	and.b32  	%r8231, %r8227, %r8230;
	and.b32  	%r8232, %r21, 522133279;
	add.s32 	%r8233, %r8232, 522133279;
	mov.u32 	%r8234, -84215046;
	sub.s32 	%r8235, %r8234, %r8232;
	and.b32  	%r8236, %r8231, %r8235;
	and.b32  	%r8237, %r8236, %r8233;
	and.b32  	%r8238, %r8237, %r1710;
	xor.b32  	%r8942, %r8238, %r21;
	bra.uni 	BB0_1026;

BB0_1177:
	setp.gt.s32	%p796, %r24, 11;
	@%p796 bra 	BB0_1185;

	setp.gt.s32	%p802, %r24, 9;
	@%p802 bra 	BB0_1182;

	setp.eq.s32	%p805, %r24, 8;
	@%p805 bra 	BB0_1237;
	bra.uni 	BB0_1180;

BB0_1237:
	mov.u32 	%r8945, 0;
	mov.u32 	%r8941, %r16;
	mov.u32 	%r8942, %r15;
	mov.u32 	%r8943, %r22;
	mov.u32 	%r22, %r21;
	mov.u32 	%r8946, %r8945;
	mov.u32 	%r8947, %r18;
	mov.u32 	%r18, %r17;
	bra.uni 	BB0_1245;

BB0_987:
	setp.gt.s32	%p671, %r4923, 5;
	@%p671 bra 	BB0_991;

	setp.eq.s32	%p674, %r4923, 4;
	@%p674 bra 	BB0_997;
	bra.uni 	BB0_989;

BB0_997:
	and.b32  	%r8948, %r904, %r15;
	mov.u32 	%r8945, 0;
	mov.u32 	%r8941, %r22;
	mov.u32 	%r8942, %r21;
	mov.u32 	%r8943, %r20;
	mov.u32 	%r8944, %r19;
	mov.u32 	%r8946, %r8945;
	mov.u32 	%r8947, %r8945;
	mov.u32 	%r8949, %r24;
	bra.uni 	BB0_1554;

BB0_724:
	setp.gt.s32	%p464, %r14, 23;
	@%p464 bra 	BB0_738;

	setp.gt.s32	%p476, %r14, 19;
	@%p476 bra 	BB0_730;

	setp.eq.s32	%p482, %r14, 17;
	@%p482 bra 	BB0_766;

	setp.eq.s32	%p483, %r14, 18;
	@%p483 bra 	BB0_762;
	bra.uni 	BB0_728;

BB0_762:
	shl.b32 	%r3931, %r15, 8;
	and.b32  	%r3932, %r3931, 65280;
	bfe.u32 	%r3933, %r15, 8, 8;
	or.b32  	%r8948, %r3932, %r3933;
	mov.u32 	%r8949, 18;
	bra.uni 	BB0_763;

BB0_1460:
	setp.gt.s32	%p999, %r7595, 11;
	@%p999 bra 	BB0_1468;

	setp.gt.s32	%p1005, %r7595, 9;
	@%p1005 bra 	BB0_1465;

	setp.eq.s32	%p1008, %r7595, 8;
	@%p1008 bra 	BB0_1520;
	bra.uni 	BB0_1463;

BB0_1520:
	mov.u32 	%r8935, 0;
	mov.u32 	%r8933, %r20;
	mov.u32 	%r8934, %r19;
	mov.u32 	%r8936, %r8935;
	mov.u32 	%r18, %r16;
	mov.u32 	%r17, %r15;
	mov.u32 	%r16, %r22;
	mov.u32 	%r19, %r21;
	bra.uni 	BB0_1529;

BB0_363:
	setp.gt.s32	%p260, %r3594, 5;
	@%p260 bra 	BB0_367;

	setp.eq.s32	%p263, %r3594, 4;
	@%p263 bra 	BB0_371;
	bra.uni 	BB0_365;

BB0_371:
	and.b32  	%r3608, %r15, %r352;
	and.b32  	%r3609, %r3582, %r351;
	or.b32  	%r8948, %r3609, %r3608;
	bra.uni 	BB0_658;

BB0_163:
	setp.gt.s32	%p128, %r24, 23;
	@%p128 bra 	BB0_181;

	setp.gt.s32	%p140, %r24, 19;
	@%p140 bra 	BB0_173;

	setp.gt.s32	%p146, %r24, 17;
	@%p146 bra 	BB0_169;

	setp.eq.s32	%p149, %r24, 16;
	@%p149 bra 	BB0_207;
	bra.uni 	BB0_167;

BB0_207:
	mov.u32 	%r8784, %r8787;
	mov.u32 	%r8785, %r8787;
	mov.u32 	%r8786, %r8787;
	mov.u32 	%r8788, %r22;
	mov.u32 	%r8789, %r21;
	mov.u32 	%r8790, %r20;
	mov.u32 	%r8791, %r19;
	bra.uni 	BB0_215;

BB0_241:
	setp.gt.s32	%p189, %r2936, 5;
	@%p189 bra 	BB0_245;

	setp.eq.s32	%p192, %r2936, 4;
	@%p192 bra 	BB0_250;
	bra.uni 	BB0_243;

BB0_250:
	and.b32  	%r8807, %r186, %r15;
	mov.u32 	%r8804, 0;
	mov.u32 	%r8800, %r22;
	mov.u32 	%r8801, %r21;
	mov.u32 	%r8802, %r20;
	mov.u32 	%r8803, %r19;
	mov.u32 	%r8805, %r8804;
	mov.u32 	%r8806, %r8804;
	bra.uni 	BB0_254;

BB0_386:
	setp.eq.s32	%p273, %r3618, 6;
	@%p273 bra 	BB0_389;
	bra.uni 	BB0_387;

BB0_389:
	and.b32  	%r3626, %r17, %r362;
	and.b32  	%r3627, %r361, %r17;
	sub.s32 	%r3628, %r3627, %r363;
	and.b32  	%r3629, %r3628, %r361;
	or.b32  	%r8946, %r3629, %r3626;
	bra.uni 	BB0_675;

BB0_1042:
	setp.eq.s32	%p698, %r4997, 6;
	@%p698 bra 	BB0_1045;
	bra.uni 	BB0_1043;

BB0_1045:
	and.b32  	%r5006, %r932, %r17;
	or.b32  	%r5007, %r5006, %r931;
	and.b32  	%r5008, %r8946, %r933;
	or.b32  	%r8946, %r5007, %r5008;
	mov.u32 	%r8941, %r22;
	mov.u32 	%r8942, %r21;
	mov.u32 	%r8943, %r20;
	mov.u32 	%r8944, %r19;
	bra.uni 	BB0_773;

BB0_1543:
	setp.eq.s32	%p1022, %r8157, 6;
	@%p1022 bra 	BB0_1546;
	bra.uni 	BB0_1544;

BB0_1546:
	and.b32  	%r8174, %r17, 1077952576;
	shr.u32 	%r8175, %r8174, 1;
	and.b32  	%r8176, %r17, -2139062144;
	shr.u32 	%r8177, %r8176, 2;
	not.b32 	%r8178, %r8177;
	and.b32  	%r8179, %r8175, %r8178;
	and.b32  	%r8180, %r17, 522133279;
	add.s32 	%r8181, %r8180, 522133279;
	mov.u32 	%r8182, -84215046;
	sub.s32 	%r8183, %r8182, %r8180;
	and.b32  	%r8184, %r8179, %r8183;
	and.b32  	%r8185, %r8184, %r8181;
	and.b32  	%r8186, %r8185, %r1710;
	xor.b32  	%r8946, %r8186, %r17;
	bra.uni 	BB0_1023;

BB0_1208:
	setp.gt.s32	%p773, %r24, 27;
	@%p773 bra 	BB0_1217;

	setp.gt.s32	%p779, %r24, 25;
	@%p779 bra 	BB0_1213;

	setp.eq.s32	%p782, %r24, 24;
	@%p782 bra 	BB0_1226;
	bra.uni 	BB0_1211;

BB0_1226:
	mov.u32 	%r8941, 0;
	mov.u32 	%r8942, %r8941;
	mov.u32 	%r8943, %r18;
	mov.u32 	%r22, %r17;
	bra.uni 	BB0_1244;

BB0_1492:
	setp.gt.s32	%p976, %r7595, 27;
	@%p976 bra 	BB0_1501;

	setp.gt.s32	%p982, %r7595, 25;
	@%p982 bra 	BB0_1497;

	setp.eq.s32	%p985, %r7595, 24;
	@%p985 bra 	BB0_1510;
	bra.uni 	BB0_1495;

BB0_1510:
	mov.u32 	%r8933, 0;
	mov.u32 	%r8934, %r8933;
	mov.u32 	%r8935, %r8933;
	mov.u32 	%r8936, %r8933;
	mov.u32 	%r18, %r20;
	mov.u32 	%r17, %r19;
	bra.uni 	BB0_1527;

BB0_399:
	setp.eq.s32	%p290, %r3654, 2;
	@%p290 bra 	BB0_411;
	bra.uni 	BB0_400;

BB0_411:
	and.b32  	%r3678, %r21, %r373;
	and.b32  	%r3679, %r372, %r21;
	add.s32 	%r3680, %r3679, %r374;
	and.b32  	%r3681, %r3680, %r372;
	or.b32  	%r8942, %r3681, %r3678;
	bra.uni 	BB0_634;

BB0_1070:
	setp.gt.s32	%p735, %r26, 11;
	@%p735 bra 	BB0_1078;

	setp.gt.s32	%p741, %r26, 9;
	@%p741 bra 	BB0_1075;

	setp.eq.s32	%p744, %r26, 8;
	@%p744 bra 	BB0_1132;
	bra.uni 	BB0_1073;

BB0_1132:
	mov.u32 	%r8941, %r16;
	mov.u32 	%r8942, %r15;
	mov.u32 	%r8943, %r22;
	mov.u32 	%r8862, %r21;
	mov.u32 	%r8946, %r8945;
	mov.u32 	%r8947, %r18;
	mov.u32 	%r8948, %r17;
	bra.uni 	BB0_1137;

BB0_1010:
	setp.eq.s32	%p689, %r4956, 2;
	@%p689 bra 	BB0_1025;
	bra.uni 	BB0_1011;

BB0_1025:
	and.b32  	%r4966, %r21, %r914;
	or.b32  	%r8942, %r4966, %r913;

BB0_1026:
	mov.u32 	%r8941, %r22;
	bra.uni 	BB0_13;

BB0_466:
	setp.gt.s32	%p346, %r24, 11;
	@%p346 bra 	BB0_474;

	setp.gt.s32	%p352, %r24, 9;
	@%p352 bra 	BB0_471;

	setp.eq.s32	%p355, %r24, 8;
	@%p355 bra 	BB0_523;
	bra.uni 	BB0_469;

BB0_523:
	and.b32  	%r8816, %r21, 255;
	bra.uni 	BB0_528;

BB0_347:
	setp.gt.s32	%p248, %r3541, 5;
	@%p248 bra 	BB0_351;

	setp.eq.s32	%p251, %r3541, 4;
	@%p251 bra 	BB0_355;
	bra.uni 	BB0_349;

BB0_355:
	and.b32  	%r3551, %r15, %r335;
	and.b32  	%r3552, %r3525, %r334;
	or.b32  	%r8948, %r3552, %r3551;
	bra.uni 	BB0_658;

BB0_1436:
	setp.eq.s32	%p970, %r7416, 2;
	@%p970 bra 	BB0_1448;
	bra.uni 	BB0_1437;

BB0_1448:
	// inline asm
	prmt.b32 %r8932, %r15, %r16, %r1533;
	// inline asm
	// inline asm
	prmt.b32 %r8931, %r22, %r15, %r1533;
	// inline asm
	// inline asm
	prmt.b32 %r8930, %r21, %r22, %r1533;
	// inline asm
	// inline asm
	prmt.b32 %r8929, %r20, %r21, %r1533;
	// inline asm
	// inline asm
	prmt.b32 %r8928, %r19, %r20, %r1533;
	// inline asm
	mov.u32 	%r8925, 0;
	// inline asm
	prmt.b32 %r8927, %r8925, %r19, %r1533;
	// inline asm
	mov.u32 	%r8926, %r8925;
	bra.uni 	BB0_1450;

BB0_1342:
	setp.gt.s32	%p890, %r6470, 23;
	@%p890 bra 	BB0_1360;

	setp.gt.s32	%p902, %r6470, 19;
	@%p902 bra 	BB0_1352;

	setp.gt.s32	%p908, %r6470, 17;
	@%p908 bra 	BB0_1348;

	setp.eq.s32	%p911, %r6470, 16;
	@%p911 bra 	BB0_1386;
	bra.uni 	BB0_1346;

BB0_1386:
	mov.u32 	%r8891, %r8899;
	mov.u32 	%r8892, %r8899;
	mov.u32 	%r8893, %r8899;
	mov.u32 	%r8894, %r8899;
	mov.u32 	%r8895, %r22;
	mov.u32 	%r8896, %r21;
	mov.u32 	%r8897, %r20;
	mov.u32 	%r8898, %r19;
	bra.uni 	BB0_1394;

BB0_434:
	setp.eq.s32	%p314, %r3726, 2;
	@%p314 bra 	BB0_446;
	bra.uni 	BB0_435;

BB0_446:
	and.b32  	%r3750, %r21, %r394;
	and.b32  	%r3751, %r393, %r21;
	shl.b32 	%r3752, %r3751, 1;
	and.b32  	%r3753, %r3752, %r393;
	or.b32  	%r8942, %r3753, %r3750;
	bra.uni 	BB0_634;

BB0_418:
	setp.gt.s32	%p296, %r3690, 5;
	@%p296 bra 	BB0_422;

	setp.eq.s32	%p299, %r3690, 4;
	@%p299 bra 	BB0_426;
	bra.uni 	BB0_420;

BB0_426:
	and.b32  	%r3706, %r15, %r384;
	and.b32  	%r3707, %r383, %r15;
	shr.u32 	%r3708, %r3707, 1;
	and.b32  	%r3709, %r3708, %r383;
	or.b32  	%r8948, %r3709, %r3706;
	bra.uni 	BB0_658;

BB0_955:
	setp.eq.s32	%p627, %r863, 2;
	mov.u32 	%r8949, 0;
	@%p627 bra 	BB0_956;
	bra.uni 	BB0_957;

BB0_956:
	mov.u32 	%r8844, %r8949;
	bra.uni 	BB0_959;

BB0_1273:
	setp.gt.s32	%p829, %r6215, 5;
	@%p829 bra 	BB0_1279;

	setp.eq.s32	%p832, %r6215, 4;
	@%p832 bra 	BB0_1286;
	bra.uni 	BB0_1275;

BB0_1286:
	and.b32  	%r6226, %r1210, %r15;
	and.b32  	%r6227, %r8948, %r1211;
	or.b32  	%r8948, %r6227, %r6226;
	mov.u32 	%r8941, %r22;
	bra.uni 	BB0_1287;

BB0_803:
	setp.gt.s32	%p559, %r24, 11;
	@%p559 bra 	BB0_811;

	setp.gt.s32	%p565, %r24, 9;
	@%p565 bra 	BB0_808;

	setp.eq.s32	%p568, %r24, 8;
	@%p568 bra 	BB0_864;
	bra.uni 	BB0_806;

BB0_864:
	mov.u32 	%r8943, 0;
	mov.u32 	%r8941, %r20;
	mov.u32 	%r8942, %r19;
	mov.u32 	%r8944, %r8943;
	mov.u32 	%r18, %r16;
	mov.u32 	%r17, %r15;
	mov.u32 	%r16, %r22;
	mov.u32 	%r15, %r21;
	bra.uni 	BB0_874;

BB0_1295:
	setp.gt.s32	%p859, %r6317, 5;
	@%p859 bra 	BB0_1299;

	setp.eq.s32	%p862, %r6317, 4;
	@%p862 bra 	BB0_1303;
	bra.uni 	BB0_1297;

BB0_1303:
	and.b32  	%r8948, %r8948, %r1255;
	mov.u32 	%r8945, 0;
	mov.u32 	%r8946, %r8945;
	mov.u32 	%r8947, %r8945;
	bra.uni 	BB0_1553;

BB0_406:
	setp.eq.s32	%p285, %r3654, 6;
	@%p285 bra 	BB0_409;
	bra.uni 	BB0_407;

BB0_409:
	and.b32  	%r3662, %r17, %r373;
	and.b32  	%r3663, %r372, %r17;
	add.s32 	%r3664, %r3663, %r374;
	and.b32  	%r3665, %r3664, %r372;
	or.b32  	%r8946, %r3665, %r3662;
	bra.uni 	BB0_675;

BB0_1102:
	setp.gt.s32	%p712, %r26, 27;
	@%p712 bra 	BB0_1112;

	setp.gt.s32	%p718, %r26, 25;
	@%p718 bra 	BB0_1107;

	setp.eq.s32	%p721, %r26, 24;
	@%p721 bra 	BB0_1124;
	bra.uni 	BB0_1105;

BB0_1124:
	mov.u32 	%r8941, %r8945;
	mov.u32 	%r8942, %r8945;
	mov.u32 	%r8943, %r18;
	mov.u32 	%r8862, %r17;
	bra.uni 	BB0_1122;

BB0_1018:
	setp.eq.s32	%p684, %r4956, 6;
	@%p684 bra 	BB0_1022;
	bra.uni 	BB0_1019;

BB0_1022:
	and.b32  	%r4962, %r17, %r914;
	or.b32  	%r8946, %r4962, %r913;

BB0_1023:
	mov.u32 	%r8941, %r22;
	mov.u32 	%r8942, %r21;
	mov.u32 	%r8943, %r20;
	mov.u32 	%r8944, %r19;
	mov.u32 	%r8945, %r18;
	bra.uni 	BB0_17;

BB0_497:
	setp.gt.s32	%p323, %r24, 27;
	@%p323 bra 	BB0_505;

	setp.gt.s32	%p329, %r24, 25;
	@%p329 bra 	BB0_502;

	setp.eq.s32	%p332, %r24, 24;
	@%p332 bra 	BB0_515;
	bra.uni 	BB0_500;

BB0_515:
	and.b32  	%r8816, %r17, 255;
	bra.uni 	BB0_528;

BB0_1443:
	setp.eq.s32	%p965, %r7416, 6;
	@%p965 bra 	BB0_1446;
	bra.uni 	BB0_1444;

BB0_1446:
	// inline asm
	prmt.b32 %r8932, %r19, %r20, %r1533;
	// inline asm
	mov.u32 	%r8925, 0;
	// inline asm
	prmt.b32 %r8931, %r8925, %r19, %r1533;
	// inline asm
	mov.u32 	%r8926, %r8925;
	mov.u32 	%r8927, %r8925;
	mov.u32 	%r8928, %r8925;
	mov.u32 	%r8929, %r8925;
	mov.u32 	%r8930, %r8925;
	bra.uni 	BB0_1450;

BB0_441:
	setp.eq.s32	%p309, %r3726, 6;
	@%p309 bra 	BB0_444;
	bra.uni 	BB0_442;

BB0_444:
	and.b32  	%r3734, %r17, %r394;
	and.b32  	%r3735, %r393, %r17;
	shl.b32 	%r3736, %r3735, 1;
	and.b32  	%r3737, %r3736, %r393;
	or.b32  	%r8946, %r3737, %r3734;
	bra.uni 	BB0_675;

BB0_836:
	setp.gt.s32	%p536, %r24, 27;
	@%p536 bra 	BB0_845;

	setp.gt.s32	%p542, %r24, 25;
	@%p542 bra 	BB0_841;

	setp.eq.s32	%p545, %r24, 24;
	@%p545 bra 	BB0_854;
	bra.uni 	BB0_839;

BB0_854:
	mov.u32 	%r8941, 0;
	mov.u32 	%r8942, %r8941;
	mov.u32 	%r8943, %r8941;
	mov.u32 	%r8944, %r8941;
	mov.u32 	%r18, %r20;
	mov.u32 	%r17, %r19;
	bra.uni 	BB0_872;

BB0_377:
	setp.eq.s32	%p281, %r3618, 1;
	@%p281 bra 	BB0_378;
	bra.uni 	BB0_11;

BB0_378:
	and.b32  	%r3646, %r20, %r362;
	and.b32  	%r3647, %r361, %r20;
	sub.s32 	%r3648, %r3647, %r363;
	and.b32  	%r3649, %r3648, %r361;
	or.b32  	%r8943, %r3649, %r3646;
	bra.uni 	BB0_625;

BB0_1033:
	setp.eq.s32	%p706, %r4997, 1;
	@%p706 bra 	BB0_1050;
	bra.uni 	BB0_1034;

BB0_1050:
	and.b32  	%r5021, %r932, %r20;
	or.b32  	%r5022, %r5021, %r931;
	and.b32  	%r5023, %r8943, %r933;
	or.b32  	%r8943, %r5022, %r5023;
	mov.u32 	%r8944, %r19;
	bra.uni 	BB0_1554;

BB0_1534:
	setp.eq.s32	%p1030, %r8157, 1;
	@%p1030 bra 	BB0_1535;
	bra.uni 	BB0_978;

BB0_1535:
	and.b32  	%r8239, %r20, 1077952576;
	shr.u32 	%r8240, %r8239, 1;
	and.b32  	%r8241, %r20, -2139062144;
	shr.u32 	%r8242, %r8241, 2;
	not.b32 	%r8243, %r8242;
	and.b32  	%r8244, %r8240, %r8243;
	and.b32  	%r8245, %r20, 522133279;
	add.s32 	%r8246, %r8245, 522133279;
	mov.u32 	%r8247, -84215046;
	sub.s32 	%r8248, %r8247, %r8245;
	and.b32  	%r8249, %r8244, %r8248;
	and.b32  	%r8250, %r8249, %r8246;
	and.b32  	%r8251, %r8250, %r1710;
	xor.b32  	%r8943, %r8251, %r20;
	bra.uni 	BB0_1009;

BB0_1170:
	setp.gt.s32	%p808, %r24, 5;
	@%p808 bra 	BB0_1174;

	setp.eq.s32	%p811, %r24, 4;
	@%p811 bra 	BB0_1239;
	bra.uni 	BB0_1172;

BB0_1239:
	mov.u32 	%r8945, 0;
	mov.u32 	%r8941, %r15;
	mov.u32 	%r8942, %r22;
	mov.u32 	%r8943, %r21;
	mov.u32 	%r22, %r20;
	mov.u32 	%r8946, %r18;
	mov.u32 	%r8947, %r17;
	mov.u32 	%r18, %r16;
	bra.uni 	BB0_1245;

BB0_984:
	setp.eq.s32	%p677, %r4923, 2;
	@%p677 bra 	BB0_998;
	bra.uni 	BB0_985;

BB0_998:
	and.b32  	%r8942, %r904, %r21;
	mov.u32 	%r8941, 0;
	mov.u32 	%r8943, %r20;
	bra.uni 	BB0_999;

BB0_709:
	setp.gt.s32	%p486, %r14, 12;
	@%p486 bra 	BB0_717;

	setp.gt.s32	%p492, %r14, 10;
	@%p492 bra 	BB0_714;

	setp.eq.s32	%p495, %r14, 9;
	@%p495 bra 	BB0_777;
	bra.uni 	BB0_712;

BB0_777:
	or.b32  	%r3977, %r20, %r21;
	and.b32  	%r3978, %r20, 16777215;
	prmt.b32 	%r8943, %r21, %r3978, 1620;
	shr.u32 	%r8942, %r3977, 24;
	mov.u32 	%r8949, 9;
	mov.u32 	%r8941, %r22;
	bra.uni 	BB0_770;

BB0_1453:
	setp.gt.s32	%p1011, %r7595, 5;
	@%p1011 bra 	BB0_1457;

	setp.eq.s32	%p1014, %r7595, 4;
	@%p1014 bra 	BB0_1522;
	bra.uni 	BB0_1455;

BB0_1522:
	mov.u32 	%r8936, 0;
	mov.u32 	%r8933, %r21;
	mov.u32 	%r8934, %r20;
	mov.u32 	%r8935, %r19;
	mov.u32 	%r18, %r17;
	mov.u32 	%r17, %r16;
	mov.u32 	%r16, %r15;
	mov.u32 	%r19, %r22;
	bra.uni 	BB0_1529;

BB0_360:
	setp.eq.s32	%p266, %r3594, 2;
	@%p266 bra 	BB0_372;
	bra.uni 	BB0_361;

BB0_372:
	and.b32  	%r3612, %r21, %r352;
	and.b32  	%r3613, %r3574, %r351;
	or.b32  	%r8942, %r3613, %r3612;
	bra.uni 	BB0_634;

BB0_147:
	setp.gt.s32	%p152, %r24, 11;
	@%p152 bra 	BB0_155;

	setp.gt.s32	%p158, %r24, 9;
	@%p158 bra 	BB0_152;

	setp.eq.s32	%p161, %r24, 8;
	@%p161 bra 	BB0_211;
	bra.uni 	BB0_150;

BB0_211:
	mov.u32 	%r8784, %r20;
	mov.u32 	%r8785, %r19;
	mov.u32 	%r8786, %r8787;
	mov.u32 	%r8788, %r16;
	mov.u32 	%r8789, %r15;
	mov.u32 	%r8790, %r22;
	mov.u32 	%r8791, %r21;
	bra.uni 	BB0_215;

BB0_238:
	setp.eq.s32	%p195, %r2936, 2;
	@%p195 bra 	BB0_251;
	bra.uni 	BB0_239;

BB0_251:
	and.b32  	%r8801, %r186, %r21;
	mov.u32 	%r8800, 0;
	mov.u32 	%r8802, %r20;
	bra.uni 	BB0_252;

BB0_384:
	setp.eq.s32	%p276, %r3618, 5;
	@%p276 bra 	BB0_385;
	bra.uni 	BB0_11;

BB0_385:
	and.b32  	%r3630, %r16, %r362;
	and.b32  	%r3631, %r361, %r16;
	sub.s32 	%r3632, %r3631, %r363;
	and.b32  	%r3633, %r3632, %r361;
	or.b32  	%r8947, %r3633, %r3630;
	bra.uni 	BB0_666;

BB0_1040:
	setp.eq.s32	%p701, %r4997, 5;
	@%p701 bra 	BB0_1041;
	bra.uni 	BB0_1034;

BB0_1041:
	and.b32  	%r5009, %r932, %r16;
	or.b32  	%r5010, %r5009, %r931;
	and.b32  	%r5011, %r8947, %r933;
	or.b32  	%r8947, %r5010, %r5011;
	mov.u32 	%r8941, %r22;
	mov.u32 	%r8942, %r21;
	mov.u32 	%r8943, %r20;
	mov.u32 	%r8944, %r19;
	mov.u32 	%r8948, %r15;
	bra.uni 	BB0_1554;

BB0_1541:
	setp.eq.s32	%p1025, %r8157, 5;
	@%p1025 bra 	BB0_1542;
	bra.uni 	BB0_978;

BB0_1542:
	and.b32  	%r8187, %r16, 1077952576;
	shr.u32 	%r8188, %r8187, 1;
	and.b32  	%r8189, %r16, -2139062144;
	shr.u32 	%r8190, %r8189, 2;
	not.b32 	%r8191, %r8190;
	and.b32  	%r8192, %r8188, %r8191;
	and.b32  	%r8193, %r16, 522133279;
	add.s32 	%r8194, %r8193, 522133279;
	mov.u32 	%r8195, -84215046;
	sub.s32 	%r8196, %r8195, %r8193;
	and.b32  	%r8197, %r8192, %r8196;
	and.b32  	%r8198, %r8197, %r8194;
	and.b32  	%r8199, %r8198, %r1710;
	xor.b32  	%r8947, %r8199, %r16;
	bra.uni 	BB0_1017;

BB0_1201:
	setp.gt.s32	%p785, %r24, 21;
	@%p785 bra 	BB0_1205;

	setp.eq.s32	%p788, %r24, 20;
	@%p788 bra 	BB0_1228;
	bra.uni 	BB0_1203;

BB0_1228:
	mov.u32 	%r8941, 0;
	mov.u32 	%r8942, %r18;
	mov.u32 	%r8943, %r17;
	mov.u32 	%r22, %r16;
	bra.uni 	BB0_1244;

BB0_1484:
	setp.gt.s32	%p988, %r7595, 21;
	@%p988 bra 	BB0_1488;

	setp.eq.s32	%p991, %r7595, 20;
	@%p991 bra 	BB0_1512;
	bra.uni 	BB0_1486;

BB0_1512:
	mov.u32 	%r8933, 0;
	mov.u32 	%r8934, %r8933;
	mov.u32 	%r8935, %r8933;
	mov.u32 	%r8936, %r8933;
	mov.u32 	%r18, %r21;
	mov.u32 	%r17, %r20;
	mov.u32 	%r16, %r19;
	bra.uni 	BB0_1528;

BB0_380:
	setp.eq.s32	%p279, %r3618, 3;
	@%p279 bra 	BB0_381;
	bra.uni 	BB0_11;

BB0_381:
	and.b32  	%r3638, %r22, %r362;
	and.b32  	%r3639, %r361, %r22;
	sub.s32 	%r3640, %r3639, %r363;
	and.b32  	%r3641, %r3640, %r361;
	or.b32  	%r8941, %r3641, %r3638;
	bra.uni 	BB0_642;

BB0_1036:
	setp.eq.s32	%p704, %r4997, 3;
	@%p704 bra 	BB0_1037;
	bra.uni 	BB0_1034;

BB0_1037:
	and.b32  	%r5015, %r932, %r22;
	or.b32  	%r5016, %r5015, %r931;
	and.b32  	%r5017, %r8941, %r933;
	or.b32  	%r8941, %r5016, %r5017;

BB0_1047:
	mov.u32 	%r8942, %r21;

BB0_1048:
	mov.u32 	%r8943, %r20;
	mov.u32 	%r8944, %r19;
	bra.uni 	BB0_1554;

BB0_1537:
	setp.eq.s32	%p1028, %r8157, 3;
	@%p1028 bra 	BB0_1538;
	bra.uni 	BB0_978;

BB0_1538:
	and.b32  	%r8213, %r22, 1077952576;
	shr.u32 	%r8214, %r8213, 1;
	and.b32  	%r8215, %r22, -2139062144;
	shr.u32 	%r8216, %r8215, 2;
	not.b32 	%r8217, %r8216;
	and.b32  	%r8218, %r8214, %r8217;
	and.b32  	%r8219, %r22, 522133279;
	add.s32 	%r8220, %r8219, 522133279;
	mov.u32 	%r8221, -84215046;
	sub.s32 	%r8222, %r8221, %r8219;
	and.b32  	%r8223, %r8218, %r8222;
	and.b32  	%r8224, %r8223, %r8220;
	and.b32  	%r8225, %r8224, %r1710;
	xor.b32  	%r8941, %r8225, %r22;
	bra.uni 	BB0_12;

BB0_1185:
	setp.gt.s32	%p797, %r24, 13;
	@%p797 bra 	BB0_1189;

	setp.eq.s32	%p800, %r24, 12;
	@%p800 bra 	BB0_1234;
	bra.uni 	BB0_1187;

BB0_1234:
	mov.u32 	%r8945, 0;
	mov.u32 	%r8941, %r17;
	mov.u32 	%r8942, %r16;
	mov.u32 	%r8943, %r15;
	bra.uni 	BB0_1235;

BB0_991:
	setp.eq.s32	%p672, %r4923, 6;
	@%p672 bra 	BB0_996;
	bra.uni 	BB0_992;

BB0_996:
	and.b32  	%r8946, %r904, %r17;
	mov.u32 	%r8945, 0;
	mov.u32 	%r8941, %r22;
	mov.u32 	%r8942, %r21;
	mov.u32 	%r8943, %r20;
	mov.u32 	%r8944, %r19;
	bra.uni 	BB0_994;

BB0_738:
	setp.gt.s32	%p465, %r14, 27;
	@%p465 bra 	BB0_746;

	setp.gt.s32	%p471, %r14, 25;
	@%p471 bra 	BB0_743;

	setp.eq.s32	%p474, %r14, 24;
	@%p474 bra 	BB0_758;
	bra.uni 	BB0_741;

BB0_758:
	and.b32  	%r3896, %r16, 65535;
	shl.b32 	%r3897, %r16, 8;
	and.b32  	%r3898, %r3897, -16777216;
	or.b32  	%r3899, %r3898, %r3896;
	shr.u32 	%r3900, %r16, 8;
	and.b32  	%r3901, %r3900, 16711680;
	or.b32  	%r8947, %r3899, %r3901;
	mov.u32 	%r8949, 24;
	bra.uni 	BB0_760;

BB0_1468:
	setp.gt.s32	%p1000, %r7595, 13;
	@%p1000 bra 	BB0_1472;

	setp.eq.s32	%p1003, %r7595, 12;
	@%p1003 bra 	BB0_1518;
	bra.uni 	BB0_1470;

BB0_1518:
	mov.u32 	%r8934, 0;
	mov.u32 	%r8933, %r19;
	mov.u32 	%r8935, %r8934;
	mov.u32 	%r8936, %r8934;
	mov.u32 	%r18, %r15;
	mov.u32 	%r17, %r22;
	mov.u32 	%r16, %r21;
	mov.u32 	%r19, %r20;
	bra.uni 	BB0_1529;

BB0_367:
	setp.eq.s32	%p261, %r3594, 6;
	@%p261 bra 	BB0_370;
	bra.uni 	BB0_368;

BB0_370:
	and.b32  	%r3604, %r17, %r352;
	and.b32  	%r3605, %r3590, %r351;
	or.b32  	%r8946, %r3605, %r3604;
	bra.uni 	BB0_675;

BB0_181:
	setp.gt.s32	%p129, %r24, 27;
	@%p129 bra 	BB0_191;

	setp.gt.s32	%p135, %r24, 25;
	@%p135 bra 	BB0_186;

	setp.eq.s32	%p138, %r24, 24;
	@%p138 bra 	BB0_203;
	bra.uni 	BB0_184;

BB0_203:
	mov.u32 	%r8784, %r8787;
	mov.u32 	%r8785, %r8787;
	mov.u32 	%r8786, %r8787;
	mov.u32 	%r8788, %r20;
	mov.u32 	%r8789, %r19;
	bra.uni 	BB0_201;

BB0_245:
	setp.eq.s32	%p190, %r2936, 6;
	@%p190 bra 	BB0_249;
	bra.uni 	BB0_246;

BB0_249:
	and.b32  	%r8805, %r186, %r17;
	mov.u32 	%r8804, 0;
	mov.u32 	%r8800, %r22;
	mov.u32 	%r8801, %r21;
	mov.u32 	%r8802, %r20;
	mov.u32 	%r8803, %r19;
	bra.uni 	BB0_248;

BB0_387:
	setp.ne.s32	%p274, %r3618, 7;
	@%p274 bra 	BB0_11;

	and.b32  	%r3622, %r18, %r362;
	and.b32  	%r3623, %r361, %r18;
	sub.s32 	%r3624, %r3623, %r363;
	and.b32  	%r3625, %r3624, %r361;
	or.b32  	%r8945, %r3625, %r3622;
	bra.uni 	BB0_683;

BB0_1043:
	setp.ne.s32	%p699, %r4997, 7;
	@%p699 bra 	BB0_1034;

	and.b32  	%r5003, %r932, %r18;
	or.b32  	%r5004, %r5003, %r931;
	and.b32  	%r5005, %r8945, %r933;
	or.b32  	%r8945, %r5004, %r5005;
	mov.u32 	%r8941, %r22;
	mov.u32 	%r8942, %r21;
	mov.u32 	%r8943, %r20;
	mov.u32 	%r8944, %r19;
	bra.uni 	BB0_772;

BB0_1034:
	mov.u32 	%r8941, %r22;

BB0_768:
	mov.u32 	%r8942, %r21;

BB0_769:
	mov.u32 	%r8943, %r20;

BB0_770:
	mov.u32 	%r8944, %r19;

BB0_771:
	mov.u32 	%r8945, %r18;

BB0_772:
	mov.u32 	%r8946, %r17;

BB0_773:
	mov.u32 	%r8947, %r16;
	mov.u32 	%r8948, %r15;
	bra.uni 	BB0_1554;

BB0_1544:
	setp.ne.s32	%p1023, %r8157, 7;
	@%p1023 bra 	BB0_978;

	and.b32  	%r8161, %r18, 1077952576;
	shr.u32 	%r8162, %r8161, 1;
	and.b32  	%r8163, %r18, -2139062144;
	shr.u32 	%r8164, %r8163, 2;
	not.b32 	%r8165, %r8164;
	and.b32  	%r8166, %r8162, %r8165;
	and.b32  	%r8167, %r18, 522133279;
	add.s32 	%r8168, %r8167, 522133279;
	mov.u32 	%r8169, -84215046;
	sub.s32 	%r8170, %r8169, %r8167;
	and.b32  	%r8171, %r8166, %r8170;
	and.b32  	%r8172, %r8171, %r8168;
	and.b32  	%r8173, %r8172, %r1710;
	xor.b32  	%r8945, %r8173, %r18;
	bra.uni 	BB0_1021;

BB0_1217:
	setp.gt.s32	%p774, %r24, 29;
	@%p774 bra 	BB0_1221;

	setp.eq.s32	%p777, %r24, 28;
	@%p777 bra 	BB0_1224;
	bra.uni 	BB0_1219;

BB0_1224:
	mov.u32 	%r8941, 0;
	mov.u32 	%r8942, %r8941;
	mov.u32 	%r8943, %r8941;
	mov.u32 	%r22, %r18;
	bra.uni 	BB0_1244;

BB0_1501:
	setp.gt.s32	%p977, %r7595, 29;
	@%p977 bra 	BB0_1505;

	setp.eq.s32	%p980, %r7595, 28;
	@%p980 bra 	BB0_1508;
	bra.uni 	BB0_1503;

BB0_1508:
	mov.u32 	%r8933, 0;
	mov.u32 	%r8934, %r8933;
	mov.u32 	%r8935, %r8933;
	mov.u32 	%r8936, %r8933;
	mov.u32 	%r18, %r19;
	bra.uni 	BB0_1526;

BB0_397:
	setp.eq.s32	%p293, %r3654, 1;
	@%p293 bra 	BB0_398;
	bra.uni 	BB0_11;

BB0_398:
	and.b32  	%r3682, %r20, %r373;
	and.b32  	%r3683, %r372, %r20;
	add.s32 	%r3684, %r3683, %r374;
	and.b32  	%r3685, %r3684, %r372;
	or.b32  	%r8943, %r3685, %r3682;
	bra.uni 	BB0_625;

BB0_1063:
	setp.gt.s32	%p747, %r26, 5;
	@%p747 bra 	BB0_1067;

	setp.eq.s32	%p750, %r26, 4;
	@%p750 bra 	BB0_1134;
	bra.uni 	BB0_1065;

BB0_1134:
	mov.u32 	%r8941, %r15;
	mov.u32 	%r8942, %r22;
	mov.u32 	%r8943, %r21;
	mov.u32 	%r8862, %r20;
	mov.u32 	%r8946, %r18;
	mov.u32 	%r8947, %r17;
	mov.u32 	%r8948, %r16;
	bra.uni 	BB0_1137;

BB0_1007:
	setp.eq.s32	%p692, %r4956, 1;
	@%p692 bra 	BB0_1008;
	bra.uni 	BB0_978;

BB0_1008:
	and.b32  	%r4967, %r20, %r914;
	or.b32  	%r8943, %r4967, %r913;

BB0_1009:
	mov.u32 	%r8941, %r22;
	mov.u32 	%r8942, %r21;
	bra.uni 	BB0_14;

BB0_459:
	setp.gt.s32	%p358, %r24, 5;
	@%p358 bra 	BB0_463;

	setp.eq.s32	%p361, %r24, 4;
	@%p361 bra 	BB0_525;
	bra.uni 	BB0_461;

BB0_525:
	and.b32  	%r8816, %r20, 255;
	bra.uni 	BB0_528;

BB0_344:
	setp.eq.s32	%p254, %r3541, 2;
	@%p254 bra 	BB0_356;
	bra.uni 	BB0_345;

BB0_356:
	and.b32  	%r3555, %r21, %r335;
	and.b32  	%r3556, %r3533, %r334;
	or.b32  	%r8942, %r3556, %r3555;
	bra.uni 	BB0_634;

BB0_1434:
	setp.eq.s32	%p973, %r7416, 1;
	mov.u32 	%r8926, %r8925;
	mov.u32 	%r8927, %r8925;
	mov.u32 	%r8928, %r8925;
	mov.u32 	%r8929, %r8925;
	mov.u32 	%r8930, %r8925;
	mov.u32 	%r8931, %r8925;
	mov.u32 	%r8932, %r8925;
	@%p973 bra 	BB0_1435;
	bra.uni 	BB0_1450;

BB0_1435:
	// inline asm
	prmt.b32 %r8932, %r16, %r17, %r1533;
	// inline asm
	// inline asm
	prmt.b32 %r8931, %r15, %r16, %r1533;
	// inline asm
	// inline asm
	prmt.b32 %r8930, %r22, %r15, %r1533;
	// inline asm
	// inline asm
	prmt.b32 %r8929, %r21, %r22, %r1533;
	// inline asm
	// inline asm
	prmt.b32 %r8928, %r20, %r21, %r1533;
	// inline asm
	// inline asm
	prmt.b32 %r8927, %r19, %r20, %r1533;
	// inline asm
	mov.u32 	%r8925, 0;
	// inline asm
	prmt.b32 %r8926, %r8925, %r19, %r1533;
	// inline asm
	bra.uni 	BB0_1450;

BB0_1326:
	setp.gt.s32	%p914, %r6470, 11;
	@%p914 bra 	BB0_1334;

	setp.gt.s32	%p920, %r6470, 9;
	@%p920 bra 	BB0_1331;

	setp.eq.s32	%p923, %r6470, 8;
	@%p923 bra 	BB0_1390;
	bra.uni 	BB0_1329;

BB0_1390:
	mov.u32 	%r8891, %r20;
	mov.u32 	%r8892, %r19;
	mov.u32 	%r8893, %r8899;
	mov.u32 	%r8894, %r8899;
	mov.u32 	%r8895, %r16;
	mov.u32 	%r8896, %r15;
	mov.u32 	%r8897, %r22;
	mov.u32 	%r8898, %r21;
	bra.uni 	BB0_1394;

BB0_432:
	setp.eq.s32	%p317, %r3726, 1;
	@%p317 bra 	BB0_433;
	bra.uni 	BB0_11;

BB0_433:
	and.b32  	%r3754, %r20, %r394;
	and.b32  	%r3755, %r393, %r20;
	shl.b32 	%r3756, %r3755, 1;
	and.b32  	%r3757, %r3756, %r393;
	or.b32  	%r8943, %r3757, %r3754;
	bra.uni 	BB0_625;

BB0_415:
	setp.eq.s32	%p302, %r3690, 2;
	@%p302 bra 	BB0_427;
	bra.uni 	BB0_416;

BB0_427:
	and.b32  	%r3714, %r21, %r384;
	and.b32  	%r3715, %r383, %r21;
	shr.u32 	%r3716, %r3715, 1;
	and.b32  	%r3717, %r3716, %r383;
	or.b32  	%r8942, %r3717, %r3714;
	bra.uni 	BB0_634;

BB0_1270:
	setp.eq.s32	%p835, %r6215, 2;
	@%p835 bra 	BB0_1289;
	bra.uni 	BB0_1271;

BB0_1289:
	and.b32  	%r6230, %r1210, %r21;
	and.b32  	%r6231, %r8942, %r1211;
	or.b32  	%r8942, %r6231, %r6230;
	bra.uni 	BB0_1288;

BB0_796:
	setp.gt.s32	%p571, %r24, 5;
	@%p571 bra 	BB0_800;

	setp.eq.s32	%p574, %r24, 4;
	@%p574 bra 	BB0_866;
	bra.uni 	BB0_798;

BB0_866:
	mov.u32 	%r8944, 0;
	mov.u32 	%r8941, %r21;
	mov.u32 	%r8942, %r20;
	mov.u32 	%r8943, %r19;
	mov.u32 	%r18, %r17;
	mov.u32 	%r17, %r16;
	mov.u32 	%r16, %r15;
	mov.u32 	%r15, %r22;
	bra.uni 	BB0_874;

BB0_1292:
	setp.eq.s32	%p865, %r6317, 2;
	@%p865 bra 	BB0_1304;
	bra.uni 	BB0_1293;

BB0_1304:
	and.b32  	%r8942, %r8942, %r1255;
	mov.u32 	%r8941, 0;
	bra.uni 	BB0_1305;

BB0_404:
	setp.eq.s32	%p288, %r3654, 5;
	@%p288 bra 	BB0_405;
	bra.uni 	BB0_11;

BB0_405:
	and.b32  	%r3666, %r16, %r373;
	and.b32  	%r3667, %r372, %r16;
	add.s32 	%r3668, %r3667, %r374;
	and.b32  	%r3669, %r3668, %r372;
	or.b32  	%r8947, %r3669, %r3666;
	bra.uni 	BB0_666;

BB0_1095:
	setp.gt.s32	%p724, %r26, 21;
	@%p724 bra 	BB0_1099;

	setp.eq.s32	%p727, %r26, 20;
	@%p727 bra 	BB0_1126;
	bra.uni 	BB0_1097;

BB0_1126:
	mov.u32 	%r8941, %r8945;
	mov.u32 	%r8942, %r18;
	mov.u32 	%r8943, %r17;
	mov.u32 	%r8862, %r16;
	bra.uni 	BB0_1122;

BB0_1015:
	setp.eq.s32	%p687, %r4956, 5;
	@%p687 bra 	BB0_1016;
	bra.uni 	BB0_978;

BB0_1016:
	and.b32  	%r4963, %r16, %r914;
	or.b32  	%r8947, %r4963, %r913;

BB0_1017:
	mov.u32 	%r8941, %r22;
	mov.u32 	%r8942, %r21;
	mov.u32 	%r8943, %r20;
	mov.u32 	%r8944, %r19;
	mov.u32 	%r8945, %r18;
	mov.u32 	%r8946, %r17;
	bra.uni 	BB0_18;

BB0_490:
	setp.gt.s32	%p335, %r24, 21;
	@%p335 bra 	BB0_494;

	setp.eq.s32	%p338, %r24, 20;
	@%p338 bra 	BB0_517;
	bra.uni 	BB0_492;

BB0_517:
	and.b32  	%r8816, %r16, 255;
	bra.uni 	BB0_528;

BB0_1441:
	setp.eq.s32	%p968, %r7416, 5;
	mov.u32 	%r8926, %r8925;
	mov.u32 	%r8927, %r8925;
	mov.u32 	%r8928, %r8925;
	mov.u32 	%r8929, %r8925;
	mov.u32 	%r8930, %r8925;
	mov.u32 	%r8931, %r8925;
	mov.u32 	%r8932, %r8925;
	@%p968 bra 	BB0_1442;
	bra.uni 	BB0_1450;

BB0_1442:
	// inline asm
	prmt.b32 %r8932, %r20, %r21, %r1533;
	// inline asm
	// inline asm
	prmt.b32 %r8931, %r19, %r20, %r1533;
	// inline asm
	mov.u32 	%r8925, 0;
	// inline asm
	prmt.b32 %r8930, %r8925, %r19, %r1533;
	// inline asm
	mov.u32 	%r8926, %r8925;
	mov.u32 	%r8927, %r8925;
	mov.u32 	%r8928, %r8925;
	mov.u32 	%r8929, %r8925;
	bra.uni 	BB0_1450;

BB0_439:
	setp.eq.s32	%p312, %r3726, 5;
	@%p312 bra 	BB0_440;
	bra.uni 	BB0_11;

BB0_440:
	and.b32  	%r3738, %r16, %r394;
	and.b32  	%r3739, %r393, %r16;
	shl.b32 	%r3740, %r3739, 1;
	and.b32  	%r3741, %r3740, %r393;
	or.b32  	%r8947, %r3741, %r3738;
	bra.uni 	BB0_666;

BB0_828:
	setp.gt.s32	%p548, %r24, 21;
	@%p548 bra 	BB0_832;

	setp.eq.s32	%p551, %r24, 20;
	@%p551 bra 	BB0_856;
	bra.uni 	BB0_830;

BB0_856:
	mov.u32 	%r8941, 0;
	mov.u32 	%r8942, %r8941;
	mov.u32 	%r8943, %r8941;
	mov.u32 	%r8944, %r8941;
	mov.u32 	%r18, %r21;
	mov.u32 	%r17, %r20;
	mov.u32 	%r16, %r19;
	bra.uni 	BB0_873;

BB0_400:
	setp.eq.s32	%p291, %r3654, 3;
	@%p291 bra 	BB0_401;
	bra.uni 	BB0_11;

BB0_401:
	and.b32  	%r3674, %r22, %r373;
	and.b32  	%r3675, %r372, %r22;
	add.s32 	%r3676, %r3675, %r374;
	and.b32  	%r3677, %r3676, %r372;
	or.b32  	%r8941, %r3677, %r3674;
	bra.uni 	BB0_642;

BB0_1078:
	setp.gt.s32	%p736, %r26, 13;
	@%p736 bra 	BB0_1082;

	setp.eq.s32	%p739, %r26, 12;
	@%p739 bra 	BB0_1130;
	bra.uni 	BB0_1080;

BB0_1130:
	mov.u32 	%r8941, %r17;
	mov.u32 	%r8942, %r16;
	mov.u32 	%r8943, %r15;
	mov.u32 	%r8862, %r22;
	mov.u32 	%r8946, %r8945;
	mov.u32 	%r8947, %r8945;
	mov.u32 	%r8948, %r18;
	bra.uni 	BB0_1137;

BB0_1011:
	setp.eq.s32	%p690, %r4956, 3;
	@%p690 bra 	BB0_1012;
	bra.uni 	BB0_978;

BB0_1012:
	and.b32  	%r4965, %r22, %r914;
	or.b32  	%r8941, %r4965, %r913;
	bra.uni 	BB0_12;

BB0_474:
	setp.gt.s32	%p347, %r24, 13;
	@%p347 bra 	BB0_478;

	setp.eq.s32	%p350, %r24, 12;
	@%p350 bra 	BB0_521;
	bra.uni 	BB0_476;

BB0_521:
	and.b32  	%r8816, %r22, 255;
	bra.uni 	BB0_528;

BB0_351:
	setp.eq.s32	%p249, %r3541, 6;
	@%p249 bra 	BB0_354;
	bra.uni 	BB0_352;

BB0_354:
	and.b32  	%r3547, %r17, %r335;
	and.b32  	%r3548, %r3517, %r334;
	or.b32  	%r8946, %r3548, %r3547;
	bra.uni 	BB0_675;

BB0_1437:
	setp.eq.s32	%p971, %r7416, 3;
	mov.u32 	%r8926, %r8925;
	mov.u32 	%r8927, %r8925;
	mov.u32 	%r8928, %r8925;
	mov.u32 	%r8929, %r8925;
	mov.u32 	%r8930, %r8925;
	mov.u32 	%r8931, %r8925;
	mov.u32 	%r8932, %r8925;
	@%p971 bra 	BB0_1438;
	bra.uni 	BB0_1450;

BB0_1438:
	// inline asm
	prmt.b32 %r8932, %r22, %r15, %r1533;
	// inline asm
	// inline asm
	prmt.b32 %r8931, %r21, %r22, %r1533;
	// inline asm
	// inline asm
	prmt.b32 %r8930, %r20, %r21, %r1533;
	// inline asm
	// inline asm
	prmt.b32 %r8929, %r19, %r20, %r1533;
	// inline asm
	mov.u32 	%r8925, 0;
	// inline asm
	prmt.b32 %r8928, %r8925, %r19, %r1533;
	// inline asm
	mov.u32 	%r8926, %r8925;
	mov.u32 	%r8927, %r8925;
	bra.uni 	BB0_1450;

BB0_1360:
	setp.gt.s32	%p891, %r6470, 27;
	@%p891 bra 	BB0_1370;

	setp.gt.s32	%p897, %r6470, 25;
	@%p897 bra 	BB0_1365;

	setp.eq.s32	%p900, %r6470, 24;
	@%p900 bra 	BB0_1382;
	bra.uni 	BB0_1363;

BB0_1382:
	mov.u32 	%r8891, %r8899;
	mov.u32 	%r8892, %r8899;
	mov.u32 	%r8893, %r8899;
	mov.u32 	%r8894, %r8899;
	mov.u32 	%r8895, %r20;
	mov.u32 	%r8896, %r19;
	bra.uni 	BB0_1380;

BB0_435:
	setp.eq.s32	%p315, %r3726, 3;
	@%p315 bra 	BB0_436;
	bra.uni 	BB0_11;

BB0_436:
	and.b32  	%r3746, %r22, %r394;
	and.b32  	%r3747, %r393, %r22;
	shl.b32 	%r3748, %r3747, 1;
	and.b32  	%r3749, %r3748, %r393;
	or.b32  	%r8941, %r3749, %r3746;
	bra.uni 	BB0_642;

BB0_422:
	setp.eq.s32	%p297, %r3690, 6;
	@%p297 bra 	BB0_425;
	bra.uni 	BB0_423;

BB0_425:
	and.b32  	%r3698, %r17, %r384;
	and.b32  	%r3699, %r383, %r17;
	shr.u32 	%r3700, %r3699, 1;
	and.b32  	%r3701, %r3700, %r383;
	or.b32  	%r8946, %r3701, %r3698;
	bra.uni 	BB0_675;

BB0_957:
	and.b16  	%rs268, %rs2, 255;
	and.b16  	%rs269, %rs376, 255;
	setp.eq.s16	%p628, %rs269, %rs268;
	mov.u32 	%r8844, 1;
	@%p628 bra 	BB0_959;

	st.local.u8 	[%rd6], %rs376;
	mov.u32 	%r8844, 1;
	mov.u32 	%r8949, %r8844;

BB0_959:
	cvt.u64.u32	%rd16, %r8844;
	add.s64 	%rd17, %rd7, %rd16;
	ld.local.u8 	%rs3, [%rd17];
	and.b16  	%rs270, %rs2, 255;
	setp.eq.s16	%p629, %rs3, %rs270;
	@%p629 bra 	BB0_961;

	cvt.u64.u32	%rd18, %r8949;
	add.s64 	%rd19, %rd6, %rd18;
	st.local.u8 	[%rd19], %rs3;
	add.s32 	%r8949, %r8949, 1;

BB0_961:
	add.s32 	%r8847, %r8844, 1;
	cvt.u64.u32	%rd20, %r8847;
	add.s64 	%rd21, %rd7, %rd20;
	ld.local.u8 	%rs376, [%rd21];

BB0_962:
	and.b16  	%rs271, %rs2, 255;
	and.b16  	%rs272, %rs376, 255;
	setp.eq.s16	%p630, %rs272, %rs271;
	@%p630 bra 	BB0_964;

	cvt.u64.u32	%rd22, %r8949;
	add.s64 	%rd23, %rd6, %rd22;
	st.local.u8 	[%rd23], %rs376;
	add.s32 	%r8949, %r8949, 1;

BB0_964:
	add.s32 	%r8852, %r8847, 1;

BB0_965:
	setp.lt.u32	%p631, %r14, 4;
	@%p631 bra 	BB0_975;

BB0_966:
	cvt.u64.u32	%rd24, %r8852;
	add.s64 	%rd25, %rd7, %rd24;
	ld.local.u8 	%rs6, [%rd25];
	and.b16  	%rs273, %rs2, 255;
	setp.eq.s16	%p632, %rs6, %rs273;
	@%p632 bra 	BB0_968;

	cvt.u64.u32	%rd26, %r8949;
	add.s64 	%rd27, %rd6, %rd26;
	st.local.u8 	[%rd27], %rs6;
	add.s32 	%r8949, %r8949, 1;

BB0_968:
	add.s32 	%r4864, %r8852, 1;
	cvt.u64.u32	%rd28, %r4864;
	add.s64 	%rd29, %rd7, %rd28;
	ld.local.u8 	%rs7, [%rd29];
	setp.eq.s16	%p633, %rs7, %rs273;
	@%p633 bra 	BB0_970;

	cvt.u64.u32	%rd30, %r8949;
	add.s64 	%rd31, %rd6, %rd30;
	st.local.u8 	[%rd31], %rs7;
	add.s32 	%r8949, %r8949, 1;

BB0_970:
	add.s32 	%r4865, %r8852, 2;
	cvt.u64.u32	%rd32, %r4865;
	add.s64 	%rd33, %rd7, %rd32;
	ld.local.u8 	%rs8, [%rd33];
	setp.eq.s16	%p634, %rs8, %rs273;
	@%p634 bra 	BB0_972;

	cvt.u64.u32	%rd34, %r8949;
	add.s64 	%rd35, %rd6, %rd34;
	st.local.u8 	[%rd35], %rs8;
	add.s32 	%r8949, %r8949, 1;

BB0_972:
	add.s32 	%r4866, %r8852, 3;
	cvt.u64.u32	%rd36, %r4866;
	add.s64 	%rd37, %rd7, %rd36;
	ld.local.u8 	%rs9, [%rd37];
	setp.eq.s16	%p635, %rs9, %rs273;
	@%p635 bra 	BB0_974;

	cvt.u64.u32	%rd38, %r8949;
	add.s64 	%rd39, %rd6, %rd38;
	st.local.u8 	[%rd39], %rs9;
	add.s32 	%r8949, %r8949, 1;

BB0_974:
	add.s32 	%r8852, %r8852, 4;
	setp.lt.u32	%p636, %r8852, %r14;
	@%p636 bra 	BB0_966;

BB0_975:
	ld.local.v4.u32 	{%r8944, %r8943, %r8942, %r8941}, [%rd6];
	ld.local.v4.u32 	{%r8948, %r8947, %r8946, %r8945}, [%rd6+16];
	bra.uni 	BB0_1554;

BB0_1279:
	setp.eq.s32	%p830, %r6215, 6;
	@%p830 bra 	BB0_1285;
	bra.uni 	BB0_1280;

BB0_1285:
	and.b32  	%r6222, %r1210, %r17;
	and.b32  	%r6223, %r8946, %r1211;
	or.b32  	%r8946, %r6223, %r6222;
	mov.u32 	%r8941, %r22;
	mov.u32 	%r8942, %r21;
	mov.u32 	%r8943, %r20;
	mov.u32 	%r8944, %r19;
	bra.uni 	BB0_1283;

BB0_811:
	setp.gt.s32	%p560, %r24, 13;
	@%p560 bra 	BB0_815;

	setp.eq.s32	%p563, %r24, 12;
	@%p563 bra 	BB0_862;
	bra.uni 	BB0_813;

BB0_862:
	mov.u32 	%r8942, 0;
	mov.u32 	%r8941, %r19;
	mov.u32 	%r8943, %r8942;
	mov.u32 	%r8944, %r8942;
	mov.u32 	%r18, %r15;
	mov.u32 	%r17, %r22;
	mov.u32 	%r16, %r21;
	mov.u32 	%r15, %r20;
	bra.uni 	BB0_874;

BB0_1299:
	setp.eq.s32	%p860, %r6317, 6;
	@%p860 bra 	BB0_1302;
	bra.uni 	BB0_1300;

BB0_1302:
	and.b32  	%r8946, %r8946, %r1255;
	bra.uni 	BB0_1553;

BB0_407:
	setp.ne.s32	%p286, %r3654, 7;
	@%p286 bra 	BB0_11;

	and.b32  	%r3658, %r18, %r373;
	and.b32  	%r3659, %r372, %r18;
	add.s32 	%r3660, %r3659, %r374;
	and.b32  	%r3661, %r3660, %r372;
	or.b32  	%r8945, %r3661, %r3658;
	bra.uni 	BB0_683;

BB0_1112:
	setp.gt.s32	%p713, %r26, 29;
	@%p713 bra 	BB0_1116;

	setp.eq.s32	%p716, %r26, 28;
	@%p716 bra 	BB0_1121;
	bra.uni 	BB0_1114;

BB0_1121:
	mov.u32 	%r8941, %r8945;
	mov.u32 	%r8942, %r8945;
	mov.u32 	%r8943, %r8945;
	mov.u32 	%r8862, %r18;
	bra.uni 	BB0_1122;

BB0_1019:
	setp.ne.s32	%p685, %r4956, 7;
	@%p685 bra 	BB0_978;

	and.b32  	%r4961, %r18, %r914;
	or.b32  	%r8945, %r4961, %r913;

BB0_1021:
	mov.u32 	%r8941, %r22;
	mov.u32 	%r8942, %r21;
	mov.u32 	%r8943, %r20;
	mov.u32 	%r8944, %r19;
	bra.uni 	BB0_16;

BB0_978:
	mov.u32 	%r8941, %r22;

BB0_642:
	mov.u32 	%r8942, %r21;

BB0_643:
	mov.u32 	%r8943, %r20;

BB0_644:
	mov.u32 	%r8944, %r19;

BB0_645:
	mov.u32 	%r8945, %r18;

BB0_646:
	mov.u32 	%r8946, %r17;

BB0_647:
	mov.u32 	%r8947, %r16;

BB0_648:
	mov.u32 	%r8948, %r15;
	bra.uni 	BB0_1553;

BB0_505:
	setp.gt.s32	%p324, %r24, 29;
	@%p324 bra 	BB0_509;

	setp.eq.s32	%p327, %r24, 28;
	@%p327 bra 	BB0_513;
	bra.uni 	BB0_507;

BB0_513:
	and.b32  	%r8816, %r18, 255;
	bra.uni 	BB0_528;

BB0_1444:
	setp.ne.s32	%p966, %r7416, 7;
	mov.u32 	%r8926, %r8925;
	mov.u32 	%r8927, %r8925;
	mov.u32 	%r8928, %r8925;
	mov.u32 	%r8929, %r8925;
	mov.u32 	%r8930, %r8925;
	mov.u32 	%r8931, %r8925;
	mov.u32 	%r8932, %r8925;
	@%p966 bra 	BB0_1450;

	mov.u32 	%r8925, 0;
	// inline asm
	prmt.b32 %r8932, %r8925, %r19, %r1533;
	// inline asm
	mov.u32 	%r8926, %r8925;
	mov.u32 	%r8927, %r8925;
	mov.u32 	%r8928, %r8925;
	mov.u32 	%r8929, %r8925;
	mov.u32 	%r8930, %r8925;
	mov.u32 	%r8931, %r8925;

BB0_1450:
	or.b32  	%r8944, %r8925, %r19;
	or.b32  	%r8943, %r8926, %r20;
	or.b32  	%r8942, %r8927, %r21;
	or.b32  	%r8941, %r8928, %r22;
	or.b32  	%r8948, %r8929, %r15;
	or.b32  	%r8947, %r8930, %r16;
	or.b32  	%r8946, %r8931, %r17;
	or.b32  	%r8945, %r8932, %r18;
	bra.uni 	BB0_1554;

BB0_442:
	setp.ne.s32	%p310, %r3726, 7;
	@%p310 bra 	BB0_11;

	and.b32  	%r3730, %r18, %r394;
	and.b32  	%r3731, %r393, %r18;
	shl.b32 	%r3732, %r3731, 1;
	and.b32  	%r3733, %r3732, %r393;
	or.b32  	%r8945, %r3733, %r3730;
	bra.uni 	BB0_683;

BB0_845:
	setp.gt.s32	%p537, %r24, 29;
	@%p537 bra 	BB0_849;

	setp.eq.s32	%p540, %r24, 28;
	@%p540 bra 	BB0_852;
	bra.uni 	BB0_847;

BB0_852:
	mov.u32 	%r8941, 0;
	mov.u32 	%r8942, %r8941;
	mov.u32 	%r8943, %r8941;
	mov.u32 	%r8944, %r8941;
	mov.u32 	%r18, %r19;
	bra.uni 	BB0_871;

BB0_982:
	setp.eq.s32	%p680, %r4923, 1;
	@%p680 bra 	BB0_1001;
	bra.uni 	BB0_983;

BB0_1001:
	and.b32  	%r8943, %r904, %r20;
	mov.u32 	%r8941, 0;
	mov.u32 	%r8942, %r8941;

BB0_999:
	mov.u32 	%r8944, %r19;

BB0_1000:
	mov.u32 	%r8945, %r8941;
	mov.u32 	%r8946, %r8941;
	mov.u32 	%r8947, %r8941;
	mov.u32 	%r8948, %r8941;
	mov.u32 	%r8949, %r24;
	bra.uni 	BB0_1554;

BB0_702:
	setp.gt.s32	%p498, %r14, 6;
	@%p498 bra 	BB0_706;

	setp.eq.s32	%p501, %r14, 5;
	@%p501 bra 	BB0_780;
	bra.uni 	BB0_704;

BB0_780:
	or.b32  	%r3998, %r19, %r20;
	and.b32  	%r3999, %r19, 16777215;
	prmt.b32 	%r8944, %r20, %r3999, 1620;
	shr.u32 	%r8943, %r3998, 24;
	mov.u32 	%r8949, 5;
	mov.u32 	%r8941, %r22;
	mov.u32 	%r8942, %r21;
	bra.uni 	BB0_771;

BB0_358:
	setp.eq.s32	%p269, %r3594, 1;
	@%p269 bra 	BB0_359;
	bra.uni 	BB0_11;

BB0_359:
	and.b32  	%r3614, %r20, %r352;
	and.b32  	%r3615, %r3570, %r351;
	or.b32  	%r8943, %r3615, %r3614;
	bra.uni 	BB0_625;

BB0_140:
	setp.gt.s32	%p164, %r24, 5;
	@%p164 bra 	BB0_144;

	setp.eq.s32	%p167, %r24, 4;
	@%p167 bra 	BB0_213;
	bra.uni 	BB0_142;

BB0_213:
	mov.u32 	%r8784, %r21;
	mov.u32 	%r8785, %r20;
	mov.u32 	%r8786, %r19;
	mov.u32 	%r8788, %r17;
	mov.u32 	%r8789, %r16;
	mov.u32 	%r8790, %r15;
	mov.u32 	%r8791, %r22;
	bra.uni 	BB0_215;

BB0_236:
	setp.eq.s32	%p198, %r2936, 1;
	mov.u32 	%r8800, %r22;
	mov.u32 	%r8801, %r21;
	mov.u32 	%r8802, %r20;
	mov.u32 	%r8803, %r19;
	mov.u32 	%r8804, %r18;
	mov.u32 	%r8805, %r17;
	mov.u32 	%r8806, %r16;
	mov.u32 	%r8807, %r15;
	@%p198 bra 	BB0_237;
	bra.uni 	BB0_254;

BB0_237:
	and.b32  	%r8802, %r186, %r20;
	mov.u32 	%r8800, 0;
	mov.u32 	%r8801, %r8800;

BB0_252:
	mov.u32 	%r8803, %r19;

BB0_253:
	mov.u32 	%r8804, %r8800;
	mov.u32 	%r8805, %r8800;
	mov.u32 	%r8806, %r8800;
	mov.u32 	%r8807, %r8800;
	bra.uni 	BB0_254;

BB0_1198:
	setp.eq.s32	%p791, %r24, 18;
	@%p791 bra 	BB0_1229;
	bra.uni 	BB0_1199;

BB0_1229:
	mov.u32 	%r5774, 16;
	// inline asm
	shf.r.wrap.b32 %r22, %r15, %r16, %r5774;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r16, %r17, %r5774;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8942, %r17, %r18, %r5774;
	// inline asm
	mov.u32 	%r8945, 0;
	// inline asm
	shf.r.wrap.b32 %r8941, %r18, %r8945, %r5774;
	// inline asm
	bra.uni 	BB0_1231;

BB0_1481:
	setp.eq.s32	%p994, %r7595, 18;
	@%p994 bra 	BB0_1515;
	bra.uni 	BB0_1482;

BB0_1515:
	mov.u32 	%r7765, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r21, %r22, %r7765;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r20, %r21, %r7765;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r19, %r20, %r7765;
	// inline asm
	mov.u32 	%r8933, 0;
	// inline asm
	shf.r.wrap.b32 %r19, %r8933, %r19, %r7765;
	// inline asm
	bra.uni 	BB0_1514;

BB0_1182:
	setp.eq.s32	%p803, %r24, 10;
	@%p803 bra 	BB0_1236;
	bra.uni 	BB0_1183;

BB0_1236:
	mov.u32 	%r5924, 16;
	// inline asm
	shf.r.wrap.b32 %r5901, %r21, %r22, %r5924;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r22, %r15, %r5924;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8942, %r15, %r16, %r5924;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8941, %r16, %r17, %r5924;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5917, %r17, %r18, %r5924;
	// inline asm
	mov.u32 	%r8945, 0;
	// inline asm
	shf.r.wrap.b32 %r8947, %r18, %r8945, %r5924;
	// inline asm
	mov.u32 	%r22, %r5901;
	mov.u32 	%r8946, %r8945;
	mov.u32 	%r18, %r5917;
	bra.uni 	BB0_1245;

BB0_989:
	setp.eq.s32	%p675, %r4923, 5;
	@%p675 bra 	BB0_990;
	bra.uni 	BB0_983;

BB0_990:
	and.b32  	%r8947, %r904, %r16;
	mov.u32 	%r8945, 0;
	mov.u32 	%r8941, %r22;
	mov.u32 	%r8942, %r21;
	mov.u32 	%r8943, %r20;
	mov.u32 	%r8944, %r19;
	mov.u32 	%r8946, %r8945;
	bra.uni 	BB0_995;

BB0_730:
	setp.gt.s32	%p477, %r14, 21;
	@%p477 bra 	BB0_735;

	setp.eq.s32	%p480, %r14, 20;
	@%p480 bra 	BB0_761;
	bra.uni 	BB0_732;

BB0_761:
	and.b32  	%r3917, %r15, 65535;
	shl.b32 	%r3918, %r15, 8;
	and.b32  	%r3919, %r3918, -16777216;
	or.b32  	%r3920, %r3919, %r3917;
	shr.u32 	%r3921, %r15, 8;
	and.b32  	%r3922, %r3921, 16711680;
	or.b32  	%r8948, %r3920, %r3922;
	mov.u32 	%r8949, 20;
	bra.uni 	BB0_763;

BB0_1465:
	setp.eq.s32	%p1006, %r7595, 10;
	@%p1006 bra 	BB0_1519;
	bra.uni 	BB0_1466;

BB0_1519:
	mov.u32 	%r7915, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r15, %r16, %r7915;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r22, %r15, %r7915;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r21, %r22, %r7915;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7904, %r20, %r21, %r7915;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8933, %r19, %r20, %r7915;
	// inline asm
	mov.u32 	%r8935, 0;
	// inline asm
	shf.r.wrap.b32 %r8934, %r8935, %r19, %r7915;
	// inline asm
	mov.u32 	%r8936, %r8935;
	mov.u32 	%r19, %r7904;
	bra.uni 	BB0_1529;

BB0_365:
	setp.eq.s32	%p264, %r3594, 5;
	@%p264 bra 	BB0_366;
	bra.uni 	BB0_11;

BB0_366:
	and.b32  	%r3606, %r16, %r352;
	and.b32  	%r3607, %r3586, %r351;
	or.b32  	%r8947, %r3607, %r3606;
	bra.uni 	BB0_666;

BB0_173:
	setp.gt.s32	%p141, %r24, 21;
	@%p141 bra 	BB0_177;

	setp.eq.s32	%p144, %r24, 20;
	@%p144 bra 	BB0_205;
	bra.uni 	BB0_175;

BB0_205:
	mov.u32 	%r8784, %r8787;
	mov.u32 	%r8785, %r8787;
	mov.u32 	%r8786, %r8787;
	mov.u32 	%r8788, %r21;
	mov.u32 	%r8789, %r20;
	mov.u32 	%r8790, %r19;
	mov.u32 	%r8791, %r8787;
	bra.uni 	BB0_215;

BB0_243:
	setp.eq.s32	%p193, %r2936, 5;
	mov.u32 	%r8800, %r22;
	mov.u32 	%r8801, %r21;
	mov.u32 	%r8802, %r20;
	mov.u32 	%r8803, %r19;
	mov.u32 	%r8804, %r18;
	mov.u32 	%r8805, %r17;
	mov.u32 	%r8806, %r16;
	mov.u32 	%r8807, %r15;
	@%p193 bra 	BB0_244;
	bra.uni 	BB0_254;

BB0_244:
	and.b32  	%r8806, %r186, %r16;
	mov.u32 	%r8804, 0;
	mov.u32 	%r8800, %r22;
	mov.u32 	%r8801, %r21;
	mov.u32 	%r8802, %r20;
	mov.u32 	%r8803, %r19;
	mov.u32 	%r8805, %r8804;
	mov.u32 	%r8807, %r15;
	bra.uni 	BB0_254;

BB0_1213:
	setp.eq.s32	%p780, %r24, 26;
	@%p780 bra 	BB0_1225;
	bra.uni 	BB0_1214;

BB0_1225:
	mov.u32 	%r5656, 16;
	// inline asm
	shf.r.wrap.b32 %r22, %r17, %r18, %r5656;
	// inline asm
	mov.u32 	%r8941, 0;
	// inline asm
	shf.r.wrap.b32 %r8943, %r18, %r8941, %r5656;
	// inline asm
	bra.uni 	BB0_1216;

BB0_1497:
	setp.eq.s32	%p983, %r7595, 26;
	@%p983 bra 	BB0_1509;
	bra.uni 	BB0_1498;

BB0_1509:
	mov.u32 	%r7647, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r19, %r20, %r7647;
	// inline asm
	mov.u32 	%r8933, 0;
	// inline asm
	shf.r.wrap.b32 %r17, %r8933, %r19, %r7647;
	// inline asm
	bra.uni 	BB0_1500;

BB0_1174:
	setp.eq.s32	%p809, %r24, 6;
	@%p809 bra 	BB0_1238;
	bra.uni 	BB0_1175;

BB0_1238:
	mov.u32 	%r6011, 16;
	// inline asm
	shf.r.wrap.b32 %r5984, %r20, %r21, %r6011;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r21, %r22, %r6011;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8942, %r22, %r15, %r6011;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8941, %r15, %r16, %r6011;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6000, %r16, %r17, %r6011;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8947, %r17, %r18, %r6011;
	// inline asm
	mov.u32 	%r8945, 0;
	// inline asm
	shf.r.wrap.b32 %r8946, %r18, %r8945, %r6011;
	// inline asm
	mov.u32 	%r22, %r5984;
	mov.u32 	%r18, %r6000;
	bra.uni 	BB0_1245;

BB0_985:
	setp.eq.s32	%p678, %r4923, 3;
	@%p678 bra 	BB0_986;
	bra.uni 	BB0_983;

BB0_986:
	and.b32  	%r8941, %r904, %r22;
	mov.u32 	%r8945, 0;
	mov.u32 	%r8942, %r21;
	mov.u32 	%r8943, %r20;
	mov.u32 	%r8944, %r19;
	mov.u32 	%r8946, %r8945;
	mov.u32 	%r8947, %r8945;
	mov.u32 	%r8948, %r8945;
	mov.u32 	%r8949, %r24;
	bra.uni 	BB0_1554;

BB0_717:
	setp.gt.s32	%p487, %r14, 14;
	@%p487 bra 	BB0_721;

	setp.eq.s32	%p490, %r14, 13;
	@%p490 bra 	BB0_774;
	bra.uni 	BB0_719;

BB0_774:
	or.b32  	%r3956, %r21, %r22;
	and.b32  	%r3957, %r21, 16777215;
	prmt.b32 	%r8942, %r22, %r3957, 1620;
	shr.u32 	%r8941, %r3956, 24;
	mov.u32 	%r8949, 13;
	bra.uni 	BB0_769;

BB0_1457:
	setp.eq.s32	%p1012, %r7595, 6;
	@%p1012 bra 	BB0_1521;
	bra.uni 	BB0_1458;

BB0_1521:
	mov.u32 	%r8002, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r16, %r17, %r8002;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r15, %r16, %r8002;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r22, %r15, %r8002;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7987, %r21, %r22, %r8002;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8933, %r20, %r21, %r8002;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8934, %r19, %r20, %r8002;
	// inline asm
	mov.u32 	%r8936, 0;
	// inline asm
	shf.r.wrap.b32 %r8935, %r8936, %r19, %r8002;
	// inline asm
	mov.u32 	%r19, %r7987;
	bra.uni 	BB0_1529;

BB0_361:
	setp.eq.s32	%p267, %r3594, 3;
	@%p267 bra 	BB0_362;
	bra.uni 	BB0_11;

BB0_362:
	and.b32  	%r3610, %r22, %r352;
	and.b32  	%r3611, %r3578, %r351;
	or.b32  	%r8941, %r3611, %r3610;
	bra.uni 	BB0_642;

BB0_155:
	setp.gt.s32	%p153, %r24, 13;
	@%p153 bra 	BB0_159;

	setp.eq.s32	%p156, %r24, 12;
	@%p156 bra 	BB0_209;
	bra.uni 	BB0_157;

BB0_209:
	mov.u32 	%r8784, %r19;
	mov.u32 	%r8785, %r8787;
	mov.u32 	%r8786, %r8787;
	mov.u32 	%r8788, %r15;
	mov.u32 	%r8789, %r22;
	mov.u32 	%r8790, %r21;
	mov.u32 	%r8791, %r20;
	bra.uni 	BB0_215;

BB0_239:
	setp.eq.s32	%p196, %r2936, 3;
	mov.u32 	%r8800, %r22;
	mov.u32 	%r8801, %r21;
	mov.u32 	%r8802, %r20;
	mov.u32 	%r8803, %r19;
	mov.u32 	%r8804, %r18;
	mov.u32 	%r8805, %r17;
	mov.u32 	%r8806, %r16;
	mov.u32 	%r8807, %r15;
	@%p196 bra 	BB0_240;
	bra.uni 	BB0_254;

BB0_240:
	and.b32  	%r8800, %r186, %r22;
	mov.u32 	%r8804, 0;
	mov.u32 	%r8801, %r21;
	mov.u32 	%r8802, %r20;
	mov.u32 	%r8803, %r19;
	mov.u32 	%r8805, %r8804;
	mov.u32 	%r8806, %r8804;
	mov.u32 	%r8807, %r8804;
	bra.uni 	BB0_254;

BB0_1205:
	setp.eq.s32	%p786, %r24, 22;
	@%p786 bra 	BB0_1227;
	bra.uni 	BB0_1206;

BB0_1227:
	mov.u32 	%r5711, 16;
	// inline asm
	shf.r.wrap.b32 %r22, %r16, %r17, %r5711;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r17, %r18, %r5711;
	// inline asm
	mov.u32 	%r8941, 0;
	// inline asm
	shf.r.wrap.b32 %r8942, %r18, %r8941, %r5711;
	// inline asm
	bra.uni 	BB0_1244;

BB0_1488:
	setp.eq.s32	%p989, %r7595, 22;
	@%p989 bra 	BB0_1511;
	bra.uni 	BB0_1489;

BB0_1511:
	mov.u32 	%r7702, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r20, %r21, %r7702;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r19, %r20, %r7702;
	// inline asm
	mov.u32 	%r8933, 0;
	// inline asm
	shf.r.wrap.b32 %r16, %r8933, %r19, %r7702;
	// inline asm
	bra.uni 	BB0_1491;

BB0_1189:
	setp.eq.s32	%p798, %r24, 14;
	@%p798 bra 	BB0_1233;
	bra.uni 	BB0_1190;

BB0_1233:
	mov.u32 	%r5845, 16;
	// inline asm
	shf.r.wrap.b32 %r22, %r22, %r15, %r5845;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r15, %r16, %r5845;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8942, %r16, %r17, %r5845;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8941, %r17, %r18, %r5845;
	// inline asm
	mov.u32 	%r8945, 0;
	// inline asm
	shf.r.wrap.b32 %r18, %r18, %r8945, %r5845;
	// inline asm
	bra.uni 	BB0_1235;

BB0_992:
	setp.ne.s32	%p673, %r4923, 7;
	@%p673 bra 	BB0_983;

	and.b32  	%r8945, %r904, %r18;
	mov.u32 	%r8941, %r22;
	mov.u32 	%r8942, %r21;
	mov.u32 	%r8943, %r20;
	mov.u32 	%r8944, %r19;
	mov.u32 	%r8946, %r17;
	bra.uni 	BB0_994;

BB0_983:
	mov.u32 	%r8941, %r22;
	mov.u32 	%r8942, %r21;
	mov.u32 	%r8943, %r20;
	mov.u32 	%r8944, %r19;
	mov.u32 	%r8945, %r18;
	mov.u32 	%r8946, %r17;

BB0_994:
	mov.u32 	%r8947, %r16;

BB0_995:
	mov.u32 	%r8948, %r15;
	mov.u32 	%r8949, %r24;
	bra.uni 	BB0_1554;

BB0_746:
	setp.gt.s32	%p466, %r14, 29;
	@%p466 bra 	BB0_750;

	setp.eq.s32	%p469, %r14, 28;
	@%p469 bra 	BB0_755;
	bra.uni 	BB0_748;

BB0_755:
	and.b32  	%r3875, %r17, 65535;
	shl.b32 	%r3876, %r17, 8;
	and.b32  	%r3877, %r3876, -16777216;
	or.b32  	%r3878, %r3877, %r3875;
	shr.u32 	%r3879, %r17, 8;
	and.b32  	%r3880, %r3879, 16711680;
	or.b32  	%r8946, %r3878, %r3880;
	mov.u32 	%r8949, 28;
	bra.uni 	BB0_757;

BB0_1472:
	setp.eq.s32	%p1001, %r7595, 14;
	@%p1001 bra 	BB0_1517;
	bra.uni 	BB0_1473;

BB0_1517:
	mov.u32 	%r7836, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r22, %r15, %r7836;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r21, %r22, %r7836;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r20, %r21, %r7836;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7829, %r19, %r20, %r7836;
	// inline asm
	mov.u32 	%r8934, 0;
	// inline asm
	shf.r.wrap.b32 %r8933, %r8934, %r19, %r7836;
	// inline asm
	mov.u32 	%r8935, %r8934;
	mov.u32 	%r8936, %r8934;
	mov.u32 	%r19, %r7829;
	bra.uni 	BB0_1529;

BB0_368:
	setp.ne.s32	%p262, %r3594, 7;
	@%p262 bra 	BB0_11;

	mov.u32 	%r3600, 0;
	// inline asm
	shf.r.wrap.b32 %r3598, %r18, %r3600, %r3593;
	// inline asm
	and.b32  	%r3602, %r3598, %r351;
	and.b32  	%r3603, %r18, %r352;
	or.b32  	%r8945, %r3602, %r3603;
	bra.uni 	BB0_683;

BB0_191:
	setp.gt.s32	%p130, %r24, 29;
	@%p130 bra 	BB0_195;

	setp.eq.s32	%p133, %r24, 28;
	@%p133 bra 	BB0_200;
	bra.uni 	BB0_193;

BB0_200:
	mov.u32 	%r8784, %r8787;
	mov.u32 	%r8785, %r8787;
	mov.u32 	%r8786, %r8787;
	mov.u32 	%r8788, %r19;
	mov.u32 	%r8789, %r8787;

BB0_201:
	mov.u32 	%r8790, %r8787;
	mov.u32 	%r8791, %r8787;
	bra.uni 	BB0_215;

BB0_246:
	setp.ne.s32	%p191, %r2936, 7;
	mov.u32 	%r8800, %r22;
	mov.u32 	%r8801, %r21;
	mov.u32 	%r8802, %r20;
	mov.u32 	%r8803, %r19;
	mov.u32 	%r8804, %r18;
	mov.u32 	%r8805, %r17;
	mov.u32 	%r8806, %r16;
	mov.u32 	%r8807, %r15;
	@%p191 bra 	BB0_254;

	and.b32  	%r8804, %r186, %r18;
	mov.u32 	%r8800, %r22;
	mov.u32 	%r8801, %r21;
	mov.u32 	%r8802, %r20;
	mov.u32 	%r8803, %r19;
	mov.u32 	%r8805, %r17;

BB0_248:
	mov.u32 	%r8806, %r16;
	mov.u32 	%r8807, %r15;

BB0_254:
	setp.gt.s32	%p199, %r24, 15;
	@%p199 bra 	BB0_283;

	setp.gt.s32	%p223, %r24, 7;
	@%p223 bra 	BB0_268;

	setp.gt.s32	%p235, %r24, 3;
	@%p235 bra 	BB0_261;

	setp.eq.s32	%p241, %r24, 1;
	@%p241 bra 	BB0_332;

	setp.eq.s32	%p242, %r24, 2;
	@%p242 bra 	BB0_331;
	bra.uni 	BB0_259;

BB0_331:
	mov.u32 	%r3469, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r17, %r18, %r3469;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r16, %r17, %r3469;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r15, %r16, %r3469;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3450, %r22, %r15, %r3469;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8808, %r21, %r22, %r3469;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8809, %r20, %r21, %r3469;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8810, %r19, %r20, %r3469;
	// inline asm
	mov.u32 	%r3467, 0;
	// inline asm
	shf.r.wrap.b32 %r8811, %r3467, %r19, %r3469;
	// inline asm
	mov.u32 	%r19, %r3450;
	bra.uni 	BB0_338;

BB0_283:
	setp.gt.s32	%p200, %r24, 23;
	@%p200 bra 	BB0_300;

	setp.gt.s32	%p212, %r24, 19;
	@%p212 bra 	BB0_292;

	setp.gt.s32	%p218, %r24, 17;
	@%p218 bra 	BB0_289;

	setp.eq.s32	%p221, %r24, 16;
	@%p221 bra 	BB0_324;
	bra.uni 	BB0_287;

BB0_324:
	mov.u32 	%r8808, 0;
	mov.u32 	%r8809, %r8808;
	mov.u32 	%r8810, %r8808;
	mov.u32 	%r8811, %r8808;
	mov.u32 	%r18, %r22;
	mov.u32 	%r17, %r21;
	mov.u32 	%r16, %r20;
	bra.uni 	BB0_338;

BB0_268:
	setp.gt.s32	%p224, %r24, 11;
	@%p224 bra 	BB0_276;

	setp.gt.s32	%p230, %r24, 9;
	@%p230 bra 	BB0_273;

	setp.eq.s32	%p233, %r24, 8;
	@%p233 bra 	BB0_328;
	bra.uni 	BB0_271;

BB0_328:
	mov.u32 	%r8810, 0;
	mov.u32 	%r8808, %r20;
	mov.u32 	%r8809, %r19;
	mov.u32 	%r8811, %r8810;
	mov.u32 	%r18, %r16;
	mov.u32 	%r17, %r15;
	mov.u32 	%r16, %r22;
	mov.u32 	%r19, %r21;
	bra.uni 	BB0_338;

BB0_300:
	setp.gt.s32	%p201, %r24, 27;
	@%p201 bra 	BB0_309;

	setp.gt.s32	%p207, %r24, 25;
	@%p207 bra 	BB0_305;

	setp.eq.s32	%p210, %r24, 24;
	@%p210 bra 	BB0_318;
	bra.uni 	BB0_303;

BB0_318:
	mov.u32 	%r8808, 0;
	mov.u32 	%r8809, %r8808;
	mov.u32 	%r8810, %r8808;
	mov.u32 	%r8811, %r8808;
	mov.u32 	%r18, %r20;
	mov.u32 	%r17, %r19;
	bra.uni 	BB0_336;

BB0_1221:
	setp.eq.s32	%p775, %r24, 31;
	@%p775 bra 	BB0_1242;
	bra.uni 	BB0_1222;

BB0_1242:
	mov.u32 	%r8941, 0;
	mov.u32 	%r6142, 24;
	// inline asm
	shf.r.wrap.b32 %r22, %r18, %r8941, %r6142;
	// inline asm
	bra.uni 	BB0_1243;

BB0_1505:
	setp.eq.s32	%p978, %r7595, 31;
	@%p978 bra 	BB0_1524;
	bra.uni 	BB0_1506;

BB0_1524:
	mov.u32 	%r8933, 0;
	mov.u32 	%r8133, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r8933, %r19, %r8133;
	// inline asm
	bra.uni 	BB0_1525;

BB0_261:
	setp.gt.s32	%p236, %r24, 5;
	@%p236 bra 	BB0_265;

	setp.eq.s32	%p239, %r24, 4;
	@%p239 bra 	BB0_330;
	bra.uni 	BB0_263;

BB0_330:
	mov.u32 	%r8811, 0;
	mov.u32 	%r8808, %r21;
	mov.u32 	%r8809, %r20;
	mov.u32 	%r8810, %r19;
	mov.u32 	%r18, %r17;
	mov.u32 	%r17, %r16;
	mov.u32 	%r16, %r15;
	mov.u32 	%r19, %r22;
	bra.uni 	BB0_338;

BB0_292:
	setp.gt.s32	%p213, %r24, 21;
	@%p213 bra 	BB0_296;

	setp.eq.s32	%p216, %r24, 20;
	@%p216 bra 	BB0_320;
	bra.uni 	BB0_294;

BB0_320:
	mov.u32 	%r8808, 0;
	mov.u32 	%r8809, %r8808;
	mov.u32 	%r8810, %r8808;
	mov.u32 	%r8811, %r8808;
	mov.u32 	%r18, %r21;
	mov.u32 	%r17, %r20;
	mov.u32 	%r16, %r19;
	bra.uni 	BB0_337;

BB0_276:
	setp.gt.s32	%p225, %r24, 13;
	@%p225 bra 	BB0_280;

	setp.eq.s32	%p228, %r24, 12;
	@%p228 bra 	BB0_326;
	bra.uni 	BB0_278;

BB0_326:
	mov.u32 	%r8809, 0;
	mov.u32 	%r8808, %r19;
	mov.u32 	%r8810, %r8809;
	mov.u32 	%r8811, %r8809;
	mov.u32 	%r18, %r15;
	mov.u32 	%r17, %r22;
	mov.u32 	%r16, %r21;
	mov.u32 	%r19, %r20;
	bra.uni 	BB0_338;

BB0_309:
	setp.gt.s32	%p202, %r24, 29;
	@%p202 bra 	BB0_313;

	setp.eq.s32	%p205, %r24, 28;
	@%p205 bra 	BB0_316;
	bra.uni 	BB0_311;

BB0_316:
	mov.u32 	%r8808, 0;
	mov.u32 	%r8809, %r8808;
	mov.u32 	%r8810, %r8808;
	mov.u32 	%r8811, %r8808;
	mov.u32 	%r18, %r19;
	bra.uni 	BB0_335;

BB0_1241:
	mov.u32 	%r6138, 8;
	// inline asm
	shf.r.wrap.b32 %r6107, %r19, %r20, %r6138;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r20, %r21, %r6138;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8942, %r21, %r22, %r6138;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8941, %r22, %r15, %r6138;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6123, %r15, %r16, %r6138;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8947, %r16, %r17, %r6138;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8946, %r17, %r18, %r6138;
	// inline asm
	mov.u32 	%r6137, 0;
	// inline asm
	shf.r.wrap.b32 %r8945, %r18, %r6137, %r6138;
	// inline asm
	mov.u32 	%r22, %r6107;
	mov.u32 	%r18, %r6123;
	bra.uni 	BB0_1245;

BB0_1168:
	setp.eq.s32	%p815, %r24, 3;
	@%p815 bra 	BB0_1169;
	bra.uni 	BB0_1191;

BB0_1169:
	mov.u32 	%r6074, 24;
	// inline asm
	shf.r.wrap.b32 %r6043, %r19, %r20, %r6074;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r20, %r21, %r6074;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8942, %r21, %r22, %r6074;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8941, %r22, %r15, %r6074;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6059, %r15, %r16, %r6074;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8947, %r16, %r17, %r6074;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8946, %r17, %r18, %r6074;
	// inline asm
	mov.u32 	%r6073, 0;
	// inline asm
	shf.r.wrap.b32 %r8945, %r18, %r6073, %r6074;
	// inline asm
	mov.u32 	%r22, %r6043;
	mov.u32 	%r18, %r6059;
	bra.uni 	BB0_1245;

BB0_1060:
	setp.eq.s32	%p753, %r26, 2;
	@%p753 bra 	BB0_1135;
	bra.uni 	BB0_1061;

BB0_1135:
	mov.u32 	%r5551, 16;
	// inline asm
	shf.r.wrap.b32 %r8862, %r19, %r20, %r5551;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r20, %r21, %r5551;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8942, %r21, %r22, %r5551;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8941, %r22, %r15, %r5551;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8948, %r15, %r16, %r5551;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8947, %r16, %r17, %r5551;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8946, %r17, %r18, %r5551;
	// inline asm
	mov.u32 	%r5550, 0;
	// inline asm
	shf.r.wrap.b32 %r8945, %r18, %r5550, %r5551;
	// inline asm
	bra.uni 	BB0_1137;

BB0_1523:
	mov.u32 	%r8129, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r17, %r18, %r8129;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r16, %r17, %r8129;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r15, %r16, %r8129;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8110, %r22, %r15, %r8129;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8933, %r21, %r22, %r8129;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8934, %r20, %r21, %r8129;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8935, %r19, %r20, %r8129;
	// inline asm
	mov.u32 	%r8127, 0;
	// inline asm
	shf.r.wrap.b32 %r8936, %r8127, %r19, %r8129;
	// inline asm
	mov.u32 	%r19, %r8110;
	bra.uni 	BB0_1529;

BB0_1451:
	setp.eq.s32	%p1018, %r7595, 3;
	@%p1018 bra 	BB0_1452;
	bra.uni 	BB0_1483;

BB0_1452:
	mov.u32 	%r8065, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r17, %r18, %r8065;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r16, %r17, %r8065;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r15, %r16, %r8065;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8046, %r22, %r15, %r8065;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8933, %r21, %r22, %r8065;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8934, %r20, %r21, %r8065;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8935, %r19, %r20, %r8065;
	// inline asm
	mov.u32 	%r8063, 0;
	// inline asm
	shf.r.wrap.b32 %r8936, %r8063, %r19, %r8065;
	// inline asm
	mov.u32 	%r19, %r8046;
	bra.uni 	BB0_1529;

BB0_456:
	setp.eq.s32	%p364, %r24, 2;
	@%p364 bra 	BB0_526;
	bra.uni 	BB0_457;

BB0_526:
	bfe.u32 	%r8816, %r19, 16, 8;
	bra.uni 	BB0_528;

BB0_342:
	setp.eq.s32	%p257, %r3541, 1;
	@%p257 bra 	BB0_343;
	bra.uni 	BB0_11;

BB0_343:
	and.b32  	%r3557, %r20, %r335;
	and.b32  	%r3558, %r3537, %r334;
	or.b32  	%r8943, %r3558, %r3557;
	bra.uni 	BB0_625;

BB0_1319:
	setp.gt.s32	%p926, %r6470, 5;
	@%p926 bra 	BB0_1323;

	setp.eq.s32	%p929, %r6470, 4;
	@%p929 bra 	BB0_1392;
	bra.uni 	BB0_1321;

BB0_1392:
	mov.u32 	%r8891, %r21;
	mov.u32 	%r8892, %r20;
	mov.u32 	%r8893, %r19;
	mov.u32 	%r8894, %r8899;
	mov.u32 	%r8895, %r17;
	mov.u32 	%r8896, %r16;
	mov.u32 	%r8897, %r15;
	mov.u32 	%r8898, %r22;
	bra.uni 	BB0_1394;

BB0_413:
	setp.eq.s32	%p305, %r3690, 1;
	@%p305 bra 	BB0_414;
	bra.uni 	BB0_11;

BB0_414:
	and.b32  	%r3718, %r20, %r384;
	and.b32  	%r3719, %r383, %r20;
	shr.u32 	%r3720, %r3719, 1;
	and.b32  	%r3721, %r3720, %r383;
	or.b32  	%r8943, %r3721, %r3718;
	bra.uni 	BB0_625;

BB0_1268:
	setp.eq.s32	%p838, %r6215, 1;
	@%p838 bra 	BB0_1269;
	bra.uni 	BB0_1281;

BB0_1269:
	and.b32  	%r6232, %r1210, %r20;
	and.b32  	%r6233, %r8943, %r1211;
	or.b32  	%r8943, %r6233, %r6232;
	mov.u32 	%r8944, %r19;
	bra.uni 	BB0_1278;

BB0_131:
	setp.eq.s32	%p868, %r6317, 1;
	@%p868 bra 	BB0_1306;
	bra.uni 	BB0_132;

BB0_1306:
	and.b32  	%r8943, %r8943, %r1255;
	mov.u32 	%r8941, 0;
	mov.u32 	%r8942, %r8941;

BB0_1305:
	mov.u32 	%r8945, %r8941;
	mov.u32 	%r8946, %r8941;
	mov.u32 	%r8947, %r8941;
	mov.u32 	%r8948, %r8941;
	bra.uni 	BB0_1553;

BB0_1092:
	setp.eq.s32	%p730, %r26, 18;
	@%p730 bra 	BB0_1127;
	bra.uni 	BB0_1093;

BB0_1127:
	mov.u32 	%r5219, 16;
	// inline asm
	shf.r.wrap.b32 %r8862, %r15, %r16, %r5219;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r16, %r17, %r5219;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8942, %r17, %r18, %r5219;
	// inline asm
	mov.u32 	%r8945, 0;
	// inline asm
	shf.r.wrap.b32 %r8941, %r18, %r8945, %r5219;
	// inline asm
	bra.uni 	BB0_1122;

BB0_487:
	setp.eq.s32	%p341, %r24, 18;
	@%p341 bra 	BB0_518;
	bra.uni 	BB0_488;

BB0_518:
	bfe.u32 	%r8816, %r15, 16, 8;
	bra.uni 	BB0_528;

BB0_825:
	setp.eq.s32	%p554, %r24, 18;
	@%p554 bra 	BB0_859;
	bra.uni 	BB0_826;

BB0_859:
	mov.u32 	%r4261, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r21, %r22, %r4261;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r20, %r21, %r4261;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r19, %r20, %r4261;
	// inline asm
	mov.u32 	%r8941, 0;
	// inline asm
	shf.r.wrap.b32 %r15, %r8941, %r19, %r4261;
	// inline asm
	bra.uni 	BB0_858;

BB0_1075:
	setp.eq.s32	%p742, %r26, 10;
	@%p742 bra 	BB0_1131;
	bra.uni 	BB0_1076;

BB0_1131:
	mov.u32 	%r5369, 16;
	// inline asm
	shf.r.wrap.b32 %r8862, %r21, %r22, %r5369;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r22, %r15, %r5369;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8942, %r15, %r16, %r5369;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8941, %r16, %r17, %r5369;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8948, %r17, %r18, %r5369;
	// inline asm
	mov.u32 	%r8945, 0;
	// inline asm
	shf.r.wrap.b32 %r8947, %r18, %r8945, %r5369;
	// inline asm
	mov.u32 	%r8946, %r8945;
	bra.uni 	BB0_1137;

BB0_471:
	setp.eq.s32	%p353, %r24, 10;
	@%p353 bra 	BB0_522;
	bra.uni 	BB0_472;

BB0_522:
	bfe.u32 	%r8816, %r21, 16, 8;
	bra.uni 	BB0_528;

BB0_349:
	setp.eq.s32	%p252, %r3541, 5;
	@%p252 bra 	BB0_350;
	bra.uni 	BB0_11;

BB0_350:
	and.b32  	%r3549, %r16, %r335;
	and.b32  	%r3550, %r3521, %r334;
	or.b32  	%r8947, %r3550, %r3549;
	bra.uni 	BB0_666;

BB0_1352:
	setp.gt.s32	%p903, %r6470, 21;
	@%p903 bra 	BB0_1356;

	setp.eq.s32	%p906, %r6470, 20;
	@%p906 bra 	BB0_1384;
	bra.uni 	BB0_1354;

BB0_1384:
	mov.u32 	%r8891, %r8899;
	mov.u32 	%r8892, %r8899;
	mov.u32 	%r8893, %r8899;
	mov.u32 	%r8894, %r8899;
	mov.u32 	%r8895, %r21;
	mov.u32 	%r8896, %r20;
	mov.u32 	%r8897, %r19;
	mov.u32 	%r8898, %r8899;
	bra.uni 	BB0_1394;

BB0_420:
	setp.eq.s32	%p300, %r3690, 5;
	@%p300 bra 	BB0_421;
	bra.uni 	BB0_11;

BB0_421:
	and.b32  	%r3702, %r16, %r384;
	and.b32  	%r3703, %r383, %r16;
	shr.u32 	%r3704, %r3703, 1;
	and.b32  	%r3705, %r3704, %r383;
	or.b32  	%r8947, %r3705, %r3702;
	bra.uni 	BB0_666;

BB0_1275:
	setp.eq.s32	%p833, %r6215, 5;
	@%p833 bra 	BB0_1276;
	bra.uni 	BB0_1281;

BB0_1276:
	and.b32  	%r6224, %r1210, %r16;
	and.b32  	%r6225, %r8947, %r1211;
	or.b32  	%r8947, %r6225, %r6224;
	mov.u32 	%r8941, %r22;
	mov.u32 	%r8942, %r21;
	mov.u32 	%r8943, %r20;
	mov.u32 	%r8944, %r19;
	bra.uni 	BB0_1277;

BB0_808:
	setp.eq.s32	%p566, %r24, 10;
	@%p566 bra 	BB0_863;
	bra.uni 	BB0_809;

BB0_863:
	mov.u32 	%r4411, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r15, %r16, %r4411;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r22, %r15, %r4411;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r21, %r22, %r4411;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r15, %r20, %r21, %r4411;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8941, %r19, %r20, %r4411;
	// inline asm
	mov.u32 	%r8943, 0;
	// inline asm
	shf.r.wrap.b32 %r8942, %r8943, %r19, %r4411;
	// inline asm
	mov.u32 	%r8944, %r8943;
	bra.uni 	BB0_874;

BB0_1297:
	setp.eq.s32	%p863, %r6317, 5;
	@%p863 bra 	BB0_1298;
	bra.uni 	BB0_132;

BB0_1298:
	and.b32  	%r8947, %r8947, %r1255;
	mov.u32 	%r8945, 0;
	mov.u32 	%r8946, %r8945;
	bra.uni 	BB0_1553;

BB0_1107:
	setp.eq.s32	%p719, %r26, 26;
	@%p719 bra 	BB0_1123;
	bra.uni 	BB0_1108;

BB0_1123:
	mov.u32 	%r5101, 16;
	// inline asm
	shf.r.wrap.b32 %r8862, %r17, %r18, %r5101;
	// inline asm
	mov.u32 	%r8941, 0;
	// inline asm
	shf.r.wrap.b32 %r8943, %r18, %r8941, %r5101;
	// inline asm
	bra.uni 	BB0_1110;

BB0_502:
	setp.eq.s32	%p330, %r24, 26;
	@%p330 bra 	BB0_514;
	bra.uni 	BB0_503;

BB0_514:
	bfe.u32 	%r8816, %r17, 16, 8;
	bra.uni 	BB0_528;

BB0_841:
	setp.eq.s32	%p543, %r24, 26;
	@%p543 bra 	BB0_853;
	bra.uni 	BB0_842;

BB0_853:
	mov.u32 	%r4143, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r19, %r20, %r4143;
	// inline asm
	mov.u32 	%r8941, 0;
	// inline asm
	shf.r.wrap.b32 %r17, %r8941, %r19, %r4143;
	// inline asm
	bra.uni 	BB0_844;

BB0_1067:
	setp.eq.s32	%p748, %r26, 6;
	@%p748 bra 	BB0_1133;
	bra.uni 	BB0_1068;

BB0_1133:
	mov.u32 	%r5456, 16;
	// inline asm
	shf.r.wrap.b32 %r8862, %r20, %r21, %r5456;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r21, %r22, %r5456;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8942, %r22, %r15, %r5456;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8941, %r15, %r16, %r5456;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8948, %r16, %r17, %r5456;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8947, %r17, %r18, %r5456;
	// inline asm
	mov.u32 	%r8945, 0;
	// inline asm
	shf.r.wrap.b32 %r8946, %r18, %r8945, %r5456;
	// inline asm
	bra.uni 	BB0_1137;

BB0_463:
	setp.eq.s32	%p359, %r24, 6;
	@%p359 bra 	BB0_524;
	bra.uni 	BB0_464;

BB0_524:
	bfe.u32 	%r8816, %r20, 16, 8;
	bra.uni 	BB0_528;

BB0_345:
	setp.eq.s32	%p255, %r3541, 3;
	@%p255 bra 	BB0_346;
	bra.uni 	BB0_11;

BB0_346:
	and.b32  	%r3553, %r22, %r335;
	and.b32  	%r3554, %r3529, %r334;
	or.b32  	%r8941, %r3554, %r3553;
	bra.uni 	BB0_642;

BB0_1334:
	setp.gt.s32	%p915, %r6470, 13;
	@%p915 bra 	BB0_1338;

	setp.eq.s32	%p918, %r6470, 12;
	@%p918 bra 	BB0_1388;
	bra.uni 	BB0_1336;

BB0_1388:
	mov.u32 	%r8891, %r19;
	mov.u32 	%r8892, %r8899;
	mov.u32 	%r8893, %r8899;
	mov.u32 	%r8894, %r8899;
	mov.u32 	%r8895, %r15;
	mov.u32 	%r8896, %r22;
	mov.u32 	%r8897, %r21;
	mov.u32 	%r8898, %r20;
	bra.uni 	BB0_1394;

BB0_416:
	setp.eq.s32	%p303, %r3690, 3;
	@%p303 bra 	BB0_417;
	bra.uni 	BB0_11;

BB0_417:
	and.b32  	%r3710, %r22, %r384;
	and.b32  	%r3711, %r383, %r22;
	shr.u32 	%r3712, %r3711, 1;
	and.b32  	%r3713, %r3712, %r383;
	or.b32  	%r8941, %r3713, %r3710;
	bra.uni 	BB0_642;

BB0_1271:
	setp.eq.s32	%p836, %r6215, 3;
	@%p836 bra 	BB0_1272;
	bra.uni 	BB0_1281;

BB0_1272:
	and.b32  	%r6228, %r1210, %r22;
	and.b32  	%r6229, %r8941, %r1211;
	or.b32  	%r8941, %r6229, %r6228;

BB0_1287:
	mov.u32 	%r8942, %r21;

BB0_1288:
	mov.u32 	%r8943, %r20;
	mov.u32 	%r8944, %r19;
	bra.uni 	BB0_1278;

BB0_800:
	setp.eq.s32	%p572, %r24, 6;
	@%p572 bra 	BB0_865;
	bra.uni 	BB0_801;

BB0_865:
	mov.u32 	%r4498, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r16, %r17, %r4498;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r15, %r16, %r4498;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r22, %r15, %r4498;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r15, %r21, %r22, %r4498;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8941, %r20, %r21, %r4498;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8942, %r19, %r20, %r4498;
	// inline asm
	mov.u32 	%r8944, 0;
	// inline asm
	shf.r.wrap.b32 %r8943, %r8944, %r19, %r4498;
	// inline asm
	bra.uni 	BB0_874;

BB0_1293:
	setp.eq.s32	%p866, %r6317, 3;
	@%p866 bra 	BB0_1294;
	bra.uni 	BB0_132;

BB0_1294:
	and.b32  	%r8941, %r8941, %r1255;
	mov.u32 	%r8945, 0;
	mov.u32 	%r8946, %r8945;
	mov.u32 	%r8947, %r8945;
	mov.u32 	%r8948, %r8945;
	bra.uni 	BB0_1553;

BB0_1099:
	setp.eq.s32	%p725, %r26, 22;
	@%p725 bra 	BB0_1125;
	bra.uni 	BB0_1100;

BB0_1125:
	mov.u32 	%r5156, 16;
	// inline asm
	shf.r.wrap.b32 %r8862, %r16, %r17, %r5156;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r17, %r18, %r5156;
	// inline asm
	mov.u32 	%r8941, 0;
	// inline asm
	shf.r.wrap.b32 %r8942, %r18, %r8941, %r5156;
	// inline asm
	bra.uni 	BB0_1111;

BB0_494:
	setp.eq.s32	%p336, %r24, 22;
	@%p336 bra 	BB0_516;
	bra.uni 	BB0_495;

BB0_516:
	bfe.u32 	%r8816, %r16, 16, 8;
	bra.uni 	BB0_528;

BB0_832:
	setp.eq.s32	%p549, %r24, 22;
	@%p549 bra 	BB0_855;
	bra.uni 	BB0_833;

BB0_855:
	mov.u32 	%r4198, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r20, %r21, %r4198;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r19, %r20, %r4198;
	// inline asm
	mov.u32 	%r8941, 0;
	// inline asm
	shf.r.wrap.b32 %r16, %r8941, %r19, %r4198;
	// inline asm
	bra.uni 	BB0_835;

BB0_1082:
	setp.eq.s32	%p737, %r26, 14;
	@%p737 bra 	BB0_1129;
	bra.uni 	BB0_1083;

BB0_1129:
	mov.u32 	%r5290, 16;
	// inline asm
	shf.r.wrap.b32 %r8862, %r22, %r15, %r5290;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r15, %r16, %r5290;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8942, %r16, %r17, %r5290;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8941, %r17, %r18, %r5290;
	// inline asm
	mov.u32 	%r8945, 0;
	// inline asm
	shf.r.wrap.b32 %r8948, %r18, %r8945, %r5290;
	// inline asm
	bra.uni 	BB0_1085;

BB0_478:
	setp.eq.s32	%p348, %r24, 14;
	@%p348 bra 	BB0_520;
	bra.uni 	BB0_479;

BB0_520:
	bfe.u32 	%r8816, %r22, 16, 8;
	bra.uni 	BB0_528;

BB0_352:
	setp.ne.s32	%p250, %r3541, 7;
	@%p250 bra 	BB0_11;

	and.b32  	%r3545, %r18, %r335;
	and.b32  	%r3546, %r3513, %r334;
	or.b32  	%r8945, %r3546, %r3545;
	bra.uni 	BB0_683;

BB0_1370:
	setp.gt.s32	%p892, %r6470, 29;
	@%p892 bra 	BB0_1374;

	setp.eq.s32	%p895, %r6470, 28;
	@%p895 bra 	BB0_1379;
	bra.uni 	BB0_1372;

BB0_1379:
	mov.u32 	%r8891, %r8899;
	mov.u32 	%r8892, %r8899;
	mov.u32 	%r8893, %r8899;
	mov.u32 	%r8894, %r8899;
	mov.u32 	%r8895, %r19;
	mov.u32 	%r8896, %r8899;

BB0_1380:
	mov.u32 	%r8897, %r8899;
	mov.u32 	%r8898, %r8899;
	bra.uni 	BB0_1394;

BB0_423:
	setp.ne.s32	%p298, %r3690, 7;
	@%p298 bra 	BB0_11;

	and.b32  	%r3694, %r18, %r384;
	and.b32  	%r3695, %r383, %r18;
	shr.u32 	%r3696, %r3695, 1;
	and.b32  	%r3697, %r3696, %r383;
	or.b32  	%r8945, %r3697, %r3694;
	bra.uni 	BB0_683;

BB0_1280:
	setp.ne.s32	%p831, %r6215, 7;
	@%p831 bra 	BB0_1281;

	and.b32  	%r6220, %r1210, %r18;
	and.b32  	%r6221, %r8945, %r1211;
	or.b32  	%r8945, %r6221, %r6220;
	mov.u32 	%r8941, %r22;
	mov.u32 	%r8942, %r21;
	mov.u32 	%r8943, %r20;
	mov.u32 	%r8944, %r19;
	bra.uni 	BB0_1282;

BB0_1281:
	mov.u32 	%r8941, %r22;
	mov.u32 	%r8942, %r21;
	mov.u32 	%r8943, %r20;
	mov.u32 	%r8944, %r19;
	mov.u32 	%r8945, %r18;

BB0_1282:
	mov.u32 	%r8946, %r17;

BB0_1283:
	mov.u32 	%r8947, %r16;

BB0_1277:
	mov.u32 	%r8948, %r15;

BB0_1278:
	add.s32 	%r8949, %r14, -1;
	bra.uni 	BB0_1554;

BB0_815:
	setp.eq.s32	%p561, %r24, 14;
	@%p561 bra 	BB0_861;
	bra.uni 	BB0_816;

BB0_861:
	mov.u32 	%r4332, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r22, %r15, %r4332;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r21, %r22, %r4332;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r20, %r21, %r4332;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r15, %r19, %r20, %r4332;
	// inline asm
	mov.u32 	%r8942, 0;
	// inline asm
	shf.r.wrap.b32 %r8941, %r8942, %r19, %r4332;
	// inline asm
	bra.uni 	BB0_818;

BB0_1300:
	setp.ne.s32	%p861, %r6317, 7;
	@%p861 bra 	BB0_132;

	and.b32  	%r8945, %r6285, %r1255;
	bra.uni 	BB0_1553;

BB0_132:
	mov.u32 	%r8945, %r6285;
	bra.uni 	BB0_1553;

BB0_1116:
	setp.eq.s32	%p714, %r26, 30;
	@%p714 bra 	BB0_1120;
	bra.uni 	BB0_1117;

BB0_1120:
	mov.u32 	%r8941, 0;
	mov.u32 	%r5054, 16;
	// inline asm
	shf.r.wrap.b32 %r8862, %r18, %r8941, %r5054;
	// inline asm
	bra.uni 	BB0_1119;

BB0_509:
	setp.eq.s32	%p325, %r24, 30;
	@%p325 bra 	BB0_512;
	bra.uni 	BB0_510;

BB0_512:
	bfe.u32 	%r8816, %r18, 16, 8;
	bra.uni 	BB0_528;

BB0_849:
	setp.eq.s32	%p538, %r24, 31;
	@%p538 bra 	BB0_869;
	bra.uni 	BB0_850;

BB0_869:
	mov.u32 	%r8941, 0;
	mov.u32 	%r4629, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r8941, %r19, %r4629;
	// inline asm
	bra.uni 	BB0_870;

BB0_137:
	setp.eq.s32	%p170, %r24, 2;
	@%p170 bra 	BB0_214;
	bra.uni 	BB0_138;

BB0_214:
	mov.u32 	%r2871, 16;
	// inline asm
	shf.r.wrap.b32 %r8788, %r17, %r18, %r2871;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8789, %r16, %r17, %r2871;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8790, %r15, %r16, %r2871;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8791, %r22, %r15, %r2871;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8784, %r21, %r22, %r2871;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8785, %r20, %r21, %r2871;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8786, %r19, %r20, %r2871;
	// inline asm
	mov.u32 	%r2869, 0;
	// inline asm
	shf.r.wrap.b32 %r8787, %r2869, %r19, %r2871;
	// inline asm
	bra.uni 	BB0_215;

BB0_1196:
	setp.eq.s32	%p794, %r24, 17;
	@%p794 bra 	BB0_1197;
	bra.uni 	BB0_1191;

BB0_1197:
	mov.u32 	%r5794, 8;
	// inline asm
	shf.r.wrap.b32 %r22, %r15, %r16, %r5794;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r16, %r17, %r5794;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8942, %r17, %r18, %r5794;
	// inline asm
	mov.u32 	%r8945, 0;
	// inline asm
	shf.r.wrap.b32 %r8941, %r18, %r8945, %r5794;
	// inline asm
	bra.uni 	BB0_1231;

BB0_1479:
	setp.eq.s32	%p997, %r7595, 17;
	@%p997 bra 	BB0_1480;
	bra.uni 	BB0_1483;

BB0_1480:
	mov.u32 	%r7785, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r21, %r22, %r7785;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r20, %r21, %r7785;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r19, %r20, %r7785;
	// inline asm
	mov.u32 	%r8933, 0;
	// inline asm
	shf.r.wrap.b32 %r19, %r8933, %r19, %r7785;
	// inline asm
	bra.uni 	BB0_1514;

BB0_1180:
	setp.eq.s32	%p806, %r24, 9;
	@%p806 bra 	BB0_1181;
	bra.uni 	BB0_1191;

BB0_1181:
	mov.u32 	%r5950, 8;
	// inline asm
	shf.r.wrap.b32 %r5927, %r21, %r22, %r5950;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r22, %r15, %r5950;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8942, %r15, %r16, %r5950;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8941, %r16, %r17, %r5950;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5943, %r17, %r18, %r5950;
	// inline asm
	mov.u32 	%r8945, 0;
	// inline asm
	shf.r.wrap.b32 %r8947, %r18, %r8945, %r5950;
	// inline asm
	mov.u32 	%r22, %r5927;
	mov.u32 	%r8946, %r8945;
	mov.u32 	%r18, %r5943;
	bra.uni 	BB0_1245;

BB0_1463:
	setp.eq.s32	%p1009, %r7595, 9;
	@%p1009 bra 	BB0_1464;
	bra.uni 	BB0_1483;

BB0_1464:
	mov.u32 	%r7941, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r15, %r16, %r7941;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r22, %r15, %r7941;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r21, %r22, %r7941;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7930, %r20, %r21, %r7941;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8933, %r19, %r20, %r7941;
	// inline asm
	mov.u32 	%r8935, 0;
	// inline asm
	shf.r.wrap.b32 %r8934, %r8935, %r19, %r7941;
	// inline asm
	mov.u32 	%r8936, %r8935;
	mov.u32 	%r19, %r7930;
	bra.uni 	BB0_1529;

BB0_169:
	setp.eq.s32	%p147, %r24, 18;
	@%p147 bra 	BB0_206;
	bra.uni 	BB0_170;

BB0_206:
	mov.u32 	%r2539, 16;
	// inline asm
	shf.r.wrap.b32 %r8788, %r21, %r22, %r2539;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8789, %r20, %r21, %r2539;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8790, %r19, %r20, %r2539;
	// inline asm
	mov.u32 	%r8784, 0;
	// inline asm
	shf.r.wrap.b32 %r8791, %r8784, %r19, %r2539;
	// inline asm
	bra.uni 	BB0_172;

BB0_1211:
	setp.eq.s32	%p783, %r24, 25;
	@%p783 bra 	BB0_1212;
	bra.uni 	BB0_1191;

BB0_1212:
	mov.u32 	%r5670, 8;
	// inline asm
	shf.r.wrap.b32 %r22, %r17, %r18, %r5670;
	// inline asm
	mov.u32 	%r8941, 0;
	// inline asm
	shf.r.wrap.b32 %r8943, %r18, %r8941, %r5670;
	// inline asm
	bra.uni 	BB0_1216;

BB0_1495:
	setp.eq.s32	%p986, %r7595, 25;
	@%p986 bra 	BB0_1496;
	bra.uni 	BB0_1483;

BB0_1496:
	mov.u32 	%r7661, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r19, %r20, %r7661;
	// inline asm
	mov.u32 	%r8933, 0;
	// inline asm
	shf.r.wrap.b32 %r17, %r8933, %r19, %r7661;
	// inline asm
	bra.uni 	BB0_1500;

BB0_1172:
	setp.eq.s32	%p812, %r24, 5;
	@%p812 bra 	BB0_1173;
	bra.uni 	BB0_1191;

BB0_1173:
	mov.u32 	%r6040, 8;
	// inline asm
	shf.r.wrap.b32 %r6013, %r20, %r21, %r6040;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r21, %r22, %r6040;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8942, %r22, %r15, %r6040;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8941, %r15, %r16, %r6040;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6029, %r16, %r17, %r6040;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8947, %r17, %r18, %r6040;
	// inline asm
	mov.u32 	%r8945, 0;
	// inline asm
	shf.r.wrap.b32 %r8946, %r18, %r8945, %r6040;
	// inline asm
	mov.u32 	%r22, %r6013;
	mov.u32 	%r18, %r6029;
	bra.uni 	BB0_1245;

BB0_714:
	setp.eq.s32	%p493, %r14, 11;
	@%p493 bra 	BB0_775;
	bra.uni 	BB0_715;

BB0_775:
	and.b32  	%r3966, %r21, 255;
	shl.b32 	%r3967, %r21, 8;
	and.b32  	%r3968, %r3967, 16711680;
	or.b32  	%r3969, %r3968, %r3966;
	shr.u32 	%r3970, %r21, 8;
	and.b32  	%r3971, %r3970, 65280;
	or.b32  	%r8942, %r3969, %r3971;
	mov.u32 	%r8949, 11;
	bra.uni 	BB0_776;

BB0_1455:
	setp.eq.s32	%p1015, %r7595, 5;
	@%p1015 bra 	BB0_1456;
	bra.uni 	BB0_1483;

BB0_1456:
	mov.u32 	%r8031, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r16, %r17, %r8031;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r15, %r16, %r8031;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r22, %r15, %r8031;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8016, %r21, %r22, %r8031;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8933, %r20, %r21, %r8031;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8934, %r19, %r20, %r8031;
	// inline asm
	mov.u32 	%r8936, 0;
	// inline asm
	shf.r.wrap.b32 %r8935, %r8936, %r19, %r8031;
	// inline asm
	mov.u32 	%r19, %r8016;
	bra.uni 	BB0_1529;

BB0_152:
	setp.eq.s32	%p159, %r24, 10;
	@%p159 bra 	BB0_210;
	bra.uni 	BB0_153;

BB0_210:
	mov.u32 	%r2689, 16;
	// inline asm
	shf.r.wrap.b32 %r8788, %r15, %r16, %r2689;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8789, %r22, %r15, %r2689;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8790, %r21, %r22, %r2689;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8791, %r20, %r21, %r2689;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8784, %r19, %r20, %r2689;
	// inline asm
	mov.u32 	%r8786, 0;
	// inline asm
	shf.r.wrap.b32 %r8785, %r8786, %r19, %r2689;
	// inline asm
	mov.u32 	%r8787, %r8786;
	bra.uni 	BB0_215;

BB0_1203:
	setp.eq.s32	%p789, %r24, 21;
	@%p789 bra 	BB0_1204;
	bra.uni 	BB0_1191;

BB0_1204:
	mov.u32 	%r5728, 8;
	// inline asm
	shf.r.wrap.b32 %r22, %r16, %r17, %r5728;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r17, %r18, %r5728;
	// inline asm
	mov.u32 	%r8941, 0;
	// inline asm
	shf.r.wrap.b32 %r8942, %r18, %r8941, %r5728;
	// inline asm
	bra.uni 	BB0_1244;

BB0_1486:
	setp.eq.s32	%p992, %r7595, 21;
	@%p992 bra 	BB0_1487;
	bra.uni 	BB0_1483;

BB0_1487:
	mov.u32 	%r7719, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r20, %r21, %r7719;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r19, %r20, %r7719;
	// inline asm
	mov.u32 	%r8933, 0;
	// inline asm
	shf.r.wrap.b32 %r16, %r8933, %r19, %r7719;
	// inline asm
	bra.uni 	BB0_1491;

BB0_1187:
	setp.eq.s32	%p801, %r24, 13;
	@%p801 bra 	BB0_1188;
	bra.uni 	BB0_1191;

BB0_1188:
	mov.u32 	%r5868, 8;
	// inline asm
	shf.r.wrap.b32 %r22, %r22, %r15, %r5868;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r15, %r16, %r5868;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8942, %r16, %r17, %r5868;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8941, %r17, %r18, %r5868;
	// inline asm
	mov.u32 	%r8945, 0;
	// inline asm
	shf.r.wrap.b32 %r18, %r18, %r8945, %r5868;
	// inline asm
	bra.uni 	BB0_1235;

BB0_743:
	setp.eq.s32	%p472, %r14, 26;
	@%p472 bra 	BB0_756;
	bra.uni 	BB0_744;

BB0_756:
	shl.b32 	%r3889, %r17, 8;
	and.b32  	%r3890, %r3889, 65280;
	bfe.u32 	%r3891, %r17, 8, 8;
	or.b32  	%r8946, %r3890, %r3891;
	mov.u32 	%r8949, 26;
	bra.uni 	BB0_757;

BB0_1470:
	setp.eq.s32	%p1004, %r7595, 13;
	@%p1004 bra 	BB0_1471;
	bra.uni 	BB0_1483;

BB0_1471:
	mov.u32 	%r7859, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r22, %r15, %r7859;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r21, %r22, %r7859;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r20, %r21, %r7859;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7852, %r19, %r20, %r7859;
	// inline asm
	mov.u32 	%r8934, 0;
	// inline asm
	shf.r.wrap.b32 %r8933, %r8934, %r19, %r7859;
	// inline asm
	mov.u32 	%r8935, %r8934;
	mov.u32 	%r8936, %r8934;
	mov.u32 	%r19, %r7852;
	bra.uni 	BB0_1529;

BB0_186:
	setp.eq.s32	%p136, %r24, 26;
	@%p136 bra 	BB0_202;
	bra.uni 	BB0_187;

BB0_202:
	mov.u32 	%r2421, 16;
	// inline asm
	shf.r.wrap.b32 %r8788, %r19, %r20, %r2421;
	// inline asm
	mov.u32 	%r8784, 0;
	// inline asm
	shf.r.wrap.b32 %r8789, %r8784, %r19, %r2421;
	// inline asm
	bra.uni 	BB0_189;

BB0_1219:
	setp.eq.s32	%p778, %r24, 29;
	@%p778 bra 	BB0_1220;
	bra.uni 	BB0_1191;

BB0_1220:
	mov.u32 	%r8941, 0;
	mov.u32 	%r5620, 8;
	// inline asm
	shf.r.wrap.b32 %r22, %r18, %r8941, %r5620;
	// inline asm
	bra.uni 	BB0_1243;

BB0_1503:
	setp.eq.s32	%p981, %r7595, 29;
	@%p981 bra 	BB0_1504;
	bra.uni 	BB0_1483;

BB0_1504:
	mov.u32 	%r8933, 0;
	mov.u32 	%r7611, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r8933, %r19, %r7611;
	// inline asm
	bra.uni 	BB0_1525;

BB0_706:
	setp.eq.s32	%p499, %r14, 7;
	@%p499 bra 	BB0_778;
	bra.uni 	BB0_707;

BB0_778:
	and.b32  	%r3987, %r20, 255;
	shl.b32 	%r3988, %r20, 8;
	and.b32  	%r3989, %r3988, 16711680;
	or.b32  	%r3990, %r3989, %r3987;
	shr.u32 	%r3991, %r20, 8;
	and.b32  	%r3992, %r3991, 65280;
	or.b32  	%r8943, %r3990, %r3992;
	mov.u32 	%r8949, 7;
	bra.uni 	BB0_779;

BB0_144:
	setp.eq.s32	%p165, %r24, 6;
	@%p165 bra 	BB0_212;
	bra.uni 	BB0_145;

BB0_212:
	mov.u32 	%r2776, 16;
	// inline asm
	shf.r.wrap.b32 %r8788, %r16, %r17, %r2776;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8789, %r15, %r16, %r2776;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8790, %r22, %r15, %r2776;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8791, %r21, %r22, %r2776;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8784, %r20, %r21, %r2776;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8785, %r19, %r20, %r2776;
	// inline asm
	mov.u32 	%r8787, 0;
	// inline asm
	shf.r.wrap.b32 %r8786, %r8787, %r19, %r2776;
	// inline asm
	bra.uni 	BB0_215;

BB0_1199:
	setp.eq.s32	%p792, %r24, 19;
	@%p792 bra 	BB0_1200;
	bra.uni 	BB0_1191;

BB0_1200:
	mov.u32 	%r5754, 24;
	// inline asm
	shf.r.wrap.b32 %r22, %r15, %r16, %r5754;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r16, %r17, %r5754;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8942, %r17, %r18, %r5754;
	// inline asm
	mov.u32 	%r8945, 0;
	// inline asm
	shf.r.wrap.b32 %r8941, %r18, %r8945, %r5754;
	// inline asm

BB0_1231:
	mov.u32 	%r8946, %r8945;
	mov.u32 	%r8947, %r8945;
	mov.u32 	%r18, %r8945;
	bra.uni 	BB0_1245;

BB0_1482:
	setp.eq.s32	%p995, %r7595, 19;
	@%p995 bra 	BB0_1513;
	bra.uni 	BB0_1483;

BB0_1513:
	mov.u32 	%r7745, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r21, %r22, %r7745;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r20, %r21, %r7745;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r19, %r20, %r7745;
	// inline asm
	mov.u32 	%r8933, 0;
	// inline asm
	shf.r.wrap.b32 %r19, %r8933, %r19, %r7745;
	// inline asm

BB0_1514:
	mov.u32 	%r8934, %r8933;
	mov.u32 	%r8935, %r8933;
	mov.u32 	%r8936, %r8933;
	bra.uni 	BB0_1529;

BB0_1183:
	setp.eq.s32	%p804, %r24, 11;
	@%p804 bra 	BB0_1184;
	bra.uni 	BB0_1191;

BB0_1184:
	mov.u32 	%r5898, 24;
	// inline asm
	shf.r.wrap.b32 %r5875, %r21, %r22, %r5898;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r22, %r15, %r5898;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8942, %r15, %r16, %r5898;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8941, %r16, %r17, %r5898;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5891, %r17, %r18, %r5898;
	// inline asm
	mov.u32 	%r8945, 0;
	// inline asm
	shf.r.wrap.b32 %r8947, %r18, %r8945, %r5898;
	// inline asm
	mov.u32 	%r22, %r5875;
	mov.u32 	%r8946, %r8945;
	mov.u32 	%r18, %r5891;
	bra.uni 	BB0_1245;

BB0_735:
	setp.eq.s32	%p478, %r14, 22;
	@%p478 bra 	BB0_759;
	bra.uni 	BB0_736;

BB0_759:
	shl.b32 	%r3910, %r16, 8;
	and.b32  	%r3911, %r3910, 65280;
	bfe.u32 	%r3912, %r16, 8, 8;
	or.b32  	%r8947, %r3911, %r3912;
	mov.u32 	%r8949, 22;
	bra.uni 	BB0_760;

BB0_1466:
	setp.eq.s32	%p1007, %r7595, 11;
	@%p1007 bra 	BB0_1467;
	bra.uni 	BB0_1483;

BB0_1467:
	mov.u32 	%r7889, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r15, %r16, %r7889;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r22, %r15, %r7889;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r21, %r22, %r7889;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7878, %r20, %r21, %r7889;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8933, %r19, %r20, %r7889;
	// inline asm
	mov.u32 	%r8935, 0;
	// inline asm
	shf.r.wrap.b32 %r8934, %r8935, %r19, %r7889;
	// inline asm
	mov.u32 	%r8936, %r8935;
	mov.u32 	%r19, %r7878;
	bra.uni 	BB0_1529;

BB0_177:
	setp.eq.s32	%p142, %r24, 22;
	@%p142 bra 	BB0_204;
	bra.uni 	BB0_178;

BB0_204:
	mov.u32 	%r2476, 16;
	// inline asm
	shf.r.wrap.b32 %r8788, %r20, %r21, %r2476;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8789, %r19, %r20, %r2476;
	// inline asm
	mov.u32 	%r8784, 0;
	// inline asm
	shf.r.wrap.b32 %r8790, %r8784, %r19, %r2476;
	// inline asm
	bra.uni 	BB0_180;

BB0_1214:
	setp.eq.s32	%p781, %r24, 27;
	@%p781 bra 	BB0_1215;
	bra.uni 	BB0_1191;

BB0_1215:
	mov.u32 	%r5642, 24;
	// inline asm
	shf.r.wrap.b32 %r22, %r17, %r18, %r5642;
	// inline asm
	mov.u32 	%r8941, 0;
	// inline asm
	shf.r.wrap.b32 %r8943, %r18, %r8941, %r5642;
	// inline asm

BB0_1216:
	mov.u32 	%r8942, %r8941;
	bra.uni 	BB0_1244;

BB0_1498:
	setp.eq.s32	%p984, %r7595, 27;
	@%p984 bra 	BB0_1499;
	bra.uni 	BB0_1483;

BB0_1499:
	mov.u32 	%r7633, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r19, %r20, %r7633;
	// inline asm
	mov.u32 	%r8933, 0;
	// inline asm
	shf.r.wrap.b32 %r17, %r8933, %r19, %r7633;
	// inline asm

BB0_1500:
	mov.u32 	%r8934, %r8933;
	mov.u32 	%r8935, %r8933;
	mov.u32 	%r8936, %r8933;
	bra.uni 	BB0_1527;

BB0_1175:
	setp.eq.s32	%p810, %r24, 7;
	@%p810 bra 	BB0_1176;
	bra.uni 	BB0_1191;

BB0_1176:
	mov.u32 	%r5982, 24;
	// inline asm
	shf.r.wrap.b32 %r5955, %r20, %r21, %r5982;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r21, %r22, %r5982;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8942, %r22, %r15, %r5982;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8941, %r15, %r16, %r5982;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5971, %r16, %r17, %r5982;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8947, %r17, %r18, %r5982;
	// inline asm
	mov.u32 	%r8945, 0;
	// inline asm
	shf.r.wrap.b32 %r8946, %r18, %r8945, %r5982;
	// inline asm
	mov.u32 	%r22, %r5955;
	mov.u32 	%r18, %r5971;
	bra.uni 	BB0_1245;

BB0_721:
	setp.eq.s32	%p488, %r14, 15;
	@%p488 bra 	BB0_767;
	bra.uni 	BB0_722;

BB0_767:
	and.b32  	%r3945, %r22, 255;
	shl.b32 	%r3946, %r22, 8;
	and.b32  	%r3947, %r3946, 16711680;
	or.b32  	%r3948, %r3947, %r3945;
	shr.u32 	%r3949, %r22, 8;
	and.b32  	%r3950, %r3949, 65280;
	or.b32  	%r8941, %r3948, %r3950;
	mov.u32 	%r8949, 15;
	bra.uni 	BB0_768;

BB0_1458:
	setp.eq.s32	%p1013, %r7595, 7;
	@%p1013 bra 	BB0_1459;
	bra.uni 	BB0_1483;

BB0_1459:
	mov.u32 	%r7973, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r16, %r17, %r7973;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r15, %r16, %r7973;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r22, %r15, %r7973;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7958, %r21, %r22, %r7973;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8933, %r20, %r21, %r7973;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8934, %r19, %r20, %r7973;
	// inline asm
	mov.u32 	%r8936, 0;
	// inline asm
	shf.r.wrap.b32 %r8935, %r8936, %r19, %r7973;
	// inline asm
	mov.u32 	%r19, %r7958;
	bra.uni 	BB0_1529;

BB0_159:
	setp.eq.s32	%p154, %r24, 14;
	@%p154 bra 	BB0_208;
	bra.uni 	BB0_160;

BB0_208:
	mov.u32 	%r2610, 16;
	// inline asm
	shf.r.wrap.b32 %r8788, %r22, %r15, %r2610;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8789, %r21, %r22, %r2610;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8790, %r20, %r21, %r2610;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8791, %r19, %r20, %r2610;
	// inline asm
	mov.u32 	%r8785, 0;
	// inline asm
	shf.r.wrap.b32 %r8784, %r8785, %r19, %r2610;
	// inline asm
	bra.uni 	BB0_162;

BB0_1206:
	setp.eq.s32	%p787, %r24, 23;
	@%p787 bra 	BB0_1207;
	bra.uni 	BB0_1191;

BB0_1207:
	mov.u32 	%r5694, 24;
	// inline asm
	shf.r.wrap.b32 %r22, %r16, %r17, %r5694;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r17, %r18, %r5694;
	// inline asm
	mov.u32 	%r8941, 0;
	// inline asm
	shf.r.wrap.b32 %r8942, %r18, %r8941, %r5694;
	// inline asm
	bra.uni 	BB0_1244;

BB0_1489:
	setp.eq.s32	%p990, %r7595, 23;
	@%p990 bra 	BB0_1490;
	bra.uni 	BB0_1483;

BB0_1490:
	mov.u32 	%r7685, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r20, %r21, %r7685;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r19, %r20, %r7685;
	// inline asm
	mov.u32 	%r8933, 0;
	// inline asm
	shf.r.wrap.b32 %r16, %r8933, %r19, %r7685;
	// inline asm

BB0_1491:
	mov.u32 	%r8934, %r8933;
	mov.u32 	%r8935, %r8933;
	mov.u32 	%r8936, %r8933;
	bra.uni 	BB0_1528;

BB0_1190:
	setp.eq.s32	%p799, %r24, 15;
	@%p799 bra 	BB0_1232;
	bra.uni 	BB0_1191;

BB0_1232:
	mov.u32 	%r5822, 24;
	// inline asm
	shf.r.wrap.b32 %r22, %r22, %r15, %r5822;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r15, %r16, %r5822;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8942, %r16, %r17, %r5822;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8941, %r17, %r18, %r5822;
	// inline asm
	mov.u32 	%r8945, 0;
	// inline asm
	shf.r.wrap.b32 %r18, %r18, %r8945, %r5822;
	// inline asm

BB0_1235:
	mov.u32 	%r8946, %r8945;
	mov.u32 	%r8947, %r8945;
	bra.uni 	BB0_1245;

BB0_750:
	setp.eq.s32	%p467, %r14, 30;
	@%p467 bra 	BB0_753;
	bra.uni 	BB0_751;

BB0_753:
	shl.b32 	%r3868, %r18, 8;
	and.b32  	%r3869, %r3868, 65280;
	bfe.u32 	%r3870, %r18, 8, 8;
	or.b32  	%r8945, %r3869, %r3870;
	mov.u32 	%r8949, 30;
	bra.uni 	BB0_754;

BB0_1473:
	setp.eq.s32	%p1002, %r7595, 15;
	@%p1002 bra 	BB0_1474;
	bra.uni 	BB0_1483;

BB0_1474:
	mov.u32 	%r7813, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r22, %r15, %r7813;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r21, %r22, %r7813;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r20, %r21, %r7813;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7806, %r19, %r20, %r7813;
	// inline asm
	mov.u32 	%r8934, 0;
	// inline asm
	shf.r.wrap.b32 %r8933, %r8934, %r19, %r7813;
	// inline asm
	mov.u32 	%r8935, %r8934;
	mov.u32 	%r8936, %r8934;
	mov.u32 	%r19, %r7806;
	bra.uni 	BB0_1529;

BB0_195:
	setp.eq.s32	%p131, %r24, 30;
	@%p131 bra 	BB0_199;
	bra.uni 	BB0_196;

BB0_199:
	mov.u32 	%r8784, 0;
	mov.u32 	%r2374, 16;
	// inline asm
	shf.r.wrap.b32 %r8788, %r8784, %r19, %r2374;
	// inline asm
	bra.uni 	BB0_198;

BB0_289:
	setp.eq.s32	%p219, %r24, 18;
	@%p219 bra 	BB0_323;
	bra.uni 	BB0_290;

BB0_323:
	mov.u32 	%r3137, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r21, %r22, %r3137;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r20, %r21, %r3137;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r19, %r20, %r3137;
	// inline asm
	mov.u32 	%r8808, 0;
	// inline asm
	shf.r.wrap.b32 %r19, %r8808, %r19, %r3137;
	// inline asm
	bra.uni 	BB0_322;

BB0_273:
	setp.eq.s32	%p231, %r24, 10;
	@%p231 bra 	BB0_327;
	bra.uni 	BB0_274;

BB0_327:
	mov.u32 	%r3287, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r15, %r16, %r3287;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r22, %r15, %r3287;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r21, %r22, %r3287;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3276, %r20, %r21, %r3287;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8808, %r19, %r20, %r3287;
	// inline asm
	mov.u32 	%r8810, 0;
	// inline asm
	shf.r.wrap.b32 %r8809, %r8810, %r19, %r3287;
	// inline asm
	mov.u32 	%r8811, %r8810;
	mov.u32 	%r19, %r3276;
	bra.uni 	BB0_338;

BB0_305:
	setp.eq.s32	%p208, %r24, 26;
	@%p208 bra 	BB0_317;
	bra.uni 	BB0_306;

BB0_317:
	mov.u32 	%r3019, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r19, %r20, %r3019;
	// inline asm
	mov.u32 	%r8808, 0;
	// inline asm
	shf.r.wrap.b32 %r17, %r8808, %r19, %r3019;
	// inline asm
	bra.uni 	BB0_308;

BB0_1222:
	setp.ne.s32	%p776, %r24, 30;
	@%p776 bra 	BB0_1191;

	mov.u32 	%r8941, 0;
	mov.u32 	%r5609, 16;
	// inline asm
	shf.r.wrap.b32 %r22, %r18, %r8941, %r5609;
	// inline asm

BB0_1243:
	mov.u32 	%r8942, %r8941;
	mov.u32 	%r8943, %r8941;

BB0_1244:
	mov.u32 	%r8945, %r8941;
	mov.u32 	%r8946, %r8941;
	mov.u32 	%r8947, %r8941;
	mov.u32 	%r18, %r8941;
	bra.uni 	BB0_1245;

BB0_1191:
	mov.u32 	%r8941, %r22;
	mov.u32 	%r8942, %r21;
	mov.u32 	%r8943, %r20;
	mov.u32 	%r22, %r19;
	mov.u32 	%r8945, %r18;
	mov.u32 	%r8946, %r17;
	mov.u32 	%r8947, %r16;
	mov.u32 	%r18, %r15;

BB0_1245:
	and.b32  	%r6151, %r25, 3;
	shl.b32 	%r6152, %r6151, 3;
	mov.u32 	%r6153, 1;
	shl.b32 	%r6154, %r6153, %r6152;
	add.s32 	%r1193, %r6154, -1;
	shr.u32 	%r6150, %r26, 2;
	setp.gt.s32	%p816, %r6150, 3;
	@%p816 bra 	BB0_1253;

	setp.gt.s32	%p822, %r6150, 1;
	@%p822 bra 	BB0_1250;

	setp.eq.s32	%p825, %r6150, 0;
	@%p825 bra 	BB0_1267;
	bra.uni 	BB0_1248;

BB0_1267:
	and.b32  	%r8944, %r22, %r1193;
	mov.u32 	%r8941, 0;
	mov.u32 	%r8942, %r8941;
	mov.u32 	%r8943, %r8941;
	bra.uni 	BB0_1266;

BB0_1253:
	setp.gt.s32	%p817, %r6150, 5;
	@%p817 bra 	BB0_1257;

	setp.eq.s32	%p820, %r6150, 4;
	@%p820 bra 	BB0_1263;
	bra.uni 	BB0_1255;

BB0_1263:
	and.b32  	%r8948, %r18, %r1193;
	mov.u32 	%r8945, 0;
	mov.u32 	%r8944, %r22;
	mov.u32 	%r8946, %r8945;
	mov.u32 	%r8947, %r8945;
	mov.u32 	%r8949, %r26;
	bra.uni 	BB0_1554;

BB0_1250:
	setp.eq.s32	%p823, %r6150, 2;
	@%p823 bra 	BB0_1264;
	bra.uni 	BB0_1251;

BB0_1264:
	and.b32  	%r8942, %r8942, %r1193;
	mov.u32 	%r8941, 0;
	bra.uni 	BB0_1265;

BB0_1257:
	setp.eq.s32	%p818, %r6150, 6;
	@%p818 bra 	BB0_1262;
	bra.uni 	BB0_1258;

BB0_1262:
	and.b32  	%r8946, %r8946, %r1193;
	mov.u32 	%r8945, 0;
	bra.uni 	BB0_1260;

BB0_1248:
	setp.eq.s32	%p826, %r6150, 1;
	@%p826 bra 	BB0_1249;
	bra.uni 	BB0_1260;

BB0_1249:
	and.b32  	%r8943, %r8943, %r1193;
	mov.u32 	%r8941, 0;
	mov.u32 	%r8942, %r8941;

BB0_1265:
	mov.u32 	%r8944, %r22;

BB0_1266:
	mov.u32 	%r8945, %r8941;
	mov.u32 	%r8946, %r8941;
	mov.u32 	%r8947, %r8941;
	mov.u32 	%r8948, %r8941;
	mov.u32 	%r8949, %r26;
	bra.uni 	BB0_1554;

BB0_1255:
	setp.eq.s32	%p821, %r6150, 5;
	@%p821 bra 	BB0_1256;
	bra.uni 	BB0_1260;

BB0_1256:
	and.b32  	%r8947, %r8947, %r1193;
	mov.u32 	%r8945, 0;
	mov.u32 	%r8944, %r22;
	mov.u32 	%r8946, %r8945;
	bra.uni 	BB0_1261;

BB0_1251:
	setp.eq.s32	%p824, %r6150, 3;
	@%p824 bra 	BB0_1252;
	bra.uni 	BB0_1260;

BB0_1252:
	and.b32  	%r8941, %r8941, %r1193;
	mov.u32 	%r8945, 0;
	mov.u32 	%r8944, %r22;
	mov.u32 	%r8946, %r8945;
	mov.u32 	%r8947, %r8945;
	mov.u32 	%r8948, %r8945;
	mov.u32 	%r8949, %r26;
	bra.uni 	BB0_1554;

BB0_1258:
	setp.ne.s32	%p819, %r6150, 7;
	@%p819 bra 	BB0_1260;

	and.b32  	%r8945, %r8945, %r1193;

BB0_1260:
	mov.u32 	%r8944, %r22;

BB0_1261:
	mov.u32 	%r8948, %r18;
	mov.u32 	%r8949, %r26;
	bra.uni 	BB0_1554;

BB0_1506:
	setp.ne.s32	%p979, %r7595, 30;
	@%p979 bra 	BB0_1483;

	mov.u32 	%r8933, 0;
	mov.u32 	%r7600, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r8933, %r19, %r7600;
	// inline asm

BB0_1525:
	mov.u32 	%r8934, %r8933;
	mov.u32 	%r8935, %r8933;
	mov.u32 	%r8936, %r8933;

BB0_1526:
	mov.u32 	%r17, %r8933;

BB0_1527:
	mov.u32 	%r16, %r8933;

BB0_1528:
	mov.u32 	%r19, %r8933;
	bra.uni 	BB0_1529;

BB0_1483:
	mov.u32 	%r8933, %r22;
	mov.u32 	%r8934, %r21;
	mov.u32 	%r8935, %r20;
	mov.u32 	%r8936, %r19;
	mov.u32 	%r19, %r15;

BB0_1529:
	// inline asm
	prmt.b32 %r8944, %r18, 0, 0x0123;
	// inline asm
	// inline asm
	prmt.b32 %r8943, %r17, 0, 0x0123;
	// inline asm
	// inline asm
	prmt.b32 %r8942, %r16, 0, 0x0123;
	// inline asm
	// inline asm
	prmt.b32 %r8941, %r19, 0, 0x0123;
	// inline asm
	// inline asm
	prmt.b32 %r8948, %r8933, 0, 0x0123;
	// inline asm
	// inline asm
	prmt.b32 %r8947, %r8934, 0, 0x0123;
	// inline asm
	// inline asm
	prmt.b32 %r8946, %r8935, 0, 0x0123;
	// inline asm
	// inline asm
	prmt.b32 %r8945, %r8936, 0, 0x0123;
	// inline asm
	bra.uni 	BB0_1553;

BB0_265:
	setp.eq.s32	%p237, %r24, 6;
	@%p237 bra 	BB0_329;
	bra.uni 	BB0_266;

BB0_329:
	mov.u32 	%r3374, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r16, %r17, %r3374;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r15, %r16, %r3374;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r22, %r15, %r3374;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3359, %r21, %r22, %r3374;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8808, %r20, %r21, %r3374;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8809, %r19, %r20, %r3374;
	// inline asm
	mov.u32 	%r8811, 0;
	// inline asm
	shf.r.wrap.b32 %r8810, %r8811, %r19, %r3374;
	// inline asm
	mov.u32 	%r19, %r3359;
	bra.uni 	BB0_338;

BB0_296:
	setp.eq.s32	%p214, %r24, 22;
	@%p214 bra 	BB0_319;
	bra.uni 	BB0_297;

BB0_319:
	mov.u32 	%r3074, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r20, %r21, %r3074;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r19, %r20, %r3074;
	// inline asm
	mov.u32 	%r8808, 0;
	// inline asm
	shf.r.wrap.b32 %r16, %r8808, %r19, %r3074;
	// inline asm
	bra.uni 	BB0_299;

BB0_280:
	setp.eq.s32	%p226, %r24, 14;
	@%p226 bra 	BB0_325;
	bra.uni 	BB0_281;

BB0_325:
	mov.u32 	%r3208, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r22, %r15, %r3208;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r21, %r22, %r3208;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r20, %r21, %r3208;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3201, %r19, %r20, %r3208;
	// inline asm
	mov.u32 	%r8809, 0;
	// inline asm
	shf.r.wrap.b32 %r8808, %r8809, %r19, %r3208;
	// inline asm
	mov.u32 	%r8810, %r8809;
	mov.u32 	%r8811, %r8809;
	mov.u32 	%r19, %r3201;
	bra.uni 	BB0_338;

BB0_313:
	setp.eq.s32	%p203, %r24, 31;
	@%p203 bra 	BB0_333;
	bra.uni 	BB0_314;

BB0_333:
	mov.u32 	%r8808, 0;
	mov.u32 	%r3505, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r8808, %r19, %r3505;
	// inline asm
	bra.uni 	BB0_334;

BB0_868:
	mov.u32 	%r4625, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r17, %r18, %r4625;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r16, %r17, %r4625;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r15, %r16, %r4625;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r15, %r22, %r15, %r4625;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8941, %r21, %r22, %r4625;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8942, %r20, %r21, %r4625;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r19, %r20, %r4625;
	// inline asm
	mov.u32 	%r4623, 0;
	// inline asm
	shf.r.wrap.b32 %r8944, %r4623, %r19, %r4625;
	// inline asm
	bra.uni 	BB0_874;

BB0_794:
	setp.eq.s32	%p578, %r24, 3;
	@%p578 bra 	BB0_795;
	bra.uni 	BB0_827;

BB0_795:
	mov.u32 	%r4561, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r17, %r18, %r4561;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r16, %r17, %r4561;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r15, %r16, %r4561;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r15, %r22, %r15, %r4561;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8941, %r21, %r22, %r4561;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8942, %r20, %r21, %r4561;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r19, %r20, %r4561;
	// inline asm
	mov.u32 	%r4559, 0;
	// inline asm
	shf.r.wrap.b32 %r8944, %r4559, %r19, %r4561;
	// inline asm
	bra.uni 	BB0_874;

BB0_1058:
	setp.eq.s32	%p756, %r26, 1;
	mov.u32 	%r8941, %r8945;
	mov.u32 	%r8942, %r8945;
	mov.u32 	%r8943, %r8945;
	mov.u32 	%r8862, %r8945;
	mov.u32 	%r8946, %r8945;
	mov.u32 	%r8947, %r8945;
	mov.u32 	%r8948, %r8945;
	@%p756 bra 	BB0_1059;
	bra.uni 	BB0_1137;

BB0_1059:
	mov.u32 	%r5583, 8;
	// inline asm
	shf.r.wrap.b32 %r8862, %r19, %r20, %r5583;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r20, %r21, %r5583;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8942, %r21, %r22, %r5583;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8941, %r22, %r15, %r5583;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8948, %r15, %r16, %r5583;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8947, %r16, %r17, %r5583;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8946, %r17, %r18, %r5583;
	// inline asm
	mov.u32 	%r5582, 0;
	// inline asm
	shf.r.wrap.b32 %r8945, %r18, %r5582, %r5583;
	// inline asm
	bra.uni 	BB0_1137;

BB0_781:
	shl.b32 	%r4015, %r19, 8;
	and.b32  	%r4016, %r4015, 65280;
	bfe.u32 	%r4017, %r19, 8, 8;
	or.b32  	%r8944, %r4016, %r4017;
	mov.u32 	%r8949, 2;
	bra.uni 	BB0_782;

BB0_700:
	setp.eq.s32	%p505, %r14, 4;
	@%p505 bra 	BB0_701;
	bra.uni 	BB0_11;

BB0_701:
	and.b32  	%r4001, %r19, 65535;
	shl.b32 	%r4002, %r19, 8;
	and.b32  	%r4003, %r4002, -16777216;
	or.b32  	%r4004, %r4003, %r4001;
	shr.u32 	%r4005, %r19, 8;
	and.b32  	%r4006, %r4005, 16711680;
	or.b32  	%r8944, %r4004, %r4006;
	mov.u32 	%r8949, 4;

BB0_782:
	mov.u32 	%r8941, %r22;
	mov.u32 	%r8942, %r21;
	mov.u32 	%r8943, %r20;
	bra.uni 	BB0_771;

BB0_454:
	setp.eq.s32	%p367, %r24, 1;
	mov.u32 	%r8816, %r8825;
	@%p367 bra 	BB0_455;
	bra.uni 	BB0_528;

BB0_455:
	bfe.u32 	%r8816, %r19, 8, 8;
	bra.uni 	BB0_528;

BB0_1316:
	setp.eq.s32	%p932, %r6470, 2;
	@%p932 bra 	BB0_1393;
	bra.uni 	BB0_1317;

BB0_1393:
	mov.u32 	%r6983, 16;
	// inline asm
	shf.r.wrap.b32 %r8895, %r17, %r18, %r6983;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8896, %r16, %r17, %r6983;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8897, %r15, %r16, %r6983;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8898, %r22, %r15, %r6983;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8891, %r21, %r22, %r6983;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8892, %r20, %r21, %r6983;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8893, %r19, %r20, %r6983;
	// inline asm
	mov.u32 	%r6981, 0;
	// inline asm
	shf.r.wrap.b32 %r8894, %r6981, %r19, %r6983;
	// inline asm
	bra.uni 	BB0_1394;

BB0_1090:
	setp.eq.s32	%p733, %r26, 17;
	mov.u32 	%r8941, %r8945;
	mov.u32 	%r8942, %r8945;
	mov.u32 	%r8943, %r8945;
	mov.u32 	%r8862, %r8945;
	mov.u32 	%r8946, %r8945;
	mov.u32 	%r8947, %r8945;
	mov.u32 	%r8948, %r8945;
	@%p733 bra 	BB0_1091;
	bra.uni 	BB0_1137;

BB0_1091:
	mov.u32 	%r5239, 8;
	// inline asm
	shf.r.wrap.b32 %r8862, %r15, %r16, %r5239;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r16, %r17, %r5239;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8942, %r17, %r18, %r5239;
	// inline asm
	mov.u32 	%r8945, 0;
	// inline asm
	shf.r.wrap.b32 %r8941, %r18, %r8945, %r5239;
	// inline asm
	bra.uni 	BB0_1122;

BB0_485:
	setp.eq.s32	%p344, %r24, 17;
	mov.u32 	%r8816, %r8825;
	@%p344 bra 	BB0_486;
	bra.uni 	BB0_528;

BB0_486:
	bfe.u32 	%r8816, %r15, 8, 8;
	bra.uni 	BB0_528;

BB0_823:
	setp.eq.s32	%p557, %r24, 17;
	@%p557 bra 	BB0_824;
	bra.uni 	BB0_827;

BB0_824:
	mov.u32 	%r4281, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r21, %r22, %r4281;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r20, %r21, %r4281;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r19, %r20, %r4281;
	// inline asm
	mov.u32 	%r8941, 0;
	// inline asm
	shf.r.wrap.b32 %r15, %r8941, %r19, %r4281;
	// inline asm
	bra.uni 	BB0_858;

BB0_766:
	or.b32  	%r3935, %r15, %r22;
	and.b32  	%r3936, %r22, 16777215;
	prmt.b32 	%r8941, %r15, %r3936, 1620;
	shr.u32 	%r8948, %r3935, 24;
	mov.u32 	%r8949, 17;
	bra.uni 	BB0_764;

BB0_728:
	setp.eq.s32	%p484, %r14, 19;
	@%p484 bra 	BB0_729;
	bra.uni 	BB0_11;

BB0_729:
	and.b32  	%r3924, %r15, 255;
	shl.b32 	%r3925, %r15, 8;
	and.b32  	%r3926, %r3925, 16711680;
	or.b32  	%r3927, %r3926, %r3924;
	shr.u32 	%r3928, %r15, 8;
	and.b32  	%r3929, %r3928, 65280;
	or.b32  	%r8948, %r3927, %r3929;
	mov.u32 	%r8949, 19;

BB0_763:
	mov.u32 	%r8941, %r22;

BB0_764:
	mov.u32 	%r8942, %r21;
	mov.u32 	%r8943, %r20;
	mov.u32 	%r8944, %r19;
	bra.uni 	BB0_765;

BB0_1073:
	setp.eq.s32	%p745, %r26, 9;
	mov.u32 	%r8941, %r8945;
	mov.u32 	%r8942, %r8945;
	mov.u32 	%r8943, %r8945;
	mov.u32 	%r8862, %r8945;
	mov.u32 	%r8946, %r8945;
	mov.u32 	%r8947, %r8945;
	mov.u32 	%r8948, %r8945;
	@%p745 bra 	BB0_1074;
	bra.uni 	BB0_1137;

BB0_1074:
	mov.u32 	%r5395, 8;
	// inline asm
	shf.r.wrap.b32 %r8862, %r21, %r22, %r5395;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r22, %r15, %r5395;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8942, %r15, %r16, %r5395;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8941, %r16, %r17, %r5395;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8948, %r17, %r18, %r5395;
	// inline asm
	mov.u32 	%r8945, 0;
	// inline asm
	shf.r.wrap.b32 %r8947, %r18, %r8945, %r5395;
	// inline asm
	mov.u32 	%r8946, %r8945;
	bra.uni 	BB0_1137;

BB0_469:
	setp.eq.s32	%p356, %r24, 9;
	mov.u32 	%r8816, %r8825;
	@%p356 bra 	BB0_470;
	bra.uni 	BB0_528;

BB0_470:
	bfe.u32 	%r8816, %r21, 8, 8;
	bra.uni 	BB0_528;

BB0_1348:
	setp.eq.s32	%p909, %r6470, 18;
	@%p909 bra 	BB0_1385;
	bra.uni 	BB0_1349;

BB0_1385:
	mov.u32 	%r6651, 16;
	// inline asm
	shf.r.wrap.b32 %r8895, %r21, %r22, %r6651;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8896, %r20, %r21, %r6651;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8897, %r19, %r20, %r6651;
	// inline asm
	mov.u32 	%r8891, 0;
	// inline asm
	shf.r.wrap.b32 %r8898, %r8891, %r19, %r6651;
	// inline asm
	bra.uni 	BB0_1351;

BB0_806:
	setp.eq.s32	%p569, %r24, 9;
	@%p569 bra 	BB0_807;
	bra.uni 	BB0_827;

BB0_807:
	mov.u32 	%r4437, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r15, %r16, %r4437;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r22, %r15, %r4437;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r21, %r22, %r4437;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r15, %r20, %r21, %r4437;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8941, %r19, %r20, %r4437;
	// inline asm
	mov.u32 	%r8943, 0;
	// inline asm
	shf.r.wrap.b32 %r8942, %r8943, %r19, %r4437;
	// inline asm
	mov.u32 	%r8944, %r8943;
	bra.uni 	BB0_874;

BB0_1105:
	setp.eq.s32	%p722, %r26, 25;
	mov.u32 	%r8941, %r8945;
	mov.u32 	%r8942, %r8945;
	mov.u32 	%r8943, %r8945;
	mov.u32 	%r8862, %r8945;
	mov.u32 	%r8946, %r8945;
	mov.u32 	%r8947, %r8945;
	mov.u32 	%r8948, %r8945;
	@%p722 bra 	BB0_1106;
	bra.uni 	BB0_1137;

BB0_1106:
	mov.u32 	%r5115, 8;
	// inline asm
	shf.r.wrap.b32 %r8862, %r17, %r18, %r5115;
	// inline asm
	mov.u32 	%r8941, 0;
	// inline asm
	shf.r.wrap.b32 %r8943, %r18, %r8941, %r5115;
	// inline asm
	bra.uni 	BB0_1110;

BB0_500:
	setp.eq.s32	%p333, %r24, 25;
	mov.u32 	%r8816, %r8825;
	@%p333 bra 	BB0_501;
	bra.uni 	BB0_528;

BB0_501:
	bfe.u32 	%r8816, %r17, 8, 8;
	bra.uni 	BB0_528;

BB0_839:
	setp.eq.s32	%p546, %r24, 25;
	@%p546 bra 	BB0_840;
	bra.uni 	BB0_827;

BB0_840:
	mov.u32 	%r4157, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r19, %r20, %r4157;
	// inline asm
	mov.u32 	%r8941, 0;
	// inline asm
	shf.r.wrap.b32 %r17, %r8941, %r19, %r4157;
	// inline asm
	bra.uni 	BB0_844;

BB0_1065:
	setp.eq.s32	%p751, %r26, 5;
	mov.u32 	%r8941, %r8945;
	mov.u32 	%r8942, %r8945;
	mov.u32 	%r8943, %r8945;
	mov.u32 	%r8862, %r8945;
	mov.u32 	%r8946, %r8945;
	mov.u32 	%r8947, %r8945;
	mov.u32 	%r8948, %r8945;
	@%p751 bra 	BB0_1066;
	bra.uni 	BB0_1137;

BB0_1066:
	mov.u32 	%r5485, 8;
	// inline asm
	shf.r.wrap.b32 %r8862, %r20, %r21, %r5485;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r21, %r22, %r5485;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8942, %r22, %r15, %r5485;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8941, %r15, %r16, %r5485;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8948, %r16, %r17, %r5485;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8947, %r17, %r18, %r5485;
	// inline asm
	mov.u32 	%r8945, 0;
	// inline asm
	shf.r.wrap.b32 %r8946, %r18, %r8945, %r5485;
	// inline asm
	bra.uni 	BB0_1137;

BB0_461:
	setp.eq.s32	%p362, %r24, 5;
	mov.u32 	%r8816, %r8825;
	@%p362 bra 	BB0_462;
	bra.uni 	BB0_528;

BB0_462:
	bfe.u32 	%r8816, %r20, 8, 8;
	bra.uni 	BB0_528;

BB0_1331:
	setp.eq.s32	%p921, %r6470, 10;
	@%p921 bra 	BB0_1389;
	bra.uni 	BB0_1332;

BB0_1389:
	mov.u32 	%r6801, 16;
	// inline asm
	shf.r.wrap.b32 %r8895, %r15, %r16, %r6801;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8896, %r22, %r15, %r6801;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8897, %r21, %r22, %r6801;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8898, %r20, %r21, %r6801;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8891, %r19, %r20, %r6801;
	// inline asm
	mov.u32 	%r8893, 0;
	// inline asm
	shf.r.wrap.b32 %r8892, %r8893, %r19, %r6801;
	// inline asm
	mov.u32 	%r8894, %r8893;
	bra.uni 	BB0_1394;

BB0_798:
	setp.eq.s32	%p575, %r24, 5;
	@%p575 bra 	BB0_799;
	bra.uni 	BB0_827;

BB0_799:
	mov.u32 	%r4527, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r16, %r17, %r4527;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r15, %r16, %r4527;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r22, %r15, %r4527;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r15, %r21, %r22, %r4527;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8941, %r20, %r21, %r4527;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8942, %r19, %r20, %r4527;
	// inline asm
	mov.u32 	%r8944, 0;
	// inline asm
	shf.r.wrap.b32 %r8943, %r8944, %r19, %r4527;
	// inline asm
	bra.uni 	BB0_874;

BB0_1097:
	setp.eq.s32	%p728, %r26, 21;
	mov.u32 	%r8941, %r8945;
	mov.u32 	%r8942, %r8945;
	mov.u32 	%r8943, %r8945;
	mov.u32 	%r8862, %r8945;
	mov.u32 	%r8946, %r8945;
	mov.u32 	%r8947, %r8945;
	mov.u32 	%r8948, %r8945;
	@%p728 bra 	BB0_1098;
	bra.uni 	BB0_1137;

BB0_1098:
	mov.u32 	%r5173, 8;
	// inline asm
	shf.r.wrap.b32 %r8862, %r16, %r17, %r5173;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r17, %r18, %r5173;
	// inline asm
	mov.u32 	%r8941, 0;
	// inline asm
	shf.r.wrap.b32 %r8942, %r18, %r8941, %r5173;
	// inline asm
	bra.uni 	BB0_1111;

BB0_492:
	setp.eq.s32	%p339, %r24, 21;
	mov.u32 	%r8816, %r8825;
	@%p339 bra 	BB0_493;
	bra.uni 	BB0_528;

BB0_493:
	bfe.u32 	%r8816, %r16, 8, 8;
	bra.uni 	BB0_528;

BB0_830:
	setp.eq.s32	%p552, %r24, 21;
	@%p552 bra 	BB0_831;
	bra.uni 	BB0_827;

BB0_831:
	mov.u32 	%r4215, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r20, %r21, %r4215;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r19, %r20, %r4215;
	// inline asm
	mov.u32 	%r8941, 0;
	// inline asm
	shf.r.wrap.b32 %r16, %r8941, %r19, %r4215;
	// inline asm
	bra.uni 	BB0_835;

BB0_1080:
	setp.eq.s32	%p740, %r26, 13;
	mov.u32 	%r8941, %r8945;
	mov.u32 	%r8942, %r8945;
	mov.u32 	%r8943, %r8945;
	mov.u32 	%r8862, %r8945;
	mov.u32 	%r8946, %r8945;
	mov.u32 	%r8947, %r8945;
	mov.u32 	%r8948, %r8945;
	@%p740 bra 	BB0_1081;
	bra.uni 	BB0_1137;

BB0_1081:
	mov.u32 	%r5313, 8;
	// inline asm
	shf.r.wrap.b32 %r8862, %r22, %r15, %r5313;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r15, %r16, %r5313;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8942, %r16, %r17, %r5313;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8941, %r17, %r18, %r5313;
	// inline asm
	mov.u32 	%r8945, 0;
	// inline asm
	shf.r.wrap.b32 %r8948, %r18, %r8945, %r5313;
	// inline asm
	bra.uni 	BB0_1085;

BB0_476:
	setp.eq.s32	%p351, %r24, 13;
	mov.u32 	%r8816, %r8825;
	@%p351 bra 	BB0_477;
	bra.uni 	BB0_528;

BB0_477:
	bfe.u32 	%r8816, %r22, 8, 8;
	bra.uni 	BB0_528;

BB0_1365:
	setp.eq.s32	%p898, %r6470, 26;
	@%p898 bra 	BB0_1381;
	bra.uni 	BB0_1366;

BB0_1381:
	mov.u32 	%r6533, 16;
	// inline asm
	shf.r.wrap.b32 %r8895, %r19, %r20, %r6533;
	// inline asm
	mov.u32 	%r8891, 0;
	// inline asm
	shf.r.wrap.b32 %r8896, %r8891, %r19, %r6533;
	// inline asm
	bra.uni 	BB0_1368;

BB0_813:
	setp.eq.s32	%p564, %r24, 13;
	@%p564 bra 	BB0_814;
	bra.uni 	BB0_827;

BB0_814:
	mov.u32 	%r4355, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r22, %r15, %r4355;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r21, %r22, %r4355;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r20, %r21, %r4355;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r15, %r19, %r20, %r4355;
	// inline asm
	mov.u32 	%r8942, 0;
	// inline asm
	shf.r.wrap.b32 %r8941, %r8942, %r19, %r4355;
	// inline asm
	bra.uni 	BB0_818;

BB0_1114:
	setp.eq.s32	%p717, %r26, 29;
	mov.u32 	%r8941, %r8945;
	mov.u32 	%r8942, %r8945;
	mov.u32 	%r8943, %r8945;
	mov.u32 	%r8862, %r8945;
	mov.u32 	%r8946, %r8945;
	mov.u32 	%r8947, %r8945;
	mov.u32 	%r8948, %r8945;
	@%p717 bra 	BB0_1115;
	bra.uni 	BB0_1137;

BB0_1115:
	mov.u32 	%r8941, 0;
	mov.u32 	%r5065, 8;
	// inline asm
	shf.r.wrap.b32 %r8862, %r18, %r8941, %r5065;
	// inline asm
	bra.uni 	BB0_1119;

BB0_507:
	setp.eq.s32	%p328, %r24, 29;
	mov.u32 	%r8816, %r8825;
	@%p328 bra 	BB0_508;
	bra.uni 	BB0_528;

BB0_508:
	bfe.u32 	%r8816, %r18, 8, 8;
	bra.uni 	BB0_528;

BB0_847:
	setp.eq.s32	%p541, %r24, 29;
	mov.u32 	%r8941, %r22;
	mov.u32 	%r8942, %r21;
	mov.u32 	%r8943, %r20;
	mov.u32 	%r8944, %r19;
	@%p541 bra 	BB0_848;
	bra.uni 	BB0_874;

BB0_848:
	mov.u32 	%r8941, 0;
	mov.u32 	%r4107, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r8941, %r19, %r4107;
	// inline asm
	bra.uni 	BB0_870;

BB0_332:
	mov.u32 	%r3501, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r17, %r18, %r3501;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r16, %r17, %r3501;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r15, %r16, %r3501;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3482, %r22, %r15, %r3501;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8808, %r21, %r22, %r3501;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8809, %r20, %r21, %r3501;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8810, %r19, %r20, %r3501;
	// inline asm
	mov.u32 	%r3499, 0;
	// inline asm
	shf.r.wrap.b32 %r8811, %r3499, %r19, %r3501;
	// inline asm
	mov.u32 	%r19, %r3482;
	bra.uni 	BB0_338;

BB0_259:
	setp.eq.s32	%p243, %r24, 3;
	@%p243 bra 	BB0_260;
	bra.uni 	BB0_291;

BB0_260:
	mov.u32 	%r3437, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r17, %r18, %r3437;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r16, %r17, %r3437;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r15, %r16, %r3437;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3418, %r22, %r15, %r3437;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8808, %r21, %r22, %r3437;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8809, %r20, %r21, %r3437;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8810, %r19, %r20, %r3437;
	// inline asm
	mov.u32 	%r3435, 0;
	// inline asm
	shf.r.wrap.b32 %r8811, %r3435, %r19, %r3437;
	// inline asm
	mov.u32 	%r19, %r3418;
	bra.uni 	BB0_338;

BB0_1061:
	setp.eq.s32	%p754, %r26, 3;
	mov.u32 	%r8941, %r8945;
	mov.u32 	%r8942, %r8945;
	mov.u32 	%r8943, %r8945;
	mov.u32 	%r8862, %r8945;
	mov.u32 	%r8946, %r8945;
	mov.u32 	%r8947, %r8945;
	mov.u32 	%r8948, %r8945;
	@%p754 bra 	BB0_1062;
	bra.uni 	BB0_1137;

BB0_1062:
	mov.u32 	%r5519, 24;
	// inline asm
	shf.r.wrap.b32 %r8862, %r19, %r20, %r5519;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r20, %r21, %r5519;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8942, %r21, %r22, %r5519;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8941, %r22, %r15, %r5519;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8948, %r15, %r16, %r5519;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8947, %r16, %r17, %r5519;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8946, %r17, %r18, %r5519;
	// inline asm
	mov.u32 	%r5518, 0;
	// inline asm
	shf.r.wrap.b32 %r8945, %r18, %r5518, %r5519;
	// inline asm
	bra.uni 	BB0_1137;

BB0_457:
	setp.eq.s32	%p365, %r24, 3;
	mov.u32 	%r8816, %r8825;
	@%p365 bra 	BB0_458;
	bra.uni 	BB0_528;

BB0_458:
	shr.u32 	%r8816, %r19, 24;
	bra.uni 	BB0_528;

BB0_1323:
	setp.eq.s32	%p927, %r6470, 6;
	@%p927 bra 	BB0_1391;
	bra.uni 	BB0_1324;

BB0_1391:
	mov.u32 	%r6888, 16;
	// inline asm
	shf.r.wrap.b32 %r8895, %r16, %r17, %r6888;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8896, %r15, %r16, %r6888;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8897, %r22, %r15, %r6888;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8898, %r21, %r22, %r6888;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8891, %r20, %r21, %r6888;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8892, %r19, %r20, %r6888;
	// inline asm
	mov.u32 	%r8894, 0;
	// inline asm
	shf.r.wrap.b32 %r8893, %r8894, %r19, %r6888;
	// inline asm
	bra.uni 	BB0_1394;

BB0_1093:
	setp.eq.s32	%p731, %r26, 19;
	mov.u32 	%r8941, %r8945;
	mov.u32 	%r8942, %r8945;
	mov.u32 	%r8943, %r8945;
	mov.u32 	%r8862, %r8945;
	mov.u32 	%r8946, %r8945;
	mov.u32 	%r8947, %r8945;
	mov.u32 	%r8948, %r8945;
	@%p731 bra 	BB0_1094;
	bra.uni 	BB0_1137;

BB0_1094:
	mov.u32 	%r5199, 24;
	// inline asm
	shf.r.wrap.b32 %r8862, %r15, %r16, %r5199;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r16, %r17, %r5199;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8942, %r17, %r18, %r5199;
	// inline asm
	mov.u32 	%r8945, 0;
	// inline asm
	shf.r.wrap.b32 %r8941, %r18, %r8945, %r5199;
	// inline asm

BB0_1122:
	mov.u32 	%r8946, %r8945;
	mov.u32 	%r8947, %r8945;
	mov.u32 	%r8948, %r8945;
	bra.uni 	BB0_1137;

BB0_488:
	setp.eq.s32	%p342, %r24, 19;
	mov.u32 	%r8816, %r8825;
	@%p342 bra 	BB0_489;
	bra.uni 	BB0_528;

BB0_489:
	shr.u32 	%r8816, %r15, 24;
	bra.uni 	BB0_528;

BB0_826:
	setp.eq.s32	%p555, %r24, 19;
	@%p555 bra 	BB0_857;
	bra.uni 	BB0_827;

BB0_857:
	mov.u32 	%r4241, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r21, %r22, %r4241;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r20, %r21, %r4241;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r19, %r20, %r4241;
	// inline asm
	mov.u32 	%r8941, 0;
	// inline asm
	shf.r.wrap.b32 %r15, %r8941, %r19, %r4241;
	// inline asm

BB0_858:
	mov.u32 	%r8942, %r8941;
	mov.u32 	%r8943, %r8941;
	mov.u32 	%r8944, %r8941;
	bra.uni 	BB0_874;

BB0_1076:
	setp.eq.s32	%p743, %r26, 11;
	mov.u32 	%r8941, %r8945;
	mov.u32 	%r8942, %r8945;
	mov.u32 	%r8943, %r8945;
	mov.u32 	%r8862, %r8945;
	mov.u32 	%r8946, %r8945;
	mov.u32 	%r8947, %r8945;
	mov.u32 	%r8948, %r8945;
	@%p743 bra 	BB0_1077;
	bra.uni 	BB0_1137;

BB0_1077:
	mov.u32 	%r5343, 24;
	// inline asm
	shf.r.wrap.b32 %r8862, %r21, %r22, %r5343;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r22, %r15, %r5343;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8942, %r15, %r16, %r5343;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8941, %r16, %r17, %r5343;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8948, %r17, %r18, %r5343;
	// inline asm
	mov.u32 	%r8945, 0;
	// inline asm
	shf.r.wrap.b32 %r8947, %r18, %r8945, %r5343;
	// inline asm
	mov.u32 	%r8946, %r8945;
	bra.uni 	BB0_1137;

BB0_472:
	setp.eq.s32	%p354, %r24, 11;
	mov.u32 	%r8816, %r8825;
	@%p354 bra 	BB0_473;
	bra.uni 	BB0_528;

BB0_473:
	shr.u32 	%r8816, %r21, 24;
	bra.uni 	BB0_528;

BB0_1356:
	setp.eq.s32	%p904, %r6470, 22;
	@%p904 bra 	BB0_1383;
	bra.uni 	BB0_1357;

BB0_1383:
	mov.u32 	%r6588, 16;
	// inline asm
	shf.r.wrap.b32 %r8895, %r20, %r21, %r6588;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8896, %r19, %r20, %r6588;
	// inline asm
	mov.u32 	%r8891, 0;
	// inline asm
	shf.r.wrap.b32 %r8897, %r8891, %r19, %r6588;
	// inline asm
	bra.uni 	BB0_1359;

BB0_809:
	setp.eq.s32	%p567, %r24, 11;
	@%p567 bra 	BB0_810;
	bra.uni 	BB0_827;

BB0_810:
	mov.u32 	%r4385, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r15, %r16, %r4385;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r22, %r15, %r4385;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r21, %r22, %r4385;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r15, %r20, %r21, %r4385;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8941, %r19, %r20, %r4385;
	// inline asm
	mov.u32 	%r8943, 0;
	// inline asm
	shf.r.wrap.b32 %r8942, %r8943, %r19, %r4385;
	// inline asm
	mov.u32 	%r8944, %r8943;
	bra.uni 	BB0_874;

BB0_1108:
	setp.eq.s32	%p720, %r26, 27;
	mov.u32 	%r8941, %r8945;
	mov.u32 	%r8942, %r8945;
	mov.u32 	%r8943, %r8945;
	mov.u32 	%r8862, %r8945;
	mov.u32 	%r8946, %r8945;
	mov.u32 	%r8947, %r8945;
	mov.u32 	%r8948, %r8945;
	@%p720 bra 	BB0_1109;
	bra.uni 	BB0_1137;

BB0_1109:
	mov.u32 	%r5087, 24;
	// inline asm
	shf.r.wrap.b32 %r8862, %r17, %r18, %r5087;
	// inline asm
	mov.u32 	%r8941, 0;
	// inline asm
	shf.r.wrap.b32 %r8943, %r18, %r8941, %r5087;
	// inline asm

BB0_1110:
	mov.u32 	%r8942, %r8941;
	bra.uni 	BB0_1111;

BB0_503:
	setp.eq.s32	%p331, %r24, 27;
	mov.u32 	%r8816, %r8825;
	@%p331 bra 	BB0_504;
	bra.uni 	BB0_528;

BB0_504:
	shr.u32 	%r8816, %r17, 24;
	bra.uni 	BB0_528;

BB0_842:
	setp.eq.s32	%p544, %r24, 27;
	@%p544 bra 	BB0_843;
	bra.uni 	BB0_827;

BB0_843:
	mov.u32 	%r4129, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r19, %r20, %r4129;
	// inline asm
	mov.u32 	%r8941, 0;
	// inline asm
	shf.r.wrap.b32 %r17, %r8941, %r19, %r4129;
	// inline asm

BB0_844:
	mov.u32 	%r8942, %r8941;
	mov.u32 	%r8943, %r8941;
	mov.u32 	%r8944, %r8941;
	bra.uni 	BB0_872;

BB0_1068:
	setp.eq.s32	%p749, %r26, 7;
	mov.u32 	%r8941, %r8945;
	mov.u32 	%r8942, %r8945;
	mov.u32 	%r8943, %r8945;
	mov.u32 	%r8862, %r8945;
	mov.u32 	%r8946, %r8945;
	mov.u32 	%r8947, %r8945;
	mov.u32 	%r8948, %r8945;
	@%p749 bra 	BB0_1069;
	bra.uni 	BB0_1137;

BB0_1069:
	mov.u32 	%r5427, 24;
	// inline asm
	shf.r.wrap.b32 %r8862, %r20, %r21, %r5427;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r21, %r22, %r5427;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8942, %r22, %r15, %r5427;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8941, %r15, %r16, %r5427;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8948, %r16, %r17, %r5427;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8947, %r17, %r18, %r5427;
	// inline asm
	mov.u32 	%r8945, 0;
	// inline asm
	shf.r.wrap.b32 %r8946, %r18, %r8945, %r5427;
	// inline asm
	bra.uni 	BB0_1137;

BB0_464:
	setp.eq.s32	%p360, %r24, 7;
	mov.u32 	%r8816, %r8825;
	@%p360 bra 	BB0_465;
	bra.uni 	BB0_528;

BB0_465:
	shr.u32 	%r8816, %r20, 24;
	bra.uni 	BB0_528;

BB0_1338:
	setp.eq.s32	%p916, %r6470, 14;
	@%p916 bra 	BB0_1387;
	bra.uni 	BB0_1339;

BB0_1387:
	mov.u32 	%r6722, 16;
	// inline asm
	shf.r.wrap.b32 %r8895, %r22, %r15, %r6722;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8896, %r21, %r22, %r6722;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8897, %r20, %r21, %r6722;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8898, %r19, %r20, %r6722;
	// inline asm
	mov.u32 	%r8892, 0;
	// inline asm
	shf.r.wrap.b32 %r8891, %r8892, %r19, %r6722;
	// inline asm
	bra.uni 	BB0_1341;

BB0_801:
	setp.eq.s32	%p573, %r24, 7;
	@%p573 bra 	BB0_802;
	bra.uni 	BB0_827;

BB0_802:
	mov.u32 	%r4469, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r16, %r17, %r4469;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r15, %r16, %r4469;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r22, %r15, %r4469;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r15, %r21, %r22, %r4469;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8941, %r20, %r21, %r4469;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8942, %r19, %r20, %r4469;
	// inline asm
	mov.u32 	%r8944, 0;
	// inline asm
	shf.r.wrap.b32 %r8943, %r8944, %r19, %r4469;
	// inline asm
	bra.uni 	BB0_874;

BB0_1100:
	setp.eq.s32	%p726, %r26, 23;
	mov.u32 	%r8941, %r8945;
	mov.u32 	%r8942, %r8945;
	mov.u32 	%r8943, %r8945;
	mov.u32 	%r8862, %r8945;
	mov.u32 	%r8946, %r8945;
	mov.u32 	%r8947, %r8945;
	mov.u32 	%r8948, %r8945;
	@%p726 bra 	BB0_1101;
	bra.uni 	BB0_1137;

BB0_1101:
	mov.u32 	%r5139, 24;
	// inline asm
	shf.r.wrap.b32 %r8862, %r16, %r17, %r5139;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r17, %r18, %r5139;
	// inline asm
	mov.u32 	%r8941, 0;
	// inline asm
	shf.r.wrap.b32 %r8942, %r18, %r8941, %r5139;
	// inline asm
	bra.uni 	BB0_1111;

BB0_495:
	setp.eq.s32	%p337, %r24, 23;
	mov.u32 	%r8816, %r8825;
	@%p337 bra 	BB0_496;
	bra.uni 	BB0_528;

BB0_496:
	shr.u32 	%r8816, %r16, 24;
	bra.uni 	BB0_528;

BB0_833:
	setp.eq.s32	%p550, %r24, 23;
	@%p550 bra 	BB0_834;
	bra.uni 	BB0_827;

BB0_834:
	mov.u32 	%r4181, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r20, %r21, %r4181;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r19, %r20, %r4181;
	// inline asm
	mov.u32 	%r8941, 0;
	// inline asm
	shf.r.wrap.b32 %r16, %r8941, %r19, %r4181;
	// inline asm

BB0_835:
	mov.u32 	%r8942, %r8941;
	mov.u32 	%r8943, %r8941;
	mov.u32 	%r8944, %r8941;
	bra.uni 	BB0_873;

BB0_1083:
	setp.eq.s32	%p738, %r26, 15;
	mov.u32 	%r8941, %r8945;
	mov.u32 	%r8942, %r8945;
	mov.u32 	%r8943, %r8945;
	mov.u32 	%r8862, %r8945;
	mov.u32 	%r8946, %r8945;
	mov.u32 	%r8947, %r8945;
	mov.u32 	%r8948, %r8945;
	@%p738 bra 	BB0_1084;
	bra.uni 	BB0_1137;

BB0_1084:
	mov.u32 	%r5267, 24;
	// inline asm
	shf.r.wrap.b32 %r8862, %r22, %r15, %r5267;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8943, %r15, %r16, %r5267;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8942, %r16, %r17, %r5267;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8941, %r17, %r18, %r5267;
	// inline asm
	mov.u32 	%r8945, 0;
	// inline asm
	shf.r.wrap.b32 %r8948, %r18, %r8945, %r5267;
	// inline asm

BB0_1085:
	mov.u32 	%r8946, %r8945;
	mov.u32 	%r8947, %r8945;
	bra.uni 	BB0_1137;

BB0_479:
	setp.eq.s32	%p349, %r24, 15;
	mov.u32 	%r8816, %r8825;
	@%p349 bra 	BB0_480;
	bra.uni 	BB0_528;

BB0_480:
	shr.u32 	%r8816, %r22, 24;
	bra.uni 	BB0_528;

BB0_1374:
	setp.eq.s32	%p893, %r6470, 30;
	@%p893 bra 	BB0_1378;
	bra.uni 	BB0_1375;

BB0_1378:
	mov.u32 	%r8891, 0;
	mov.u32 	%r6486, 16;
	// inline asm
	shf.r.wrap.b32 %r8895, %r8891, %r19, %r6486;
	// inline asm
	bra.uni 	BB0_1377;

BB0_816:
	setp.eq.s32	%p562, %r24, 15;
	@%p562 bra 	BB0_817;
	bra.uni 	BB0_827;

BB0_817:
	mov.u32 	%r4309, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r22, %r15, %r4309;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r21, %r22, %r4309;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r20, %r21, %r4309;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r15, %r19, %r20, %r4309;
	// inline asm
	mov.u32 	%r8942, 0;
	// inline asm
	shf.r.wrap.b32 %r8941, %r8942, %r19, %r4309;
	// inline asm

BB0_818:
	mov.u32 	%r8943, %r8942;
	mov.u32 	%r8944, %r8942;
	bra.uni 	BB0_874;

BB0_827:
	mov.u32 	%r8941, %r22;
	mov.u32 	%r8942, %r21;
	mov.u32 	%r8943, %r20;
	mov.u32 	%r8944, %r19;
	bra.uni 	BB0_874;

BB0_1117:
	setp.ne.s32	%p715, %r26, 31;
	mov.u32 	%r8941, %r8945;
	mov.u32 	%r8942, %r8945;
	mov.u32 	%r8943, %r8945;
	mov.u32 	%r8862, %r8945;
	mov.u32 	%r8946, %r8945;
	mov.u32 	%r8947, %r8945;
	mov.u32 	%r8948, %r8945;
	@%p715 bra 	BB0_1137;

	mov.u32 	%r8941, 0;
	mov.u32 	%r5043, 24;
	// inline asm
	shf.r.wrap.b32 %r8862, %r18, %r8941, %r5043;
	// inline asm

BB0_1119:
	mov.u32 	%r8942, %r8941;
	mov.u32 	%r8943, %r8941;

BB0_1111:
	mov.u32 	%r8945, %r8941;
	mov.u32 	%r8946, %r8941;
	mov.u32 	%r8947, %r8941;
	mov.u32 	%r8948, %r8941;

BB0_1137:
	and.b32  	%r5585, %r23, 3;
	shl.b32 	%r5586, %r5585, 3;
	mov.u32 	%r5587, 1;
	shl.b32 	%r5588, %r5587, %r5586;
	add.s32 	%r1058, %r5588, -1;
	neg.s32 	%r1059, %r5588;
	shr.u32 	%r5584, %r24, 2;
	setp.gt.s32	%p757, %r5584, 3;
	@%p757 bra 	BB0_1145;

	setp.gt.s32	%p763, %r5584, 1;
	@%p763 bra 	BB0_1142;

	setp.eq.s32	%p766, %r5584, 0;
	@%p766 bra 	BB0_1160;
	bra.uni 	BB0_1140;

BB0_1160:
	and.b32  	%r5603, %r1058, %r19;
	and.b32  	%r5604, %r8862, %r1059;
	or.b32  	%r8944, %r5604, %r5603;
	bra.uni 	BB0_1161;

BB0_1145:
	setp.gt.s32	%p758, %r5584, 5;
	@%p758 bra 	BB0_1149;

	setp.eq.s32	%p761, %r5584, 4;
	@%p761 bra 	BB0_1156;
	bra.uni 	BB0_1147;

BB0_1156:
	and.b32  	%r5595, %r1058, %r15;
	and.b32  	%r5596, %r8948, %r1059;
	or.b32  	%r8948, %r5596, %r5595;
	mov.u32 	%r8941, %r22;
	bra.uni 	BB0_1157;

BB0_1142:
	setp.eq.s32	%p764, %r5584, 2;
	@%p764 bra 	BB0_1159;
	bra.uni 	BB0_1143;

BB0_1159:
	and.b32  	%r5599, %r1058, %r21;
	and.b32  	%r5600, %r8942, %r1059;
	or.b32  	%r8942, %r5600, %r5599;
	bra.uni 	BB0_1158;

BB0_1149:
	setp.eq.s32	%p759, %r5584, 6;
	@%p759 bra 	BB0_1155;
	bra.uni 	BB0_1150;

BB0_1155:
	and.b32  	%r5591, %r1058, %r17;
	and.b32  	%r5592, %r8946, %r1059;
	or.b32  	%r8946, %r5592, %r5591;
	mov.u32 	%r8941, %r22;
	mov.u32 	%r8942, %r21;
	mov.u32 	%r8943, %r20;
	mov.u32 	%r8944, %r19;
	bra.uni 	BB0_1153;

BB0_1140:
	setp.eq.s32	%p767, %r5584, 1;
	@%p767 bra 	BB0_1141;
	bra.uni 	BB0_1151;

BB0_1141:
	and.b32  	%r5601, %r1058, %r20;
	and.b32  	%r5602, %r8943, %r1059;
	or.b32  	%r8943, %r5602, %r5601;
	mov.u32 	%r8944, %r19;
	bra.uni 	BB0_1161;

BB0_1147:
	setp.eq.s32	%p762, %r5584, 5;
	@%p762 bra 	BB0_1148;
	bra.uni 	BB0_1151;

BB0_1148:
	and.b32  	%r5593, %r1058, %r16;
	and.b32  	%r5594, %r8947, %r1059;
	or.b32  	%r8947, %r5594, %r5593;
	mov.u32 	%r8941, %r22;
	mov.u32 	%r8942, %r21;
	mov.u32 	%r8943, %r20;
	mov.u32 	%r8944, %r19;
	mov.u32 	%r8948, %r15;
	bra.uni 	BB0_1161;

BB0_1143:
	setp.eq.s32	%p765, %r5584, 3;
	@%p765 bra 	BB0_1144;
	bra.uni 	BB0_1151;

BB0_1144:
	and.b32  	%r5597, %r1058, %r22;
	and.b32  	%r5598, %r8941, %r1059;
	or.b32  	%r8941, %r5598, %r5597;

BB0_1157:
	mov.u32 	%r8942, %r21;

BB0_1158:
	mov.u32 	%r8943, %r20;
	mov.u32 	%r8944, %r19;
	bra.uni 	BB0_1161;

BB0_1150:
	setp.ne.s32	%p760, %r5584, 7;
	@%p760 bra 	BB0_1151;

	and.b32  	%r5589, %r1058, %r18;
	and.b32  	%r5590, %r8945, %r1059;
	or.b32  	%r8945, %r5590, %r5589;
	mov.u32 	%r8941, %r22;
	mov.u32 	%r8942, %r21;
	mov.u32 	%r8943, %r20;
	mov.u32 	%r8944, %r19;
	bra.uni 	BB0_1152;

BB0_1151:
	mov.u32 	%r8941, %r22;
	mov.u32 	%r8942, %r21;
	mov.u32 	%r8943, %r20;
	mov.u32 	%r8944, %r19;
	mov.u32 	%r8945, %r18;

BB0_1152:
	mov.u32 	%r8946, %r17;

BB0_1153:
	mov.u32 	%r8947, %r16;
	mov.u32 	%r8948, %r15;

BB0_1161:
	sub.s32 	%r8949, %r14, %r26;
	bra.uni 	BB0_1554;

BB0_510:
	setp.ne.s32	%p326, %r24, 31;
	mov.u32 	%r8816, %r8825;
	@%p326 bra 	BB0_528;

	shr.u32 	%r8816, %r18, 24;

BB0_528:
	setp.gt.s32	%p368, %r26, 15;
	@%p368 bra 	BB0_560;

	setp.gt.s32	%p392, %r26, 7;
	@%p392 bra 	BB0_545;

	setp.gt.s32	%p404, %r26, 3;
	@%p404 bra 	BB0_538;

	setp.gt.s32	%p410, %r26, 1;
	@%p410 bra 	BB0_535;

	setp.eq.s32	%p413, %r26, 0;
	@%p413 bra 	BB0_606;
	bra.uni 	BB0_533;

BB0_606:
	and.b32  	%r8825, %r19, 255;
	and.b32  	%r3811, %r19, -256;
	or.b32  	%r19, %r8816, %r3811;
	bra.uni 	BB0_607;

BB0_560:
	setp.gt.s32	%p369, %r26, 23;
	@%p369 bra 	BB0_576;

	setp.gt.s32	%p381, %r26, 19;
	@%p381 bra 	BB0_569;

	setp.gt.s32	%p387, %r26, 17;
	@%p387 bra 	BB0_566;

	setp.eq.s32	%p390, %r26, 16;
	@%p390 bra 	BB0_598;
	bra.uni 	BB0_564;

BB0_598:
	and.b32  	%r8825, %r15, 255;
	and.b32  	%r3787, %r15, -256;
	or.b32  	%r15, %r8816, %r3787;
	bra.uni 	BB0_607;

BB0_545:
	setp.gt.s32	%p393, %r26, 11;
	@%p393 bra 	BB0_553;

	setp.gt.s32	%p399, %r26, 9;
	@%p399 bra 	BB0_550;

	setp.eq.s32	%p402, %r26, 8;
	@%p402 bra 	BB0_602;
	bra.uni 	BB0_548;

BB0_602:
	and.b32  	%r8825, %r21, 255;
	and.b32  	%r3799, %r21, -256;
	or.b32  	%r21, %r8816, %r3799;
	bra.uni 	BB0_607;

BB0_576:
	setp.gt.s32	%p370, %r26, 27;
	@%p370 bra 	BB0_584;

	setp.gt.s32	%p376, %r26, 25;
	@%p376 bra 	BB0_581;

	setp.eq.s32	%p379, %r26, 24;
	@%p379 bra 	BB0_594;
	bra.uni 	BB0_579;

BB0_594:
	and.b32  	%r8825, %r17, 255;
	and.b32  	%r3775, %r17, -256;
	or.b32  	%r17, %r8816, %r3775;
	bra.uni 	BB0_607;

BB0_538:
	setp.gt.s32	%p405, %r26, 5;
	@%p405 bra 	BB0_542;

	setp.eq.s32	%p408, %r26, 4;
	@%p408 bra 	BB0_604;
	bra.uni 	BB0_540;

BB0_604:
	and.b32  	%r8825, %r20, 255;
	and.b32  	%r3805, %r20, -256;
	or.b32  	%r20, %r8816, %r3805;
	bra.uni 	BB0_607;

BB0_569:
	setp.gt.s32	%p382, %r26, 21;
	@%p382 bra 	BB0_573;

	setp.eq.s32	%p385, %r26, 20;
	@%p385 bra 	BB0_596;
	bra.uni 	BB0_571;

BB0_596:
	and.b32  	%r8825, %r16, 255;
	and.b32  	%r3781, %r16, -256;
	or.b32  	%r16, %r8816, %r3781;
	bra.uni 	BB0_607;

BB0_553:
	setp.gt.s32	%p394, %r26, 13;
	@%p394 bra 	BB0_557;

	setp.eq.s32	%p397, %r26, 12;
	@%p397 bra 	BB0_600;
	bra.uni 	BB0_555;

BB0_600:
	and.b32  	%r8825, %r22, 255;
	and.b32  	%r3793, %r22, -256;
	or.b32  	%r22, %r8816, %r3793;
	bra.uni 	BB0_607;

BB0_584:
	setp.gt.s32	%p371, %r26, 29;
	@%p371 bra 	BB0_588;

	setp.eq.s32	%p374, %r26, 28;
	@%p374 bra 	BB0_592;
	bra.uni 	BB0_586;

BB0_592:
	and.b32  	%r8825, %r18, 255;
	and.b32  	%r3769, %r18, -256;
	or.b32  	%r18, %r8816, %r3769;
	bra.uni 	BB0_607;

BB0_535:
	setp.eq.s32	%p411, %r26, 2;
	@%p411 bra 	BB0_605;
	bra.uni 	BB0_536;

BB0_605:
	bfe.u32 	%r8825, %r19, 16, 8;
	shl.b32 	%r3807, %r8816, 16;
	and.b32  	%r3808, %r19, -16711681;
	or.b32  	%r19, %r3807, %r3808;
	bra.uni 	BB0_607;

BB0_566:
	setp.eq.s32	%p388, %r26, 18;
	@%p388 bra 	BB0_597;
	bra.uni 	BB0_567;

BB0_597:
	bfe.u32 	%r8825, %r15, 16, 8;
	shl.b32 	%r3783, %r8816, 16;
	and.b32  	%r3784, %r15, -16711681;
	or.b32  	%r15, %r3783, %r3784;
	bra.uni 	BB0_607;

BB0_550:
	setp.eq.s32	%p400, %r26, 10;
	@%p400 bra 	BB0_601;
	bra.uni 	BB0_551;

BB0_601:
	bfe.u32 	%r8825, %r21, 16, 8;
	shl.b32 	%r3795, %r8816, 16;
	and.b32  	%r3796, %r21, -16711681;
	or.b32  	%r21, %r3795, %r3796;
	bra.uni 	BB0_607;

BB0_581:
	setp.eq.s32	%p377, %r26, 26;
	@%p377 bra 	BB0_593;
	bra.uni 	BB0_582;

BB0_593:
	bfe.u32 	%r8825, %r17, 16, 8;
	shl.b32 	%r3771, %r8816, 16;
	and.b32  	%r3772, %r17, -16711681;
	or.b32  	%r17, %r3771, %r3772;
	bra.uni 	BB0_607;

BB0_542:
	setp.eq.s32	%p406, %r26, 6;
	@%p406 bra 	BB0_603;
	bra.uni 	BB0_543;

BB0_603:
	bfe.u32 	%r8825, %r20, 16, 8;
	shl.b32 	%r3801, %r8816, 16;
	and.b32  	%r3802, %r20, -16711681;
	or.b32  	%r20, %r3801, %r3802;
	bra.uni 	BB0_607;

BB0_573:
	setp.eq.s32	%p383, %r26, 22;
	@%p383 bra 	BB0_595;
	bra.uni 	BB0_574;

BB0_595:
	bfe.u32 	%r8825, %r16, 16, 8;
	shl.b32 	%r3777, %r8816, 16;
	and.b32  	%r3778, %r16, -16711681;
	or.b32  	%r16, %r3777, %r3778;
	bra.uni 	BB0_607;

BB0_557:
	setp.eq.s32	%p395, %r26, 14;
	@%p395 bra 	BB0_599;
	bra.uni 	BB0_558;

BB0_599:
	bfe.u32 	%r8825, %r22, 16, 8;
	shl.b32 	%r3789, %r8816, 16;
	and.b32  	%r3790, %r22, -16711681;
	or.b32  	%r22, %r3789, %r3790;
	bra.uni 	BB0_607;

BB0_588:
	setp.eq.s32	%p372, %r26, 30;
	@%p372 bra 	BB0_591;
	bra.uni 	BB0_589;

BB0_591:
	bfe.u32 	%r8825, %r18, 16, 8;
	shl.b32 	%r3765, %r8816, 16;
	and.b32  	%r3766, %r18, -16711681;
	or.b32  	%r18, %r3765, %r3766;
	bra.uni 	BB0_607;

BB0_850:
	setp.ne.s32	%p539, %r24, 30;
	mov.u32 	%r8941, %r22;
	mov.u32 	%r8942, %r21;
	mov.u32 	%r8943, %r20;
	mov.u32 	%r8944, %r19;
	@%p539 bra 	BB0_874;

	mov.u32 	%r8941, 0;
	mov.u32 	%r4096, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r8941, %r19, %r4096;
	// inline asm

BB0_870:
	mov.u32 	%r8942, %r8941;
	mov.u32 	%r8943, %r8941;
	mov.u32 	%r8944, %r8941;

BB0_871:
	mov.u32 	%r17, %r8941;

BB0_872:
	mov.u32 	%r16, %r8941;

BB0_873:
	mov.u32 	%r15, %r8941;

BB0_874:
	@%p534 bra 	BB0_903;

	setp.gt.s32	%p603, %r24, 7;
	@%p603 bra 	BB0_888;

	setp.gt.s32	%p615, %r24, 3;
	@%p615 bra 	BB0_881;

	setp.eq.s32	%p621, %r24, 1;
	@%p621 bra 	BB0_950;

	setp.eq.s32	%p622, %r24, 2;
	@%p622 bra 	BB0_949;
	bra.uni 	BB0_879;

BB0_949:
	shl.b32 	%r4851, %r610, 8;
	or.b32  	%r4852, %r4851, %r610;
	or.b32  	%r8944, %r4852, %r8944;
	bra.uni 	BB0_771;

BB0_903:
	setp.gt.s32	%p580, %r24, 23;
	@%p580 bra 	BB0_919;

	setp.gt.s32	%p592, %r24, 19;
	@%p592 bra 	BB0_912;

	setp.gt.s32	%p598, %r24, 17;
	@%p598 bra 	BB0_909;

	setp.eq.s32	%p601, %r24, 16;
	@%p601 bra 	BB0_942;
	bra.uni 	BB0_907;

BB0_942:
	mov.u32 	%r4751, 64;
	prmt.b32 	%r4752, %r19, %r19, %r4751;
	mov.u32 	%r4753, 1040;
	prmt.b32 	%r4754, %r4752, %r19, %r4753;
	mov.u32 	%r4755, 16912;
	prmt.b32 	%r4756, %r4754, %r19, %r4755;
	or.b32  	%r8944, %r4756, %r8944;
	or.b32  	%r8943, %r4756, %r8943;
	or.b32  	%r8942, %r4756, %r8942;
	or.b32  	%r8941, %r4756, %r8941;
	bra.uni 	BB0_771;

BB0_888:
	setp.gt.s32	%p604, %r24, 11;
	@%p604 bra 	BB0_896;

	setp.gt.s32	%p610, %r24, 9;
	@%p610 bra 	BB0_893;

	setp.eq.s32	%p613, %r24, 8;
	@%p613 bra 	BB0_946;
	bra.uni 	BB0_891;

BB0_946:
	mov.u32 	%r4811, 64;
	prmt.b32 	%r4812, %r19, %r19, %r4811;
	mov.u32 	%r4813, 1040;
	prmt.b32 	%r4814, %r4812, %r19, %r4813;
	mov.u32 	%r4815, 16912;
	prmt.b32 	%r4816, %r4814, %r19, %r4815;
	or.b32  	%r8944, %r4816, %r8944;
	or.b32  	%r8943, %r4816, %r8943;
	bra.uni 	BB0_771;

BB0_919:
	setp.gt.s32	%p581, %r24, 27;
	@%p581 bra 	BB0_927;

	setp.gt.s32	%p587, %r24, 25;
	@%p587 bra 	BB0_924;

	setp.eq.s32	%p590, %r24, 24;
	@%p590 bra 	BB0_938;
	bra.uni 	BB0_922;

BB0_938:
	mov.u32 	%r4691, 64;
	prmt.b32 	%r4692, %r19, %r19, %r4691;
	mov.u32 	%r4693, 1040;
	prmt.b32 	%r4694, %r4692, %r19, %r4693;
	mov.u32 	%r4695, 16912;
	prmt.b32 	%r4696, %r4694, %r19, %r4695;
	or.b32  	%r8944, %r4696, %r8944;
	or.b32  	%r8943, %r4696, %r8943;
	or.b32  	%r8942, %r4696, %r8942;
	or.b32  	%r8941, %r4696, %r8941;
	or.b32  	%r8948, %r4696, %r15;
	or.b32  	%r8947, %r4696, %r16;
	bra.uni 	BB0_734;

BB0_881:
	setp.gt.s32	%p616, %r24, 5;
	@%p616 bra 	BB0_885;

	setp.eq.s32	%p619, %r24, 4;
	@%p619 bra 	BB0_948;
	bra.uni 	BB0_883;

BB0_948:
	mov.u32 	%r4841, 64;
	prmt.b32 	%r4842, %r19, %r19, %r4841;
	mov.u32 	%r4843, 1040;
	prmt.b32 	%r4844, %r4842, %r19, %r4843;
	mov.u32 	%r4845, 16912;
	prmt.b32 	%r4846, %r4844, %r19, %r4845;
	or.b32  	%r8944, %r4846, %r8944;
	bra.uni 	BB0_771;

BB0_912:
	setp.gt.s32	%p593, %r24, 21;
	@%p593 bra 	BB0_916;

	setp.eq.s32	%p596, %r24, 20;
	@%p596 bra 	BB0_940;
	bra.uni 	BB0_914;

BB0_940:
	mov.u32 	%r4721, 64;
	prmt.b32 	%r4722, %r19, %r19, %r4721;
	mov.u32 	%r4723, 1040;
	prmt.b32 	%r4724, %r4722, %r19, %r4723;
	mov.u32 	%r4725, 16912;
	prmt.b32 	%r4726, %r4724, %r19, %r4725;
	or.b32  	%r8944, %r4726, %r8944;
	or.b32  	%r8943, %r4726, %r8943;
	or.b32  	%r8942, %r4726, %r8942;
	or.b32  	%r8941, %r4726, %r8941;
	or.b32  	%r8948, %r4726, %r15;
	bra.uni 	BB0_765;

BB0_896:
	setp.gt.s32	%p605, %r24, 13;
	@%p605 bra 	BB0_900;

	setp.eq.s32	%p608, %r24, 12;
	@%p608 bra 	BB0_944;
	bra.uni 	BB0_898;

BB0_944:
	mov.u32 	%r4781, 64;
	prmt.b32 	%r4782, %r19, %r19, %r4781;
	mov.u32 	%r4783, 1040;
	prmt.b32 	%r4784, %r4782, %r19, %r4783;
	mov.u32 	%r4785, 16912;
	prmt.b32 	%r4786, %r4784, %r19, %r4785;
	or.b32  	%r8944, %r4786, %r8944;
	or.b32  	%r8943, %r4786, %r8943;
	or.b32  	%r8942, %r4786, %r8942;
	bra.uni 	BB0_771;

BB0_927:
	setp.gt.s32	%p582, %r24, 29;
	@%p582 bra 	BB0_931;

	setp.eq.s32	%p585, %r24, 28;
	@%p585 bra 	BB0_935;
	bra.uni 	BB0_929;

BB0_935:
	mov.u32 	%r4661, 64;
	prmt.b32 	%r4662, %r19, %r19, %r4661;
	mov.u32 	%r4663, 1040;
	prmt.b32 	%r4664, %r4662, %r19, %r4663;
	mov.u32 	%r4665, 16912;
	prmt.b32 	%r4666, %r4664, %r19, %r4665;
	or.b32  	%r8944, %r4666, %r8944;
	or.b32  	%r8943, %r4666, %r8943;
	or.b32  	%r8942, %r4666, %r8942;
	or.b32  	%r8941, %r4666, %r8941;
	or.b32  	%r8948, %r4666, %r15;
	or.b32  	%r8947, %r4666, %r16;
	or.b32  	%r8946, %r4666, %r17;
	mov.u32 	%r8945, %r18;
	bra.uni 	BB0_1554;

BB0_909:
	setp.eq.s32	%p599, %r24, 18;
	@%p599 bra 	BB0_941;
	bra.uni 	BB0_910;

BB0_941:
	mov.u32 	%r4737, 64;
	prmt.b32 	%r4738, %r19, %r19, %r4737;
	mov.u32 	%r4739, 1040;
	prmt.b32 	%r4740, %r4738, %r19, %r4739;
	mov.u32 	%r4741, 16912;
	prmt.b32 	%r4742, %r4740, %r19, %r4741;
	or.b32  	%r8944, %r4742, %r8944;
	or.b32  	%r8943, %r4742, %r8943;
	or.b32  	%r8942, %r4742, %r8942;
	or.b32  	%r8941, %r4742, %r8941;
	shl.b32 	%r4743, %r610, 8;
	or.b32  	%r4744, %r4743, %r610;
	or.b32  	%r8948, %r4744, %r15;
	bra.uni 	BB0_765;

BB0_893:
	setp.eq.s32	%p611, %r24, 10;
	@%p611 bra 	BB0_945;
	bra.uni 	BB0_894;

BB0_945:
	mov.u32 	%r4797, 64;
	prmt.b32 	%r4798, %r19, %r19, %r4797;
	mov.u32 	%r4799, 1040;
	prmt.b32 	%r4800, %r4798, %r19, %r4799;
	mov.u32 	%r4801, 16912;
	prmt.b32 	%r4802, %r4800, %r19, %r4801;
	or.b32  	%r8944, %r4802, %r8944;
	or.b32  	%r8943, %r4802, %r8943;
	shl.b32 	%r4803, %r610, 8;
	or.b32  	%r4804, %r4803, %r610;
	or.b32  	%r8942, %r4804, %r8942;
	bra.uni 	BB0_771;

BB0_924:
	setp.eq.s32	%p588, %r24, 26;
	@%p588 bra 	BB0_936;
	bra.uni 	BB0_925;

BB0_936:
	mov.u32 	%r4677, 64;
	prmt.b32 	%r4678, %r19, %r19, %r4677;
	mov.u32 	%r4679, 1040;
	prmt.b32 	%r4680, %r4678, %r19, %r4679;
	mov.u32 	%r4681, 16912;
	prmt.b32 	%r4682, %r4680, %r19, %r4681;
	or.b32  	%r8944, %r4682, %r8944;
	or.b32  	%r8943, %r4682, %r8943;
	or.b32  	%r8942, %r4682, %r8942;
	or.b32  	%r8941, %r4682, %r8941;
	or.b32  	%r8948, %r4682, %r15;
	or.b32  	%r8947, %r4682, %r16;
	shl.b32 	%r4683, %r610, 8;
	or.b32  	%r4684, %r4683, %r610;
	or.b32  	%r8946, %r4684, %r17;
	mov.u32 	%r8945, %r18;
	bra.uni 	BB0_1554;

BB0_885:
	setp.eq.s32	%p617, %r24, 6;
	@%p617 bra 	BB0_947;
	bra.uni 	BB0_886;

BB0_947:
	mov.u32 	%r4827, 64;
	prmt.b32 	%r4828, %r19, %r19, %r4827;
	mov.u32 	%r4829, 1040;
	prmt.b32 	%r4830, %r4828, %r19, %r4829;
	mov.u32 	%r4831, 16912;
	prmt.b32 	%r4832, %r4830, %r19, %r4831;
	or.b32  	%r8944, %r4832, %r8944;
	shl.b32 	%r4833, %r610, 8;
	or.b32  	%r4834, %r4833, %r610;
	or.b32  	%r8943, %r4834, %r8943;
	bra.uni 	BB0_771;

BB0_916:
	setp.eq.s32	%p594, %r24, 22;
	@%p594 bra 	BB0_939;
	bra.uni 	BB0_917;

BB0_939:
	mov.u32 	%r4707, 64;
	prmt.b32 	%r4708, %r19, %r19, %r4707;
	mov.u32 	%r4709, 1040;
	prmt.b32 	%r4710, %r4708, %r19, %r4709;
	mov.u32 	%r4711, 16912;
	prmt.b32 	%r4712, %r4710, %r19, %r4711;
	or.b32  	%r8944, %r4712, %r8944;
	or.b32  	%r8943, %r4712, %r8943;
	or.b32  	%r8942, %r4712, %r8942;
	or.b32  	%r8941, %r4712, %r8941;
	or.b32  	%r8948, %r4712, %r15;
	shl.b32 	%r4713, %r610, 8;
	or.b32  	%r4714, %r4713, %r610;
	or.b32  	%r8947, %r4714, %r16;
	bra.uni 	BB0_734;

BB0_900:
	setp.eq.s32	%p606, %r24, 14;
	@%p606 bra 	BB0_943;
	bra.uni 	BB0_901;

BB0_943:
	mov.u32 	%r4767, 64;
	prmt.b32 	%r4768, %r19, %r19, %r4767;
	mov.u32 	%r4769, 1040;
	prmt.b32 	%r4770, %r4768, %r19, %r4769;
	mov.u32 	%r4771, 16912;
	prmt.b32 	%r4772, %r4770, %r19, %r4771;
	or.b32  	%r8944, %r4772, %r8944;
	or.b32  	%r8943, %r4772, %r8943;
	or.b32  	%r8942, %r4772, %r8942;
	shl.b32 	%r4773, %r610, 8;
	or.b32  	%r4774, %r4773, %r610;
	or.b32  	%r8941, %r4774, %r8941;
	bra.uni 	BB0_771;

BB0_931:
	setp.eq.s32	%p583, %r24, 30;
	@%p583 bra 	BB0_934;
	bra.uni 	BB0_932;

BB0_934:
	mov.u32 	%r4647, 64;
	prmt.b32 	%r4648, %r19, %r19, %r4647;
	mov.u32 	%r4649, 1040;
	prmt.b32 	%r4650, %r4648, %r19, %r4649;
	mov.u32 	%r4651, 16912;
	prmt.b32 	%r4652, %r4650, %r19, %r4651;
	or.b32  	%r8944, %r4652, %r8944;
	or.b32  	%r8943, %r4652, %r8943;
	or.b32  	%r8942, %r4652, %r8942;
	or.b32  	%r8941, %r4652, %r8941;
	or.b32  	%r8948, %r4652, %r15;
	or.b32  	%r8947, %r4652, %r16;
	or.b32  	%r8946, %r4652, %r17;
	shl.b32 	%r4653, %r610, 8;
	or.b32  	%r4654, %r4653, %r610;
	or.b32  	%r8945, %r4654, %r18;
	bra.uni 	BB0_1554;

BB0_950:
	or.b32  	%r8944, %r8944, %r610;
	bra.uni 	BB0_771;

BB0_879:
	setp.eq.s32	%p623, %r24, 3;
	@%p623 bra 	BB0_880;
	bra.uni 	BB0_771;

BB0_880:
	shl.b32 	%r4847, %r610, 8;
	or.b32  	%r4848, %r4847, %r610;
	shl.b32 	%r4849, %r610, 16;
	or.b32  	%r4850, %r4848, %r4849;
	or.b32  	%r8944, %r4850, %r8944;
	bra.uni 	BB0_771;

BB0_533:
	setp.eq.s32	%p414, %r26, 1;
	@%p414 bra 	BB0_534;
	bra.uni 	BB0_607;

BB0_534:
	bfe.u32 	%r8825, %r19, 8, 8;
	shl.b32 	%r3809, %r8816, 8;
	and.b32  	%r3810, %r19, -65281;
	or.b32  	%r19, %r3809, %r3810;
	bra.uni 	BB0_607;

BB0_564:
	setp.eq.s32	%p391, %r26, 17;
	@%p391 bra 	BB0_565;
	bra.uni 	BB0_607;

BB0_565:
	bfe.u32 	%r8825, %r15, 8, 8;
	shl.b32 	%r3785, %r8816, 8;
	and.b32  	%r3786, %r15, -65281;
	or.b32  	%r15, %r3785, %r3786;
	bra.uni 	BB0_607;

BB0_548:
	setp.eq.s32	%p403, %r26, 9;
	@%p403 bra 	BB0_549;
	bra.uni 	BB0_607;

BB0_549:
	bfe.u32 	%r8825, %r21, 8, 8;
	shl.b32 	%r3797, %r8816, 8;
	and.b32  	%r3798, %r21, -65281;
	or.b32  	%r21, %r3797, %r3798;
	bra.uni 	BB0_607;

BB0_579:
	setp.eq.s32	%p380, %r26, 25;
	@%p380 bra 	BB0_580;
	bra.uni 	BB0_607;

BB0_580:
	bfe.u32 	%r8825, %r17, 8, 8;
	shl.b32 	%r3773, %r8816, 8;
	and.b32  	%r3774, %r17, -65281;
	or.b32  	%r17, %r3773, %r3774;
	bra.uni 	BB0_607;

BB0_540:
	setp.eq.s32	%p409, %r26, 5;
	@%p409 bra 	BB0_541;
	bra.uni 	BB0_607;

BB0_541:
	bfe.u32 	%r8825, %r20, 8, 8;
	shl.b32 	%r3803, %r8816, 8;
	and.b32  	%r3804, %r20, -65281;
	or.b32  	%r20, %r3803, %r3804;
	bra.uni 	BB0_607;

BB0_571:
	setp.eq.s32	%p386, %r26, 21;
	@%p386 bra 	BB0_572;
	bra.uni 	BB0_607;

BB0_572:
	bfe.u32 	%r8825, %r16, 8, 8;
	shl.b32 	%r3779, %r8816, 8;
	and.b32  	%r3780, %r16, -65281;
	or.b32  	%r16, %r3779, %r3780;
	bra.uni 	BB0_607;

BB0_555:
	setp.eq.s32	%p398, %r26, 13;
	@%p398 bra 	BB0_556;
	bra.uni 	BB0_607;

BB0_556:
	bfe.u32 	%r8825, %r22, 8, 8;
	shl.b32 	%r3791, %r8816, 8;
	and.b32  	%r3792, %r22, -65281;
	or.b32  	%r22, %r3791, %r3792;
	bra.uni 	BB0_607;

BB0_586:
	setp.eq.s32	%p375, %r26, 29;
	@%p375 bra 	BB0_587;
	bra.uni 	BB0_607;

BB0_587:
	bfe.u32 	%r8825, %r18, 8, 8;
	shl.b32 	%r3767, %r8816, 8;
	and.b32  	%r3768, %r18, -65281;
	or.b32  	%r18, %r3767, %r3768;
	bra.uni 	BB0_607;

BB0_536:
	setp.eq.s32	%p412, %r26, 3;
	@%p412 bra 	BB0_537;
	bra.uni 	BB0_607;

BB0_537:
	shr.u32 	%r8825, %r19, 24;
	and.b32  	%r3806, %r19, 16777215;
	prmt.b32 	%r19, %r8816, %r3806, 1620;
	bra.uni 	BB0_607;

BB0_567:
	setp.eq.s32	%p389, %r26, 19;
	@%p389 bra 	BB0_568;
	bra.uni 	BB0_607;

BB0_568:
	shr.u32 	%r8825, %r15, 24;
	and.b32  	%r3782, %r15, 16777215;
	prmt.b32 	%r15, %r8816, %r3782, 1620;
	bra.uni 	BB0_607;

BB0_551:
	setp.eq.s32	%p401, %r26, 11;
	@%p401 bra 	BB0_552;
	bra.uni 	BB0_607;

BB0_552:
	shr.u32 	%r8825, %r21, 24;
	and.b32  	%r3794, %r21, 16777215;
	prmt.b32 	%r21, %r8816, %r3794, 1620;
	bra.uni 	BB0_607;

BB0_582:
	setp.eq.s32	%p378, %r26, 27;
	@%p378 bra 	BB0_583;
	bra.uni 	BB0_607;

BB0_583:
	shr.u32 	%r8825, %r17, 24;
	and.b32  	%r3770, %r17, 16777215;
	prmt.b32 	%r17, %r8816, %r3770, 1620;
	bra.uni 	BB0_607;

BB0_543:
	setp.eq.s32	%p407, %r26, 7;
	@%p407 bra 	BB0_544;
	bra.uni 	BB0_607;

BB0_544:
	shr.u32 	%r8825, %r20, 24;
	and.b32  	%r3800, %r20, 16777215;
	prmt.b32 	%r20, %r8816, %r3800, 1620;
	bra.uni 	BB0_607;

BB0_574:
	setp.eq.s32	%p384, %r26, 23;
	@%p384 bra 	BB0_575;
	bra.uni 	BB0_607;

BB0_575:
	shr.u32 	%r8825, %r16, 24;
	and.b32  	%r3776, %r16, 16777215;
	prmt.b32 	%r16, %r8816, %r3776, 1620;
	bra.uni 	BB0_607;

BB0_558:
	setp.eq.s32	%p396, %r26, 15;
	@%p396 bra 	BB0_559;
	bra.uni 	BB0_607;

BB0_559:
	shr.u32 	%r8825, %r22, 24;
	and.b32  	%r3788, %r22, 16777215;
	prmt.b32 	%r22, %r8816, %r3788, 1620;
	bra.uni 	BB0_607;

BB0_589:
	setp.ne.s32	%p373, %r26, 31;
	@%p373 bra 	BB0_607;

	shr.u32 	%r8825, %r18, 24;
	and.b32  	%r3764, %r18, 16777215;
	prmt.b32 	%r18, %r8816, %r3764, 1620;

BB0_607:
	@%p321 bra 	BB0_649;

	setp.gt.s32	%p439, %r24, 7;
	@%p439 bra 	BB0_626;

	setp.gt.s32	%p451, %r24, 3;
	@%p451 bra 	BB0_618;

	setp.gt.s32	%p457, %r24, 1;
	@%p457 bra 	BB0_614;

	setp.eq.s32	%p460, %r24, 0;
	@%p460 bra 	BB0_699;
	bra.uni 	BB0_612;

BB0_699:
	and.b32  	%r3859, %r19, -256;
	or.b32  	%r8944, %r8825, %r3859;
	bra.uni 	BB0_617;

BB0_649:
	setp.gt.s32	%p416, %r24, 23;
	@%p416 bra 	BB0_667;

	setp.gt.s32	%p428, %r24, 19;
	@%p428 bra 	BB0_659;

	setp.gt.s32	%p434, %r24, 17;
	@%p434 bra 	BB0_655;

	setp.eq.s32	%p437, %r24, 16;
	@%p437 bra 	BB0_691;
	bra.uni 	BB0_653;

BB0_691:
	and.b32  	%r3835, %r15, -256;
	or.b32  	%r8948, %r3835, %r8825;
	bra.uni 	BB0_658;

BB0_626:
	setp.gt.s32	%p440, %r24, 11;
	@%p440 bra 	BB0_635;

	setp.gt.s32	%p446, %r24, 9;
	@%p446 bra 	BB0_631;

	setp.eq.s32	%p449, %r24, 8;
	@%p449 bra 	BB0_695;
	bra.uni 	BB0_629;

BB0_695:
	and.b32  	%r3847, %r21, -256;
	or.b32  	%r8942, %r8825, %r3847;
	bra.uni 	BB0_634;

BB0_667:
	setp.gt.s32	%p417, %r24, 27;
	@%p417 bra 	BB0_676;

	setp.gt.s32	%p423, %r24, 25;
	@%p423 bra 	BB0_672;

	setp.eq.s32	%p426, %r24, 24;
	@%p426 bra 	BB0_687;
	bra.uni 	BB0_670;

BB0_687:
	and.b32  	%r3823, %r17, -256;
	or.b32  	%r8946, %r8825, %r3823;
	bra.uni 	BB0_675;

BB0_618:
	setp.gt.s32	%p452, %r24, 5;
	@%p452 bra 	BB0_622;

	setp.eq.s32	%p455, %r24, 4;
	@%p455 bra 	BB0_697;
	bra.uni 	BB0_620;

BB0_697:
	and.b32  	%r3853, %r20, -256;
	or.b32  	%r8943, %r8825, %r3853;
	bra.uni 	BB0_625;

BB0_659:
	setp.gt.s32	%p429, %r24, 21;
	@%p429 bra 	BB0_663;

	setp.eq.s32	%p432, %r24, 20;
	@%p432 bra 	BB0_689;
	bra.uni 	BB0_661;

BB0_689:
	and.b32  	%r3829, %r16, -256;
	or.b32  	%r8947, %r8825, %r3829;
	bra.uni 	BB0_666;

BB0_635:
	setp.gt.s32	%p441, %r24, 13;
	@%p441 bra 	BB0_639;

	setp.eq.s32	%p444, %r24, 12;
	@%p444 bra 	BB0_693;
	bra.uni 	BB0_637;

BB0_693:
	and.b32  	%r3841, %r22, -256;
	or.b32  	%r8941, %r8825, %r3841;
	bra.uni 	BB0_642;

BB0_676:
	setp.gt.s32	%p418, %r24, 29;
	@%p418 bra 	BB0_680;

	setp.eq.s32	%p421, %r24, 28;
	@%p421 bra 	BB0_685;
	bra.uni 	BB0_678;

BB0_685:
	and.b32  	%r3817, %r18, -256;
	or.b32  	%r8945, %r8825, %r3817;
	bra.uni 	BB0_683;

BB0_614:
	setp.eq.s32	%p458, %r24, 2;
	@%p458 bra 	BB0_698;
	bra.uni 	BB0_615;

BB0_698:
	and.b32  	%r3855, %r19, -16711681;
	shl.b32 	%r3856, %r8825, 16;
	or.b32  	%r8944, %r3856, %r3855;
	bra.uni 	BB0_617;

BB0_655:
	setp.eq.s32	%p435, %r24, 18;
	@%p435 bra 	BB0_690;
	bra.uni 	BB0_656;

BB0_690:
	and.b32  	%r3831, %r15, -16711681;
	shl.b32 	%r3832, %r8825, 16;
	or.b32  	%r8948, %r3832, %r3831;
	bra.uni 	BB0_658;

BB0_631:
	setp.eq.s32	%p447, %r24, 10;
	@%p447 bra 	BB0_694;
	bra.uni 	BB0_632;

BB0_694:
	and.b32  	%r3843, %r21, -16711681;
	shl.b32 	%r3844, %r8825, 16;
	or.b32  	%r8942, %r3844, %r3843;
	bra.uni 	BB0_634;

BB0_672:
	setp.eq.s32	%p424, %r24, 26;
	@%p424 bra 	BB0_686;
	bra.uni 	BB0_673;

BB0_686:
	and.b32  	%r3819, %r17, -16711681;
	shl.b32 	%r3820, %r8825, 16;
	or.b32  	%r8946, %r3820, %r3819;
	bra.uni 	BB0_675;

BB0_622:
	setp.eq.s32	%p453, %r24, 6;
	@%p453 bra 	BB0_696;
	bra.uni 	BB0_623;

BB0_696:
	and.b32  	%r3849, %r20, -16711681;
	shl.b32 	%r3850, %r8825, 16;
	or.b32  	%r8943, %r3850, %r3849;
	bra.uni 	BB0_625;

BB0_663:
	setp.eq.s32	%p430, %r24, 22;
	@%p430 bra 	BB0_688;
	bra.uni 	BB0_664;

BB0_688:
	and.b32  	%r3825, %r16, -16711681;
	shl.b32 	%r3826, %r8825, 16;
	or.b32  	%r8947, %r3826, %r3825;
	bra.uni 	BB0_666;

BB0_639:
	setp.eq.s32	%p442, %r24, 14;
	@%p442 bra 	BB0_692;
	bra.uni 	BB0_640;

BB0_692:
	and.b32  	%r3837, %r22, -16711681;
	shl.b32 	%r3838, %r8825, 16;
	or.b32  	%r8941, %r3838, %r3837;
	bra.uni 	BB0_642;

BB0_680:
	setp.eq.s32	%p419, %r24, 30;
	@%p419 bra 	BB0_684;
	bra.uni 	BB0_681;

BB0_684:
	and.b32  	%r3813, %r18, -16711681;
	shl.b32 	%r3814, %r8825, 16;
	or.b32  	%r8945, %r3814, %r3813;
	bra.uni 	BB0_683;

BB0_907:
	setp.eq.s32	%p602, %r24, 17;
	@%p602 bra 	BB0_908;
	bra.uni 	BB0_771;

BB0_908:
	mov.u32 	%r4745, 64;
	prmt.b32 	%r4746, %r19, %r19, %r4745;
	mov.u32 	%r4747, 1040;
	prmt.b32 	%r4748, %r4746, %r19, %r4747;
	mov.u32 	%r4749, 16912;
	prmt.b32 	%r4750, %r4748, %r19, %r4749;
	or.b32  	%r8944, %r4750, %r8944;
	or.b32  	%r8943, %r4750, %r8943;
	or.b32  	%r8942, %r4750, %r8942;
	or.b32  	%r8941, %r4750, %r8941;
	or.b32  	%r8948, %r15, %r610;
	bra.uni 	BB0_765;

BB0_891:
	setp.eq.s32	%p614, %r24, 9;
	@%p614 bra 	BB0_892;
	bra.uni 	BB0_771;

BB0_892:
	mov.u32 	%r4805, 64;
	prmt.b32 	%r4806, %r19, %r19, %r4805;
	mov.u32 	%r4807, 1040;
	prmt.b32 	%r4808, %r4806, %r19, %r4807;
	mov.u32 	%r4809, 16912;
	prmt.b32 	%r4810, %r4808, %r19, %r4809;
	or.b32  	%r8944, %r4810, %r8944;
	or.b32  	%r8943, %r4810, %r8943;
	or.b32  	%r8942, %r8942, %r610;
	bra.uni 	BB0_771;

BB0_922:
	setp.eq.s32	%p591, %r24, 25;
	@%p591 bra 	BB0_937;
	bra.uni 	BB0_923;

BB0_937:
	mov.u32 	%r4685, 64;
	prmt.b32 	%r4686, %r19, %r19, %r4685;
	mov.u32 	%r4687, 1040;
	prmt.b32 	%r4688, %r4686, %r19, %r4687;
	mov.u32 	%r4689, 16912;
	prmt.b32 	%r4690, %r4688, %r19, %r4689;
	or.b32  	%r8944, %r4690, %r8944;
	or.b32  	%r8943, %r4690, %r8943;
	or.b32  	%r8942, %r4690, %r8942;
	or.b32  	%r8941, %r4690, %r8941;
	or.b32  	%r8948, %r4690, %r15;
	or.b32  	%r8947, %r4690, %r16;
	or.b32  	%r8946, %r17, %r610;
	mov.u32 	%r8945, %r18;
	bra.uni 	BB0_1554;

BB0_883:
	setp.eq.s32	%p620, %r24, 5;
	@%p620 bra 	BB0_884;
	bra.uni 	BB0_771;

BB0_884:
	mov.u32 	%r4835, 64;
	prmt.b32 	%r4836, %r19, %r19, %r4835;
	mov.u32 	%r4837, 1040;
	prmt.b32 	%r4838, %r4836, %r19, %r4837;
	mov.u32 	%r4839, 16912;
	prmt.b32 	%r4840, %r4838, %r19, %r4839;
	or.b32  	%r8944, %r4840, %r8944;
	or.b32  	%r8943, %r8943, %r610;
	bra.uni 	BB0_771;

BB0_914:
	setp.eq.s32	%p597, %r24, 21;
	@%p597 bra 	BB0_915;
	bra.uni 	BB0_771;

BB0_915:
	mov.u32 	%r4715, 64;
	prmt.b32 	%r4716, %r19, %r19, %r4715;
	mov.u32 	%r4717, 1040;
	prmt.b32 	%r4718, %r4716, %r19, %r4717;
	mov.u32 	%r4719, 16912;
	prmt.b32 	%r4720, %r4718, %r19, %r4719;
	or.b32  	%r8944, %r4720, %r8944;
	or.b32  	%r8943, %r4720, %r8943;
	or.b32  	%r8942, %r4720, %r8942;
	or.b32  	%r8941, %r4720, %r8941;
	or.b32  	%r8948, %r4720, %r15;
	or.b32  	%r8947, %r16, %r610;
	bra.uni 	BB0_734;

BB0_898:
	setp.eq.s32	%p609, %r24, 13;
	@%p609 bra 	BB0_899;
	bra.uni 	BB0_771;

BB0_899:
	mov.u32 	%r4775, 64;
	prmt.b32 	%r4776, %r19, %r19, %r4775;
	mov.u32 	%r4777, 1040;
	prmt.b32 	%r4778, %r4776, %r19, %r4777;
	mov.u32 	%r4779, 16912;
	prmt.b32 	%r4780, %r4778, %r19, %r4779;
	or.b32  	%r8944, %r4780, %r8944;
	or.b32  	%r8943, %r4780, %r8943;
	or.b32  	%r8942, %r4780, %r8942;
	or.b32  	%r8941, %r8941, %r610;
	bra.uni 	BB0_771;

BB0_929:
	setp.eq.s32	%p586, %r24, 29;
	@%p586 bra 	BB0_930;
	bra.uni 	BB0_923;

BB0_930:
	mov.u32 	%r4655, 64;
	prmt.b32 	%r4656, %r19, %r19, %r4655;
	mov.u32 	%r4657, 1040;
	prmt.b32 	%r4658, %r4656, %r19, %r4657;
	mov.u32 	%r4659, 16912;
	prmt.b32 	%r4660, %r4658, %r19, %r4659;
	or.b32  	%r8944, %r4660, %r8944;
	or.b32  	%r8943, %r4660, %r8943;
	or.b32  	%r8942, %r4660, %r8942;
	or.b32  	%r8941, %r4660, %r8941;
	or.b32  	%r8948, %r4660, %r15;
	or.b32  	%r8947, %r4660, %r16;
	or.b32  	%r8946, %r4660, %r17;
	or.b32  	%r8945, %r18, %r610;
	bra.uni 	BB0_1554;

BB0_910:
	setp.eq.s32	%p600, %r24, 19;
	@%p600 bra 	BB0_911;
	bra.uni 	BB0_771;

BB0_911:
	mov.u32 	%r4727, 64;
	prmt.b32 	%r4728, %r19, %r19, %r4727;
	mov.u32 	%r4729, 1040;
	prmt.b32 	%r4730, %r4728, %r19, %r4729;
	mov.u32 	%r4731, 16912;
	prmt.b32 	%r4732, %r4730, %r19, %r4731;
	or.b32  	%r8944, %r4732, %r8944;
	or.b32  	%r8943, %r4732, %r8943;
	or.b32  	%r8942, %r4732, %r8942;
	or.b32  	%r8941, %r4732, %r8941;
	shl.b32 	%r4733, %r610, 8;
	or.b32  	%r4734, %r4733, %r610;
	shl.b32 	%r4735, %r610, 16;
	or.b32  	%r4736, %r4734, %r4735;
	or.b32  	%r8948, %r4736, %r15;

BB0_765:
	mov.u32 	%r8945, %r18;
	mov.u32 	%r8946, %r17;
	mov.u32 	%r8947, %r16;
	bra.uni 	BB0_1554;

BB0_894:
	setp.eq.s32	%p612, %r24, 11;
	@%p612 bra 	BB0_895;
	bra.uni 	BB0_771;

BB0_895:
	mov.u32 	%r4787, 64;
	prmt.b32 	%r4788, %r19, %r19, %r4787;
	mov.u32 	%r4789, 1040;
	prmt.b32 	%r4790, %r4788, %r19, %r4789;
	mov.u32 	%r4791, 16912;
	prmt.b32 	%r4792, %r4790, %r19, %r4791;
	or.b32  	%r8944, %r4792, %r8944;
	or.b32  	%r8943, %r4792, %r8943;
	shl.b32 	%r4793, %r610, 8;
	or.b32  	%r4794, %r4793, %r610;
	shl.b32 	%r4795, %r610, 16;
	or.b32  	%r4796, %r4794, %r4795;
	or.b32  	%r8942, %r4796, %r8942;
	bra.uni 	BB0_771;

BB0_925:
	setp.eq.s32	%p589, %r24, 27;
	@%p589 bra 	BB0_926;
	bra.uni 	BB0_923;

BB0_926:
	mov.u32 	%r4667, 64;
	prmt.b32 	%r4668, %r19, %r19, %r4667;
	mov.u32 	%r4669, 1040;
	prmt.b32 	%r4670, %r4668, %r19, %r4669;
	mov.u32 	%r4671, 16912;
	prmt.b32 	%r4672, %r4670, %r19, %r4671;
	or.b32  	%r8944, %r4672, %r8944;
	or.b32  	%r8943, %r4672, %r8943;
	or.b32  	%r8942, %r4672, %r8942;
	or.b32  	%r8941, %r4672, %r8941;
	or.b32  	%r8948, %r4672, %r15;
	or.b32  	%r8947, %r4672, %r16;
	shl.b32 	%r4673, %r610, 8;
	or.b32  	%r4674, %r4673, %r610;
	shl.b32 	%r4675, %r610, 16;
	or.b32  	%r4676, %r4674, %r4675;
	or.b32  	%r8946, %r4676, %r17;
	mov.u32 	%r8945, %r18;
	bra.uni 	BB0_1554;

BB0_886:
	setp.eq.s32	%p618, %r24, 7;
	@%p618 bra 	BB0_887;
	bra.uni 	BB0_771;

BB0_887:
	mov.u32 	%r4817, 64;
	prmt.b32 	%r4818, %r19, %r19, %r4817;
	mov.u32 	%r4819, 1040;
	prmt.b32 	%r4820, %r4818, %r19, %r4819;
	mov.u32 	%r4821, 16912;
	prmt.b32 	%r4822, %r4820, %r19, %r4821;
	or.b32  	%r8944, %r4822, %r8944;
	shl.b32 	%r4823, %r610, 8;
	or.b32  	%r4824, %r4823, %r610;
	shl.b32 	%r4825, %r610, 16;
	or.b32  	%r4826, %r4824, %r4825;
	or.b32  	%r8943, %r4826, %r8943;
	bra.uni 	BB0_771;

BB0_917:
	setp.eq.s32	%p595, %r24, 23;
	@%p595 bra 	BB0_918;
	bra.uni 	BB0_771;

BB0_918:
	mov.u32 	%r4697, 64;
	prmt.b32 	%r4698, %r19, %r19, %r4697;
	mov.u32 	%r4699, 1040;
	prmt.b32 	%r4700, %r4698, %r19, %r4699;
	mov.u32 	%r4701, 16912;
	prmt.b32 	%r4702, %r4700, %r19, %r4701;
	or.b32  	%r8944, %r4702, %r8944;
	or.b32  	%r8943, %r4702, %r8943;
	or.b32  	%r8942, %r4702, %r8942;
	or.b32  	%r8941, %r4702, %r8941;
	or.b32  	%r8948, %r4702, %r15;
	shl.b32 	%r4703, %r610, 8;
	or.b32  	%r4704, %r4703, %r610;
	shl.b32 	%r4705, %r610, 16;
	or.b32  	%r4706, %r4704, %r4705;
	or.b32  	%r8947, %r4706, %r16;
	bra.uni 	BB0_734;

BB0_901:
	setp.eq.s32	%p607, %r24, 15;
	@%p607 bra 	BB0_902;
	bra.uni 	BB0_771;

BB0_902:
	mov.u32 	%r4757, 64;
	prmt.b32 	%r4758, %r19, %r19, %r4757;
	mov.u32 	%r4759, 1040;
	prmt.b32 	%r4760, %r4758, %r19, %r4759;
	mov.u32 	%r4761, 16912;
	prmt.b32 	%r4762, %r4760, %r19, %r4761;
	or.b32  	%r8944, %r4762, %r8944;
	or.b32  	%r8943, %r4762, %r8943;
	or.b32  	%r8942, %r4762, %r8942;
	shl.b32 	%r4763, %r610, 8;
	or.b32  	%r4764, %r4763, %r610;
	shl.b32 	%r4765, %r610, 16;
	or.b32  	%r4766, %r4764, %r4765;
	or.b32  	%r8941, %r4766, %r8941;
	bra.uni 	BB0_771;

BB0_932:
	setp.ne.s32	%p584, %r24, 31;
	@%p584 bra 	BB0_923;

	mov.u32 	%r4637, 64;
	prmt.b32 	%r4638, %r19, %r19, %r4637;
	mov.u32 	%r4639, 1040;
	prmt.b32 	%r4640, %r4638, %r19, %r4639;
	mov.u32 	%r4641, 16912;
	prmt.b32 	%r4642, %r4640, %r19, %r4641;
	or.b32  	%r8944, %r4642, %r8944;
	or.b32  	%r8943, %r4642, %r8943;
	or.b32  	%r8942, %r4642, %r8942;
	or.b32  	%r8941, %r4642, %r8941;
	or.b32  	%r8948, %r4642, %r15;
	or.b32  	%r8947, %r4642, %r16;
	or.b32  	%r8946, %r4642, %r17;
	shl.b32 	%r4643, %r610, 8;
	or.b32  	%r4644, %r4643, %r610;
	shl.b32 	%r4645, %r610, 16;
	or.b32  	%r4646, %r4644, %r4645;
	or.b32  	%r8945, %r4646, %r18;
	bra.uni 	BB0_1554;

BB0_923:
	mov.u32 	%r8945, %r18;
	bra.uni 	BB0_772;

BB0_612:
	setp.eq.s32	%p461, %r24, 1;
	@%p461 bra 	BB0_613;
	bra.uni 	BB0_11;

BB0_613:
	and.b32  	%r3857, %r19, -65281;
	shl.b32 	%r3858, %r8825, 8;
	or.b32  	%r8944, %r3858, %r3857;
	bra.uni 	BB0_617;

BB0_653:
	setp.eq.s32	%p438, %r24, 17;
	@%p438 bra 	BB0_654;
	bra.uni 	BB0_11;

BB0_654:
	and.b32  	%r3833, %r15, -65281;
	shl.b32 	%r3834, %r8825, 8;
	or.b32  	%r8948, %r3834, %r3833;
	bra.uni 	BB0_658;

BB0_629:
	setp.eq.s32	%p450, %r24, 9;
	@%p450 bra 	BB0_630;
	bra.uni 	BB0_11;

BB0_630:
	and.b32  	%r3845, %r21, -65281;
	shl.b32 	%r3846, %r8825, 8;
	or.b32  	%r8942, %r3846, %r3845;
	bra.uni 	BB0_634;

BB0_670:
	setp.eq.s32	%p427, %r24, 25;
	@%p427 bra 	BB0_671;
	bra.uni 	BB0_11;

BB0_671:
	and.b32  	%r3821, %r17, -65281;
	shl.b32 	%r3822, %r8825, 8;
	or.b32  	%r8946, %r3822, %r3821;
	bra.uni 	BB0_675;

BB0_620:
	setp.eq.s32	%p456, %r24, 5;
	@%p456 bra 	BB0_621;
	bra.uni 	BB0_11;

BB0_621:
	and.b32  	%r3851, %r20, -65281;
	shl.b32 	%r3852, %r8825, 8;
	or.b32  	%r8943, %r3852, %r3851;
	bra.uni 	BB0_625;

BB0_661:
	setp.eq.s32	%p433, %r24, 21;
	@%p433 bra 	BB0_662;
	bra.uni 	BB0_11;

BB0_662:
	and.b32  	%r3827, %r16, -65281;
	shl.b32 	%r3828, %r8825, 8;
	or.b32  	%r8947, %r3828, %r3827;
	bra.uni 	BB0_666;

BB0_637:
	setp.eq.s32	%p445, %r24, 13;
	@%p445 bra 	BB0_638;
	bra.uni 	BB0_11;

BB0_638:
	and.b32  	%r3839, %r22, -65281;
	shl.b32 	%r3840, %r8825, 8;
	or.b32  	%r8941, %r3840, %r3839;
	bra.uni 	BB0_642;

BB0_678:
	setp.eq.s32	%p422, %r24, 29;
	@%p422 bra 	BB0_679;
	bra.uni 	BB0_11;

BB0_679:
	and.b32  	%r3815, %r18, -65281;
	shl.b32 	%r3816, %r8825, 8;
	or.b32  	%r8945, %r3816, %r3815;
	bra.uni 	BB0_683;

BB0_615:
	setp.eq.s32	%p459, %r24, 3;
	@%p459 bra 	BB0_616;
	bra.uni 	BB0_11;

BB0_616:
	and.b32  	%r3854, %r19, 16777215;
	prmt.b32 	%r8944, %r8825, %r3854, 1620;
	bra.uni 	BB0_617;

BB0_656:
	setp.eq.s32	%p436, %r24, 19;
	@%p436 bra 	BB0_657;
	bra.uni 	BB0_11;

BB0_657:
	and.b32  	%r3830, %r15, 16777215;
	prmt.b32 	%r8948, %r8825, %r3830, 1620;

BB0_658:
	mov.u32 	%r8941, %r22;
	mov.u32 	%r8942, %r21;
	mov.u32 	%r8943, %r20;
	mov.u32 	%r8944, %r19;
	mov.u32 	%r8945, %r18;
	mov.u32 	%r8946, %r17;
	mov.u32 	%r8947, %r16;
	bra.uni 	BB0_1553;

BB0_632:
	setp.eq.s32	%p448, %r24, 11;
	@%p448 bra 	BB0_633;
	bra.uni 	BB0_11;

BB0_633:
	and.b32  	%r3842, %r21, 16777215;
	prmt.b32 	%r8942, %r8825, %r3842, 1620;

BB0_634:
	mov.u32 	%r8941, %r22;
	bra.uni 	BB0_643;

BB0_673:
	setp.eq.s32	%p425, %r24, 27;
	@%p425 bra 	BB0_674;
	bra.uni 	BB0_11;

BB0_674:
	and.b32  	%r3818, %r17, 16777215;
	prmt.b32 	%r8946, %r8825, %r3818, 1620;

BB0_675:
	mov.u32 	%r8941, %r22;
	mov.u32 	%r8942, %r21;
	mov.u32 	%r8943, %r20;
	mov.u32 	%r8944, %r19;
	mov.u32 	%r8945, %r18;
	bra.uni 	BB0_647;

BB0_623:
	setp.eq.s32	%p454, %r24, 7;
	@%p454 bra 	BB0_624;
	bra.uni 	BB0_11;

BB0_624:
	and.b32  	%r3848, %r20, 16777215;
	prmt.b32 	%r8943, %r8825, %r3848, 1620;

BB0_625:
	mov.u32 	%r8941, %r22;
	mov.u32 	%r8942, %r21;
	bra.uni 	BB0_644;

BB0_664:
	setp.eq.s32	%p431, %r24, 23;
	@%p431 bra 	BB0_665;
	bra.uni 	BB0_11;

BB0_665:
	and.b32  	%r3824, %r16, 16777215;
	prmt.b32 	%r8947, %r8825, %r3824, 1620;

BB0_666:
	mov.u32 	%r8941, %r22;
	mov.u32 	%r8942, %r21;
	mov.u32 	%r8943, %r20;
	mov.u32 	%r8944, %r19;
	mov.u32 	%r8945, %r18;
	mov.u32 	%r8946, %r17;
	bra.uni 	BB0_648;

BB0_640:
	setp.eq.s32	%p443, %r24, 15;
	@%p443 bra 	BB0_641;
	bra.uni 	BB0_11;

BB0_641:
	and.b32  	%r3836, %r22, 16777215;
	prmt.b32 	%r8941, %r8825, %r3836, 1620;
	bra.uni 	BB0_642;

BB0_681:
	setp.ne.s32	%p420, %r24, 31;
	@%p420 bra 	BB0_11;

	and.b32  	%r3812, %r18, 16777215;
	prmt.b32 	%r8945, %r8825, %r3812, 1620;

BB0_683:
	mov.u32 	%r8941, %r22;
	mov.u32 	%r8942, %r21;
	mov.u32 	%r8943, %r20;
	mov.u32 	%r8944, %r19;
	bra.uni 	BB0_646;

BB0_135:
	setp.eq.s32	%p173, %r24, 1;
	mov.u32 	%r8784, %r8787;
	mov.u32 	%r8785, %r8787;
	mov.u32 	%r8786, %r8787;
	mov.u32 	%r8788, %r8787;
	mov.u32 	%r8789, %r8787;
	mov.u32 	%r8790, %r8787;
	mov.u32 	%r8791, %r8787;
	@%p173 bra 	BB0_136;
	bra.uni 	BB0_215;

BB0_136:
	mov.u32 	%r2903, 24;
	// inline asm
	shf.r.wrap.b32 %r8788, %r17, %r18, %r2903;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8789, %r16, %r17, %r2903;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8790, %r15, %r16, %r2903;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8791, %r22, %r15, %r2903;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8784, %r21, %r22, %r2903;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8785, %r20, %r21, %r2903;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8786, %r19, %r20, %r2903;
	// inline asm
	mov.u32 	%r2901, 0;
	// inline asm
	shf.r.wrap.b32 %r8787, %r2901, %r19, %r2903;
	// inline asm
	bra.uni 	BB0_215;

BB0_167:
	setp.eq.s32	%p150, %r24, 17;
	mov.u32 	%r8784, %r8787;
	mov.u32 	%r8785, %r8787;
	mov.u32 	%r8786, %r8787;
	mov.u32 	%r8788, %r8787;
	mov.u32 	%r8789, %r8787;
	mov.u32 	%r8790, %r8787;
	mov.u32 	%r8791, %r8787;
	@%p150 bra 	BB0_168;
	bra.uni 	BB0_215;

BB0_168:
	mov.u32 	%r2559, 24;
	// inline asm
	shf.r.wrap.b32 %r8788, %r21, %r22, %r2559;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8789, %r20, %r21, %r2559;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8790, %r19, %r20, %r2559;
	// inline asm
	mov.u32 	%r8784, 0;
	// inline asm
	shf.r.wrap.b32 %r8791, %r8784, %r19, %r2559;
	// inline asm
	bra.uni 	BB0_172;

BB0_712:
	setp.eq.s32	%p496, %r14, 10;
	@%p496 bra 	BB0_713;
	bra.uni 	BB0_11;

BB0_713:
	shl.b32 	%r3973, %r21, 8;
	and.b32  	%r3974, %r3973, 65280;
	bfe.u32 	%r3975, %r21, 8, 8;
	or.b32  	%r8942, %r3974, %r3975;
	mov.u32 	%r8949, 10;
	bra.uni 	BB0_776;

BB0_150:
	setp.eq.s32	%p162, %r24, 9;
	mov.u32 	%r8784, %r8787;
	mov.u32 	%r8785, %r8787;
	mov.u32 	%r8786, %r8787;
	mov.u32 	%r8788, %r8787;
	mov.u32 	%r8789, %r8787;
	mov.u32 	%r8790, %r8787;
	mov.u32 	%r8791, %r8787;
	@%p162 bra 	BB0_151;
	bra.uni 	BB0_215;

BB0_151:
	mov.u32 	%r2715, 24;
	// inline asm
	shf.r.wrap.b32 %r8788, %r15, %r16, %r2715;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8789, %r22, %r15, %r2715;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8790, %r21, %r22, %r2715;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8791, %r20, %r21, %r2715;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8784, %r19, %r20, %r2715;
	// inline asm
	mov.u32 	%r8786, 0;
	// inline asm
	shf.r.wrap.b32 %r8785, %r8786, %r19, %r2715;
	// inline asm
	mov.u32 	%r8787, %r8786;
	bra.uni 	BB0_215;

BB0_741:
	setp.eq.s32	%p475, %r14, 25;
	@%p475 bra 	BB0_742;
	bra.uni 	BB0_11;

BB0_742:
	or.b32  	%r3893, %r16, %r17;
	and.b32  	%r3894, %r16, 16777215;
	prmt.b32 	%r8947, %r17, %r3894, 1620;
	shr.u32 	%r8946, %r3893, 24;
	mov.u32 	%r8949, 25;
	mov.u32 	%r8941, %r22;
	mov.u32 	%r8942, %r21;
	mov.u32 	%r8943, %r20;
	mov.u32 	%r8944, %r19;
	mov.u32 	%r8945, %r18;
	mov.u32 	%r8948, %r15;
	bra.uni 	BB0_1554;

BB0_184:
	setp.eq.s32	%p139, %r24, 25;
	mov.u32 	%r8784, %r8787;
	mov.u32 	%r8785, %r8787;
	mov.u32 	%r8786, %r8787;
	mov.u32 	%r8788, %r8787;
	mov.u32 	%r8789, %r8787;
	mov.u32 	%r8790, %r8787;
	mov.u32 	%r8791, %r8787;
	@%p139 bra 	BB0_185;
	bra.uni 	BB0_215;

BB0_185:
	mov.u32 	%r2435, 24;
	// inline asm
	shf.r.wrap.b32 %r8788, %r19, %r20, %r2435;
	// inline asm
	mov.u32 	%r8784, 0;
	// inline asm
	shf.r.wrap.b32 %r8789, %r8784, %r19, %r2435;
	// inline asm
	bra.uni 	BB0_189;

BB0_704:
	setp.eq.s32	%p502, %r14, 6;
	@%p502 bra 	BB0_705;
	bra.uni 	BB0_11;

BB0_705:
	shl.b32 	%r3994, %r20, 8;
	and.b32  	%r3995, %r3994, 65280;
	bfe.u32 	%r3996, %r20, 8, 8;
	or.b32  	%r8943, %r3995, %r3996;
	mov.u32 	%r8949, 6;
	bra.uni 	BB0_779;

BB0_142:
	setp.eq.s32	%p168, %r24, 5;
	mov.u32 	%r8784, %r8787;
	mov.u32 	%r8785, %r8787;
	mov.u32 	%r8786, %r8787;
	mov.u32 	%r8788, %r8787;
	mov.u32 	%r8789, %r8787;
	mov.u32 	%r8790, %r8787;
	mov.u32 	%r8791, %r8787;
	@%p168 bra 	BB0_143;
	bra.uni 	BB0_215;

BB0_143:
	mov.u32 	%r2805, 24;
	// inline asm
	shf.r.wrap.b32 %r8788, %r16, %r17, %r2805;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8789, %r15, %r16, %r2805;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8790, %r22, %r15, %r2805;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8791, %r21, %r22, %r2805;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8784, %r20, %r21, %r2805;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8785, %r19, %r20, %r2805;
	// inline asm
	mov.u32 	%r8787, 0;
	// inline asm
	shf.r.wrap.b32 %r8786, %r8787, %r19, %r2805;
	// inline asm
	bra.uni 	BB0_215;

BB0_732:
	setp.eq.s32	%p481, %r14, 21;
	@%p481 bra 	BB0_733;
	bra.uni 	BB0_11;

BB0_733:
	or.b32  	%r3914, %r15, %r16;
	and.b32  	%r3915, %r15, 16777215;
	prmt.b32 	%r8948, %r16, %r3915, 1620;
	shr.u32 	%r8947, %r3914, 24;
	mov.u32 	%r8949, 21;
	mov.u32 	%r8941, %r22;
	mov.u32 	%r8942, %r21;
	mov.u32 	%r8943, %r20;
	mov.u32 	%r8944, %r19;

BB0_734:
	mov.u32 	%r8945, %r18;
	mov.u32 	%r8946, %r17;
	bra.uni 	BB0_1554;

BB0_175:
	setp.eq.s32	%p145, %r24, 21;
	mov.u32 	%r8784, %r8787;
	mov.u32 	%r8785, %r8787;
	mov.u32 	%r8786, %r8787;
	mov.u32 	%r8788, %r8787;
	mov.u32 	%r8789, %r8787;
	mov.u32 	%r8790, %r8787;
	mov.u32 	%r8791, %r8787;
	@%p145 bra 	BB0_176;
	bra.uni 	BB0_215;

BB0_176:
	mov.u32 	%r2493, 24;
	// inline asm
	shf.r.wrap.b32 %r8788, %r20, %r21, %r2493;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8789, %r19, %r20, %r2493;
	// inline asm
	mov.u32 	%r8784, 0;
	// inline asm
	shf.r.wrap.b32 %r8790, %r8784, %r19, %r2493;
	// inline asm
	bra.uni 	BB0_180;

BB0_719:
	setp.eq.s32	%p491, %r14, 14;
	@%p491 bra 	BB0_720;
	bra.uni 	BB0_11;

BB0_720:
	shl.b32 	%r3952, %r22, 8;
	and.b32  	%r3953, %r3952, 65280;
	bfe.u32 	%r3954, %r22, 8, 8;
	or.b32  	%r8941, %r3953, %r3954;
	mov.u32 	%r8949, 14;
	bra.uni 	BB0_768;

BB0_157:
	setp.eq.s32	%p157, %r24, 13;
	mov.u32 	%r8784, %r8787;
	mov.u32 	%r8785, %r8787;
	mov.u32 	%r8786, %r8787;
	mov.u32 	%r8788, %r8787;
	mov.u32 	%r8789, %r8787;
	mov.u32 	%r8790, %r8787;
	mov.u32 	%r8791, %r8787;
	@%p157 bra 	BB0_158;
	bra.uni 	BB0_215;

BB0_158:
	mov.u32 	%r2633, 24;
	// inline asm
	shf.r.wrap.b32 %r8788, %r22, %r15, %r2633;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8789, %r21, %r22, %r2633;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8790, %r20, %r21, %r2633;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8791, %r19, %r20, %r2633;
	// inline asm
	mov.u32 	%r8785, 0;
	// inline asm
	shf.r.wrap.b32 %r8784, %r8785, %r19, %r2633;
	// inline asm
	bra.uni 	BB0_162;

BB0_748:
	setp.eq.s32	%p470, %r14, 29;
	@%p470 bra 	BB0_749;
	bra.uni 	BB0_11;

BB0_749:
	or.b32  	%r3872, %r17, %r18;
	and.b32  	%r3873, %r17, 16777215;
	prmt.b32 	%r8946, %r18, %r3873, 1620;
	shr.u32 	%r8945, %r3872, 24;
	mov.u32 	%r8949, 29;
	mov.u32 	%r8941, %r22;
	mov.u32 	%r8942, %r21;
	mov.u32 	%r8943, %r20;
	mov.u32 	%r8944, %r19;
	bra.uni 	BB0_773;

BB0_193:
	setp.eq.s32	%p134, %r24, 29;
	mov.u32 	%r8784, %r8787;
	mov.u32 	%r8785, %r8787;
	mov.u32 	%r8786, %r8787;
	mov.u32 	%r8788, %r8787;
	mov.u32 	%r8789, %r8787;
	mov.u32 	%r8790, %r8787;
	mov.u32 	%r8791, %r8787;
	@%p134 bra 	BB0_194;
	bra.uni 	BB0_215;

BB0_194:
	mov.u32 	%r8784, 0;
	mov.u32 	%r2385, 24;
	// inline asm
	shf.r.wrap.b32 %r8788, %r8784, %r19, %r2385;
	// inline asm
	bra.uni 	BB0_198;

BB0_287:
	setp.eq.s32	%p222, %r24, 17;
	@%p222 bra 	BB0_288;
	bra.uni 	BB0_291;

BB0_288:
	mov.u32 	%r3157, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r21, %r22, %r3157;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r20, %r21, %r3157;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r19, %r20, %r3157;
	// inline asm
	mov.u32 	%r8808, 0;
	// inline asm
	shf.r.wrap.b32 %r19, %r8808, %r19, %r3157;
	// inline asm
	bra.uni 	BB0_322;

BB0_271:
	setp.eq.s32	%p234, %r24, 9;
	@%p234 bra 	BB0_272;
	bra.uni 	BB0_291;

BB0_272:
	mov.u32 	%r3313, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r15, %r16, %r3313;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r22, %r15, %r3313;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r21, %r22, %r3313;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3302, %r20, %r21, %r3313;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8808, %r19, %r20, %r3313;
	// inline asm
	mov.u32 	%r8810, 0;
	// inline asm
	shf.r.wrap.b32 %r8809, %r8810, %r19, %r3313;
	// inline asm
	mov.u32 	%r8811, %r8810;
	mov.u32 	%r19, %r3302;
	bra.uni 	BB0_338;

BB0_303:
	setp.eq.s32	%p211, %r24, 25;
	@%p211 bra 	BB0_304;
	bra.uni 	BB0_291;

BB0_304:
	mov.u32 	%r3033, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r19, %r20, %r3033;
	// inline asm
	mov.u32 	%r8808, 0;
	// inline asm
	shf.r.wrap.b32 %r17, %r8808, %r19, %r3033;
	// inline asm
	bra.uni 	BB0_308;

BB0_263:
	setp.eq.s32	%p240, %r24, 5;
	@%p240 bra 	BB0_264;
	bra.uni 	BB0_291;

BB0_264:
	mov.u32 	%r3403, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r16, %r17, %r3403;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r15, %r16, %r3403;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r22, %r15, %r3403;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3388, %r21, %r22, %r3403;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8808, %r20, %r21, %r3403;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8809, %r19, %r20, %r3403;
	// inline asm
	mov.u32 	%r8811, 0;
	// inline asm
	shf.r.wrap.b32 %r8810, %r8811, %r19, %r3403;
	// inline asm
	mov.u32 	%r19, %r3388;
	bra.uni 	BB0_338;

BB0_294:
	setp.eq.s32	%p217, %r24, 21;
	@%p217 bra 	BB0_295;
	bra.uni 	BB0_291;

BB0_295:
	mov.u32 	%r3091, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r20, %r21, %r3091;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r19, %r20, %r3091;
	// inline asm
	mov.u32 	%r8808, 0;
	// inline asm
	shf.r.wrap.b32 %r16, %r8808, %r19, %r3091;
	// inline asm
	bra.uni 	BB0_299;

BB0_278:
	setp.eq.s32	%p229, %r24, 13;
	@%p229 bra 	BB0_279;
	bra.uni 	BB0_291;

BB0_279:
	mov.u32 	%r3231, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r22, %r15, %r3231;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r21, %r22, %r3231;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r20, %r21, %r3231;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3224, %r19, %r20, %r3231;
	// inline asm
	mov.u32 	%r8809, 0;
	// inline asm
	shf.r.wrap.b32 %r8808, %r8809, %r19, %r3231;
	// inline asm
	mov.u32 	%r8810, %r8809;
	mov.u32 	%r8811, %r8809;
	mov.u32 	%r19, %r3224;
	bra.uni 	BB0_338;

BB0_311:
	setp.eq.s32	%p206, %r24, 29;
	@%p206 bra 	BB0_312;
	bra.uni 	BB0_291;

BB0_312:
	mov.u32 	%r8808, 0;
	mov.u32 	%r2983, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r8808, %r19, %r2983;
	// inline asm
	bra.uni 	BB0_334;

BB0_138:
	setp.eq.s32	%p171, %r24, 3;
	mov.u32 	%r8784, %r8787;
	mov.u32 	%r8785, %r8787;
	mov.u32 	%r8786, %r8787;
	mov.u32 	%r8788, %r8787;
	mov.u32 	%r8789, %r8787;
	mov.u32 	%r8790, %r8787;
	mov.u32 	%r8791, %r8787;
	@%p171 bra 	BB0_139;
	bra.uni 	BB0_215;

BB0_139:
	mov.u32 	%r2839, 8;
	// inline asm
	shf.r.wrap.b32 %r8788, %r17, %r18, %r2839;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8789, %r16, %r17, %r2839;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8790, %r15, %r16, %r2839;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8791, %r22, %r15, %r2839;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8784, %r21, %r22, %r2839;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8785, %r20, %r21, %r2839;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8786, %r19, %r20, %r2839;
	// inline asm
	mov.u32 	%r2837, 0;
	// inline asm
	shf.r.wrap.b32 %r8787, %r2837, %r19, %r2839;
	// inline asm
	bra.uni 	BB0_215;

BB0_170:
	setp.eq.s32	%p148, %r24, 19;
	mov.u32 	%r8784, %r8787;
	mov.u32 	%r8785, %r8787;
	mov.u32 	%r8786, %r8787;
	mov.u32 	%r8788, %r8787;
	mov.u32 	%r8789, %r8787;
	mov.u32 	%r8790, %r8787;
	mov.u32 	%r8791, %r8787;
	@%p148 bra 	BB0_171;
	bra.uni 	BB0_215;

BB0_171:
	mov.u32 	%r2519, 8;
	// inline asm
	shf.r.wrap.b32 %r8788, %r21, %r22, %r2519;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8789, %r20, %r21, %r2519;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8790, %r19, %r20, %r2519;
	// inline asm
	mov.u32 	%r8784, 0;
	// inline asm
	shf.r.wrap.b32 %r8791, %r8784, %r19, %r2519;
	// inline asm

BB0_172:
	mov.u32 	%r8785, %r8784;
	mov.u32 	%r8786, %r8784;
	mov.u32 	%r8787, %r8784;
	bra.uni 	BB0_215;

BB0_715:
	setp.eq.s32	%p494, %r14, 12;
	@%p494 bra 	BB0_716;
	bra.uni 	BB0_11;

BB0_716:
	and.b32  	%r3959, %r21, 65535;
	shl.b32 	%r3960, %r21, 8;
	and.b32  	%r3961, %r3960, -16777216;
	or.b32  	%r3962, %r3961, %r3959;
	shr.u32 	%r3963, %r21, 8;
	and.b32  	%r3964, %r3963, 16711680;
	or.b32  	%r8942, %r3962, %r3964;
	mov.u32 	%r8949, 12;

BB0_776:
	mov.u32 	%r8941, %r22;
	bra.uni 	BB0_769;

BB0_153:
	setp.eq.s32	%p160, %r24, 11;
	mov.u32 	%r8784, %r8787;
	mov.u32 	%r8785, %r8787;
	mov.u32 	%r8786, %r8787;
	mov.u32 	%r8788, %r8787;
	mov.u32 	%r8789, %r8787;
	mov.u32 	%r8790, %r8787;
	mov.u32 	%r8791, %r8787;
	@%p160 bra 	BB0_154;
	bra.uni 	BB0_215;

BB0_154:
	mov.u32 	%r2663, 8;
	// inline asm
	shf.r.wrap.b32 %r8788, %r15, %r16, %r2663;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8789, %r22, %r15, %r2663;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8790, %r21, %r22, %r2663;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8791, %r20, %r21, %r2663;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8784, %r19, %r20, %r2663;
	// inline asm
	mov.u32 	%r8786, 0;
	// inline asm
	shf.r.wrap.b32 %r8785, %r8786, %r19, %r2663;
	// inline asm
	mov.u32 	%r8787, %r8786;
	bra.uni 	BB0_215;

BB0_744:
	setp.eq.s32	%p473, %r14, 27;
	@%p473 bra 	BB0_745;
	bra.uni 	BB0_11;

BB0_745:
	and.b32  	%r3882, %r17, 255;
	shl.b32 	%r3883, %r17, 8;
	and.b32  	%r3884, %r3883, 16711680;
	or.b32  	%r3885, %r3884, %r3882;
	shr.u32 	%r3886, %r17, 8;
	and.b32  	%r3887, %r3886, 65280;
	or.b32  	%r8946, %r3885, %r3887;
	mov.u32 	%r8949, 27;

BB0_757:
	mov.u32 	%r8941, %r22;
	mov.u32 	%r8942, %r21;
	mov.u32 	%r8943, %r20;
	mov.u32 	%r8944, %r19;
	mov.u32 	%r8945, %r18;
	bra.uni 	BB0_773;

BB0_187:
	setp.eq.s32	%p137, %r24, 27;
	mov.u32 	%r8784, %r8787;
	mov.u32 	%r8785, %r8787;
	mov.u32 	%r8786, %r8787;
	mov.u32 	%r8788, %r8787;
	mov.u32 	%r8789, %r8787;
	mov.u32 	%r8790, %r8787;
	mov.u32 	%r8791, %r8787;
	@%p137 bra 	BB0_188;
	bra.uni 	BB0_215;

BB0_188:
	mov.u32 	%r2407, 8;
	// inline asm
	shf.r.wrap.b32 %r8788, %r19, %r20, %r2407;
	// inline asm
	mov.u32 	%r8784, 0;
	// inline asm
	shf.r.wrap.b32 %r8789, %r8784, %r19, %r2407;
	// inline asm

BB0_189:
	mov.u32 	%r8785, %r8784;
	mov.u32 	%r8786, %r8784;
	mov.u32 	%r8787, %r8784;
	bra.uni 	BB0_190;

BB0_707:
	setp.eq.s32	%p500, %r14, 8;
	@%p500 bra 	BB0_708;
	bra.uni 	BB0_11;

BB0_708:
	and.b32  	%r3980, %r20, 65535;
	shl.b32 	%r3981, %r20, 8;
	and.b32  	%r3982, %r3981, -16777216;
	or.b32  	%r3983, %r3982, %r3980;
	shr.u32 	%r3984, %r20, 8;
	and.b32  	%r3985, %r3984, 16711680;
	or.b32  	%r8943, %r3983, %r3985;
	mov.u32 	%r8949, 8;

BB0_779:
	mov.u32 	%r8941, %r22;
	mov.u32 	%r8942, %r21;
	bra.uni 	BB0_770;

BB0_145:
	setp.eq.s32	%p166, %r24, 7;
	mov.u32 	%r8784, %r8787;
	mov.u32 	%r8785, %r8787;
	mov.u32 	%r8786, %r8787;
	mov.u32 	%r8788, %r8787;
	mov.u32 	%r8789, %r8787;
	mov.u32 	%r8790, %r8787;
	mov.u32 	%r8791, %r8787;
	@%p166 bra 	BB0_146;
	bra.uni 	BB0_215;

BB0_146:
	mov.u32 	%r2747, 8;
	// inline asm
	shf.r.wrap.b32 %r8788, %r16, %r17, %r2747;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8789, %r15, %r16, %r2747;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8790, %r22, %r15, %r2747;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8791, %r21, %r22, %r2747;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8784, %r20, %r21, %r2747;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8785, %r19, %r20, %r2747;
	// inline asm
	mov.u32 	%r8787, 0;
	// inline asm
	shf.r.wrap.b32 %r8786, %r8787, %r19, %r2747;
	// inline asm
	bra.uni 	BB0_215;

BB0_736:
	setp.eq.s32	%p479, %r14, 23;
	@%p479 bra 	BB0_737;
	bra.uni 	BB0_11;

BB0_737:
	and.b32  	%r3903, %r16, 255;
	shl.b32 	%r3904, %r16, 8;
	and.b32  	%r3905, %r3904, 16711680;
	or.b32  	%r3906, %r3905, %r3903;
	shr.u32 	%r3907, %r16, 8;
	and.b32  	%r3908, %r3907, 65280;
	or.b32  	%r8947, %r3906, %r3908;
	mov.u32 	%r8949, 23;

BB0_760:
	mov.u32 	%r8941, %r22;
	mov.u32 	%r8942, %r21;
	mov.u32 	%r8943, %r20;
	mov.u32 	%r8944, %r19;
	mov.u32 	%r8945, %r18;
	mov.u32 	%r8946, %r17;
	mov.u32 	%r8948, %r15;
	bra.uni 	BB0_1554;

BB0_178:
	setp.eq.s32	%p143, %r24, 23;
	mov.u32 	%r8784, %r8787;
	mov.u32 	%r8785, %r8787;
	mov.u32 	%r8786, %r8787;
	mov.u32 	%r8788, %r8787;
	mov.u32 	%r8789, %r8787;
	mov.u32 	%r8790, %r8787;
	mov.u32 	%r8791, %r8787;
	@%p143 bra 	BB0_179;
	bra.uni 	BB0_215;

BB0_179:
	mov.u32 	%r2459, 8;
	// inline asm
	shf.r.wrap.b32 %r8788, %r20, %r21, %r2459;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8789, %r19, %r20, %r2459;
	// inline asm
	mov.u32 	%r8784, 0;
	// inline asm
	shf.r.wrap.b32 %r8790, %r8784, %r19, %r2459;
	// inline asm

BB0_180:
	mov.u32 	%r8785, %r8784;
	mov.u32 	%r8786, %r8784;
	mov.u32 	%r8787, %r8784;
	mov.u32 	%r8791, %r8784;
	bra.uni 	BB0_215;

BB0_722:
	setp.eq.s32	%p489, %r14, 16;
	@%p489 bra 	BB0_723;
	bra.uni 	BB0_11;

BB0_723:
	and.b32  	%r3938, %r22, 65535;
	shl.b32 	%r3939, %r22, 8;
	and.b32  	%r3940, %r3939, -16777216;
	or.b32  	%r3941, %r3940, %r3938;
	shr.u32 	%r3942, %r22, 8;
	and.b32  	%r3943, %r3942, 16711680;
	or.b32  	%r8941, %r3941, %r3943;
	mov.u32 	%r8949, 16;
	bra.uni 	BB0_768;

BB0_160:
	setp.eq.s32	%p155, %r24, 15;
	mov.u32 	%r8784, %r8787;
	mov.u32 	%r8785, %r8787;
	mov.u32 	%r8786, %r8787;
	mov.u32 	%r8788, %r8787;
	mov.u32 	%r8789, %r8787;
	mov.u32 	%r8790, %r8787;
	mov.u32 	%r8791, %r8787;
	@%p155 bra 	BB0_161;
	bra.uni 	BB0_215;

BB0_161:
	mov.u32 	%r2587, 8;
	// inline asm
	shf.r.wrap.b32 %r8788, %r22, %r15, %r2587;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8789, %r21, %r22, %r2587;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8790, %r20, %r21, %r2587;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8791, %r19, %r20, %r2587;
	// inline asm
	mov.u32 	%r8785, 0;
	// inline asm
	shf.r.wrap.b32 %r8784, %r8785, %r19, %r2587;
	// inline asm

BB0_162:
	mov.u32 	%r8786, %r8785;
	mov.u32 	%r8787, %r8785;
	bra.uni 	BB0_215;

BB0_751:
	setp.ne.s32	%p468, %r14, 31;
	@%p468 bra 	BB0_11;

	and.b32  	%r3861, %r18, 255;
	shl.b32 	%r3862, %r18, 8;
	and.b32  	%r3863, %r3862, 16711680;
	or.b32  	%r3864, %r3863, %r3861;
	shr.u32 	%r3865, %r18, 8;
	and.b32  	%r3866, %r3865, 65280;
	or.b32  	%r8945, %r3864, %r3866;
	mov.u32 	%r8949, 31;

BB0_754:
	mov.u32 	%r8941, %r22;
	mov.u32 	%r8942, %r21;
	mov.u32 	%r8943, %r20;
	mov.u32 	%r8944, %r19;
	bra.uni 	BB0_772;

BB0_11:
	mov.u32 	%r8941, %r22;

BB0_12:
	mov.u32 	%r8942, %r21;

BB0_13:
	mov.u32 	%r8943, %r20;

BB0_14:
	mov.u32 	%r8944, %r19;

BB0_15:
	mov.u32 	%r8945, %r18;

BB0_16:
	mov.u32 	%r8946, %r17;

BB0_17:
	mov.u32 	%r8947, %r16;

BB0_18:
	mov.u32 	%r8948, %r15;

BB0_1553:
	mov.u32 	%r8949, %r14;

BB0_1554:
	ld.param.u64 	%rd42, [amp_param_2];
	add.s32 	%r8774, %r8774, 1;
	mul.wide.u32 	%rd40, %r8774, 4;
	add.s64 	%rd41, %rd42, %rd40;
	ld.global.u32 	%r8773, [%rd41];
	setp.ne.s32	%p1031, %r8773, 0;
	@%p1031 bra 	BB0_5;

BB0_1555:
	st.global.u32 	[%rd3], %r8944;
	st.global.u32 	[%rd3+4], %r8943;
	st.global.u32 	[%rd3+8], %r8942;
	st.global.u32 	[%rd3+12], %r8941;
	st.global.u32 	[%rd3+16], %r8948;
	st.global.u32 	[%rd3+20], %r8947;
	st.global.u32 	[%rd3+24], %r8946;
	st.global.u32 	[%rd3+28], %r8945;
	st.global.u32 	[%rd3+64], %r8949;

BB0_1557:
	ret;
}


  