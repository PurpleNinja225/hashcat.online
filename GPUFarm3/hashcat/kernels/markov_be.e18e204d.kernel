//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: UNKNOWN
// Driver 
// Based on LLVM 3.4svn
//

.version 6.1
.target sm_61, texmode_independent
.address_size 64

	// .globl	l_markov

.entry l_markov(
	.param .u64 .ptr .global .align 4 l_markov_param_0,
	.param .u64 .ptr .global .align 4 l_markov_param_1,
	.param .u64 .ptr .global .align 4 l_markov_param_2,
	.param .u64 l_markov_param_3,
	.param .u32 l_markov_param_4,
	.param .u32 l_markov_param_5,
	.param .u32 l_markov_param_6,
	.param .u32 l_markov_param_7,
	.param .u32 l_markov_param_8,
	.param .u32 l_markov_param_9
)
{
	.local .align 16 .b8 	__local_depot0[64];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<17>;
	.reg .b32 	%r<201>;
	.reg .b64 	%rd<173>;


	mov.u64 	%rd172, __local_depot0;
	cvta.local.u64 	%SP, %rd172;
	ld.param.u64 	%rd82, [l_markov_param_0];
	ld.param.u64 	%rd83, [l_markov_param_1];
	ld.param.u64 	%rd84, [l_markov_param_2];
	ld.param.u64 	%rd85, [l_markov_param_3];
	ld.param.u32 	%r31, [l_markov_param_4];
	ld.param.u32 	%r32, [l_markov_param_5];
	ld.param.u32 	%r33, [l_markov_param_6];
	ld.param.u32 	%r34, [l_markov_param_7];
	ld.param.u32 	%r35, [l_markov_param_8];
	ld.param.u32 	%r36, [l_markov_param_9];
	add.u64 	%rd86, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd86;
	mov.u32 	%r37, %ctaid.x;
	mov.u32 	%r38, %ntid.x;
	mov.b32	%r39, %envreg3;
	mad.lo.s32 	%r40, %r37, %r38, %r39;
	mov.u32 	%r41, %tid.x;
	add.s32 	%r1, %r40, %r41;
	setp.ge.u32	%p1, %r1, %r36;
	@%p1 bra 	BB0_42;

	cvt.u64.u32	%rd2, %r1;
	add.s64 	%rd153, %rd2, %rd85;
	mov.u64 	%rd171, 0;
	st.local.v2.u64 	[%rd1], {%rd171, %rd171};
	st.local.v2.u64 	[%rd1+16], {%rd171, %rd171};
	st.local.v2.u64 	[%rd1+32], {%rd171, %rd171};
	st.local.v2.u64 	[%rd1+48], {%rd171, %rd171};
	cvt.u64.u32	%rd5, %r32;
	not.b32 	%r42, %r32;
	and.b32  	%r43, %r42, 3;
	shl.b32 	%r2, %r43, 3;
	and.b32  	%r44, %r32, -4;
	cvt.u64.u32	%rd88, %r44;
	add.s64 	%rd6, %rd1, %rd88;
	setp.eq.s32	%p2, %r31, 0;
	@%p2 bra 	BB0_2;

	mul.lo.s64 	%rd90, %rd5, 1028;
	add.s64 	%rd147, %rd83, %rd90;
	and.b32  	%r49, %r31, 3;
	mov.u32 	%r191, 1;
	mov.u32 	%r198, 0;
	setp.eq.s32	%p3, %r49, 0;
	@%p3 bra 	BB0_4;

	setp.eq.s32	%p4, %r49, 1;
	@%p4 bra 	BB0_6;
	bra.uni 	BB0_7;

BB0_6:
	mov.u32 	%r190, %r32;
	mov.u32 	%r191, %r198;
	bra.uni 	BB0_17;

BB0_2:
	mov.u64 	%rd171, %rd6;
	mov.u32 	%r199, %r2;
	bra.uni 	BB0_36;

BB0_4:
	mov.u32 	%r197, %r32;
	mov.u64 	%rd162, %rd153;
	mov.u32 	%r199, %r198;
	bra.uni 	BB0_21;

BB0_7:
	setp.eq.s32	%p5, %r49, 2;
	@%p5 bra 	BB0_8;
	bra.uni 	BB0_9;

BB0_8:
	mov.u32 	%r187, %r32;
	mov.u64 	%rd148, %rd153;
	bra.uni 	BB0_13;

BB0_9:
	add.s64 	%rd92, %rd83, %rd90;
	ld.global.u32 	%rd8, [%rd92+1024];
	and.b64  	%rd93, %rd153, -4294967296;
	setp.eq.s64	%p6, %rd93, 0;
	@%p6 bra 	BB0_11;

	div.u64 	%rd148, %rd153, %rd8;
	rem.u64 	%rd145, %rd153, %rd8;
	bra.uni 	BB0_12;

BB0_11:
	cvt.u32.u64	%r50, %rd8;
	cvt.u32.u64	%r51, %rd153;
	div.u32 	%r52, %r51, %r50;
	rem.u32 	%r53, %r51, %r50;
	cvt.u64.u32	%rd148, %r52;
	cvt.u64.u32	%rd145, %r53;

BB0_12:
	shl.b64 	%rd96, %rd145, 2;
	add.s64 	%rd97, %rd92, %rd96;
	ld.global.u32 	%r55, [%rd97];
	shl.b32 	%r56, %r55, %r2;
	ld.local.u32 	%r57, [%rd6];
	or.b32  	%r58, %r57, %r56;
	st.local.u32 	[%rd6], %r58;
	shl.b32 	%r59, %r32, 8;
	add.s32 	%r60, %r55, %r59;
	mul.wide.u32 	%rd98, %r60, 1028;
	add.s64 	%rd147, %rd84, %rd98;
	add.s32 	%r187, %r32, 1;
	not.b32 	%r61, %r187;
	and.b32  	%r62, %r61, 3;
	shl.b32 	%r2, %r62, 3;
	and.b32  	%r63, %r187, -4;
	cvt.u64.u32	%rd99, %r63;
	add.s64 	%rd6, %rd1, %rd99;
	mov.u32 	%r191, 2;

BB0_13:
	ld.global.u32 	%rd20, [%rd147+1024];
	and.b64  	%rd100, %rd148, -4294967296;
	setp.eq.s64	%p7, %rd100, 0;
	@%p7 bra 	BB0_15;

	div.u64 	%rd153, %rd148, %rd20;
	rem.u64 	%rd150, %rd148, %rd20;
	bra.uni 	BB0_16;

BB0_15:
	cvt.u32.u64	%r64, %rd20;
	cvt.u32.u64	%r65, %rd148;
	div.u32 	%r66, %r65, %r64;
	rem.u32 	%r67, %r65, %r64;
	cvt.u64.u32	%rd153, %r66;
	cvt.u64.u32	%rd150, %r67;

BB0_16:
	shl.b64 	%rd101, %rd150, 2;
	add.s64 	%rd102, %rd147, %rd101;
	ld.global.u32 	%r68, [%rd102];
	shl.b32 	%r69, %r68, %r2;
	ld.local.u32 	%r70, [%rd6];
	or.b32  	%r71, %r70, %r69;
	st.local.u32 	[%rd6], %r71;
	shl.b32 	%r72, %r187, 8;
	add.s32 	%r73, %r68, %r72;
	mul.wide.u32 	%rd103, %r73, 1028;
	add.s64 	%rd147, %rd84, %rd103;
	add.s32 	%r190, %r187, 1;
	not.b32 	%r74, %r190;
	and.b32  	%r75, %r74, 3;
	shl.b32 	%r2, %r75, 3;
	and.b32  	%r76, %r190, -4;
	cvt.u64.u32	%rd104, %r76;
	add.s64 	%rd6, %rd1, %rd104;

BB0_17:
	ld.global.u32 	%rd32, [%rd147+1024];
	and.b64  	%rd105, %rd153, -4294967296;
	setp.eq.s64	%p8, %rd105, 0;
	@%p8 bra 	BB0_19;

	div.u64 	%rd162, %rd153, %rd32;
	rem.u64 	%rd155, %rd153, %rd32;
	bra.uni 	BB0_20;

BB0_19:
	cvt.u32.u64	%r77, %rd32;
	cvt.u32.u64	%r78, %rd153;
	div.u32 	%r79, %r78, %r77;
	rem.u32 	%r80, %r78, %r77;
	cvt.u64.u32	%rd162, %r79;
	cvt.u64.u32	%rd155, %r80;

BB0_20:
	shl.b64 	%rd106, %rd155, 2;
	add.s64 	%rd107, %rd147, %rd106;
	ld.global.u32 	%r81, [%rd107];
	shl.b32 	%r82, %r81, %r2;
	ld.local.u32 	%r83, [%rd6];
	or.b32  	%r84, %r83, %r82;
	st.local.u32 	[%rd6], %r84;
	shl.b32 	%r85, %r190, 8;
	add.s32 	%r86, %r81, %r85;
	mul.wide.u32 	%rd108, %r86, 1028;
	add.s64 	%rd147, %rd84, %rd108;
	add.s32 	%r198, %r191, 1;
	add.s32 	%r197, %r190, 1;
	not.b32 	%r87, %r197;
	and.b32  	%r88, %r87, 3;
	shl.b32 	%r2, %r88, 3;
	and.b32  	%r89, %r197, -4;
	cvt.u64.u32	%rd109, %r89;
	add.s64 	%rd6, %rd1, %rd109;
	mov.u64 	%rd171, %rd6;
	mov.u32 	%r199, %r2;

BB0_21:
	setp.lt.u32	%p9, %r31, 4;
	@%p9 bra 	BB0_36;

	mov.u64 	%rd171, %rd6;
	mov.u32 	%r199, %r2;

BB0_23:
	ld.global.u32 	%rd48, [%rd147+1024];
	and.b64  	%rd110, %rd162, -4294967296;
	setp.eq.s64	%p10, %rd110, 0;
	@%p10 bra 	BB0_25;
	bra.uni 	BB0_24;

BB0_25:
	cvt.u32.u64	%r90, %rd48;
	cvt.u32.u64	%r91, %rd162;
	div.u32 	%r92, %r91, %r90;
	rem.u32 	%r93, %r91, %r90;
	cvt.u64.u32	%rd163, %r92;
	cvt.u64.u32	%rd164, %r93;
	bra.uni 	BB0_26;

BB0_24:
	div.u64 	%rd163, %rd162, %rd48;
	rem.u64 	%rd164, %rd162, %rd48;

BB0_26:
	shl.b64 	%rd111, %rd164, 2;
	add.s64 	%rd112, %rd147, %rd111;
	ld.global.u32 	%r94, [%rd112];
	shl.b32 	%r95, %r94, %r199;
	ld.local.u32 	%r96, [%rd171];
	or.b32  	%r97, %r96, %r95;
	st.local.u32 	[%rd171], %r97;
	shl.b32 	%r98, %r197, 8;
	add.s32 	%r99, %r94, %r98;
	cvt.u64.u32	%rd55, %r99;
	mul.wide.u32 	%rd113, %r99, 1028;
	add.s64 	%rd114, %rd84, %rd113;
	ld.global.u32 	%rd56, [%rd114+1024];
	and.b64  	%rd115, %rd163, -4294967296;
	setp.eq.s64	%p11, %rd115, 0;
	@%p11 bra 	BB0_28;
	bra.uni 	BB0_27;

BB0_28:
	cvt.u32.u64	%r100, %rd56;
	cvt.u32.u64	%r101, %rd163;
	div.u32 	%r102, %r101, %r100;
	rem.u32 	%r103, %r101, %r100;
	cvt.u64.u32	%rd165, %r102;
	cvt.u64.u32	%rd166, %r103;
	bra.uni 	BB0_29;

BB0_27:
	div.u64 	%rd165, %rd163, %rd56;
	rem.u64 	%rd166, %rd163, %rd56;

BB0_29:
	add.s32 	%r104, %r197, 1;
	not.b32 	%r105, %r104;
	and.b32  	%r106, %r104, -4;
	cvt.u64.u32	%rd116, %r106;
	add.s64 	%rd117, %rd1, %rd116;
	mul.lo.s64 	%rd118, %rd55, 1028;
	add.s64 	%rd119, %rd84, %rd118;
	shl.b64 	%rd120, %rd166, 2;
	add.s64 	%rd121, %rd119, %rd120;
	ld.global.u32 	%r107, [%rd121];
	and.b32  	%r108, %r105, 3;
	shl.b32 	%r109, %r108, 3;
	shl.b32 	%r110, %r107, %r109;
	ld.local.u32 	%r111, [%rd117];
	or.b32  	%r112, %r111, %r110;
	st.local.u32 	[%rd117], %r112;
	shl.b32 	%r113, %r104, 8;
	add.s32 	%r114, %r107, %r113;
	cvt.u64.u32	%rd63, %r114;
	mul.wide.u32 	%rd122, %r114, 1028;
	add.s64 	%rd123, %rd84, %rd122;
	ld.global.u32 	%rd64, [%rd123+1024];
	and.b64  	%rd124, %rd165, -4294967296;
	setp.eq.s64	%p12, %rd124, 0;
	@%p12 bra 	BB0_31;
	bra.uni 	BB0_30;

BB0_31:
	cvt.u32.u64	%r115, %rd64;
	cvt.u32.u64	%r116, %rd165;
	div.u32 	%r117, %r116, %r115;
	rem.u32 	%r118, %r116, %r115;
	cvt.u64.u32	%rd167, %r117;
	cvt.u64.u32	%rd168, %r118;
	bra.uni 	BB0_32;

BB0_30:
	div.u64 	%rd167, %rd165, %rd64;
	rem.u64 	%rd168, %rd165, %rd64;

BB0_32:
	add.s32 	%r119, %r197, 2;
	not.b32 	%r120, %r119;
	and.b32  	%r121, %r119, -4;
	cvt.u64.u32	%rd125, %r121;
	add.s64 	%rd126, %rd1, %rd125;
	mul.lo.s64 	%rd127, %rd63, 1028;
	add.s64 	%rd128, %rd84, %rd127;
	shl.b64 	%rd129, %rd168, 2;
	add.s64 	%rd130, %rd128, %rd129;
	ld.global.u32 	%r122, [%rd130];
	and.b32  	%r123, %r120, 3;
	shl.b32 	%r124, %r123, 3;
	shl.b32 	%r125, %r122, %r124;
	ld.local.u32 	%r126, [%rd126];
	or.b32  	%r127, %r126, %r125;
	st.local.u32 	[%rd126], %r127;
	shl.b32 	%r128, %r119, 8;
	add.s32 	%r129, %r122, %r128;
	cvt.u64.u32	%rd71, %r129;
	mul.wide.u32 	%rd131, %r129, 1028;
	add.s64 	%rd132, %rd84, %rd131;
	ld.global.u32 	%rd72, [%rd132+1024];
	and.b64  	%rd133, %rd167, -4294967296;
	setp.eq.s64	%p13, %rd133, 0;
	@%p13 bra 	BB0_34;
	bra.uni 	BB0_33;

BB0_34:
	cvt.u32.u64	%r130, %rd72;
	cvt.u32.u64	%r131, %rd167;
	div.u32 	%r132, %r131, %r130;
	rem.u32 	%r133, %r131, %r130;
	cvt.u64.u32	%rd162, %r132;
	cvt.u64.u32	%rd170, %r133;
	bra.uni 	BB0_35;

BB0_33:
	div.u64 	%rd162, %rd167, %rd72;
	rem.u64 	%rd170, %rd167, %rd72;

BB0_35:
	add.s32 	%r134, %r197, 3;
	and.b32  	%r135, %r134, -4;
	cvt.u64.u32	%rd134, %r135;
	add.s64 	%rd135, %rd1, %rd134;
	mul.lo.s64 	%rd136, %rd71, 1028;
	add.s64 	%rd137, %rd84, %rd136;
	shl.b64 	%rd138, %rd170, 2;
	add.s64 	%rd139, %rd137, %rd138;
	ld.global.u32 	%r136, [%rd139];
	shl.b32 	%r137, %r134, 3;
	not.b32 	%r138, %r137;
	and.b32  	%r139, %r138, 24;
	shl.b32 	%r140, %r136, %r139;
	ld.local.u32 	%r141, [%rd135];
	or.b32  	%r142, %r141, %r140;
	st.local.u32 	[%rd135], %r142;
	shl.b32 	%r143, %r134, 8;
	add.s32 	%r144, %r136, %r143;
	mul.wide.u32 	%rd140, %r144, 1028;
	add.s64 	%rd147, %rd84, %rd140;
	add.s32 	%r198, %r198, 4;
	setp.lt.u32	%p14, %r198, %r31;
	add.s32 	%r197, %r197, 4;
	shl.b32 	%r145, %r197, 3;
	not.b32 	%r146, %r145;
	and.b32  	%r199, %r146, 24;
	and.b32  	%r147, %r197, -4;
	cvt.u64.u32	%rd141, %r147;
	add.s64 	%rd171, %rd1, %rd141;
	@%p14 bra 	BB0_23;

BB0_36:
	mov.u32 	%r148, 255;
	shl.b32 	%r149, %r148, %r199;
	and.b32  	%r150, %r149, %r33;
	ld.local.u32 	%r151, [%rd171];
	or.b32  	%r152, %r151, %r150;
	st.local.u32 	[%rd171], %r152;
	setp.eq.s32	%p15, %r34, 0;
	@%p15 bra 	BB0_38;

	add.s32 	%r153, %r32, %r31;
	shl.b32 	%r154, %r153, 3;
	st.local.u32 	[%rd1+56], %r154;

BB0_38:
	add.s32 	%r27, %r32, %r31;
	setp.eq.s32	%p16, %r35, 0;
	@%p16 bra 	BB0_40;

	shl.b32 	%r200, %r27, 3;
	st.local.u32 	[%rd1+60], %r200;
	bra.uni 	BB0_41;

BB0_40:
	ld.local.u32 	%r200, [%rd1+60];

BB0_41:
	mul.lo.s64 	%rd142, %rd2, 80;
	add.s64 	%rd143, %rd82, %rd142;
	ld.local.v4.u32 	{%r155, %r156, %r157, %r158}, [%rd1];
	ld.local.v4.u32 	{%r160, %r161, %r162, %r163}, [%rd1+16];
	ld.local.v4.u32 	{%r164, %r165, %r166, %r167}, [%rd1+32];
	ld.local.v4.u32 	{%r168, %r169, %r170, %r171}, [%rd1+48];
	st.global.u32 	[%rd143], %r155;
	st.global.u32 	[%rd143+4], %r156;
	st.global.u32 	[%rd143+8], %r157;
	st.global.u32 	[%rd143+12], %r158;
	st.global.u32 	[%rd143+16], %r160;
	st.global.u32 	[%rd143+20], %r161;
	st.global.u32 	[%rd143+24], %r162;
	st.global.u32 	[%rd143+28], %r163;
	st.global.u32 	[%rd143+32], %r164;
	st.global.u32 	[%rd143+36], %r165;
	st.global.u32 	[%rd143+40], %r166;
	st.global.u32 	[%rd143+44], %r167;
	st.global.u32 	[%rd143+48], %r168;
	st.global.u32 	[%rd143+52], %r169;
	st.global.u32 	[%rd143+56], %r170;
	st.global.u32 	[%rd143+60], %r200;
	st.global.u32 	[%rd143+64], %r27;

BB0_42:
	ret;
}

	// .globl	r_markov
.entry r_markov(
	.param .u64 .ptr .global .align 4 r_markov_param_0,
	.param .u64 .ptr .global .align 4 r_markov_param_1,
	.param .u64 .ptr .global .align 4 r_markov_param_2,
	.param .u64 r_markov_param_3,
	.param .u32 r_markov_param_4,
	.param .u32 r_markov_param_5,
	.param .u32 r_markov_param_6,
	.param .u32 r_markov_param_7,
	.param .u32 r_markov_param_8
)
{
	.local .align 16 .b8 	__local_depot1[64];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<15>;
	.reg .b32 	%r<136>;
	.reg .b64 	%rd<147>;


	mov.u64 	%rd146, __local_depot1;
	cvta.local.u64 	%SP, %rd146;
	ld.param.u64 	%rd69, [r_markov_param_0];
	ld.param.u64 	%rd70, [r_markov_param_1];
	ld.param.u64 	%rd71, [r_markov_param_2];
	ld.param.u64 	%rd72, [r_markov_param_3];
	ld.param.u32 	%r20, [r_markov_param_4];
	ld.param.u32 	%r21, [r_markov_param_8];
	add.u64 	%rd73, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd73;
	mov.u32 	%r22, %ctaid.x;
	mov.u32 	%r23, %ntid.x;
	mov.b32	%r24, %envreg3;
	mad.lo.s32 	%r25, %r22, %r23, %r24;
	mov.u32 	%r26, %tid.x;
	add.s32 	%r1, %r25, %r26;
	setp.ge.u32	%p1, %r1, %r21;
	@%p1 bra 	BB1_36;

	cvt.u64.u32	%rd2, %r1;
	add.s64 	%rd131, %rd2, %rd72;
	mov.u64 	%rd74, 0;
	st.local.v2.u64 	[%rd1], {%rd74, %rd74};
	st.local.v2.u64 	[%rd1+16], {%rd74, %rd74};
	st.local.v2.u64 	[%rd1+32], {%rd74, %rd74};
	st.local.v2.u64 	[%rd1+48], {%rd74, %rd74};
	setp.eq.s32	%p2, %r20, 0;
	@%p2 bra 	BB1_35;

	and.b32  	%r34, %r20, 3;
	mov.u32 	%r130, 1;
	mov.u32 	%r126, 0;
	setp.eq.s32	%p3, %r34, 0;
	@%p3 bra 	BB1_3;

	setp.eq.s32	%p4, %r34, 1;
	@%p4 bra 	BB1_5;
	bra.uni 	BB1_6;

BB1_5:
	mov.u32 	%r130, %r126;
	bra.uni 	BB1_16;

BB1_3:
	mov.u32 	%r135, %r126;
	mov.u64 	%rd137, %rd131;
	bra.uni 	BB1_20;

BB1_6:
	setp.eq.s32	%p5, %r34, 2;
	@%p5 bra 	BB1_7;
	bra.uni 	BB1_8;

BB1_7:
	mov.u32 	%r127, %r126;
	mov.u64 	%rd127, %rd131;
	bra.uni 	BB1_12;

BB1_8:
	ld.global.u32 	%rd5, [%rd70+1024];
	and.b64  	%rd75, %rd131, -4294967296;
	setp.eq.s64	%p6, %rd75, 0;
	@%p6 bra 	BB1_10;

	div.u64 	%rd127, %rd131, %rd5;
	rem.u64 	%rd125, %rd131, %rd5;
	bra.uni 	BB1_11;

BB1_10:
	cvt.u32.u64	%r35, %rd5;
	cvt.u32.u64	%r36, %rd131;
	div.u32 	%r37, %r36, %r35;
	rem.u32 	%r38, %r36, %r35;
	cvt.u64.u32	%rd127, %r37;
	cvt.u64.u32	%rd125, %r38;

BB1_11:
	shl.b64 	%rd76, %rd125, 2;
	add.s64 	%rd77, %rd70, %rd76;
	ld.global.u32 	%r41, [%rd77];
	shl.b32 	%r126, %r41, 24;
	st.local.u32 	[%rd1], %r126;
	mul.wide.u32 	%rd78, %r41, 1028;
	add.s64 	%rd70, %rd71, %rd78;
	mov.u32 	%r130, 2;
	mov.u32 	%r127, 1;

BB1_12:
	ld.global.u32 	%rd15, [%rd70+1024];
	and.b64  	%rd79, %rd127, -4294967296;
	setp.eq.s64	%p7, %rd79, 0;
	@%p7 bra 	BB1_14;

	div.u64 	%rd131, %rd127, %rd15;
	rem.u64 	%rd129, %rd127, %rd15;
	bra.uni 	BB1_15;

BB1_14:
	cvt.u32.u64	%r42, %rd15;
	cvt.u32.u64	%r43, %rd127;
	div.u32 	%r44, %r43, %r42;
	rem.u32 	%r45, %r43, %r42;
	cvt.u64.u32	%rd131, %r44;
	cvt.u64.u32	%rd129, %r45;

BB1_15:
	xor.b32  	%r46, %r127, 3;
	shl.b32 	%r47, %r46, 3;
	shl.b64 	%rd80, %rd129, 2;
	add.s64 	%rd81, %rd70, %rd80;
	ld.global.u32 	%r48, [%rd81];
	shl.b32 	%r49, %r48, %r47;
	or.b32  	%r50, %r126, %r49;
	st.local.u32 	[%rd1], %r50;
	shl.b32 	%r51, %r127, 8;
	add.s32 	%r52, %r48, %r51;
	mul.wide.u32 	%rd82, %r52, 1028;
	add.s64 	%rd70, %rd71, %rd82;
	add.s32 	%r126, %r127, 1;

BB1_16:
	ld.global.u32 	%rd25, [%rd70+1024];
	and.b64  	%rd83, %rd131, -4294967296;
	setp.eq.s64	%p8, %rd83, 0;
	@%p8 bra 	BB1_18;

	div.u64 	%rd137, %rd131, %rd25;
	rem.u64 	%rd133, %rd131, %rd25;
	bra.uni 	BB1_19;

BB1_18:
	cvt.u32.u64	%r53, %rd25;
	cvt.u32.u64	%r54, %rd131;
	div.u32 	%r55, %r54, %r53;
	rem.u32 	%r56, %r54, %r53;
	cvt.u64.u32	%rd137, %r55;
	cvt.u64.u32	%rd133, %r56;

BB1_19:
	not.b32 	%r57, %r126;
	and.b32  	%r58, %r57, 3;
	shl.b32 	%r59, %r58, 3;
	shl.b64 	%rd84, %rd133, 2;
	add.s64 	%rd85, %rd70, %rd84;
	ld.global.u32 	%r60, [%rd85];
	shl.b32 	%r61, %r60, %r59;
	and.b32  	%r62, %r126, -4;
	cvt.u64.u32	%rd86, %r62;
	add.s64 	%rd87, %rd1, %rd86;
	ld.local.u32 	%r63, [%rd87];
	or.b32  	%r64, %r63, %r61;
	st.local.u32 	[%rd87], %r64;
	shl.b32 	%r65, %r126, 8;
	add.s32 	%r66, %r60, %r65;
	mul.wide.u32 	%rd88, %r66, 1028;
	add.s64 	%rd70, %rd71, %rd88;
	add.s32 	%r135, %r130, 1;
	add.s32 	%r126, %r126, 1;

BB1_20:
	setp.lt.u32	%p9, %r20, 4;
	@%p9 bra 	BB1_35;

	shl.b32 	%r133, %r126, 8;

BB1_22:
	ld.global.u32 	%rd37, [%rd70+1024];
	and.b64  	%rd89, %rd137, -4294967296;
	setp.eq.s64	%p10, %rd89, 0;
	@%p10 bra 	BB1_24;
	bra.uni 	BB1_23;

BB1_24:
	cvt.u32.u64	%r67, %rd37;
	cvt.u32.u64	%r68, %rd137;
	div.u32 	%r69, %r68, %r67;
	rem.u32 	%r70, %r68, %r67;
	cvt.u64.u32	%rd138, %r69;
	cvt.u64.u32	%rd139, %r70;
	bra.uni 	BB1_25;

BB1_23:
	div.u64 	%rd138, %rd137, %rd37;
	rem.u64 	%rd139, %rd137, %rd37;

BB1_25:
	not.b32 	%r71, %r126;
	and.b32  	%r72, %r71, 3;
	shl.b32 	%r73, %r72, 3;
	shl.b64 	%rd90, %rd139, 2;
	add.s64 	%rd91, %rd70, %rd90;
	ld.global.u32 	%r74, [%rd91];
	shl.b32 	%r75, %r74, %r73;
	and.b32  	%r76, %r126, -4;
	cvt.u64.u32	%rd92, %r76;
	add.s64 	%rd93, %rd1, %rd92;
	ld.local.u32 	%r77, [%rd93];
	or.b32  	%r78, %r77, %r75;
	st.local.u32 	[%rd93], %r78;
	add.s32 	%r79, %r133, %r74;
	cvt.u64.u32	%rd44, %r79;
	mul.wide.u32 	%rd94, %r79, 1028;
	add.s64 	%rd95, %rd71, %rd94;
	ld.global.u32 	%rd45, [%rd95+1024];
	and.b64  	%rd96, %rd138, -4294967296;
	setp.eq.s64	%p11, %rd96, 0;
	@%p11 bra 	BB1_27;
	bra.uni 	BB1_26;

BB1_27:
	cvt.u32.u64	%r80, %rd45;
	cvt.u32.u64	%r81, %rd138;
	div.u32 	%r82, %r81, %r80;
	rem.u32 	%r83, %r81, %r80;
	cvt.u64.u32	%rd140, %r82;
	cvt.u64.u32	%rd141, %r83;
	bra.uni 	BB1_28;

BB1_26:
	div.u64 	%rd140, %rd138, %rd45;
	rem.u64 	%rd141, %rd138, %rd45;

BB1_28:
	add.s32 	%r84, %r126, 1;
	not.b32 	%r85, %r84;
	and.b32  	%r86, %r85, 3;
	shl.b32 	%r87, %r86, 3;
	mul.lo.s64 	%rd97, %rd44, 1028;
	add.s64 	%rd98, %rd71, %rd97;
	shl.b64 	%rd99, %rd141, 2;
	add.s64 	%rd100, %rd98, %rd99;
	ld.global.u32 	%r88, [%rd100];
	shl.b32 	%r89, %r88, %r87;
	and.b32  	%r90, %r84, -4;
	cvt.u64.u32	%rd101, %r90;
	add.s64 	%rd102, %rd1, %rd101;
	ld.local.u32 	%r91, [%rd102];
	or.b32  	%r92, %r91, %r89;
	st.local.u32 	[%rd102], %r92;
	add.s32 	%r93, %r133, %r88;
	add.s32 	%r94, %r93, 256;
	cvt.u64.u32	%rd52, %r94;
	mul.wide.u32 	%rd103, %r94, 1028;
	add.s64 	%rd104, %rd71, %rd103;
	ld.global.u32 	%rd53, [%rd104+1024];
	and.b64  	%rd105, %rd140, -4294967296;
	setp.eq.s64	%p12, %rd105, 0;
	@%p12 bra 	BB1_30;
	bra.uni 	BB1_29;

BB1_30:
	cvt.u32.u64	%r95, %rd53;
	cvt.u32.u64	%r96, %rd140;
	div.u32 	%r97, %r96, %r95;
	rem.u32 	%r98, %r96, %r95;
	cvt.u64.u32	%rd142, %r97;
	cvt.u64.u32	%rd143, %r98;
	bra.uni 	BB1_31;

BB1_29:
	div.u64 	%rd142, %rd140, %rd53;
	rem.u64 	%rd143, %rd140, %rd53;

BB1_31:
	add.s32 	%r99, %r126, 2;
	not.b32 	%r100, %r99;
	and.b32  	%r101, %r100, 3;
	shl.b32 	%r102, %r101, 3;
	mul.lo.s64 	%rd106, %rd52, 1028;
	add.s64 	%rd107, %rd71, %rd106;
	shl.b64 	%rd108, %rd143, 2;
	add.s64 	%rd109, %rd107, %rd108;
	ld.global.u32 	%r103, [%rd109];
	shl.b32 	%r104, %r103, %r102;
	and.b32  	%r105, %r99, -4;
	cvt.u64.u32	%rd110, %r105;
	add.s64 	%rd111, %rd1, %rd110;
	ld.local.u32 	%r106, [%rd111];
	or.b32  	%r107, %r106, %r104;
	st.local.u32 	[%rd111], %r107;
	add.s32 	%r108, %r133, %r103;
	add.s32 	%r109, %r108, 512;
	cvt.u64.u32	%rd60, %r109;
	mul.wide.u32 	%rd112, %r109, 1028;
	add.s64 	%rd113, %rd71, %rd112;
	ld.global.u32 	%rd61, [%rd113+1024];
	and.b64  	%rd114, %rd142, -4294967296;
	setp.eq.s64	%p13, %rd114, 0;
	@%p13 bra 	BB1_33;
	bra.uni 	BB1_32;

BB1_33:
	cvt.u32.u64	%r110, %rd61;
	cvt.u32.u64	%r111, %rd142;
	div.u32 	%r112, %r111, %r110;
	rem.u32 	%r113, %r111, %r110;
	cvt.u64.u32	%rd137, %r112;
	cvt.u64.u32	%rd145, %r113;
	bra.uni 	BB1_34;

BB1_32:
	div.u64 	%rd137, %rd142, %rd61;
	rem.u64 	%rd145, %rd142, %rd61;

BB1_34:
	add.s32 	%r114, %r126, 3;
	not.b32 	%r115, %r114;
	and.b32  	%r116, %r115, 3;
	shl.b32 	%r117, %r116, 3;
	mul.lo.s64 	%rd115, %rd60, 1028;
	add.s64 	%rd116, %rd71, %rd115;
	shl.b64 	%rd117, %rd145, 2;
	add.s64 	%rd118, %rd116, %rd117;
	ld.global.u32 	%r118, [%rd118];
	shl.b32 	%r119, %r118, %r117;
	and.b32  	%r120, %r114, -4;
	cvt.u64.u32	%rd119, %r120;
	add.s64 	%rd120, %rd1, %rd119;
	ld.local.u32 	%r121, [%rd120];
	or.b32  	%r122, %r121, %r119;
	st.local.u32 	[%rd120], %r122;
	add.s32 	%r123, %r133, %r118;
	add.s32 	%r124, %r123, 768;
	mul.wide.u32 	%rd121, %r124, 1028;
	add.s64 	%rd70, %rd71, %rd121;
	add.s32 	%r126, %r126, 4;
	add.s32 	%r133, %r133, 1024;
	add.s32 	%r135, %r135, 4;
	setp.lt.u32	%p14, %r135, %r20;
	@%p14 bra 	BB1_22;

BB1_35:
	ld.local.u32 	%r125, [%rd1];
	shl.b64 	%rd122, %rd2, 2;
	add.s64 	%rd123, %rd69, %rd122;
	st.global.u32 	[%rd123], %r125;

BB1_36:
	ret;
}

	// .globl	C_markov
.entry C_markov(
	.param .u64 .ptr .global .align 4 C_markov_param_0,
	.param .u64 .ptr .global .align 4 C_markov_param_1,
	.param .u64 .ptr .global .align 4 C_markov_param_2,
	.param .u64 C_markov_param_3,
	.param .u32 C_markov_param_4,
	.param .u32 C_markov_param_5,
	.param .u32 C_markov_param_6,
	.param .u32 C_markov_param_7,
	.param .u32 C_markov_param_8
)
{
	.local .align 16 .b8 	__local_depot2[64];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<17>;
	.reg .b32 	%r<181>;
	.reg .b64 	%rd<161>;


	mov.u64 	%rd160, __local_depot2;
	cvta.local.u64 	%SP, %rd160;
	ld.param.u64 	%rd78, [C_markov_param_0];
	ld.param.u64 	%rd79, [C_markov_param_1];
	ld.param.u64 	%rd80, [C_markov_param_2];
	ld.param.u64 	%rd81, [C_markov_param_3];
	ld.param.u32 	%r28, [C_markov_param_4];
	ld.param.u32 	%r29, [C_markov_param_5];
	ld.param.u32 	%r30, [C_markov_param_6];
	ld.param.u32 	%r31, [C_markov_param_7];
	ld.param.u32 	%r32, [C_markov_param_8];
	add.u64 	%rd82, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd82;
	mov.u32 	%r33, %ctaid.x;
	mov.u32 	%r34, %ntid.x;
	mov.b32	%r35, %envreg3;
	mad.lo.s32 	%r36, %r33, %r34, %r35;
	mov.u32 	%r37, %tid.x;
	add.s32 	%r1, %r36, %r37;
	setp.ge.u32	%p1, %r1, %r32;
	@%p1 bra 	BB2_40;

	cvt.u64.u32	%rd2, %r1;
	add.s64 	%rd141, %rd2, %rd81;
	mov.u64 	%rd83, 0;
	st.local.v2.u64 	[%rd1], {%rd83, %rd83};
	st.local.v2.u64 	[%rd1+16], {%rd83, %rd83};
	st.local.v2.u64 	[%rd1+32], {%rd83, %rd83};
	st.local.v2.u64 	[%rd1+48], {%rd83, %rd83};
	setp.eq.s32	%p2, %r28, 0;
	mov.u32 	%r180, 24;
	mov.u64 	%rd159, %rd1;
	@%p2 bra 	BB2_35;

	and.b32  	%r51, %r28, 3;
	mov.u32 	%r172, 1;
	mov.u32 	%r165, 0;
	mov.u32 	%r166, 24;
	setp.eq.s32	%p3, %r51, 0;
	@%p3 bra 	BB2_3;

	setp.eq.s32	%p4, %r51, 1;
	@%p4 bra 	BB2_5;
	bra.uni 	BB2_6;

BB2_5:
	mov.u64 	%rd139, %rd1;
	mov.u32 	%r171, %r165;
	mov.u32 	%r172, %r165;
	bra.uni 	BB2_16;

BB2_3:
	mov.u64 	%rd144, %rd1;
	mov.u32 	%r179, %r165;
	mov.u64 	%rd150, %rd141;
	mov.u64 	%rd159, %rd83;
	mov.u32 	%r180, %r165;
	bra.uni 	BB2_20;

BB2_6:
	setp.eq.s32	%p5, %r51, 2;
	@%p5 bra 	BB2_7;
	bra.uni 	BB2_8;

BB2_7:
	mov.u32 	%r167, %r165;
	mov.u64 	%rd136, %rd141;
	bra.uni 	BB2_12;

BB2_8:
	ld.global.u32 	%rd6, [%rd79+1024];
	and.b64  	%rd85, %rd141, -4294967296;
	setp.eq.s64	%p6, %rd85, 0;
	@%p6 bra 	BB2_10;

	div.u64 	%rd136, %rd141, %rd6;
	rem.u64 	%rd134, %rd141, %rd6;
	bra.uni 	BB2_11;

BB2_10:
	cvt.u32.u64	%r52, %rd6;
	cvt.u32.u64	%r53, %rd141;
	div.u32 	%r54, %r53, %r52;
	rem.u32 	%r55, %r53, %r52;
	cvt.u64.u32	%rd136, %r54;
	cvt.u64.u32	%rd134, %r55;

BB2_11:
	shl.b64 	%rd86, %rd134, 2;
	add.s64 	%rd87, %rd79, %rd86;
	ld.global.u32 	%r59, [%rd87];
	shl.b32 	%r165, %r59, 24;
	st.local.u32 	[%rd1], %r165;
	mul.wide.u32 	%rd88, %r59, 1028;
	add.s64 	%rd79, %rd80, %rd88;
	mov.u32 	%r172, 2;
	mov.u32 	%r167, 1;
	mov.u32 	%r166, 16;

BB2_12:
	ld.global.u32 	%rd16, [%rd79+1024];
	and.b64  	%rd89, %rd136, -4294967296;
	setp.eq.s64	%p7, %rd89, 0;
	@%p7 bra 	BB2_14;

	div.u64 	%rd141, %rd136, %rd16;
	rem.u64 	%rd138, %rd136, %rd16;
	bra.uni 	BB2_15;

BB2_14:
	cvt.u32.u64	%r60, %rd16;
	cvt.u32.u64	%r61, %rd136;
	div.u32 	%r62, %r61, %r60;
	rem.u32 	%r63, %r61, %r60;
	cvt.u64.u32	%rd141, %r62;
	cvt.u64.u32	%rd138, %r63;

BB2_15:
	shl.b64 	%rd90, %rd138, 2;
	add.s64 	%rd91, %rd79, %rd90;
	ld.global.u32 	%r64, [%rd91];
	shl.b32 	%r65, %r64, %r166;
	or.b32  	%r66, %r165, %r65;
	st.local.u32 	[%rd1], %r66;
	shl.b32 	%r67, %r167, 8;
	add.s32 	%r68, %r64, %r67;
	mul.wide.u32 	%rd92, %r68, 1028;
	add.s64 	%rd79, %rd80, %rd92;
	add.s32 	%r171, %r167, 1;
	not.b32 	%r69, %r171;
	and.b32  	%r70, %r69, 3;
	shl.b32 	%r166, %r70, 3;
	and.b32  	%r71, %r171, -4;
	cvt.u64.u32	%rd93, %r71;
	add.s64 	%rd139, %rd1, %rd93;
	ld.local.u32 	%r165, [%rd139];

BB2_16:
	ld.global.u32 	%rd28, [%rd79+1024];
	and.b64  	%rd94, %rd141, -4294967296;
	setp.eq.s64	%p8, %rd94, 0;
	@%p8 bra 	BB2_18;

	div.u64 	%rd150, %rd141, %rd28;
	rem.u64 	%rd143, %rd141, %rd28;
	bra.uni 	BB2_19;

BB2_18:
	cvt.u32.u64	%r72, %rd28;
	cvt.u32.u64	%r73, %rd141;
	div.u32 	%r74, %r73, %r72;
	rem.u32 	%r75, %r73, %r72;
	cvt.u64.u32	%rd150, %r74;
	cvt.u64.u32	%rd143, %r75;

BB2_19:
	shl.b64 	%rd95, %rd143, 2;
	add.s64 	%rd96, %rd79, %rd95;
	ld.global.u32 	%r76, [%rd96];
	shl.b32 	%r77, %r76, %r166;
	or.b32  	%r78, %r165, %r77;
	st.local.u32 	[%rd139], %r78;
	shl.b32 	%r79, %r171, 8;
	add.s32 	%r80, %r76, %r79;
	mul.wide.u32 	%rd97, %r80, 1028;
	add.s64 	%rd79, %rd80, %rd97;
	add.s32 	%r179, %r172, 1;
	add.s32 	%r165, %r171, 1;
	not.b32 	%r81, %r165;
	and.b32  	%r82, %r81, 3;
	shl.b32 	%r166, %r82, 3;
	and.b32  	%r83, %r165, -4;
	cvt.u64.u32	%rd98, %r83;
	add.s64 	%rd144, %rd1, %rd98;
	mov.u64 	%rd159, %rd144;
	mov.u32 	%r180, %r166;

BB2_20:
	setp.lt.u32	%p9, %r28, 4;
	@%p9 bra 	BB2_35;

	mov.u64 	%rd159, %rd144;
	mov.u32 	%r180, %r166;

BB2_22:
	ld.global.u32 	%rd44, [%rd79+1024];
	and.b64  	%rd99, %rd150, -4294967296;
	setp.eq.s64	%p10, %rd99, 0;
	@%p10 bra 	BB2_24;
	bra.uni 	BB2_23;

BB2_24:
	cvt.u32.u64	%r84, %rd44;
	cvt.u32.u64	%r85, %rd150;
	div.u32 	%r86, %r85, %r84;
	rem.u32 	%r87, %r85, %r84;
	cvt.u64.u32	%rd151, %r86;
	cvt.u64.u32	%rd152, %r87;
	bra.uni 	BB2_25;

BB2_23:
	div.u64 	%rd151, %rd150, %rd44;
	rem.u64 	%rd152, %rd150, %rd44;

BB2_25:
	shl.b64 	%rd100, %rd152, 2;
	add.s64 	%rd101, %rd79, %rd100;
	ld.global.u32 	%r88, [%rd101];
	shl.b32 	%r89, %r88, %r180;
	ld.local.u32 	%r90, [%rd159];
	or.b32  	%r91, %r90, %r89;
	st.local.u32 	[%rd159], %r91;
	shl.b32 	%r92, %r165, 8;
	add.s32 	%r93, %r88, %r92;
	cvt.u64.u32	%rd51, %r93;
	mul.wide.u32 	%rd102, %r93, 1028;
	add.s64 	%rd103, %rd80, %rd102;
	ld.global.u32 	%rd52, [%rd103+1024];
	and.b64  	%rd104, %rd151, -4294967296;
	setp.eq.s64	%p11, %rd104, 0;
	@%p11 bra 	BB2_27;
	bra.uni 	BB2_26;

BB2_27:
	cvt.u32.u64	%r94, %rd52;
	cvt.u32.u64	%r95, %rd151;
	div.u32 	%r96, %r95, %r94;
	rem.u32 	%r97, %r95, %r94;
	cvt.u64.u32	%rd153, %r96;
	cvt.u64.u32	%rd154, %r97;
	bra.uni 	BB2_28;

BB2_26:
	div.u64 	%rd153, %rd151, %rd52;
	rem.u64 	%rd154, %rd151, %rd52;

BB2_28:
	add.s32 	%r98, %r165, 1;
	not.b32 	%r99, %r98;
	and.b32  	%r100, %r98, -4;
	cvt.u64.u32	%rd105, %r100;
	add.s64 	%rd106, %rd1, %rd105;
	mul.lo.s64 	%rd107, %rd51, 1028;
	add.s64 	%rd108, %rd80, %rd107;
	shl.b64 	%rd109, %rd154, 2;
	add.s64 	%rd110, %rd108, %rd109;
	ld.global.u32 	%r101, [%rd110];
	and.b32  	%r102, %r99, 3;
	shl.b32 	%r103, %r102, 3;
	shl.b32 	%r104, %r101, %r103;
	ld.local.u32 	%r105, [%rd106];
	or.b32  	%r106, %r105, %r104;
	st.local.u32 	[%rd106], %r106;
	shl.b32 	%r107, %r98, 8;
	add.s32 	%r108, %r101, %r107;
	cvt.u64.u32	%rd59, %r108;
	mul.wide.u32 	%rd111, %r108, 1028;
	add.s64 	%rd112, %rd80, %rd111;
	ld.global.u32 	%rd60, [%rd112+1024];
	and.b64  	%rd113, %rd153, -4294967296;
	setp.eq.s64	%p12, %rd113, 0;
	@%p12 bra 	BB2_30;
	bra.uni 	BB2_29;

BB2_30:
	cvt.u32.u64	%r109, %rd60;
	cvt.u32.u64	%r110, %rd153;
	div.u32 	%r111, %r110, %r109;
	rem.u32 	%r112, %r110, %r109;
	cvt.u64.u32	%rd155, %r111;
	cvt.u64.u32	%rd156, %r112;
	bra.uni 	BB2_31;

BB2_29:
	div.u64 	%rd155, %rd153, %rd60;
	rem.u64 	%rd156, %rd153, %rd60;

BB2_31:
	add.s32 	%r113, %r165, 2;
	not.b32 	%r114, %r113;
	and.b32  	%r115, %r113, -4;
	cvt.u64.u32	%rd114, %r115;
	add.s64 	%rd115, %rd1, %rd114;
	mul.lo.s64 	%rd116, %rd59, 1028;
	add.s64 	%rd117, %rd80, %rd116;
	shl.b64 	%rd118, %rd156, 2;
	add.s64 	%rd119, %rd117, %rd118;
	ld.global.u32 	%r116, [%rd119];
	and.b32  	%r117, %r114, 3;
	shl.b32 	%r118, %r117, 3;
	shl.b32 	%r119, %r116, %r118;
	ld.local.u32 	%r120, [%rd115];
	or.b32  	%r121, %r120, %r119;
	st.local.u32 	[%rd115], %r121;
	shl.b32 	%r122, %r113, 8;
	add.s32 	%r123, %r116, %r122;
	cvt.u64.u32	%rd67, %r123;
	mul.wide.u32 	%rd120, %r123, 1028;
	add.s64 	%rd121, %rd80, %rd120;
	ld.global.u32 	%rd68, [%rd121+1024];
	and.b64  	%rd122, %rd155, -4294967296;
	setp.eq.s64	%p13, %rd122, 0;
	@%p13 bra 	BB2_33;
	bra.uni 	BB2_32;

BB2_33:
	cvt.u32.u64	%r124, %rd68;
	cvt.u32.u64	%r125, %rd155;
	div.u32 	%r126, %r125, %r124;
	rem.u32 	%r127, %r125, %r124;
	cvt.u64.u32	%rd150, %r126;
	cvt.u64.u32	%rd158, %r127;
	bra.uni 	BB2_34;

BB2_32:
	div.u64 	%rd150, %rd155, %rd68;
	rem.u64 	%rd158, %rd155, %rd68;

BB2_34:
	add.s32 	%r128, %r165, 3;
	and.b32  	%r129, %r128, -4;
	cvt.u64.u32	%rd123, %r129;
	add.s64 	%rd124, %rd1, %rd123;
	mul.lo.s64 	%rd125, %rd67, 1028;
	add.s64 	%rd126, %rd80, %rd125;
	shl.b64 	%rd127, %rd158, 2;
	add.s64 	%rd128, %rd126, %rd127;
	ld.global.u32 	%r130, [%rd128];
	shl.b32 	%r131, %r128, 3;
	not.b32 	%r132, %r131;
	and.b32  	%r133, %r132, 24;
	shl.b32 	%r134, %r130, %r133;
	ld.local.u32 	%r135, [%rd124];
	or.b32  	%r136, %r135, %r134;
	st.local.u32 	[%rd124], %r136;
	shl.b32 	%r137, %r128, 8;
	add.s32 	%r138, %r130, %r137;
	mul.wide.u32 	%rd129, %r138, 1028;
	add.s64 	%rd79, %rd80, %rd129;
	add.s32 	%r179, %r179, 4;
	setp.lt.u32	%p14, %r179, %r28;
	add.s32 	%r165, %r165, 4;
	shl.b32 	%r139, %r165, 3;
	not.b32 	%r140, %r139;
	and.b32  	%r180, %r140, 24;
	and.b32  	%r141, %r165, -4;
	cvt.u64.u32	%rd130, %r141;
	add.s64 	%rd159, %rd1, %rd130;
	@%p14 bra 	BB2_22;

BB2_35:
	mov.u32 	%r142, 255;
	shl.b32 	%r143, %r142, %r180;
	and.b32  	%r144, %r143, %r29;
	ld.local.u32 	%r145, [%rd159];
	or.b32  	%r146, %r145, %r144;
	st.local.u32 	[%rd159], %r146;
	setp.eq.s32	%p15, %r30, 0;
	@%p15 bra 	BB2_37;

	shl.b32 	%r147, %r28, 3;
	st.local.u32 	[%rd1+56], %r147;

BB2_37:
	setp.eq.s32	%p16, %r31, 0;
	@%p16 bra 	BB2_39;

	shl.b32 	%r148, %r28, 3;
	st.local.u32 	[%rd1+60], %r148;

BB2_39:
	mul.lo.s64 	%rd131, %rd2, 36;
	add.s64 	%rd132, %rd78, %rd131;
	ld.local.v4.u32 	{%r149, %r150, %r151, %r152}, [%rd1];
	ld.local.v4.u32 	{%r154, %r155, %r156, %r157}, [%rd1+16];
	st.global.u32 	[%rd132], %r149;
	st.global.u32 	[%rd132+4], %r150;
	st.global.u32 	[%rd132+8], %r151;
	st.global.u32 	[%rd132+12], %r152;
	st.global.u32 	[%rd132+16], %r154;
	st.global.u32 	[%rd132+20], %r155;
	st.global.u32 	[%rd132+24], %r156;
	st.global.u32 	[%rd132+28], %r157;
	st.global.u32 	[%rd132+32], %r28;

BB2_40:
	ret;
}


  