//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: UNKNOWN
// Driver 
// Based on LLVM 3.4svn
//

.version 6.1
.target sm_61, texmode_independent
.address_size 64

	// .globl	gpu_decompress

.entry gpu_decompress(
	.param .u64 .ptr .global .align 4 gpu_decompress_param_0,
	.param .u64 .ptr .global .align 4 gpu_decompress_param_1,
	.param .u64 .ptr .global .align 4 gpu_decompress_param_2,
	.param .u64 gpu_decompress_param_3
)
{
	.local .align 4 .b8 	__local_depot0[260];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<10>;
	.reg .b32 	%r<56>;
	.reg .b64 	%rd<45>;


	mov.u64 	%rd44, __local_depot0;
	cvta.local.u64 	%SP, %rd44;
	ld.param.u64 	%rd6, [gpu_decompress_param_0];
	ld.param.u64 	%rd7, [gpu_decompress_param_1];
	ld.param.u64 	%rd8, [gpu_decompress_param_2];
	ld.param.u64 	%rd9, [gpu_decompress_param_3];
	add.u64 	%rd10, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd10;
	mov.u32 	%r22, %ctaid.x;
	mov.u32 	%r23, %ntid.x;
	mov.b32	%r24, %envreg3;
	mad.lo.s32 	%r25, %r22, %r23, %r24;
	mov.u32 	%r26, %tid.x;
	add.s32 	%r27, %r25, %r26;
	cvt.s64.s32	%rd2, %r27;
	setp.ge.u64	%p1, %rd2, %rd9;
	@%p1 bra 	BB0_12;

	mul.lo.s64 	%rd11, %rd2, 12;
	add.s64 	%rd12, %rd6, %rd11;
	ld.global.u32 	%r1, [%rd12];
	ld.global.u32 	%r2, [%rd12+4];
	ld.global.u32 	%r3, [%rd12+8];
	mov.u64 	%rd13, 0;
	st.local.u32 	[%rd1+4], %rd13;
	st.local.u32 	[%rd1], %rd13;
	st.local.u32 	[%rd1+12], %rd13;
	st.local.u32 	[%rd1+8], %rd13;
	st.local.u32 	[%rd1+20], %rd13;
	st.local.u32 	[%rd1+16], %rd13;
	st.local.u32 	[%rd1+28], %rd13;
	st.local.u32 	[%rd1+24], %rd13;
	st.local.u32 	[%rd1+36], %rd13;
	st.local.u32 	[%rd1+32], %rd13;
	st.local.u32 	[%rd1+44], %rd13;
	st.local.u32 	[%rd1+40], %rd13;
	st.local.u32 	[%rd1+52], %rd13;
	st.local.u32 	[%rd1+48], %rd13;
	st.local.u32 	[%rd1+60], %rd13;
	st.local.u32 	[%rd1+56], %rd13;
	st.local.u32 	[%rd1+68], %rd13;
	st.local.u32 	[%rd1+64], %rd13;
	st.local.u32 	[%rd1+76], %rd13;
	st.local.u32 	[%rd1+72], %rd13;
	st.local.u32 	[%rd1+84], %rd13;
	st.local.u32 	[%rd1+80], %rd13;
	st.local.u32 	[%rd1+92], %rd13;
	st.local.u32 	[%rd1+88], %rd13;
	st.local.u32 	[%rd1+100], %rd13;
	st.local.u32 	[%rd1+96], %rd13;
	st.local.u32 	[%rd1+108], %rd13;
	st.local.u32 	[%rd1+104], %rd13;
	st.local.u32 	[%rd1+116], %rd13;
	st.local.u32 	[%rd1+112], %rd13;
	st.local.u32 	[%rd1+124], %rd13;
	st.local.u32 	[%rd1+120], %rd13;
	st.local.u32 	[%rd1+132], %rd13;
	st.local.u32 	[%rd1+128], %rd13;
	st.local.u32 	[%rd1+140], %rd13;
	st.local.u32 	[%rd1+136], %rd13;
	st.local.u32 	[%rd1+148], %rd13;
	st.local.u32 	[%rd1+144], %rd13;
	st.local.u32 	[%rd1+156], %rd13;
	st.local.u32 	[%rd1+152], %rd13;
	st.local.u32 	[%rd1+164], %rd13;
	st.local.u32 	[%rd1+160], %rd13;
	st.local.u32 	[%rd1+172], %rd13;
	st.local.u32 	[%rd1+168], %rd13;
	st.local.u32 	[%rd1+180], %rd13;
	st.local.u32 	[%rd1+176], %rd13;
	st.local.u32 	[%rd1+188], %rd13;
	st.local.u32 	[%rd1+184], %rd13;
	st.local.u32 	[%rd1+196], %rd13;
	st.local.u32 	[%rd1+192], %rd13;
	st.local.u32 	[%rd1+204], %rd13;
	st.local.u32 	[%rd1+200], %rd13;
	st.local.u32 	[%rd1+212], %rd13;
	st.local.u32 	[%rd1+208], %rd13;
	st.local.u32 	[%rd1+220], %rd13;
	st.local.u32 	[%rd1+216], %rd13;
	st.local.u32 	[%rd1+228], %rd13;
	st.local.u32 	[%rd1+224], %rd13;
	st.local.u32 	[%rd1+236], %rd13;
	st.local.u32 	[%rd1+232], %rd13;
	st.local.u32 	[%rd1+244], %rd13;
	st.local.u32 	[%rd1+240], %rd13;
	st.local.u32 	[%rd1+252], %rd13;
	st.local.u32 	[%rd1+248], %rd13;
	setp.eq.s32	%p2, %r2, 0;
	@%p2 bra 	BB0_10;

	and.b32  	%r4, %r2, 3;
	setp.eq.s32	%p3, %r4, 0;
	mov.u32 	%r54, 0;
	@%p3 bra 	BB0_8;

	setp.eq.s32	%p4, %r4, 1;
	mov.u32 	%r50, 0;
	@%p4 bra 	BB0_7;

	setp.eq.s32	%p5, %r4, 2;
	mov.u32 	%r48, 0;
	@%p5 bra 	BB0_6;

	mul.wide.u32 	%rd14, %r1, 4;
	add.s64 	%rd15, %rd7, %rd14;
	ld.global.u32 	%r32, [%rd15];
	st.local.u32 	[%rd1], %r32;
	add.s32 	%r1, %r1, 1;
	mov.u32 	%r48, 1;

BB0_6:
	mul.wide.u32 	%rd16, %r1, 4;
	add.s64 	%rd17, %rd7, %rd16;
	ld.global.u32 	%r33, [%rd17];
	mul.wide.u32 	%rd18, %r48, 4;
	add.s64 	%rd19, %rd1, %rd18;
	st.local.u32 	[%rd19], %r33;
	add.s32 	%r50, %r48, 1;
	add.s32 	%r1, %r1, 1;

BB0_7:
	mul.wide.u32 	%rd20, %r1, 4;
	add.s64 	%rd21, %rd7, %rd20;
	ld.global.u32 	%r34, [%rd21];
	mul.wide.u32 	%rd22, %r50, 4;
	add.s64 	%rd23, %rd1, %rd22;
	st.local.u32 	[%rd23], %r34;
	add.s32 	%r54, %r50, 1;
	add.s32 	%r1, %r1, 1;

BB0_8:
	setp.lt.u32	%p6, %r2, 4;
	@%p6 bra 	BB0_10;

BB0_9:
	mul.wide.u32 	%rd24, %r1, 4;
	add.s64 	%rd25, %rd7, %rd24;
	ld.global.u32 	%r35, [%rd25];
	mul.wide.u32 	%rd26, %r54, 4;
	add.s64 	%rd27, %rd1, %rd26;
	st.local.u32 	[%rd27], %r35;
	add.s32 	%r36, %r1, 1;
	mul.wide.u32 	%rd28, %r36, 4;
	add.s64 	%rd29, %rd7, %rd28;
	ld.global.u32 	%r37, [%rd29];
	add.s32 	%r38, %r54, 1;
	mul.wide.u32 	%rd30, %r38, 4;
	add.s64 	%rd31, %rd1, %rd30;
	st.local.u32 	[%rd31], %r37;
	add.s32 	%r39, %r1, 2;
	mul.wide.u32 	%rd32, %r39, 4;
	add.s64 	%rd33, %rd7, %rd32;
	ld.global.u32 	%r40, [%rd33];
	add.s32 	%r41, %r54, 2;
	mul.wide.u32 	%rd34, %r41, 4;
	add.s64 	%rd35, %rd1, %rd34;
	st.local.u32 	[%rd35], %r40;
	add.s32 	%r42, %r1, 3;
	mul.wide.u32 	%rd36, %r42, 4;
	add.s64 	%rd37, %rd7, %rd36;
	ld.global.u32 	%r43, [%rd37];
	add.s32 	%r44, %r54, 3;
	mul.wide.u32 	%rd38, %r44, 4;
	add.s64 	%rd39, %rd1, %rd38;
	st.local.u32 	[%rd39], %r43;
	add.s32 	%r1, %r1, 4;
	add.s32 	%r54, %r54, 4;
	setp.lt.u32	%p7, %r54, %r2;
	@%p7 bra 	BB0_9;

BB0_10:
	st.local.u32 	[%rd1+256], %r3;
	mul.lo.s64 	%rd40, %rd2, 260;
	add.s64 	%rd5, %rd8, %rd40;
	mov.u32 	%r55, 0;
	mov.pred 	%p8, 0;
	@%p8 bra 	BB0_12;

BB0_11:
	mul.wide.s32 	%rd41, %r55, 4;
	add.s64 	%rd42, %rd1, %rd41;
	ld.local.u32 	%r46, [%rd42];
	add.s64 	%rd43, %rd5, %rd41;
	st.global.u32 	[%rd43], %r46;
	add.s32 	%r55, %r55, 1;
	setp.lt.u32	%p9, %r55, 65;
	@%p9 bra 	BB0_11;

BB0_12:
	ret;
}

	// .globl	gpu_memset
.entry gpu_memset(
	.param .u64 .ptr .global .align 16 gpu_memset_param_0,
	.param .u32 gpu_memset_param_1,
	.param .u64 gpu_memset_param_2
)
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<8>;
	.reg .b64 	%rd<6>;


	ld.param.u64 	%rd2, [gpu_memset_param_0];
	ld.param.u32 	%r1, [gpu_memset_param_1];
	ld.param.u64 	%rd3, [gpu_memset_param_2];
	mov.b32	%r2, %envreg3;
	mov.u32 	%r3, %ctaid.x;
	mov.u32 	%r4, %ntid.x;
	mad.lo.s32 	%r5, %r3, %r4, %r2;
	mov.u32 	%r6, %tid.x;
	add.s32 	%r7, %r5, %r6;
	cvt.s64.s32	%rd1, %r7;
	setp.ge.u64	%p1, %rd1, %rd3;
	@%p1 bra 	BB1_2;

	shl.b64 	%rd4, %rd1, 4;
	add.s64 	%rd5, %rd2, %rd4;
	st.global.v4.u32 	[%rd5], {%r1, %r1, %r1, %r1};

BB1_2:
	ret;
}

	// .globl	gpu_atinit
.entry gpu_atinit(
	.param .u64 .ptr .global .align 4 gpu_atinit_param_0,
	.param .u64 gpu_atinit_param_1
)
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<13>;
	.reg .b64 	%rd<7>;


	ld.param.u64 	%rd2, [gpu_atinit_param_0];
	ld.param.u64 	%rd3, [gpu_atinit_param_1];
	mov.b32	%r1, %envreg3;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mad.lo.s32 	%r4, %r2, %r3, %r1;
	mov.u32 	%r5, %tid.x;
	add.s32 	%r6, %r4, %r5;
	cvt.s64.s32	%rd1, %r6;
	setp.ge.u64	%p1, %rd1, %rd3;
	@%p1 bra 	BB2_2;

	cvt.u32.u64	%r7, %rd1;
	shr.u64 	%rd4, %rd1, 32;
	cvt.u32.u64	%r8, %rd4;
	xor.b32  	%r9, %r7, 1549556828;
	xor.b32  	%r10, %r8, 909522486;
	mul.lo.s64 	%rd5, %rd1, 260;
	add.s64 	%rd6, %rd2, %rd5;
	st.global.u32 	[%rd6], %r9;
	st.global.u32 	[%rd6+4], %r10;
	mov.u32 	%r11, 0;
	st.global.u32 	[%rd6+8], %r11;
	st.global.u32 	[%rd6+12], %r11;
	st.global.u32 	[%rd6+16], %r11;
	st.global.u32 	[%rd6+20], %r11;
	st.global.u32 	[%rd6+24], %r11;
	st.global.u32 	[%rd6+28], %r11;
	st.global.u32 	[%rd6+32], %r11;
	st.global.u32 	[%rd6+36], %r11;
	st.global.u32 	[%rd6+40], %r11;
	st.global.u32 	[%rd6+44], %r11;
	st.global.u32 	[%rd6+48], %r11;
	st.global.u32 	[%rd6+52], %r11;
	st.global.u32 	[%rd6+56], %r11;
	st.global.u32 	[%rd6+60], %r11;
	st.global.u32 	[%rd6+64], %r11;
	st.global.u32 	[%rd6+68], %r11;
	st.global.u32 	[%rd6+72], %r11;
	st.global.u32 	[%rd6+76], %r11;
	st.global.u32 	[%rd6+80], %r11;
	st.global.u32 	[%rd6+84], %r11;
	st.global.u32 	[%rd6+88], %r11;
	st.global.u32 	[%rd6+92], %r11;
	st.global.u32 	[%rd6+96], %r11;
	st.global.u32 	[%rd6+100], %r11;
	st.global.u32 	[%rd6+104], %r11;
	st.global.u32 	[%rd6+108], %r11;
	st.global.u32 	[%rd6+112], %r11;
	st.global.u32 	[%rd6+116], %r11;
	st.global.u32 	[%rd6+120], %r11;
	st.global.u32 	[%rd6+124], %r11;
	st.global.u32 	[%rd6+128], %r11;
	st.global.u32 	[%rd6+132], %r11;
	st.global.u32 	[%rd6+136], %r11;
	st.global.u32 	[%rd6+140], %r11;
	st.global.u32 	[%rd6+144], %r11;
	st.global.u32 	[%rd6+148], %r11;
	st.global.u32 	[%rd6+152], %r11;
	st.global.u32 	[%rd6+156], %r11;
	st.global.u32 	[%rd6+160], %r11;
	st.global.u32 	[%rd6+164], %r11;
	st.global.u32 	[%rd6+168], %r11;
	st.global.u32 	[%rd6+172], %r11;
	st.global.u32 	[%rd6+176], %r11;
	st.global.u32 	[%rd6+180], %r11;
	st.global.u32 	[%rd6+184], %r11;
	st.global.u32 	[%rd6+188], %r11;
	st.global.u32 	[%rd6+192], %r11;
	st.global.u32 	[%rd6+196], %r11;
	st.global.u32 	[%rd6+200], %r11;
	st.global.u32 	[%rd6+204], %r11;
	st.global.u32 	[%rd6+208], %r11;
	st.global.u32 	[%rd6+212], %r11;
	st.global.u32 	[%rd6+216], %r11;
	st.global.u32 	[%rd6+220], %r11;
	st.global.u32 	[%rd6+224], %r11;
	st.global.u32 	[%rd6+228], %r11;
	st.global.u32 	[%rd6+232], %r11;
	st.global.u32 	[%rd6+236], %r11;
	st.global.u32 	[%rd6+240], %r11;
	st.global.u32 	[%rd6+244], %r11;
	st.global.u32 	[%rd6+248], %r11;
	st.global.u32 	[%rd6+252], %r11;
	mov.u32 	%r12, 7;
	st.global.u32 	[%rd6+256], %r12;

BB2_2:
	ret;
}

	// .globl	m15500_m04
.entry m15500_m04(
	.param .u64 .ptr .global .align 4 m15500_m04_param_0,
	.param .u64 .ptr .global .align 4 m15500_m04_param_1,
	.param .u64 .ptr .global .align 4 m15500_m04_param_2,
	.param .u64 .ptr .global .align 4 m15500_m04_param_3,
	.param .u64 .ptr .global .align 1 m15500_m04_param_4,
	.param .u64 .ptr .global .align 1 m15500_m04_param_5,
	.param .u64 .ptr .global .align 4 m15500_m04_param_6,
	.param .u64 .ptr .global .align 4 m15500_m04_param_7,
	.param .u64 .ptr .global .align 4 m15500_m04_param_8,
	.param .u64 .ptr .global .align 4 m15500_m04_param_9,
	.param .u64 .ptr .global .align 4 m15500_m04_param_10,
	.param .u64 .ptr .global .align 4 m15500_m04_param_11,
	.param .u64 .ptr .global .align 4 m15500_m04_param_12,
	.param .u64 .ptr .global .align 4 m15500_m04_param_13,
	.param .u64 .ptr .global .align 8 m15500_m04_param_14,
	.param .u64 .ptr .global .align 4 m15500_m04_param_15,
	.param .u64 .ptr .global .align 4 m15500_m04_param_16,
	.param .u64 .ptr .global .align 4 m15500_m04_param_17,
	.param .u64 .ptr .global .align 1 m15500_m04_param_18,
	.param .u64 .ptr .global .align 4 m15500_m04_param_19,
	.param .u64 .ptr .global .align 4 m15500_m04_param_20,
	.param .u64 .ptr .global .align 4 m15500_m04_param_21,
	.param .u64 .ptr .global .align 4 m15500_m04_param_22,
	.param .u64 .ptr .global .align 4 m15500_m04_param_23,
	.param .u32 m15500_m04_param_24,
	.param .u32 m15500_m04_param_25,
	.param .u32 m15500_m04_param_26,
	.param .u32 m15500_m04_param_27,
	.param .u32 m15500_m04_param_28,
	.param .u32 m15500_m04_param_29,
	.param .u32 m15500_m04_param_30,
	.param .u32 m15500_m04_param_31,
	.param .u32 m15500_m04_param_32,
	.param .u32 m15500_m04_param_33,
	.param .u64 m15500_m04_param_34
)
{
	.reg .pred 	%p<97>;
	.reg .b32 	%r<2255>;
	.reg .b64 	%rd<63>;


	ld.param.u64 	%rd5, [m15500_m04_param_0];
	ld.param.u64 	%rd18, [m15500_m04_param_17];
	ld.param.u64 	%rd19, [m15500_m04_param_19];
	ld.param.u32 	%r242, [m15500_m04_param_24];
	ld.param.u32 	%r243, [m15500_m04_param_25];
	ld.param.u32 	%r244, [m15500_m04_param_26];
	ld.param.u32 	%r245, [m15500_m04_param_27];
	ld.param.u32 	%r246, [m15500_m04_param_30];
	ld.param.u32 	%r247, [m15500_m04_param_31];
	ld.param.u32 	%r248, [m15500_m04_param_32];
	ld.param.u64 	%rd20, [m15500_m04_param_34];
	mov.b32	%r250, %envreg3;
	mov.u32 	%r251, %ctaid.x;
	mov.u32 	%r252, %ntid.x;
	mad.lo.s32 	%r253, %r251, %r252, %r250;
	mov.u32 	%r254, %tid.x;
	add.s32 	%r255, %r253, %r254;
	cvt.s64.s32	%rd1, %r255;
	setp.ge.u64	%p1, %rd1, %rd20;
	@%p1 bra 	BB3_141;

	mul.lo.s64 	%rd21, %rd1, 260;
	add.s64 	%rd22, %rd5, %rd21;
	ld.global.u32 	%r1, [%rd22];
	ld.global.u32 	%r2, [%rd22+4];
	ld.global.u32 	%r3, [%rd22+8];
	ld.global.u32 	%r4, [%rd22+12];
	ld.global.u32 	%r5, [%rd22+16];
	ld.global.u32 	%r6, [%rd22+20];
	ld.global.u32 	%r7, [%rd22+24];
	ld.global.u32 	%r8, [%rd22+256];
	mul.wide.u32 	%rd23, %r245, 564;
	add.s64 	%rd24, %rd18, %rd23;
	ld.global.u32 	%r9, [%rd24];
	ld.global.u32 	%r10, [%rd24+4];
	ld.global.u32 	%r11, [%rd24+8];
	ld.global.u32 	%r12, [%rd24+12];
	ld.global.u32 	%r13, [%rd24+16];
	setp.eq.s32	%p2, %r246, 0;
	@%p2 bra 	BB3_141;

	and.b32  	%r257, %r8, 3;
	mov.u32 	%r258, 4;
	sub.s32 	%r259, %r258, %r257;
	shr.u32 	%r14, %r8, 2;
	shl.b32 	%r260, %r259, 2;
	mov.u32 	%r261, 1985229328;
	shr.u32 	%r262, %r261, %r260;
	and.b32  	%r15, %r262, 65535;
	mov.u32 	%r263, 1732584193;
	mov.u32 	%r264, -271733879;
	shf.l.wrap.b32 	%r17, %r264, %r264, 30;
	or.b32  	%r18, %r17, -1732584194;
	shf.l.wrap.b32 	%r19, %r263, %r263, 30;
	xor.b32  	%r20, %r19, %r17;
	and.b32  	%r21, %r243, 31;
	and.b32  	%r22, %r244, 31;
	cvt.u64.u32	%rd2, %r248;
	and.b64  	%rd3, %rd1, 4294967295;
	mov.u32 	%r2222, 0;

BB3_3:
	ld.param.u32 	%r2206, [m15500_m04_param_33];
	ld.param.u64 	%rd58, [m15500_m04_param_2];
	mul.wide.u32 	%rd25, %r2222, 260;
	add.s64 	%rd26, %rd58, %rd25;
	ld.global.u32 	%r24, [%rd26+256];
	add.s32 	%r25, %r24, %r8;
	ld.global.u32 	%r2229, [%rd26];
	ld.global.u32 	%r2228, [%rd26+4];
	ld.global.u32 	%r2227, [%rd26+8];
	ld.global.u32 	%r2226, [%rd26+12];
	ld.global.u32 	%r2232, [%rd26+16];
	ld.global.u32 	%r2231, [%rd26+20];
	ld.global.u32 	%r2230, [%rd26+24];
	setp.eq.s32	%p3, %r2206, 10001;
	@%p3 bra 	BB3_35;
	bra.uni 	BB3_4;

BB3_35:
	setp.gt.s32	%p27, %r14, 7;
	@%p27 bra 	BB3_50;

	setp.gt.s32	%p39, %r14, 3;
	@%p39 bra 	BB3_44;

	setp.gt.s32	%p45, %r14, 1;
	@%p45 bra 	BB3_41;

	setp.eq.s32	%p48, %r14, 0;
	@%p48 bra 	BB3_67;
	bra.uni 	BB3_39;

BB3_67:
	// inline asm
	prmt.b32 %r2230, %r2231, %r2230, %r15;
	// inline asm
	// inline asm
	prmt.b32 %r2231, %r2232, %r2231, %r15;
	// inline asm
	// inline asm
	prmt.b32 %r2232, %r2226, %r2232, %r15;
	// inline asm
	// inline asm
	prmt.b32 %r2226, %r2227, %r2226, %r15;
	// inline asm
	// inline asm
	prmt.b32 %r2227, %r2228, %r2227, %r15;
	// inline asm
	// inline asm
	prmt.b32 %r2228, %r2229, %r2228, %r15;
	// inline asm
	mov.u32 	%r661, 0;
	// inline asm
	prmt.b32 %r2229, %r661, %r2229, %r15;
	// inline asm
	bra.uni 	BB3_68;

BB3_4:
	and.b32  	%r266, %r24, 3;
	sub.s32 	%r268, %r258, %r266;
	shl.b32 	%r269, %r268, 2;
	shr.u32 	%r271, %r261, %r269;
	and.b32  	%r33, %r271, 65535;
	shr.u32 	%r265, %r24, 2;
	setp.gt.s32	%p4, %r265, 7;
	@%p4 bra 	BB3_19;

	setp.gt.s32	%p16, %r265, 3;
	@%p16 bra 	BB3_13;

	setp.gt.s32	%p22, %r265, 1;
	@%p22 bra 	BB3_10;

	setp.eq.s32	%p25, %r265, 0;
	@%p25 bra 	BB3_34;
	bra.uni 	BB3_8;

BB3_34:
	// inline asm
	prmt.b32 %r2223, %r6, %r7, %r33;
	// inline asm
	// inline asm
	prmt.b32 %r2224, %r5, %r6, %r33;
	// inline asm
	// inline asm
	prmt.b32 %r2225, %r4, %r5, %r33;
	// inline asm
	// inline asm
	prmt.b32 %r2236, %r3, %r4, %r33;
	// inline asm
	// inline asm
	prmt.b32 %r2235, %r2, %r3, %r33;
	// inline asm
	// inline asm
	prmt.b32 %r2234, %r1, %r2, %r33;
	// inline asm
	mov.u32 	%r465, 0;
	// inline asm
	prmt.b32 %r2233, %r465, %r1, %r33;
	// inline asm
	bra.uni 	BB3_70;

BB3_50:
	setp.gt.s32	%p28, %r14, 11;
	@%p28 bra 	BB3_56;

	setp.gt.s32	%p34, %r14, 9;
	@%p34 bra 	BB3_54;

	setp.eq.s32	%p37, %r14, 8;
	@%p37 bra 	BB3_61;

	setp.eq.s32	%p38, %r14, 9;
	mov.u32 	%r2223, %r7;
	mov.u32 	%r2224, %r6;
	mov.u32 	%r2225, %r5;
	mov.u32 	%r2233, %r1;
	mov.u32 	%r2234, %r2;
	mov.u32 	%r2235, %r3;
	mov.u32 	%r2236, %r4;
	@%p38 bra 	BB3_61;
	bra.uni 	BB3_70;

BB3_19:
	setp.gt.s32	%p5, %r265, 11;
	@%p5 bra 	BB3_25;

	setp.gt.s32	%p11, %r265, 9;
	@%p11 bra 	BB3_23;

	setp.eq.s32	%p14, %r265, 8;
	@%p14 bra 	BB3_30;

	setp.eq.s32	%p15, %r265, 9;
	@%p15 bra 	BB3_30;
	bra.uni 	BB3_68;

BB3_44:
	setp.gt.s32	%p40, %r14, 5;
	@%p40 bra 	BB3_48;

	setp.eq.s32	%p43, %r14, 4;
	@%p43 bra 	BB3_65;
	bra.uni 	BB3_46;

BB3_65:
	// inline asm
	prmt.b32 %r2230, %r2228, %r2227, %r15;
	// inline asm
	// inline asm
	prmt.b32 %r2231, %r2229, %r2228, %r15;
	// inline asm
	mov.u32 	%r2226, 0;
	// inline asm
	prmt.b32 %r2232, %r2226, %r2229, %r15;
	// inline asm
	mov.u32 	%r2223, %r7;
	mov.u32 	%r2224, %r6;
	mov.u32 	%r2225, %r5;
	mov.u32 	%r2227, %r2226;
	mov.u32 	%r2228, %r2226;
	mov.u32 	%r2229, %r2226;
	bra.uni 	BB3_69;

BB3_13:
	setp.gt.s32	%p17, %r265, 5;
	@%p17 bra 	BB3_17;

	setp.eq.s32	%p20, %r265, 4;
	@%p20 bra 	BB3_32;
	bra.uni 	BB3_15;

BB3_32:
	// inline asm
	prmt.b32 %r2223, %r2, %r3, %r33;
	// inline asm
	// inline asm
	prmt.b32 %r2224, %r1, %r2, %r33;
	// inline asm
	mov.u32 	%r2233, 0;
	// inline asm
	prmt.b32 %r2225, %r2233, %r1, %r33;
	// inline asm
	mov.u32 	%r2234, %r2233;
	mov.u32 	%r2235, %r2233;
	mov.u32 	%r2236, %r2233;
	bra.uni 	BB3_70;

BB3_56:
	setp.gt.s32	%p29, %r14, 13;
	@%p29 bra 	BB3_59;

	setp.eq.s32	%p32, %r14, 12;
	@%p32 bra 	BB3_61;

	setp.eq.s32	%p33, %r14, 13;
	mov.u32 	%r2223, %r7;
	mov.u32 	%r2224, %r6;
	mov.u32 	%r2225, %r5;
	mov.u32 	%r2233, %r1;
	mov.u32 	%r2234, %r2;
	mov.u32 	%r2235, %r3;
	mov.u32 	%r2236, %r4;
	@%p33 bra 	BB3_61;
	bra.uni 	BB3_70;

BB3_25:
	setp.gt.s32	%p6, %r265, 13;
	@%p6 bra 	BB3_28;

	setp.eq.s32	%p9, %r265, 12;
	@%p9 bra 	BB3_30;

	setp.eq.s32	%p10, %r265, 13;
	@%p10 bra 	BB3_30;
	bra.uni 	BB3_68;

BB3_41:
	setp.eq.s32	%p46, %r14, 2;
	@%p46 bra 	BB3_66;
	bra.uni 	BB3_42;

BB3_66:
	// inline asm
	prmt.b32 %r2230, %r2226, %r2232, %r15;
	// inline asm
	// inline asm
	prmt.b32 %r2231, %r2227, %r2226, %r15;
	// inline asm
	// inline asm
	prmt.b32 %r2232, %r2228, %r2227, %r15;
	// inline asm
	// inline asm
	prmt.b32 %r2226, %r2229, %r2228, %r15;
	// inline asm
	mov.u32 	%r2228, 0;
	// inline asm
	prmt.b32 %r2227, %r2228, %r2229, %r15;
	// inline asm
	mov.u32 	%r2223, %r7;
	mov.u32 	%r2224, %r6;
	mov.u32 	%r2225, %r5;
	mov.u32 	%r2229, %r2228;
	bra.uni 	BB3_69;

BB3_10:
	setp.eq.s32	%p23, %r265, 2;
	@%p23 bra 	BB3_33;
	bra.uni 	BB3_11;

BB3_33:
	// inline asm
	prmt.b32 %r2223, %r4, %r5, %r33;
	// inline asm
	// inline asm
	prmt.b32 %r2224, %r3, %r4, %r33;
	// inline asm
	// inline asm
	prmt.b32 %r2225, %r2, %r3, %r33;
	// inline asm
	// inline asm
	prmt.b32 %r2236, %r1, %r2, %r33;
	// inline asm
	mov.u32 	%r2233, 0;
	// inline asm
	prmt.b32 %r2235, %r2233, %r1, %r33;
	// inline asm
	mov.u32 	%r2234, %r2233;
	bra.uni 	BB3_70;

BB3_54:
	setp.eq.s32	%p35, %r14, 10;
	@%p35 bra 	BB3_61;

	setp.eq.s32	%p36, %r14, 11;
	mov.u32 	%r2223, %r7;
	mov.u32 	%r2224, %r6;
	mov.u32 	%r2225, %r5;
	mov.u32 	%r2233, %r1;
	mov.u32 	%r2234, %r2;
	mov.u32 	%r2235, %r3;
	mov.u32 	%r2236, %r4;
	@%p36 bra 	BB3_61;
	bra.uni 	BB3_70;

BB3_23:
	setp.eq.s32	%p12, %r265, 10;
	@%p12 bra 	BB3_30;

	setp.eq.s32	%p13, %r265, 11;
	@%p13 bra 	BB3_30;
	bra.uni 	BB3_68;

BB3_48:
	setp.eq.s32	%p41, %r14, 6;
	@%p41 bra 	BB3_64;
	bra.uni 	BB3_49;

BB3_64:
	mov.u32 	%r2226, 0;
	// inline asm
	prmt.b32 %r2230, %r2226, %r2229, %r15;
	// inline asm
	mov.u32 	%r2223, %r7;
	mov.u32 	%r2224, %r6;
	mov.u32 	%r2225, %r5;
	mov.u32 	%r2227, %r2226;
	mov.u32 	%r2228, %r2226;
	mov.u32 	%r2229, %r2226;
	bra.uni 	BB3_62;

BB3_17:
	setp.eq.s32	%p18, %r265, 6;
	@%p18 bra 	BB3_31;
	bra.uni 	BB3_18;

BB3_31:
	mov.u32 	%r2224, 0;
	// inline asm
	prmt.b32 %r2223, %r2224, %r1, %r33;
	// inline asm
	mov.u32 	%r2225, %r2224;
	mov.u32 	%r2233, %r2224;
	mov.u32 	%r2234, %r2224;
	mov.u32 	%r2235, %r2224;
	mov.u32 	%r2236, %r2224;
	bra.uni 	BB3_70;

BB3_59:
	setp.eq.s32	%p30, %r14, 14;
	@%p30 bra 	BB3_61;

	setp.ne.s32	%p31, %r14, 15;
	mov.u32 	%r2223, %r7;
	mov.u32 	%r2224, %r6;
	mov.u32 	%r2225, %r5;
	mov.u32 	%r2233, %r1;
	mov.u32 	%r2234, %r2;
	mov.u32 	%r2235, %r3;
	mov.u32 	%r2236, %r4;
	@%p31 bra 	BB3_70;
	bra.uni 	BB3_61;

BB3_28:
	setp.eq.s32	%p7, %r265, 14;
	@%p7 bra 	BB3_30;

	setp.ne.s32	%p8, %r265, 15;
	@%p8 bra 	BB3_68;
	bra.uni 	BB3_30;

BB3_39:
	setp.eq.s32	%p49, %r14, 1;
	@%p49 bra 	BB3_40;
	bra.uni 	BB3_68;

BB3_40:
	// inline asm
	prmt.b32 %r2230, %r2232, %r2231, %r15;
	// inline asm
	// inline asm
	prmt.b32 %r2231, %r2226, %r2232, %r15;
	// inline asm
	// inline asm
	prmt.b32 %r2232, %r2227, %r2226, %r15;
	// inline asm
	// inline asm
	prmt.b32 %r2226, %r2228, %r2227, %r15;
	// inline asm
	// inline asm
	prmt.b32 %r2227, %r2229, %r2228, %r15;
	// inline asm
	mov.u32 	%r635, 0;
	// inline asm
	prmt.b32 %r2228, %r635, %r2229, %r15;
	// inline asm
	mov.u32 	%r2223, %r7;
	mov.u32 	%r2224, %r6;
	mov.u32 	%r2225, %r5;
	mov.u32 	%r2229, %r635;
	bra.uni 	BB3_69;

BB3_8:
	setp.eq.s32	%p26, %r265, 1;
	@%p26 bra 	BB3_9;
	bra.uni 	BB3_68;

BB3_9:
	// inline asm
	prmt.b32 %r2223, %r5, %r6, %r33;
	// inline asm
	// inline asm
	prmt.b32 %r2224, %r4, %r5, %r33;
	// inline asm
	// inline asm
	prmt.b32 %r2225, %r3, %r4, %r33;
	// inline asm
	// inline asm
	prmt.b32 %r2236, %r2, %r3, %r33;
	// inline asm
	// inline asm
	prmt.b32 %r2235, %r1, %r2, %r33;
	// inline asm
	mov.u32 	%r2233, 0;
	// inline asm
	prmt.b32 %r2234, %r2233, %r1, %r33;
	// inline asm
	bra.uni 	BB3_70;

BB3_46:
	setp.eq.s32	%p44, %r14, 5;
	@%p44 bra 	BB3_47;
	bra.uni 	BB3_68;

BB3_47:
	// inline asm
	prmt.b32 %r2230, %r2229, %r2228, %r15;
	// inline asm
	mov.u32 	%r2226, 0;
	// inline asm
	prmt.b32 %r2231, %r2226, %r2229, %r15;
	// inline asm
	mov.u32 	%r2223, %r7;
	mov.u32 	%r2224, %r6;
	mov.u32 	%r2225, %r5;
	mov.u32 	%r2227, %r2226;
	mov.u32 	%r2228, %r2226;
	mov.u32 	%r2229, %r2226;
	bra.uni 	BB3_63;

BB3_15:
	setp.eq.s32	%p21, %r265, 5;
	@%p21 bra 	BB3_16;
	bra.uni 	BB3_68;

BB3_16:
	// inline asm
	prmt.b32 %r2223, %r1, %r2, %r33;
	// inline asm
	mov.u32 	%r2225, 0;
	// inline asm
	prmt.b32 %r2224, %r2225, %r1, %r33;
	// inline asm
	mov.u32 	%r2233, %r2225;
	mov.u32 	%r2234, %r2225;
	mov.u32 	%r2235, %r2225;
	mov.u32 	%r2236, %r2225;
	bra.uni 	BB3_70;

BB3_42:
	setp.eq.s32	%p47, %r14, 3;
	@%p47 bra 	BB3_43;
	bra.uni 	BB3_68;

BB3_43:
	// inline asm
	prmt.b32 %r2230, %r2227, %r2226, %r15;
	// inline asm
	// inline asm
	prmt.b32 %r2231, %r2228, %r2227, %r15;
	// inline asm
	// inline asm
	prmt.b32 %r2232, %r2229, %r2228, %r15;
	// inline asm
	mov.u32 	%r2227, 0;
	// inline asm
	prmt.b32 %r2226, %r2227, %r2229, %r15;
	// inline asm
	mov.u32 	%r2223, %r7;
	mov.u32 	%r2224, %r6;
	mov.u32 	%r2225, %r5;
	mov.u32 	%r2228, %r2227;
	mov.u32 	%r2229, %r2227;
	bra.uni 	BB3_69;

BB3_11:
	setp.eq.s32	%p24, %r265, 3;
	@%p24 bra 	BB3_12;
	bra.uni 	BB3_68;

BB3_12:
	// inline asm
	prmt.b32 %r2223, %r3, %r4, %r33;
	// inline asm
	// inline asm
	prmt.b32 %r2224, %r2, %r3, %r33;
	// inline asm
	// inline asm
	prmt.b32 %r2225, %r1, %r2, %r33;
	// inline asm
	mov.u32 	%r2233, 0;
	// inline asm
	prmt.b32 %r2236, %r2233, %r1, %r33;
	// inline asm
	mov.u32 	%r2234, %r2233;
	mov.u32 	%r2235, %r2233;
	bra.uni 	BB3_70;

BB3_49:
	setp.eq.s32	%p42, %r14, 7;
	mov.u32 	%r2223, %r7;
	mov.u32 	%r2224, %r6;
	mov.u32 	%r2225, %r5;
	mov.u32 	%r2233, %r1;
	mov.u32 	%r2234, %r2;
	mov.u32 	%r2235, %r3;
	mov.u32 	%r2236, %r4;
	@%p42 bra 	BB3_61;
	bra.uni 	BB3_70;

BB3_61:
	mov.u32 	%r2226, 0;
	mov.u32 	%r2223, %r7;
	mov.u32 	%r2224, %r6;
	mov.u32 	%r2225, %r5;
	mov.u32 	%r2227, %r2226;
	mov.u32 	%r2228, %r2226;
	mov.u32 	%r2229, %r2226;
	mov.u32 	%r2230, %r2226;

BB3_62:
	mov.u32 	%r2231, %r2226;

BB3_63:
	mov.u32 	%r2232, %r2226;
	bra.uni 	BB3_69;

BB3_18:
	setp.eq.s32	%p19, %r265, 7;
	@%p19 bra 	BB3_30;
	bra.uni 	BB3_68;

BB3_30:
	mov.u32 	%r2223, 0;
	mov.u32 	%r2224, %r2223;
	mov.u32 	%r2225, %r2223;
	mov.u32 	%r2233, %r2223;
	mov.u32 	%r2234, %r2223;
	mov.u32 	%r2235, %r2223;
	mov.u32 	%r2236, %r2223;
	bra.uni 	BB3_70;

BB3_68:
	mov.u32 	%r2223, %r7;
	mov.u32 	%r2224, %r6;
	mov.u32 	%r2225, %r5;

BB3_69:
	mov.u32 	%r2233, %r1;
	mov.u32 	%r2234, %r2;
	mov.u32 	%r2235, %r3;
	mov.u32 	%r2236, %r4;

BB3_70:
	or.b32  	%r669, %r2230, %r2223;
	mov.u32 	%r2241, 0;
	mov.u32 	%r715, 14119;
	// inline asm
	prmt.b32 %r664, %r669, %r2241, %r715;
	// inline asm
	mov.u32 	%r719, 5895;
	// inline asm
	prmt.b32 %r668, %r669, %r2241, %r719;
	// inline asm
	or.b32  	%r677, %r2231, %r2224;
	// inline asm
	prmt.b32 %r672, %r677, %r2241, %r715;
	// inline asm
	// inline asm
	prmt.b32 %r676, %r677, %r2241, %r719;
	// inline asm
	or.b32  	%r685, %r2232, %r2225;
	// inline asm
	prmt.b32 %r680, %r685, %r2241, %r715;
	// inline asm
	// inline asm
	prmt.b32 %r684, %r685, %r2241, %r719;
	// inline asm
	or.b32  	%r693, %r2236, %r2226;
	// inline asm
	prmt.b32 %r688, %r693, %r2241, %r715;
	// inline asm
	// inline asm
	prmt.b32 %r692, %r693, %r2241, %r719;
	// inline asm
	or.b32  	%r701, %r2235, %r2227;
	// inline asm
	prmt.b32 %r696, %r701, %r2241, %r715;
	// inline asm
	// inline asm
	prmt.b32 %r700, %r701, %r2241, %r719;
	// inline asm
	or.b32  	%r709, %r2234, %r2228;
	// inline asm
	prmt.b32 %r704, %r709, %r2241, %r715;
	// inline asm
	// inline asm
	prmt.b32 %r708, %r709, %r2241, %r719;
	// inline asm
	or.b32  	%r717, %r2233, %r2229;
	// inline asm
	prmt.b32 %r712, %r717, %r2241, %r715;
	// inline asm
	// inline asm
	prmt.b32 %r716, %r717, %r2241, %r719;
	// inline asm
	shl.b32 	%r730, %r25, 1;
	and.b32  	%r731, %r730, 2;
	sub.s32 	%r733, %r258, %r731;
	bfe.u32 	%r729, %r25, 1, 30;
	shl.b32 	%r734, %r733, 2;
	shr.u32 	%r736, %r261, %r734;
	and.b32  	%r118, %r736, 65535;
	mov.u32 	%r2243, 128;
	setp.gt.s32	%p50, %r729, 7;
	@%p50 bra 	BB3_86;

	setp.gt.s32	%p62, %r729, 3;
	@%p62 bra 	BB3_79;

	setp.gt.s32	%p68, %r729, 1;
	@%p68 bra 	BB3_76;

	setp.eq.s32	%p71, %r729, 0;
	@%p71 bra 	BB3_112;
	bra.uni 	BB3_74;

BB3_112:
	mov.u32 	%r1189, 0;
	// inline asm
	prmt.b32 %r2241, %r1189, %r1189, %r118;
	// inline asm
	mov.u32 	%r1170, 128;
	// inline asm
	prmt.b32 %r2242, %r1170, %r1189, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2243, %r13, %r1170, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2244, %r12, %r13, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2237, %r11, %r12, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2238, %r10, %r11, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2239, %r9, %r10, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2240, %r1189, %r9, %r118;
	// inline asm
	mov.u32 	%r2245, %r2241;
	mov.u32 	%r2246, %r2241;
	mov.u32 	%r2247, %r2241;
	mov.u32 	%r2248, %r2241;
	mov.u32 	%r2249, %r2241;
	mov.u32 	%r2250, %r2241;
	bra.uni 	BB3_113;

BB3_86:
	setp.gt.s32	%p51, %r729, 11;
	@%p51 bra 	BB3_94;

	setp.gt.s32	%p57, %r729, 9;
	@%p57 bra 	BB3_91;

	setp.eq.s32	%p60, %r729, 8;
	@%p60 bra 	BB3_105;
	bra.uni 	BB3_89;

BB3_105:
	mov.u32 	%r882, 128;
	// inline asm
	prmt.b32 %r2249, %r13, %r882, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2250, %r12, %r13, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2245, %r11, %r12, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2246, %r10, %r11, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2247, %r9, %r10, %r118;
	// inline asm
	mov.u32 	%r2237, 0;
	// inline asm
	prmt.b32 %r2248, %r2237, %r9, %r118;
	// inline asm
	mov.u32 	%r2238, %r2237;
	mov.u32 	%r2239, %r2237;
	mov.u32 	%r2240, %r2237;
	mov.u32 	%r2241, %r2237;
	bra.uni 	BB3_106;

BB3_79:
	setp.gt.s32	%p63, %r729, 5;
	@%p63 bra 	BB3_83;

	setp.eq.s32	%p66, %r729, 4;
	@%p66 bra 	BB3_109;
	bra.uni 	BB3_81;

BB3_109:
	mov.u32 	%r2237, 0;
	// inline asm
	prmt.b32 %r2245, %r2237, %r2237, %r118;
	// inline asm
	mov.u32 	%r1032, 128;
	// inline asm
	prmt.b32 %r2246, %r1032, %r2237, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2247, %r13, %r1032, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2248, %r12, %r13, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2241, %r11, %r12, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2242, %r10, %r11, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2243, %r9, %r10, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2244, %r2237, %r9, %r118;
	// inline asm
	mov.u32 	%r2238, %r2237;
	mov.u32 	%r2239, %r2237;
	mov.u32 	%r2240, %r2237;
	bra.uni 	BB3_110;

BB3_94:
	setp.gt.s32	%p52, %r729, 13;
	@%p52 bra 	BB3_98;

	setp.eq.s32	%p55, %r729, 12;
	@%p55 bra 	BB3_101;
	bra.uni 	BB3_96;

BB3_101:
	// inline asm
	prmt.b32 %r2249, %r9, %r10, %r118;
	// inline asm
	mov.u32 	%r2237, 0;
	// inline asm
	prmt.b32 %r2250, %r2237, %r9, %r118;
	// inline asm
	mov.u32 	%r2238, %r2237;
	mov.u32 	%r2239, %r2237;
	mov.u32 	%r2240, %r2237;
	mov.u32 	%r2241, %r2237;
	mov.u32 	%r2242, %r2237;
	mov.u32 	%r2243, %r2237;
	mov.u32 	%r2244, %r2237;
	mov.u32 	%r2245, %r2237;
	bra.uni 	BB3_102;

BB3_76:
	setp.eq.s32	%p69, %r729, 2;
	@%p69 bra 	BB3_111;
	bra.uni 	BB3_77;

BB3_111:
	mov.u32 	%r2239, 0;
	// inline asm
	prmt.b32 %r2245, %r2239, %r2239, %r118;
	// inline asm
	mov.u32 	%r1103, 128;
	// inline asm
	prmt.b32 %r2248, %r1103, %r2239, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2241, %r13, %r1103, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2242, %r12, %r13, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2243, %r11, %r12, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2244, %r10, %r11, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2237, %r9, %r10, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2238, %r2239, %r9, %r118;
	// inline asm
	mov.u32 	%r2240, %r2239;
	mov.u32 	%r2246, %r2245;
	mov.u32 	%r2247, %r2245;
	bra.uni 	BB3_110;

BB3_91:
	setp.eq.s32	%p58, %r729, 10;
	@%p58 bra 	BB3_104;
	bra.uni 	BB3_92;

BB3_104:
	// inline asm
	prmt.b32 %r2249, %r11, %r12, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2250, %r10, %r11, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2245, %r9, %r10, %r118;
	// inline asm
	mov.u32 	%r2237, 0;
	// inline asm
	prmt.b32 %r2246, %r2237, %r9, %r118;
	// inline asm
	mov.u32 	%r2238, %r2237;
	mov.u32 	%r2239, %r2237;
	mov.u32 	%r2240, %r2237;
	mov.u32 	%r2241, %r2237;
	mov.u32 	%r2242, %r2237;
	mov.u32 	%r2243, %r2237;
	mov.u32 	%r2244, %r2237;
	bra.uni 	BB3_103;

BB3_83:
	setp.eq.s32	%p64, %r729, 6;
	@%p64 bra 	BB3_108;
	bra.uni 	BB3_84;

BB3_108:
	mov.u32 	%r2237, 0;
	// inline asm
	prmt.b32 %r2249, %r2237, %r2237, %r118;
	// inline asm
	mov.u32 	%r957, 128;
	// inline asm
	prmt.b32 %r2250, %r957, %r2237, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2245, %r13, %r957, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2246, %r12, %r13, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2247, %r11, %r12, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2248, %r10, %r11, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2241, %r9, %r10, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2242, %r2237, %r9, %r118;
	// inline asm
	mov.u32 	%r2238, %r2237;
	mov.u32 	%r2239, %r2237;
	mov.u32 	%r2240, %r2237;
	bra.uni 	BB3_107;

BB3_98:
	setp.eq.s32	%p53, %r729, 14;
	@%p53 bra 	BB3_100;

	setp.ne.s32	%p54, %r729, 15;
	mov.u32 	%r2237, %r12;
	mov.u32 	%r2238, %r11;
	mov.u32 	%r2239, %r10;
	mov.u32 	%r2240, %r9;
	mov.u32 	%r2242, %r2241;
	mov.u32 	%r2244, %r13;
	mov.u32 	%r2245, %r2241;
	mov.u32 	%r2246, %r2241;
	mov.u32 	%r2247, %r2241;
	mov.u32 	%r2248, %r2241;
	mov.u32 	%r2249, %r2241;
	mov.u32 	%r2250, %r2241;
	@%p54 bra 	BB3_113;

BB3_100:
	mov.u32 	%r2237, 0;
	mov.u32 	%r2238, %r2237;
	mov.u32 	%r2239, %r2237;
	mov.u32 	%r2240, %r2237;
	mov.u32 	%r2241, %r2237;
	mov.u32 	%r2242, %r2237;
	mov.u32 	%r2243, %r2237;
	mov.u32 	%r2244, %r2237;
	mov.u32 	%r2245, %r2237;
	mov.u32 	%r2246, %r2237;
	mov.u32 	%r2247, %r2237;
	mov.u32 	%r2248, %r2237;
	mov.u32 	%r2249, %r2237;
	mov.u32 	%r2250, %r2237;
	bra.uni 	BB3_113;

BB3_74:
	setp.eq.s32	%p72, %r729, 1;
	mov.u32 	%r2237, %r12;
	mov.u32 	%r2238, %r11;
	mov.u32 	%r2239, %r10;
	mov.u32 	%r2240, %r9;
	mov.u32 	%r2242, %r2241;
	mov.u32 	%r2244, %r13;
	mov.u32 	%r2245, %r2241;
	mov.u32 	%r2246, %r2241;
	mov.u32 	%r2247, %r2241;
	mov.u32 	%r2248, %r2241;
	mov.u32 	%r2249, %r2241;
	mov.u32 	%r2250, %r2241;
	@%p72 bra 	BB3_75;
	bra.uni 	BB3_113;

BB3_75:
	mov.u32 	%r2240, 0;
	// inline asm
	prmt.b32 %r2245, %r2240, %r2240, %r118;
	// inline asm
	mov.u32 	%r1137, 128;
	// inline asm
	prmt.b32 %r2241, %r1137, %r2240, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2242, %r13, %r1137, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2243, %r12, %r13, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2244, %r11, %r12, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2237, %r10, %r11, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2238, %r9, %r10, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2239, %r2240, %r9, %r118;
	// inline asm
	mov.u32 	%r2246, %r2245;
	mov.u32 	%r2247, %r2245;
	mov.u32 	%r2248, %r2245;
	bra.uni 	BB3_110;

BB3_89:
	setp.eq.s32	%p61, %r729, 9;
	mov.u32 	%r2237, %r12;
	mov.u32 	%r2238, %r11;
	mov.u32 	%r2239, %r10;
	mov.u32 	%r2240, %r9;
	mov.u32 	%r2242, %r2241;
	mov.u32 	%r2244, %r13;
	mov.u32 	%r2245, %r2241;
	mov.u32 	%r2246, %r2241;
	mov.u32 	%r2247, %r2241;
	mov.u32 	%r2248, %r2241;
	mov.u32 	%r2249, %r2241;
	mov.u32 	%r2250, %r2241;
	@%p61 bra 	BB3_90;
	bra.uni 	BB3_113;

BB3_90:
	// inline asm
	prmt.b32 %r2249, %r12, %r13, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2250, %r11, %r12, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2245, %r10, %r11, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2246, %r9, %r10, %r118;
	// inline asm
	mov.u32 	%r2237, 0;
	// inline asm
	prmt.b32 %r2247, %r2237, %r9, %r118;
	// inline asm
	mov.u32 	%r2238, %r2237;
	mov.u32 	%r2239, %r2237;
	mov.u32 	%r2240, %r2237;
	mov.u32 	%r2241, %r2237;
	mov.u32 	%r2242, %r2237;
	mov.u32 	%r2243, %r2237;
	mov.u32 	%r2244, %r2237;
	mov.u32 	%r2248, %r2237;
	bra.uni 	BB3_113;

BB3_81:
	setp.eq.s32	%p67, %r729, 5;
	mov.u32 	%r2237, %r12;
	mov.u32 	%r2238, %r11;
	mov.u32 	%r2239, %r10;
	mov.u32 	%r2240, %r9;
	mov.u32 	%r2242, %r2241;
	mov.u32 	%r2244, %r13;
	mov.u32 	%r2245, %r2241;
	mov.u32 	%r2246, %r2241;
	mov.u32 	%r2247, %r2241;
	mov.u32 	%r2248, %r2241;
	mov.u32 	%r2249, %r2241;
	mov.u32 	%r2250, %r2241;
	@%p67 bra 	BB3_82;
	bra.uni 	BB3_113;

BB3_82:
	mov.u32 	%r2237, 0;
	// inline asm
	prmt.b32 %r2249, %r2237, %r2237, %r118;
	// inline asm
	mov.u32 	%r995, 128;
	// inline asm
	prmt.b32 %r2245, %r995, %r2237, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2246, %r13, %r995, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2247, %r12, %r13, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2248, %r11, %r12, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2241, %r10, %r11, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2242, %r9, %r10, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2243, %r2237, %r9, %r118;
	// inline asm
	mov.u32 	%r2238, %r2237;
	mov.u32 	%r2239, %r2237;
	mov.u32 	%r2240, %r2237;
	mov.u32 	%r2244, %r2237;
	mov.u32 	%r2250, %r2249;
	bra.uni 	BB3_113;

BB3_96:
	setp.eq.s32	%p56, %r729, 13;
	mov.u32 	%r2237, %r12;
	mov.u32 	%r2238, %r11;
	mov.u32 	%r2239, %r10;
	mov.u32 	%r2240, %r9;
	mov.u32 	%r2242, %r2241;
	mov.u32 	%r2244, %r13;
	mov.u32 	%r2245, %r2241;
	mov.u32 	%r2246, %r2241;
	mov.u32 	%r2247, %r2241;
	mov.u32 	%r2248, %r2241;
	mov.u32 	%r2249, %r2241;
	mov.u32 	%r2250, %r2241;
	@%p56 bra 	BB3_97;
	bra.uni 	BB3_113;

BB3_97:
	mov.u32 	%r2237, 0;
	// inline asm
	prmt.b32 %r2249, %r2237, %r9, %r118;
	// inline asm
	mov.u32 	%r2238, %r2237;
	mov.u32 	%r2239, %r2237;
	mov.u32 	%r2240, %r2237;
	mov.u32 	%r2241, %r2237;
	mov.u32 	%r2242, %r2237;
	mov.u32 	%r2243, %r2237;
	mov.u32 	%r2244, %r2237;
	mov.u32 	%r2245, %r2237;
	mov.u32 	%r2246, %r2237;
	mov.u32 	%r2247, %r2237;
	mov.u32 	%r2248, %r2237;
	mov.u32 	%r2250, %r2237;
	bra.uni 	BB3_113;

BB3_77:
	setp.eq.s32	%p70, %r729, 3;
	mov.u32 	%r2237, %r12;
	mov.u32 	%r2238, %r11;
	mov.u32 	%r2239, %r10;
	mov.u32 	%r2240, %r9;
	mov.u32 	%r2242, %r2241;
	mov.u32 	%r2244, %r13;
	mov.u32 	%r2245, %r2241;
	mov.u32 	%r2246, %r2241;
	mov.u32 	%r2247, %r2241;
	mov.u32 	%r2248, %r2241;
	mov.u32 	%r2249, %r2241;
	mov.u32 	%r2250, %r2241;
	@%p70 bra 	BB3_78;
	bra.uni 	BB3_113;

BB3_78:
	mov.u32 	%r2238, 0;
	// inline asm
	prmt.b32 %r2245, %r2238, %r2238, %r118;
	// inline asm
	mov.u32 	%r1068, 128;
	// inline asm
	prmt.b32 %r2247, %r1068, %r2238, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2248, %r13, %r1068, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2241, %r12, %r13, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2242, %r11, %r12, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2243, %r10, %r11, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2244, %r9, %r10, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2237, %r2238, %r9, %r118;
	// inline asm
	mov.u32 	%r2239, %r2238;
	mov.u32 	%r2240, %r2238;
	mov.u32 	%r2246, %r2245;

BB3_110:
	mov.u32 	%r2249, %r2245;
	mov.u32 	%r2250, %r2245;
	bra.uni 	BB3_113;

BB3_92:
	setp.eq.s32	%p59, %r729, 11;
	mov.u32 	%r2237, %r12;
	mov.u32 	%r2238, %r11;
	mov.u32 	%r2239, %r10;
	mov.u32 	%r2240, %r9;
	mov.u32 	%r2242, %r2241;
	mov.u32 	%r2244, %r13;
	mov.u32 	%r2245, %r2241;
	mov.u32 	%r2246, %r2241;
	mov.u32 	%r2247, %r2241;
	mov.u32 	%r2248, %r2241;
	mov.u32 	%r2249, %r2241;
	mov.u32 	%r2250, %r2241;
	@%p59 bra 	BB3_93;
	bra.uni 	BB3_113;

BB3_93:
	// inline asm
	prmt.b32 %r2249, %r10, %r11, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2250, %r9, %r10, %r118;
	// inline asm
	mov.u32 	%r2237, 0;
	// inline asm
	prmt.b32 %r2245, %r2237, %r9, %r118;
	// inline asm
	mov.u32 	%r2238, %r2237;
	mov.u32 	%r2239, %r2237;
	mov.u32 	%r2240, %r2237;
	mov.u32 	%r2241, %r2237;
	mov.u32 	%r2242, %r2237;
	mov.u32 	%r2243, %r2237;
	mov.u32 	%r2244, %r2237;

BB3_102:
	mov.u32 	%r2246, %r2237;

BB3_103:
	mov.u32 	%r2247, %r2237;
	mov.u32 	%r2248, %r2237;
	bra.uni 	BB3_113;

BB3_84:
	setp.eq.s32	%p65, %r729, 7;
	mov.u32 	%r2237, %r12;
	mov.u32 	%r2238, %r11;
	mov.u32 	%r2239, %r10;
	mov.u32 	%r2240, %r9;
	mov.u32 	%r2242, %r2241;
	mov.u32 	%r2244, %r13;
	mov.u32 	%r2245, %r2241;
	mov.u32 	%r2246, %r2241;
	mov.u32 	%r2247, %r2241;
	mov.u32 	%r2248, %r2241;
	mov.u32 	%r2249, %r2241;
	mov.u32 	%r2250, %r2241;
	@%p65 bra 	BB3_85;
	bra.uni 	BB3_113;

BB3_85:
	mov.u32 	%r918, 128;
	mov.u32 	%r2237, 0;
	// inline asm
	prmt.b32 %r2249, %r918, %r2237, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2250, %r13, %r918, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2245, %r12, %r13, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2246, %r11, %r12, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2247, %r10, %r11, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2248, %r9, %r10, %r118;
	// inline asm
	// inline asm
	prmt.b32 %r2241, %r2237, %r9, %r118;
	// inline asm
	mov.u32 	%r2238, %r2237;
	mov.u32 	%r2239, %r2237;
	mov.u32 	%r2240, %r2237;

BB3_106:
	mov.u32 	%r2242, %r2237;

BB3_107:
	mov.u32 	%r2243, %r2237;
	mov.u32 	%r2244, %r2237;

BB3_113:
	mov.u32 	%r2211, 1732584193;
	ld.param.u64 	%rd59, [m15500_m04_param_6];
	shf.l.wrap.b32 	%r2210, %r2211, %r2211, 30;
	mov.u32 	%r2209, -271733879;
	shf.l.wrap.b32 	%r2208, %r2209, %r2209, 30;
	shf.l.wrap.b32 	%r2207, %r2211, %r2211, 5;
	or.b32  	%r1193, %r2240, %r716;
	// inline asm
	prmt.b32 %r1192, %r1193, 0, 0x0123;
	// inline asm
	or.b32  	%r1195, %r2239, %r712;
	// inline asm
	prmt.b32 %r1194, %r1195, 0, 0x0123;
	// inline asm
	or.b32  	%r1197, %r2238, %r708;
	// inline asm
	prmt.b32 %r1196, %r1197, 0, 0x0123;
	// inline asm
	or.b32  	%r1199, %r2237, %r704;
	// inline asm
	prmt.b32 %r1198, %r1199, 0, 0x0123;
	// inline asm
	or.b32  	%r1201, %r2244, %r700;
	// inline asm
	prmt.b32 %r1200, %r1201, 0, 0x0123;
	// inline asm
	or.b32  	%r1203, %r2243, %r696;
	// inline asm
	prmt.b32 %r1202, %r1203, 0, 0x0123;
	// inline asm
	or.b32  	%r1205, %r2242, %r692;
	// inline asm
	prmt.b32 %r1204, %r1205, 0, 0x0123;
	// inline asm
	or.b32  	%r1207, %r2241, %r688;
	// inline asm
	prmt.b32 %r1206, %r1207, 0, 0x0123;
	// inline asm
	or.b32  	%r1209, %r2248, %r684;
	// inline asm
	prmt.b32 %r1208, %r1209, 0, 0x0123;
	// inline asm
	or.b32  	%r1211, %r2247, %r680;
	// inline asm
	prmt.b32 %r1210, %r1211, 0, 0x0123;
	// inline asm
	or.b32  	%r1213, %r2246, %r676;
	// inline asm
	prmt.b32 %r1212, %r1213, 0, 0x0123;
	// inline asm
	or.b32  	%r1215, %r2245, %r672;
	// inline asm
	prmt.b32 %r1214, %r1215, 0, 0x0123;
	// inline asm
	or.b32  	%r1217, %r2250, %r668;
	// inline asm
	prmt.b32 %r1216, %r1217, 0, 0x0123;
	// inline asm
	or.b32  	%r1219, %r2249, %r664;
	// inline asm
	prmt.b32 %r1218, %r1219, 0, 0x0123;
	// inline asm
	shl.b32 	%r1220, %r25, 4;
	add.s32 	%r1221, %r1220, 160;
	add.s32 	%r1222, %r1192, %r2207;
	add.s32 	%r1223, %r1222, -1223673721;
	shf.l.wrap.b32 	%r1224, %r1223, %r1223, 5;
	add.s32 	%r1225, %r1194, %r1224;
	add.s32 	%r1226, %r1225, %r18;
	add.s32 	%r1227, %r1226, 1790234127;
	and.b32  	%r1228, %r20, %r1223;
	xor.b32  	%r1229, %r1228, %r2208;
	shf.l.wrap.b32 	%r1230, %r1227, %r1227, 5;
	add.s32 	%r1231, %r1196, %r1230;
	add.s32 	%r1232, %r1231, %r1229;
	add.s32 	%r1233, %r1232, -214083945;
	shf.l.wrap.b32 	%r1234, %r1223, %r1223, 30;
	xor.b32  	%r1235, %r1234, %r2210;
	and.b32  	%r1236, %r1235, %r1227;
	xor.b32  	%r1237, %r1236, %r2210;
	shf.l.wrap.b32 	%r1238, %r1233, %r1233, 5;
	add.s32 	%r1239, %r1198, %r2208;
	add.s32 	%r1240, %r1239, %r1238;
	add.s32 	%r1241, %r1240, %r1237;
	add.s32 	%r1242, %r1241, 1518500249;
	shf.l.wrap.b32 	%r1243, %r1227, %r1227, 30;
	xor.b32  	%r1244, %r1243, %r1234;
	and.b32  	%r1245, %r1244, %r1233;
	xor.b32  	%r1246, %r1245, %r1234;
	shf.l.wrap.b32 	%r1247, %r1242, %r1242, 5;
	add.s32 	%r1248, %r1200, %r2210;
	add.s32 	%r1249, %r1248, %r1247;
	add.s32 	%r1250, %r1249, %r1246;
	add.s32 	%r1251, %r1250, 1518500249;
	shf.l.wrap.b32 	%r1252, %r1233, %r1233, 30;
	xor.b32  	%r1253, %r1252, %r1243;
	and.b32  	%r1254, %r1253, %r1242;
	xor.b32  	%r1255, %r1254, %r1243;
	shf.l.wrap.b32 	%r1256, %r1251, %r1251, 5;
	add.s32 	%r1257, %r1202, %r1234;
	add.s32 	%r1258, %r1257, %r1256;
	add.s32 	%r1259, %r1258, %r1255;
	add.s32 	%r1260, %r1259, 1518500249;
	shf.l.wrap.b32 	%r1261, %r1242, %r1242, 30;
	xor.b32  	%r1262, %r1261, %r1252;
	and.b32  	%r1263, %r1262, %r1251;
	xor.b32  	%r1264, %r1263, %r1252;
	shf.l.wrap.b32 	%r1265, %r1260, %r1260, 5;
	add.s32 	%r1266, %r1204, %r1243;
	add.s32 	%r1267, %r1266, %r1265;
	add.s32 	%r1268, %r1267, %r1264;
	add.s32 	%r1269, %r1268, 1518500249;
	shf.l.wrap.b32 	%r1270, %r1251, %r1251, 30;
	xor.b32  	%r1271, %r1270, %r1261;
	and.b32  	%r1272, %r1271, %r1260;
	xor.b32  	%r1273, %r1272, %r1261;
	shf.l.wrap.b32 	%r1274, %r1269, %r1269, 5;
	add.s32 	%r1275, %r1206, %r1252;
	add.s32 	%r1276, %r1275, %r1274;
	add.s32 	%r1277, %r1276, %r1273;
	add.s32 	%r1278, %r1277, 1518500249;
	shf.l.wrap.b32 	%r1279, %r1260, %r1260, 30;
	xor.b32  	%r1280, %r1279, %r1270;
	and.b32  	%r1281, %r1280, %r1269;
	xor.b32  	%r1282, %r1281, %r1270;
	shf.l.wrap.b32 	%r1283, %r1278, %r1278, 5;
	add.s32 	%r1284, %r1208, %r1261;
	add.s32 	%r1285, %r1284, %r1283;
	add.s32 	%r1286, %r1285, %r1282;
	add.s32 	%r1287, %r1286, 1518500249;
	shf.l.wrap.b32 	%r1288, %r1269, %r1269, 30;
	xor.b32  	%r1289, %r1288, %r1279;
	and.b32  	%r1290, %r1289, %r1278;
	xor.b32  	%r1291, %r1290, %r1279;
	shf.l.wrap.b32 	%r1292, %r1287, %r1287, 5;
	add.s32 	%r1293, %r1210, %r1270;
	add.s32 	%r1294, %r1293, %r1292;
	add.s32 	%r1295, %r1294, %r1291;
	add.s32 	%r1296, %r1295, 1518500249;
	shf.l.wrap.b32 	%r1297, %r1278, %r1278, 30;
	xor.b32  	%r1298, %r1297, %r1288;
	and.b32  	%r1299, %r1298, %r1287;
	xor.b32  	%r1300, %r1299, %r1288;
	shf.l.wrap.b32 	%r1301, %r1296, %r1296, 5;
	add.s32 	%r1302, %r1212, %r1279;
	add.s32 	%r1303, %r1302, %r1301;
	add.s32 	%r1304, %r1303, %r1300;
	add.s32 	%r1305, %r1304, 1518500249;
	shf.l.wrap.b32 	%r1306, %r1287, %r1287, 30;
	xor.b32  	%r1307, %r1306, %r1297;
	and.b32  	%r1308, %r1307, %r1296;
	xor.b32  	%r1309, %r1308, %r1297;
	shf.l.wrap.b32 	%r1310, %r1305, %r1305, 5;
	add.s32 	%r1311, %r1214, %r1288;
	add.s32 	%r1312, %r1311, %r1310;
	add.s32 	%r1313, %r1312, %r1309;
	add.s32 	%r1314, %r1313, 1518500249;
	shf.l.wrap.b32 	%r1315, %r1296, %r1296, 30;
	xor.b32  	%r1316, %r1315, %r1306;
	and.b32  	%r1317, %r1316, %r1305;
	xor.b32  	%r1318, %r1317, %r1306;
	shf.l.wrap.b32 	%r1319, %r1314, %r1314, 5;
	add.s32 	%r1320, %r1216, %r1297;
	add.s32 	%r1321, %r1320, %r1319;
	add.s32 	%r1322, %r1321, %r1318;
	add.s32 	%r1323, %r1322, 1518500249;
	shf.l.wrap.b32 	%r1324, %r1305, %r1305, 30;
	xor.b32  	%r1325, %r1324, %r1315;
	and.b32  	%r1326, %r1325, %r1314;
	xor.b32  	%r1327, %r1326, %r1315;
	shf.l.wrap.b32 	%r1328, %r1323, %r1323, 5;
	add.s32 	%r1329, %r1218, %r1306;
	add.s32 	%r1330, %r1329, %r1328;
	add.s32 	%r1331, %r1330, %r1327;
	add.s32 	%r1332, %r1331, 1518500249;
	shf.l.wrap.b32 	%r1333, %r1314, %r1314, 30;
	shf.l.wrap.b32 	%r1334, %r1332, %r1332, 5;
	add.s32 	%r1335, %r1315, %r1334;
	xor.b32  	%r1336, %r1333, %r1324;
	and.b32  	%r1337, %r1336, %r1323;
	xor.b32  	%r1338, %r1337, %r1324;
	add.s32 	%r1339, %r1335, %r1338;
	add.s32 	%r1340, %r1339, 1518500249;
	shf.l.wrap.b32 	%r1341, %r1323, %r1323, 30;
	xor.b32  	%r1342, %r1341, %r1333;
	and.b32  	%r1343, %r1342, %r1332;
	xor.b32  	%r1344, %r1343, %r1333;
	shf.l.wrap.b32 	%r1345, %r1340, %r1340, 5;
	add.s32 	%r1346, %r1220, %r1324;
	add.s32 	%r1347, %r1346, %r1345;
	add.s32 	%r1348, %r1347, %r1344;
	add.s32 	%r1349, %r1348, 1518500409;
	shf.l.wrap.b32 	%r1350, %r1332, %r1332, 30;
	xor.b32  	%r1351, %r1196, %r1192;
	xor.b32  	%r1352, %r1351, %r1208;
	xor.b32  	%r1353, %r1352, %r1218;
	shf.l.wrap.b32 	%r1354, %r1353, %r1353, 1;
	add.s32 	%r1355, %r1333, %r1354;
	xor.b32  	%r1356, %r1350, %r1341;
	and.b32  	%r1357, %r1356, %r1340;
	xor.b32  	%r1358, %r1357, %r1341;
	shf.l.wrap.b32 	%r1359, %r1349, %r1349, 5;
	add.s32 	%r1360, %r1355, %r1359;
	add.s32 	%r1361, %r1360, %r1358;
	add.s32 	%r1362, %r1361, 1518500249;
	shf.l.wrap.b32 	%r1363, %r1340, %r1340, 30;
	xor.b32  	%r1364, %r1198, %r1194;
	xor.b32  	%r1365, %r1364, %r1210;
	shf.l.wrap.b32 	%r1366, %r1365, %r1365, 1;
	add.s32 	%r1367, %r1341, %r1366;
	xor.b32  	%r1368, %r1363, %r1350;
	and.b32  	%r1369, %r1368, %r1349;
	xor.b32  	%r1370, %r1369, %r1350;
	shf.l.wrap.b32 	%r1371, %r1362, %r1362, 5;
	add.s32 	%r1372, %r1367, %r1371;
	add.s32 	%r1373, %r1372, %r1370;
	add.s32 	%r1374, %r1373, 1518500249;
	shf.l.wrap.b32 	%r1375, %r1349, %r1349, 30;
	xor.b32  	%r1376, %r1196, %r1221;
	xor.b32  	%r1377, %r1376, %r1200;
	xor.b32  	%r1378, %r1377, %r1212;
	shf.l.wrap.b32 	%r1379, %r1378, %r1378, 1;
	add.s32 	%r1380, %r1350, %r1379;
	xor.b32  	%r1381, %r1375, %r1363;
	and.b32  	%r1382, %r1381, %r1362;
	xor.b32  	%r1383, %r1382, %r1363;
	shf.l.wrap.b32 	%r1384, %r1374, %r1374, 5;
	add.s32 	%r1385, %r1380, %r1384;
	add.s32 	%r1386, %r1385, %r1383;
	add.s32 	%r1387, %r1386, 1518500249;
	shf.l.wrap.b32 	%r1388, %r1362, %r1362, 30;
	xor.b32  	%r1389, %r1202, %r1198;
	xor.b32  	%r1390, %r1389, %r1214;
	xor.b32  	%r1391, %r1390, %r1354;
	shf.l.wrap.b32 	%r1392, %r1391, %r1391, 1;
	add.s32 	%r1393, %r1363, %r1392;
	xor.b32  	%r1394, %r1388, %r1375;
	and.b32  	%r1395, %r1394, %r1374;
	xor.b32  	%r1396, %r1395, %r1375;
	shf.l.wrap.b32 	%r1397, %r1387, %r1387, 5;
	add.s32 	%r1398, %r1393, %r1397;
	add.s32 	%r1399, %r1398, %r1396;
	add.s32 	%r1400, %r1399, 1518500249;
	shf.l.wrap.b32 	%r1401, %r1374, %r1374, 30;
	xor.b32  	%r1402, %r1204, %r1200;
	xor.b32  	%r1403, %r1402, %r1216;
	xor.b32  	%r1404, %r1403, %r1366;
	shf.l.wrap.b32 	%r1405, %r1404, %r1404, 1;
	add.s32 	%r1406, %r1375, %r1405;
	xor.b32  	%r1407, %r1387, %r1388;
	xor.b32  	%r1408, %r1407, %r1401;
	add.s32 	%r1409, %r1406, %r1408;
	shf.l.wrap.b32 	%r1410, %r1400, %r1400, 5;
	add.s32 	%r1411, %r1409, %r1410;
	add.s32 	%r1412, %r1411, 1859775393;
	shf.l.wrap.b32 	%r1413, %r1387, %r1387, 30;
	xor.b32  	%r1414, %r1206, %r1202;
	xor.b32  	%r1415, %r1414, %r1218;
	xor.b32  	%r1416, %r1415, %r1379;
	shf.l.wrap.b32 	%r1417, %r1416, %r1416, 1;
	add.s32 	%r1418, %r1388, %r1417;
	xor.b32  	%r1419, %r1400, %r1401;
	xor.b32  	%r1420, %r1419, %r1413;
	add.s32 	%r1421, %r1418, %r1420;
	shf.l.wrap.b32 	%r1422, %r1412, %r1412, 5;
	add.s32 	%r1423, %r1421, %r1422;
	add.s32 	%r1424, %r1423, 1859775393;
	shf.l.wrap.b32 	%r1425, %r1400, %r1400, 30;
	xor.b32  	%r1426, %r1208, %r1204;
	xor.b32  	%r1427, %r1426, %r1392;
	shf.l.wrap.b32 	%r1428, %r1427, %r1427, 1;
	add.s32 	%r1429, %r1401, %r1428;
	xor.b32  	%r1430, %r1412, %r1413;
	xor.b32  	%r1431, %r1430, %r1425;
	add.s32 	%r1432, %r1429, %r1431;
	shf.l.wrap.b32 	%r1433, %r1424, %r1424, 5;
	add.s32 	%r1434, %r1432, %r1433;
	add.s32 	%r1435, %r1434, 1859775393;
	shf.l.wrap.b32 	%r1436, %r1412, %r1412, 30;
	xor.b32  	%r1437, %r1206, %r1221;
	xor.b32  	%r1438, %r1437, %r1210;
	xor.b32  	%r1439, %r1438, %r1405;
	shf.l.wrap.b32 	%r1440, %r1439, %r1439, 1;
	add.s32 	%r1441, %r1413, %r1440;
	xor.b32  	%r1442, %r1424, %r1425;
	xor.b32  	%r1443, %r1442, %r1436;
	add.s32 	%r1444, %r1441, %r1443;
	shf.l.wrap.b32 	%r1445, %r1435, %r1435, 5;
	add.s32 	%r1446, %r1444, %r1445;
	add.s32 	%r1447, %r1446, 1859775393;
	shf.l.wrap.b32 	%r1448, %r1424, %r1424, 30;
	xor.b32  	%r1449, %r1212, %r1208;
	xor.b32  	%r1450, %r1449, %r1354;
	xor.b32  	%r1451, %r1450, %r1417;
	shf.l.wrap.b32 	%r1452, %r1451, %r1451, 1;
	add.s32 	%r1453, %r1425, %r1452;
	xor.b32  	%r1454, %r1435, %r1436;
	xor.b32  	%r1455, %r1454, %r1448;
	add.s32 	%r1456, %r1453, %r1455;
	shf.l.wrap.b32 	%r1457, %r1447, %r1447, 5;
	add.s32 	%r1458, %r1456, %r1457;
	add.s32 	%r1459, %r1458, 1859775393;
	shf.l.wrap.b32 	%r1460, %r1435, %r1435, 30;
	xor.b32  	%r1461, %r1214, %r1210;
	xor.b32  	%r1462, %r1461, %r1366;
	xor.b32  	%r1463, %r1462, %r1428;
	shf.l.wrap.b32 	%r1464, %r1463, %r1463, 1;
	add.s32 	%r1465, %r1436, %r1464;
	xor.b32  	%r1466, %r1447, %r1448;
	xor.b32  	%r1467, %r1466, %r1460;
	add.s32 	%r1468, %r1465, %r1467;
	shf.l.wrap.b32 	%r1469, %r1459, %r1459, 5;
	add.s32 	%r1470, %r1468, %r1469;
	add.s32 	%r1471, %r1470, 1859775393;
	shf.l.wrap.b32 	%r1472, %r1447, %r1447, 30;
	xor.b32  	%r1473, %r1216, %r1212;
	xor.b32  	%r1474, %r1473, %r1379;
	xor.b32  	%r1475, %r1474, %r1440;
	shf.l.wrap.b32 	%r1476, %r1475, %r1475, 1;
	add.s32 	%r1477, %r1448, %r1476;
	xor.b32  	%r1478, %r1459, %r1460;
	xor.b32  	%r1479, %r1478, %r1472;
	add.s32 	%r1480, %r1477, %r1479;
	shf.l.wrap.b32 	%r1481, %r1471, %r1471, 5;
	add.s32 	%r1482, %r1480, %r1481;
	add.s32 	%r1483, %r1482, 1859775393;
	shf.l.wrap.b32 	%r1484, %r1459, %r1459, 30;
	xor.b32  	%r1485, %r1218, %r1214;
	xor.b32  	%r1486, %r1485, %r1392;
	xor.b32  	%r1487, %r1486, %r1452;
	shf.l.wrap.b32 	%r1488, %r1487, %r1487, 1;
	add.s32 	%r1489, %r1460, %r1488;
	xor.b32  	%r1490, %r1471, %r1472;
	xor.b32  	%r1491, %r1490, %r1484;
	add.s32 	%r1492, %r1489, %r1491;
	shf.l.wrap.b32 	%r1493, %r1483, %r1483, 5;
	add.s32 	%r1494, %r1492, %r1493;
	add.s32 	%r1495, %r1494, 1859775393;
	shf.l.wrap.b32 	%r1496, %r1471, %r1471, 30;
	xor.b32  	%r1497, %r1405, %r1216;
	xor.b32  	%r1498, %r1497, %r1464;
	shf.l.wrap.b32 	%r1499, %r1498, %r1498, 1;
	add.s32 	%r1500, %r1472, %r1499;
	xor.b32  	%r1501, %r1483, %r1484;
	xor.b32  	%r1502, %r1501, %r1496;
	add.s32 	%r1503, %r1500, %r1502;
	shf.l.wrap.b32 	%r1504, %r1495, %r1495, 5;
	add.s32 	%r1505, %r1503, %r1504;
	add.s32 	%r1506, %r1505, 1859775393;
	shf.l.wrap.b32 	%r1507, %r1483, %r1483, 30;
	xor.b32  	%r1508, %r1218, %r1221;
	xor.b32  	%r1509, %r1508, %r1417;
	xor.b32  	%r1510, %r1509, %r1476;
	shf.l.wrap.b32 	%r1511, %r1510, %r1510, 1;
	add.s32 	%r1512, %r1484, %r1511;
	xor.b32  	%r1513, %r1495, %r1496;
	xor.b32  	%r1514, %r1513, %r1507;
	add.s32 	%r1515, %r1512, %r1514;
	shf.l.wrap.b32 	%r1516, %r1506, %r1506, 5;
	add.s32 	%r1517, %r1515, %r1516;
	add.s32 	%r1518, %r1517, 1859775393;
	shf.l.wrap.b32 	%r1519, %r1495, %r1495, 30;
	xor.b32  	%r1520, %r1428, %r1354;
	xor.b32  	%r1521, %r1520, %r1488;
	shf.l.wrap.b32 	%r1522, %r1521, %r1521, 1;
	add.s32 	%r1523, %r1496, %r1522;
	xor.b32  	%r1524, %r1506, %r1507;
	xor.b32  	%r1525, %r1524, %r1519;
	add.s32 	%r1526, %r1523, %r1525;
	shf.l.wrap.b32 	%r1527, %r1518, %r1518, 5;
	add.s32 	%r1528, %r1526, %r1527;
	add.s32 	%r1529, %r1528, 1859775393;
	shf.l.wrap.b32 	%r1530, %r1506, %r1506, 30;
	xor.b32  	%r1531, %r1366, %r1221;
	xor.b32  	%r1532, %r1531, %r1440;
	xor.b32  	%r1533, %r1532, %r1499;
	shf.l.wrap.b32 	%r1534, %r1533, %r1533, 1;
	add.s32 	%r1535, %r1507, %r1534;
	xor.b32  	%r1536, %r1518, %r1519;
	xor.b32  	%r1537, %r1536, %r1530;
	add.s32 	%r1538, %r1535, %r1537;
	shf.l.wrap.b32 	%r1539, %r1529, %r1529, 5;
	add.s32 	%r1540, %r1538, %r1539;
	add.s32 	%r1541, %r1540, 1859775393;
	shf.l.wrap.b32 	%r1542, %r1518, %r1518, 30;
	xor.b32  	%r1543, %r1379, %r1354;
	xor.b32  	%r1544, %r1543, %r1452;
	xor.b32  	%r1545, %r1544, %r1511;
	shf.l.wrap.b32 	%r1546, %r1545, %r1545, 1;
	add.s32 	%r1547, %r1519, %r1546;
	xor.b32  	%r1548, %r1529, %r1530;
	xor.b32  	%r1549, %r1548, %r1542;
	add.s32 	%r1550, %r1547, %r1549;
	shf.l.wrap.b32 	%r1551, %r1541, %r1541, 5;
	add.s32 	%r1552, %r1550, %r1551;
	add.s32 	%r1553, %r1552, 1859775393;
	shf.l.wrap.b32 	%r1554, %r1529, %r1529, 30;
	xor.b32  	%r1555, %r1392, %r1366;
	xor.b32  	%r1556, %r1555, %r1464;
	xor.b32  	%r1557, %r1556, %r1522;
	shf.l.wrap.b32 	%r1558, %r1557, %r1557, 1;
	add.s32 	%r1559, %r1530, %r1558;
	xor.b32  	%r1560, %r1541, %r1542;
	xor.b32  	%r1561, %r1560, %r1554;
	add.s32 	%r1562, %r1559, %r1561;
	shf.l.wrap.b32 	%r1563, %r1553, %r1553, 5;
	add.s32 	%r1564, %r1562, %r1563;
	add.s32 	%r1565, %r1564, 1859775393;
	shf.l.wrap.b32 	%r1566, %r1541, %r1541, 30;
	xor.b32  	%r1567, %r1405, %r1379;
	xor.b32  	%r1568, %r1567, %r1476;
	xor.b32  	%r1569, %r1568, %r1534;
	shf.l.wrap.b32 	%r1570, %r1569, %r1569, 1;
	add.s32 	%r1571, %r1542, %r1570;
	xor.b32  	%r1572, %r1553, %r1554;
	xor.b32  	%r1573, %r1572, %r1566;
	add.s32 	%r1574, %r1571, %r1573;
	shf.l.wrap.b32 	%r1575, %r1565, %r1565, 5;
	add.s32 	%r1576, %r1574, %r1575;
	add.s32 	%r1577, %r1576, 1859775393;
	shf.l.wrap.b32 	%r1578, %r1553, %r1553, 30;
	xor.b32  	%r1579, %r1417, %r1392;
	xor.b32  	%r1580, %r1579, %r1488;
	xor.b32  	%r1581, %r1580, %r1546;
	shf.l.wrap.b32 	%r1582, %r1581, %r1581, 1;
	add.s32 	%r1583, %r1554, %r1582;
	xor.b32  	%r1584, %r1565, %r1566;
	xor.b32  	%r1585, %r1584, %r1578;
	add.s32 	%r1586, %r1583, %r1585;
	shf.l.wrap.b32 	%r1587, %r1577, %r1577, 5;
	add.s32 	%r1588, %r1586, %r1587;
	add.s32 	%r1589, %r1588, 1859775393;
	shf.l.wrap.b32 	%r1590, %r1565, %r1565, 30;
	xor.b32  	%r1591, %r1428, %r1405;
	xor.b32  	%r1592, %r1591, %r1499;
	xor.b32  	%r1593, %r1592, %r1558;
	shf.l.wrap.b32 	%r1594, %r1593, %r1593, 1;
	add.s32 	%r1595, %r1566, %r1594;
	xor.b32  	%r1596, %r1577, %r1578;
	xor.b32  	%r1597, %r1596, %r1590;
	add.s32 	%r1598, %r1595, %r1597;
	shf.l.wrap.b32 	%r1599, %r1589, %r1589, 5;
	add.s32 	%r1600, %r1598, %r1599;
	add.s32 	%r1601, %r1600, 1859775393;
	shf.l.wrap.b32 	%r1602, %r1577, %r1577, 30;
	xor.b32  	%r1603, %r1440, %r1417;
	xor.b32  	%r1604, %r1603, %r1511;
	xor.b32  	%r1605, %r1604, %r1570;
	shf.l.wrap.b32 	%r1606, %r1605, %r1605, 1;
	add.s32 	%r1607, %r1578, %r1606;
	xor.b32  	%r1608, %r1589, %r1590;
	xor.b32  	%r1609, %r1608, %r1602;
	add.s32 	%r1610, %r1607, %r1609;
	shf.l.wrap.b32 	%r1611, %r1601, %r1601, 5;
	add.s32 	%r1612, %r1610, %r1611;
	add.s32 	%r1613, %r1612, 1859775393;
	shf.l.wrap.b32 	%r1614, %r1589, %r1589, 30;
	xor.b32  	%r1615, %r1452, %r1428;
	xor.b32  	%r1616, %r1615, %r1522;
	xor.b32  	%r1617, %r1616, %r1582;
	shf.l.wrap.b32 	%r1618, %r1617, %r1617, 1;
	add.s32 	%r1619, %r1590, %r1618;
	xor.b32  	%r1620, %r1601, %r1602;
	xor.b32  	%r1621, %r1620, %r1614;
	add.s32 	%r1622, %r1619, %r1621;
	shf.l.wrap.b32 	%r1623, %r1613, %r1613, 5;
	add.s32 	%r1624, %r1622, %r1623;
	add.s32 	%r1625, %r1624, 1859775393;
	shf.l.wrap.b32 	%r1626, %r1601, %r1601, 30;
	xor.b32  	%r1627, %r1464, %r1440;
	xor.b32  	%r1628, %r1627, %r1534;
	xor.b32  	%r1629, %r1628, %r1594;
	shf.l.wrap.b32 	%r1630, %r1629, %r1629, 1;
	add.s32 	%r1631, %r1602, %r1630;
	xor.b32  	%r1632, %r1613, %r1614;
	xor.b32  	%r1633, %r1632, %r1626;
	add.s32 	%r1634, %r1631, %r1633;
	shf.l.wrap.b32 	%r1635, %r1625, %r1625, 5;
	add.s32 	%r1636, %r1634, %r1635;
	add.s32 	%r1637, %r1636, 1859775393;
	shf.l.wrap.b32 	%r1638, %r1613, %r1613, 30;
	xor.b32  	%r1639, %r1476, %r1452;
	xor.b32  	%r1640, %r1639, %r1546;
	xor.b32  	%r1641, %r1640, %r1606;
	shf.l.wrap.b32 	%r1642, %r1641, %r1641, 1;
	add.s32 	%r1643, %r1614, %r1642;
	xor.b32  	%r1644, %r1625, %r1626;
	xor.b32  	%r1645, %r1638, %r1625;
	and.b32  	%r1646, %r1645, %r1644;
	xor.b32  	%r1647, %r1646, %r1625;
	shf.l.wrap.b32 	%r1648, %r1637, %r1637, 5;
	add.s32 	%r1649, %r1643, %r1648;
	add.s32 	%r1650, %r1649, %r1647;
	add.s32 	%r1651, %r1650, -1894007588;
	shf.l.wrap.b32 	%r1652, %r1625, %r1625, 30;
	xor.b32  	%r1653, %r1488, %r1464;
	xor.b32  	%r1654, %r1653, %r1558;
	xor.b32  	%r1655, %r1654, %r1618;
	shf.l.wrap.b32 	%r1656, %r1655, %r1655, 1;
	add.s32 	%r1657, %r1626, %r1656;
	xor.b32  	%r1658, %r1637, %r1638;
	xor.b32  	%r1659, %r1652, %r1637;
	and.b32  	%r1660, %r1659, %r1658;
	xor.b32  	%r1661, %r1660, %r1637;
	shf.l.wrap.b32 	%r1662, %r1651, %r1651, 5;
	add.s32 	%r1663, %r1657, %r1662;
	add.s32 	%r1664, %r1663, %r1661;
	add.s32 	%r1665, %r1664, -1894007588;
	shf.l.wrap.b32 	%r1666, %r1637, %r1637, 30;
	xor.b32  	%r1667, %r1499, %r1476;
	xor.b32  	%r1668, %r1667, %r1570;
	xor.b32  	%r1669, %r1668, %r1630;
	shf.l.wrap.b32 	%r1670, %r1669, %r1669, 1;
	add.s32 	%r1671, %r1638, %r1670;
	xor.b32  	%r1672, %r1651, %r1652;
	xor.b32  	%r1673, %r1666, %r1651;
	and.b32  	%r1674, %r1673, %r1672;
	xor.b32  	%r1675, %r1674, %r1651;
	shf.l.wrap.b32 	%r1676, %r1665, %r1665, 5;
	add.s32 	%r1677, %r1671, %r1676;
	add.s32 	%r1678, %r1677, %r1675;
	add.s32 	%r1679, %r1678, -1894007588;
	shf.l.wrap.b32 	%r1680, %r1651, %r1651, 30;
	xor.b32  	%r1681, %r1511, %r1488;
	xor.b32  	%r1682, %r1681, %r1582;
	xor.b32  	%r1683, %r1682, %r1642;
	shf.l.wrap.b32 	%r1684, %r1683, %r1683, 1;
	add.s32 	%r1685, %r1652, %r1684;
	xor.b32  	%r1686, %r1665, %r1666;
	xor.b32  	%r1687, %r1680, %r1665;
	and.b32  	%r1688, %r1687, %r1686;
	xor.b32  	%r1689, %r1688, %r1665;
	shf.l.wrap.b32 	%r1690, %r1679, %r1679, 5;
	add.s32 	%r1691, %r1685, %r1690;
	add.s32 	%r1692, %r1691, %r1689;
	add.s32 	%r1693, %r1692, -1894007588;
	shf.l.wrap.b32 	%r1694, %r1665, %r1665, 30;
	xor.b32  	%r1695, %r1522, %r1499;
	xor.b32  	%r1696, %r1695, %r1594;
	xor.b32  	%r1697, %r1696, %r1656;
	shf.l.wrap.b32 	%r1698, %r1697, %r1697, 1;
	add.s32 	%r1699, %r1666, %r1698;
	xor.b32  	%r1700, %r1679, %r1680;
	xor.b32  	%r1701, %r1694, %r1679;
	and.b32  	%r1702, %r1701, %r1700;
	xor.b32  	%r1703, %r1702, %r1679;
	shf.l.wrap.b32 	%r1704, %r1693, %r1693, 5;
	add.s32 	%r1705, %r1699, %r1704;
	add.s32 	%r1706, %r1705, %r1703;
	add.s32 	%r1707, %r1706, -1894007588;
	shf.l.wrap.b32 	%r1708, %r1679, %r1679, 30;
	xor.b32  	%r1709, %r1534, %r1511;
	xor.b32  	%r1710, %r1709, %r1606;
	xor.b32  	%r1711, %r1710, %r1670;
	shf.l.wrap.b32 	%r1712, %r1711, %r1711, 1;
	add.s32 	%r1713, %r1680, %r1712;
	xor.b32  	%r1714, %r1693, %r1694;
	xor.b32  	%r1715, %r1708, %r1693;
	and.b32  	%r1716, %r1715, %r1714;
	xor.b32  	%r1717, %r1716, %r1693;
	shf.l.wrap.b32 	%r1718, %r1707, %r1707, 5;
	add.s32 	%r1719, %r1713, %r1718;
	add.s32 	%r1720, %r1719, %r1717;
	add.s32 	%r1721, %r1720, -1894007588;
	shf.l.wrap.b32 	%r1722, %r1693, %r1693, 30;
	xor.b32  	%r1723, %r1546, %r1522;
	xor.b32  	%r1724, %r1723, %r1618;
	xor.b32  	%r1725, %r1724, %r1684;
	shf.l.wrap.b32 	%r1726, %r1725, %r1725, 1;
	add.s32 	%r1727, %r1694, %r1726;
	xor.b32  	%r1728, %r1707, %r1708;
	xor.b32  	%r1729, %r1722, %r1707;
	and.b32  	%r1730, %r1729, %r1728;
	xor.b32  	%r1731, %r1730, %r1707;
	shf.l.wrap.b32 	%r1732, %r1721, %r1721, 5;
	add.s32 	%r1733, %r1727, %r1732;
	add.s32 	%r1734, %r1733, %r1731;
	add.s32 	%r1735, %r1734, -1894007588;
	shf.l.wrap.b32 	%r1736, %r1707, %r1707, 30;
	xor.b32  	%r1737, %r1558, %r1534;
	xor.b32  	%r1738, %r1737, %r1630;
	xor.b32  	%r1739, %r1738, %r1698;
	shf.l.wrap.b32 	%r1740, %r1739, %r1739, 1;
	add.s32 	%r1741, %r1708, %r1740;
	xor.b32  	%r1742, %r1721, %r1722;
	xor.b32  	%r1743, %r1736, %r1721;
	and.b32  	%r1744, %r1743, %r1742;
	xor.b32  	%r1745, %r1744, %r1721;
	shf.l.wrap.b32 	%r1746, %r1735, %r1735, 5;
	add.s32 	%r1747, %r1741, %r1746;
	add.s32 	%r1748, %r1747, %r1745;
	add.s32 	%r1749, %r1748, -1894007588;
	shf.l.wrap.b32 	%r1750, %r1721, %r1721, 30;
	xor.b32  	%r1751, %r1570, %r1546;
	xor.b32  	%r1752, %r1751, %r1642;
	xor.b32  	%r1753, %r1752, %r1712;
	shf.l.wrap.b32 	%r1754, %r1753, %r1753, 1;
	add.s32 	%r1755, %r1722, %r1754;
	xor.b32  	%r1756, %r1735, %r1736;
	xor.b32  	%r1757, %r1750, %r1735;
	and.b32  	%r1758, %r1757, %r1756;
	xor.b32  	%r1759, %r1758, %r1735;
	shf.l.wrap.b32 	%r1760, %r1749, %r1749, 5;
	add.s32 	%r1761, %r1755, %r1760;
	add.s32 	%r1762, %r1761, %r1759;
	add.s32 	%r1763, %r1762, -1894007588;
	shf.l.wrap.b32 	%r1764, %r1735, %r1735, 30;
	xor.b32  	%r1765, %r1582, %r1558;
	xor.b32  	%r1766, %r1765, %r1656;
	xor.b32  	%r1767, %r1766, %r1726;
	shf.l.wrap.b32 	%r1768, %r1767, %r1767, 1;
	add.s32 	%r1769, %r1736, %r1768;
	xor.b32  	%r1770, %r1749, %r1750;
	xor.b32  	%r1771, %r1764, %r1749;
	and.b32  	%r1772, %r1771, %r1770;
	xor.b32  	%r1773, %r1772, %r1749;
	shf.l.wrap.b32 	%r1774, %r1763, %r1763, 5;
	add.s32 	%r1775, %r1769, %r1774;
	add.s32 	%r1776, %r1775, %r1773;
	add.s32 	%r1777, %r1776, -1894007588;
	shf.l.wrap.b32 	%r1778, %r1749, %r1749, 30;
	xor.b32  	%r1779, %r1594, %r1570;
	xor.b32  	%r1780, %r1779, %r1670;
	xor.b32  	%r1781, %r1780, %r1740;
	shf.l.wrap.b32 	%r1782, %r1781, %r1781, 1;
	add.s32 	%r1783, %r1750, %r1782;
	xor.b32  	%r1784, %r1763, %r1764;
	xor.b32  	%r1785, %r1778, %r1763;
	and.b32  	%r1786, %r1785, %r1784;
	xor.b32  	%r1787, %r1786, %r1763;
	shf.l.wrap.b32 	%r1788, %r1777, %r1777, 5;
	add.s32 	%r1789, %r1783, %r1788;
	add.s32 	%r1790, %r1789, %r1787;
	add.s32 	%r1791, %r1790, -1894007588;
	shf.l.wrap.b32 	%r1792, %r1763, %r1763, 30;
	xor.b32  	%r1793, %r1606, %r1582;
	xor.b32  	%r1794, %r1793, %r1684;
	xor.b32  	%r1795, %r1794, %r1754;
	shf.l.wrap.b32 	%r1796, %r1795, %r1795, 1;
	add.s32 	%r1797, %r1764, %r1796;
	xor.b32  	%r1798, %r1777, %r1778;
	xor.b32  	%r1799, %r1792, %r1777;
	and.b32  	%r1800, %r1799, %r1798;
	xor.b32  	%r1801, %r1800, %r1777;
	shf.l.wrap.b32 	%r1802, %r1791, %r1791, 5;
	add.s32 	%r1803, %r1797, %r1802;
	add.s32 	%r1804, %r1803, %r1801;
	add.s32 	%r1805, %r1804, -1894007588;
	shf.l.wrap.b32 	%r1806, %r1777, %r1777, 30;
	xor.b32  	%r1807, %r1618, %r1594;
	xor.b32  	%r1808, %r1807, %r1698;
	xor.b32  	%r1809, %r1808, %r1768;
	shf.l.wrap.b32 	%r1810, %r1809, %r1809, 1;
	add.s32 	%r1811, %r1778, %r1810;
	xor.b32  	%r1812, %r1791, %r1792;
	xor.b32  	%r1813, %r1806, %r1791;
	and.b32  	%r1814, %r1813, %r1812;
	xor.b32  	%r1815, %r1814, %r1791;
	shf.l.wrap.b32 	%r1816, %r1805, %r1805, 5;
	add.s32 	%r1817, %r1811, %r1816;
	add.s32 	%r1818, %r1817, %r1815;
	add.s32 	%r1819, %r1818, -1894007588;
	shf.l.wrap.b32 	%r1820, %r1791, %r1791, 30;
	xor.b32  	%r1821, %r1630, %r1606;
	xor.b32  	%r1822, %r1821, %r1712;
	xor.b32  	%r1823, %r1822, %r1782;
	shf.l.wrap.b32 	%r1824, %r1823, %r1823, 1;
	add.s32 	%r1825, %r1792, %r1824;
	xor.b32  	%r1826, %r1805, %r1806;
	xor.b32  	%r1827, %r1820, %r1805;
	and.b32  	%r1828, %r1827, %r1826;
	xor.b32  	%r1829, %r1828, %r1805;
	shf.l.wrap.b32 	%r1830, %r1819, %r1819, 5;
	add.s32 	%r1831, %r1825, %r1830;
	add.s32 	%r1832, %r1831, %r1829;
	add.s32 	%r1833, %r1832, -1894007588;
	shf.l.wrap.b32 	%r1834, %r1805, %r1805, 30;
	xor.b32  	%r1835, %r1642, %r1618;
	xor.b32  	%r1836, %r1835, %r1726;
	xor.b32  	%r1837, %r1836, %r1796;
	shf.l.wrap.b32 	%r1838, %r1837, %r1837, 1;
	add.s32 	%r1839, %r1806, %r1838;
	xor.b32  	%r1840, %r1819, %r1820;
	xor.b32  	%r1841, %r1834, %r1819;
	and.b32  	%r1842, %r1841, %r1840;
	xor.b32  	%r1843, %r1842, %r1819;
	shf.l.wrap.b32 	%r1844, %r1833, %r1833, 5;
	add.s32 	%r1845, %r1839, %r1844;
	add.s32 	%r1846, %r1845, %r1843;
	add.s32 	%r1847, %r1846, -1894007588;
	shf.l.wrap.b32 	%r1848, %r1819, %r1819, 30;
	xor.b32  	%r1849, %r1656, %r1630;
	xor.b32  	%r1850, %r1849, %r1740;
	xor.b32  	%r1851, %r1850, %r1810;
	shf.l.wrap.b32 	%r1852, %r1851, %r1851, 1;
	add.s32 	%r1853, %r1820, %r1852;
	xor.b32  	%r1854, %r1833, %r1834;
	xor.b32  	%r1855, %r1848, %r1833;
	and.b32  	%r1856, %r1855, %r1854;
	xor.b32  	%r1857, %r1856, %r1833;
	shf.l.wrap.b32 	%r1858, %r1847, %r1847, 5;
	add.s32 	%r1859, %r1853, %r1858;
	add.s32 	%r1860, %r1859, %r1857;
	add.s32 	%r1861, %r1860, -1894007588;
	shf.l.wrap.b32 	%r1862, %r1833, %r1833, 30;
	xor.b32  	%r1863, %r1670, %r1642;
	xor.b32  	%r1864, %r1863, %r1754;
	xor.b32  	%r1865, %r1864, %r1824;
	shf.l.wrap.b32 	%r1866, %r1865, %r1865, 1;
	add.s32 	%r1867, %r1834, %r1866;
	xor.b32  	%r1868, %r1847, %r1848;
	xor.b32  	%r1869, %r1862, %r1847;
	and.b32  	%r1870, %r1869, %r1868;
	xor.b32  	%r1871, %r1870, %r1847;
	shf.l.wrap.b32 	%r1872, %r1861, %r1861, 5;
	add.s32 	%r1873, %r1867, %r1872;
	add.s32 	%r1874, %r1873, %r1871;
	add.s32 	%r1875, %r1874, -1894007588;
	shf.l.wrap.b32 	%r1876, %r1847, %r1847, 30;
	xor.b32  	%r1877, %r1684, %r1656;
	xor.b32  	%r1878, %r1877, %r1768;
	xor.b32  	%r1879, %r1878, %r1838;
	shf.l.wrap.b32 	%r1880, %r1879, %r1879, 1;
	add.s32 	%r1881, %r1848, %r1880;
	xor.b32  	%r1882, %r1861, %r1862;
	xor.b32  	%r1883, %r1876, %r1861;
	and.b32  	%r1884, %r1883, %r1882;
	xor.b32  	%r1885, %r1884, %r1861;
	shf.l.wrap.b32 	%r1886, %r1875, %r1875, 5;
	add.s32 	%r1887, %r1881, %r1886;
	add.s32 	%r1888, %r1887, %r1885;
	add.s32 	%r1889, %r1888, -1894007588;
	shf.l.wrap.b32 	%r1890, %r1861, %r1861, 30;
	xor.b32  	%r1891, %r1698, %r1670;
	xor.b32  	%r1892, %r1891, %r1782;
	xor.b32  	%r1893, %r1892, %r1852;
	shf.l.wrap.b32 	%r1894, %r1893, %r1893, 1;
	add.s32 	%r1895, %r1862, %r1894;
	xor.b32  	%r1896, %r1875, %r1876;
	xor.b32  	%r1897, %r1890, %r1875;
	and.b32  	%r1898, %r1897, %r1896;
	xor.b32  	%r1899, %r1898, %r1875;
	shf.l.wrap.b32 	%r1900, %r1889, %r1889, 5;
	add.s32 	%r1901, %r1895, %r1900;
	add.s32 	%r1902, %r1901, %r1899;
	add.s32 	%r1903, %r1902, -1894007588;
	shf.l.wrap.b32 	%r1904, %r1875, %r1875, 30;
	xor.b32  	%r1905, %r1712, %r1684;
	xor.b32  	%r1906, %r1905, %r1796;
	xor.b32  	%r1907, %r1906, %r1866;
	shf.l.wrap.b32 	%r1908, %r1907, %r1907, 1;
	add.s32 	%r1909, %r1876, %r1908;
	xor.b32  	%r1910, %r1889, %r1890;
	xor.b32  	%r1911, %r1904, %r1889;
	and.b32  	%r1912, %r1911, %r1910;
	xor.b32  	%r1913, %r1912, %r1889;
	shf.l.wrap.b32 	%r1914, %r1903, %r1903, 5;
	add.s32 	%r1915, %r1909, %r1914;
	add.s32 	%r1916, %r1915, %r1913;
	add.s32 	%r1917, %r1916, -1894007588;
	shf.l.wrap.b32 	%r1918, %r1889, %r1889, 30;
	xor.b32  	%r1919, %r1726, %r1698;
	xor.b32  	%r1920, %r1919, %r1810;
	xor.b32  	%r1921, %r1920, %r1880;
	shf.l.wrap.b32 	%r1922, %r1921, %r1921, 1;
	add.s32 	%r1923, %r1890, %r1922;
	xor.b32  	%r1924, %r1903, %r1904;
	xor.b32  	%r1925, %r1924, %r1918;
	add.s32 	%r1926, %r1923, %r1925;
	shf.l.wrap.b32 	%r1927, %r1917, %r1917, 5;
	add.s32 	%r1928, %r1926, %r1927;
	add.s32 	%r1929, %r1928, -899497514;
	shf.l.wrap.b32 	%r1930, %r1903, %r1903, 30;
	xor.b32  	%r1931, %r1740, %r1712;
	xor.b32  	%r1932, %r1931, %r1824;
	xor.b32  	%r1933, %r1932, %r1894;
	shf.l.wrap.b32 	%r1934, %r1933, %r1933, 1;
	add.s32 	%r1935, %r1904, %r1934;
	xor.b32  	%r1936, %r1917, %r1918;
	xor.b32  	%r1937, %r1936, %r1930;
	add.s32 	%r1938, %r1935, %r1937;
	shf.l.wrap.b32 	%r1939, %r1929, %r1929, 5;
	add.s32 	%r1940, %r1938, %r1939;
	add.s32 	%r1941, %r1940, -899497514;
	shf.l.wrap.b32 	%r1942, %r1917, %r1917, 30;
	xor.b32  	%r1943, %r1754, %r1726;
	xor.b32  	%r1944, %r1943, %r1838;
	xor.b32  	%r1945, %r1944, %r1908;
	shf.l.wrap.b32 	%r1946, %r1945, %r1945, 1;
	add.s32 	%r1947, %r1918, %r1946;
	xor.b32  	%r1948, %r1929, %r1930;
	xor.b32  	%r1949, %r1948, %r1942;
	add.s32 	%r1950, %r1947, %r1949;
	shf.l.wrap.b32 	%r1951, %r1941, %r1941, 5;
	add.s32 	%r1952, %r1950, %r1951;
	add.s32 	%r1953, %r1952, -899497514;
	shf.l.wrap.b32 	%r1954, %r1929, %r1929, 30;
	xor.b32  	%r1955, %r1768, %r1740;
	xor.b32  	%r1956, %r1955, %r1852;
	xor.b32  	%r1957, %r1956, %r1922;
	shf.l.wrap.b32 	%r1958, %r1957, %r1957, 1;
	add.s32 	%r1959, %r1930, %r1958;
	xor.b32  	%r1960, %r1941, %r1942;
	xor.b32  	%r1961, %r1960, %r1954;
	add.s32 	%r1962, %r1959, %r1961;
	shf.l.wrap.b32 	%r1963, %r1953, %r1953, 5;
	add.s32 	%r1964, %r1962, %r1963;
	add.s32 	%r1965, %r1964, -899497514;
	shf.l.wrap.b32 	%r1966, %r1941, %r1941, 30;
	xor.b32  	%r1967, %r1782, %r1754;
	xor.b32  	%r1968, %r1967, %r1866;
	xor.b32  	%r1969, %r1968, %r1934;
	shf.l.wrap.b32 	%r1970, %r1969, %r1969, 1;
	add.s32 	%r1971, %r1942, %r1970;
	xor.b32  	%r1972, %r1953, %r1954;
	xor.b32  	%r1973, %r1972, %r1966;
	add.s32 	%r1974, %r1971, %r1973;
	shf.l.wrap.b32 	%r1975, %r1965, %r1965, 5;
	add.s32 	%r1976, %r1974, %r1975;
	add.s32 	%r1977, %r1976, -899497514;
	shf.l.wrap.b32 	%r1978, %r1953, %r1953, 30;
	xor.b32  	%r1979, %r1796, %r1768;
	xor.b32  	%r1980, %r1979, %r1880;
	xor.b32  	%r1981, %r1980, %r1946;
	shf.l.wrap.b32 	%r1982, %r1981, %r1981, 1;
	add.s32 	%r1983, %r1954, %r1982;
	xor.b32  	%r1984, %r1965, %r1966;
	xor.b32  	%r1985, %r1984, %r1978;
	add.s32 	%r1986, %r1983, %r1985;
	shf.l.wrap.b32 	%r1987, %r1977, %r1977, 5;
	add.s32 	%r1988, %r1986, %r1987;
	add.s32 	%r1989, %r1988, -899497514;
	shf.l.wrap.b32 	%r1990, %r1965, %r1965, 30;
	xor.b32  	%r1991, %r1810, %r1782;
	xor.b32  	%r1992, %r1991, %r1894;
	xor.b32  	%r1993, %r1992, %r1958;
	shf.l.wrap.b32 	%r1994, %r1993, %r1993, 1;
	add.s32 	%r1995, %r1966, %r1994;
	xor.b32  	%r1996, %r1977, %r1978;
	xor.b32  	%r1997, %r1996, %r1990;
	add.s32 	%r1998, %r1995, %r1997;
	shf.l.wrap.b32 	%r1999, %r1989, %r1989, 5;
	add.s32 	%r2000, %r1998, %r1999;
	add.s32 	%r2001, %r2000, -899497514;
	shf.l.wrap.b32 	%r2002, %r1977, %r1977, 30;
	xor.b32  	%r2003, %r1824, %r1796;
	xor.b32  	%r2004, %r2003, %r1908;
	xor.b32  	%r2005, %r2004, %r1970;
	shf.l.wrap.b32 	%r2006, %r2005, %r2005, 1;
	add.s32 	%r2007, %r1978, %r2006;
	xor.b32  	%r2008, %r1989, %r1990;
	xor.b32  	%r2009, %r2008, %r2002;
	add.s32 	%r2010, %r2007, %r2009;
	shf.l.wrap.b32 	%r2011, %r2001, %r2001, 5;
	add.s32 	%r2012, %r2010, %r2011;
	add.s32 	%r2013, %r2012, -899497514;
	shf.l.wrap.b32 	%r2014, %r1989, %r1989, 30;
	xor.b32  	%r2015, %r1838, %r1810;
	xor.b32  	%r2016, %r2015, %r1922;
	xor.b32  	%r2017, %r2016, %r1982;
	shf.l.wrap.b32 	%r2018, %r2017, %r2017, 1;
	add.s32 	%r2019, %r1990, %r2018;
	xor.b32  	%r2020, %r2001, %r2002;
	xor.b32  	%r2021, %r2020, %r2014;
	add.s32 	%r2022, %r2019, %r2021;
	shf.l.wrap.b32 	%r2023, %r2013, %r2013, 5;
	add.s32 	%r2024, %r2022, %r2023;
	add.s32 	%r2025, %r2024, -899497514;
	shf.l.wrap.b32 	%r2026, %r2001, %r2001, 30;
	xor.b32  	%r2027, %r1852, %r1824;
	xor.b32  	%r2028, %r2027, %r1934;
	xor.b32  	%r2029, %r2028, %r1994;
	shf.l.wrap.b32 	%r2030, %r2029, %r2029, 1;
	add.s32 	%r2031, %r2002, %r2030;
	xor.b32  	%r2032, %r2013, %r2014;
	xor.b32  	%r2033, %r2032, %r2026;
	add.s32 	%r2034, %r2031, %r2033;
	shf.l.wrap.b32 	%r2035, %r2025, %r2025, 5;
	add.s32 	%r2036, %r2034, %r2035;
	add.s32 	%r2037, %r2036, -899497514;
	shf.l.wrap.b32 	%r2038, %r2013, %r2013, 30;
	xor.b32  	%r2039, %r1866, %r1838;
	xor.b32  	%r2040, %r2039, %r1946;
	xor.b32  	%r2041, %r2040, %r2006;
	shf.l.wrap.b32 	%r2042, %r2041, %r2041, 1;
	add.s32 	%r2043, %r2014, %r2042;
	xor.b32  	%r2044, %r2025, %r2026;
	xor.b32  	%r2045, %r2044, %r2038;
	add.s32 	%r2046, %r2043, %r2045;
	shf.l.wrap.b32 	%r2047, %r2037, %r2037, 5;
	add.s32 	%r2048, %r2046, %r2047;
	add.s32 	%r2049, %r2048, -899497514;
	shf.l.wrap.b32 	%r2050, %r2025, %r2025, 30;
	xor.b32  	%r2051, %r1880, %r1852;
	xor.b32  	%r2052, %r2051, %r1958;
	xor.b32  	%r2053, %r2052, %r2018;
	shf.l.wrap.b32 	%r2054, %r2053, %r2053, 1;
	add.s32 	%r2055, %r2026, %r2054;
	xor.b32  	%r2056, %r2037, %r2038;
	xor.b32  	%r2057, %r2056, %r2050;
	add.s32 	%r2058, %r2055, %r2057;
	shf.l.wrap.b32 	%r2059, %r2049, %r2049, 5;
	add.s32 	%r2060, %r2058, %r2059;
	add.s32 	%r2061, %r2060, -899497514;
	shf.l.wrap.b32 	%r2062, %r2037, %r2037, 30;
	xor.b32  	%r2063, %r1894, %r1866;
	xor.b32  	%r2064, %r2063, %r1970;
	xor.b32  	%r2065, %r2064, %r2030;
	shf.l.wrap.b32 	%r2066, %r2065, %r2065, 1;
	add.s32 	%r2067, %r2038, %r2066;
	xor.b32  	%r2068, %r2049, %r2050;
	xor.b32  	%r2069, %r2068, %r2062;
	add.s32 	%r2070, %r2067, %r2069;
	shf.l.wrap.b32 	%r2071, %r2061, %r2061, 5;
	add.s32 	%r2072, %r2070, %r2071;
	add.s32 	%r2073, %r2072, -899497514;
	shf.l.wrap.b32 	%r2074, %r2049, %r2049, 30;
	xor.b32  	%r2075, %r1908, %r1880;
	xor.b32  	%r2076, %r2075, %r1982;
	xor.b32  	%r2077, %r2076, %r2042;
	shf.l.wrap.b32 	%r2078, %r2077, %r2077, 1;
	add.s32 	%r2079, %r2050, %r2078;
	xor.b32  	%r2080, %r2061, %r2062;
	xor.b32  	%r2081, %r2080, %r2074;
	add.s32 	%r2082, %r2079, %r2081;
	shf.l.wrap.b32 	%r2083, %r2073, %r2073, 5;
	add.s32 	%r2084, %r2082, %r2083;
	add.s32 	%r2085, %r2084, -899497514;
	shf.l.wrap.b32 	%r2086, %r2061, %r2061, 30;
	xor.b32  	%r2087, %r1922, %r1894;
	xor.b32  	%r2088, %r2087, %r1994;
	xor.b32  	%r2089, %r2088, %r2054;
	shf.l.wrap.b32 	%r2090, %r2089, %r2089, 1;
	add.s32 	%r2091, %r2062, %r2090;
	xor.b32  	%r2092, %r2073, %r2074;
	xor.b32  	%r2093, %r2092, %r2086;
	add.s32 	%r2094, %r2091, %r2093;
	shf.l.wrap.b32 	%r2095, %r2085, %r2085, 5;
	add.s32 	%r2096, %r2094, %r2095;
	add.s32 	%r2097, %r2096, -899497514;
	shf.l.wrap.b32 	%r2098, %r2073, %r2073, 30;
	xor.b32  	%r2099, %r1934, %r1908;
	xor.b32  	%r2100, %r2099, %r2006;
	xor.b32  	%r2101, %r2100, %r2066;
	shf.l.wrap.b32 	%r2102, %r2101, %r2101, 1;
	add.s32 	%r2103, %r2074, %r2102;
	xor.b32  	%r2104, %r2085, %r2086;
	xor.b32  	%r2105, %r2104, %r2098;
	add.s32 	%r2106, %r2103, %r2105;
	shf.l.wrap.b32 	%r2107, %r2097, %r2097, 5;
	add.s32 	%r2108, %r2106, %r2107;
	add.s32 	%r2109, %r2108, -899497514;
	shf.l.wrap.b32 	%r2110, %r2085, %r2085, 30;
	xor.b32  	%r2111, %r1946, %r1922;
	xor.b32  	%r2112, %r2111, %r2018;
	xor.b32  	%r2113, %r2112, %r2078;
	shf.l.wrap.b32 	%r2114, %r2113, %r2113, 1;
	add.s32 	%r2115, %r2086, %r2114;
	xor.b32  	%r2116, %r2097, %r2098;
	xor.b32  	%r2117, %r2116, %r2110;
	add.s32 	%r2118, %r2115, %r2117;
	shf.l.wrap.b32 	%r2119, %r2109, %r2109, 5;
	add.s32 	%r2120, %r2118, %r2119;
	add.s32 	%r2121, %r2120, -899497514;
	shf.l.wrap.b32 	%r2122, %r2097, %r2097, 30;
	xor.b32  	%r2123, %r1958, %r1934;
	xor.b32  	%r2124, %r2123, %r2030;
	xor.b32  	%r2125, %r2124, %r2090;
	shf.l.wrap.b32 	%r2126, %r2125, %r2125, 1;
	add.s32 	%r2127, %r2098, %r2126;
	xor.b32  	%r2128, %r2109, %r2110;
	xor.b32  	%r2129, %r2128, %r2122;
	add.s32 	%r2130, %r2127, %r2129;
	shf.l.wrap.b32 	%r2131, %r2121, %r2121, 5;
	add.s32 	%r2132, %r2130, %r2131;
	add.s32 	%r2133, %r2132, -899497514;
	shf.l.wrap.b32 	%r2134, %r2109, %r2109, 30;
	xor.b32  	%r2135, %r1970, %r1946;
	xor.b32  	%r2136, %r2135, %r2042;
	xor.b32  	%r2137, %r2136, %r2102;
	shf.l.wrap.b32 	%r2138, %r2137, %r2137, 1;
	xor.b32  	%r2139, %r2121, %r2122;
	xor.b32  	%r2140, %r2139, %r2134;
	shf.l.wrap.b32 	%r2141, %r2133, %r2133, 5;
	shf.l.wrap.b32 	%r2142, %r2121, %r2121, 30;
	shf.l.wrap.b32 	%r2143, %r2133, %r2133, 30;
	add.s32 	%r2144, %r2110, %r2138;
	add.s32 	%r2145, %r2144, %r2140;
	add.s32 	%r2146, %r2145, %r2141;
	add.s32 	%r217, %r2146, -899453601;
	add.s32 	%r218, %r2143, -1732584194;
	add.s32 	%r219, %r2142, 271733878;
	add.s32 	%r220, %r2134, -1009589776;
	and.b32  	%r221, %r217, 65535;
	shr.u32 	%r2147, %r219, %r21;
	and.b32  	%r2148, %r2147, %r242;
	mul.wide.u32 	%rd27, %r2148, 4;
	add.s64 	%rd28, %rd59, %rd27;
	and.b32  	%r2149, %r219, 31;
	mov.u32 	%r2150, 1;
	shl.b32 	%r222, %r2150, %r2149;
	ld.global.u32 	%r2151, [%rd28];
	and.b32  	%r2152, %r222, %r2151;
	setp.eq.s32	%p73, %r2152, 0;
	@%p73 bra 	BB3_140;

	mov.u32 	%r2212, 1;
	ld.param.u64 	%rd51, [m15500_m04_param_7];
	shr.u32 	%r2153, %r220, %r21;
	and.b32  	%r2154, %r2153, %r242;
	mul.wide.u32 	%rd29, %r2154, 4;
	add.s64 	%rd30, %rd51, %rd29;
	and.b32  	%r2155, %r220, 31;
	shl.b32 	%r223, %r2212, %r2155;
	ld.global.u32 	%r2157, [%rd30];
	and.b32  	%r2158, %r2157, %r223;
	setp.eq.s32	%p74, %r2158, 0;
	@%p74 bra 	BB3_140;

	mov.u32 	%r2213, 1;
	ld.param.u64 	%rd52, [m15500_m04_param_8];
	shr.u32 	%r2159, %r218, %r21;
	and.b32  	%r2160, %r2159, %r242;
	mul.wide.u32 	%rd31, %r2160, 4;
	add.s64 	%rd32, %rd52, %rd31;
	and.b32  	%r2161, %r218, 31;
	shl.b32 	%r224, %r2213, %r2161;
	ld.global.u32 	%r2163, [%rd32];
	and.b32  	%r2164, %r2163, %r224;
	setp.eq.s32	%p75, %r2164, 0;
	@%p75 bra 	BB3_140;

	mov.u32 	%r2214, 1;
	ld.param.u64 	%rd53, [m15500_m04_param_9];
	shr.u32 	%r2165, %r221, %r21;
	and.b32  	%r2166, %r2165, %r242;
	mul.wide.u32 	%rd33, %r2166, 4;
	add.s64 	%rd34, %rd53, %rd33;
	and.b32  	%r2167, %r217, 31;
	shl.b32 	%r225, %r2214, %r2167;
	ld.global.u32 	%r2169, [%rd34];
	and.b32  	%r2170, %r2169, %r225;
	setp.eq.s32	%p76, %r2170, 0;
	@%p76 bra 	BB3_140;

	and.b32  	%r2217, %r219, 31;
	mov.u32 	%r2216, 1;
	shl.b32 	%r2215, %r2216, %r2217;
	ld.param.u64 	%rd54, [m15500_m04_param_10];
	shr.u32 	%r2171, %r219, %r22;
	and.b32  	%r2172, %r2171, %r242;
	mul.wide.u32 	%rd35, %r2172, 4;
	add.s64 	%rd36, %rd54, %rd35;
	ld.global.u32 	%r2173, [%rd36];
	and.b32  	%r2174, %r2173, %r2215;
	setp.eq.s32	%p77, %r2174, 0;
	@%p77 bra 	BB3_140;

	ld.param.u64 	%rd55, [m15500_m04_param_11];
	shr.u32 	%r2175, %r220, %r22;
	and.b32  	%r2176, %r2175, %r242;
	mul.wide.u32 	%rd37, %r2176, 4;
	add.s64 	%rd38, %rd55, %rd37;
	ld.global.u32 	%r2177, [%rd38];
	and.b32  	%r2178, %r2177, %r223;
	setp.eq.s32	%p78, %r2178, 0;
	@%p78 bra 	BB3_140;

	ld.param.u64 	%rd56, [m15500_m04_param_12];
	shr.u32 	%r2179, %r218, %r22;
	and.b32  	%r2180, %r2179, %r242;
	mul.wide.u32 	%rd39, %r2180, 4;
	add.s64 	%rd40, %rd56, %rd39;
	ld.global.u32 	%r2181, [%rd40];
	and.b32  	%r2182, %r2181, %r224;
	setp.eq.s32	%p79, %r2182, 0;
	@%p79 bra 	BB3_140;

	ld.param.u64 	%rd57, [m15500_m04_param_13];
	shr.u32 	%r2183, %r221, %r22;
	and.b32  	%r2184, %r2183, %r242;
	mul.wide.u32 	%rd41, %r2184, 4;
	add.s64 	%rd42, %rd57, %rd41;
	ld.global.u32 	%r2185, [%rd42];
	and.b32  	%r2186, %r2185, %r225;
	setp.eq.s32	%p80, %r2186, 0;
	@%p80 bra 	BB3_140;

	setp.eq.s32	%p81, %r247, 0;
	mov.u32 	%r2252, 0;
	mov.u32 	%r2187, -1;
	mov.u32 	%r2251, %r247;
	@%p81 bra 	BB3_134;

BB3_122:
	ld.param.u64 	%rd60, [m15500_m04_param_15];
	mov.u32 	%r2253, 1;
	shr.u32 	%r228, %r2251, 1;
	add.s32 	%r2254, %r228, %r2252;
	cvt.u64.u32	%rd43, %r2254;
	add.s64 	%rd44, %rd43, %rd2;
	mul.lo.s64 	%rd45, %rd44, 20;
	add.s64 	%rd46, %rd60, %rd45;
	add.s64 	%rd4, %rd46, 4;
	ld.global.u32 	%r230, [%rd46+4];
	setp.gt.u32	%p82, %r221, %r230;
	@%p82 bra 	BB3_132;

	setp.lt.u32	%p83, %r221, %r230;
	mov.u32 	%r2190, -1;
	@%p83 bra 	BB3_124;
	bra.uni 	BB3_125;

BB3_124:
	mov.u32 	%r2253, %r2190;
	bra.uni 	BB3_132;

BB3_125:
	mov.u32 	%r2253, 1;
	ld.global.u32 	%r231, [%rd4+4];
	setp.gt.u32	%p84, %r218, %r231;
	@%p84 bra 	BB3_132;

	setp.lt.u32	%p85, %r218, %r231;
	@%p85 bra 	BB3_127;
	bra.uni 	BB3_128;

BB3_127:
	mov.u32 	%r2253, %r2190;
	bra.uni 	BB3_132;

BB3_128:
	mov.u32 	%r2253, 1;
	ld.global.u32 	%r232, [%rd4+12];
	setp.gt.u32	%p86, %r220, %r232;
	@%p86 bra 	BB3_132;

	setp.lt.u32	%p87, %r220, %r232;
	mov.u32 	%r2253, %r2190;
	@%p87 bra 	BB3_132;

	mov.u32 	%r2253, 1;
	ld.global.u32 	%r233, [%rd4+8];
	setp.gt.u32	%p88, %r219, %r233;
	@%p88 bra 	BB3_132;

	setp.lt.u32	%p89, %r219, %r233;
	selp.b32	%r2253, -1, 0, %p89;

BB3_132:
	add.s32 	%r2196, %r228, 1;
	setp.gt.s32	%p90, %r2253, 0;
	selp.b32	%r2197, %r2196, 0, %p90;
	add.s32 	%r2252, %r2197, %r2252;
	selp.b32	%r2198, -1, 0, %p90;
	add.s32 	%r2199, %r2198, %r2251;
	shr.u32 	%r2251, %r2199, 1;
	setp.eq.s32	%p91, %r2253, 0;
	@%p91 bra 	BB3_135;

	setp.ne.s32	%p92, %r2251, 0;
	@%p92 bra 	BB3_122;

BB3_134:
	mov.u32 	%r2254, %r2187;

BB3_135:
	setp.eq.s32	%p93, %r2254, -1;
	@%p93 bra 	BB3_140;

	ld.param.u64 	%rd61, [m15500_m04_param_16];
	ld.param.u32 	%r2203, [m15500_m04_param_32];
	add.s32 	%r239, %r2254, %r2203;
	mul.wide.u32 	%rd47, %r239, 4;
	add.s64 	%rd48, %rd61, %rd47;
	atom.global.add.u32 	%r2201, [%rd48], 1;
	setp.ne.s32	%p94, %r2201, 0;
	@%p94 bra 	BB3_140;

	atom.global.add.u32 	%r240, [%rd19], 1;
	setp.lt.u32	%p95, %r240, %r247;
	@%p95 bra 	BB3_139;
	bra.uni 	BB3_138;

BB3_139:
	ld.param.u64 	%rd62, [m15500_m04_param_14];
	ld.param.u32 	%r2204, [m15500_m04_param_27];
	mul.wide.u32 	%rd49, %r240, 32;
	add.s64 	%rd50, %rd62, %rd49;
	st.global.v2.u32 	[%rd50], {%r2204, %r2254};
	st.global.u32 	[%rd50+8], %r239;
	st.global.u32 	[%rd50+24], %r2222;
	st.global.u64 	[%rd50+16], %rd3;
	bra.uni 	BB3_140;

BB3_138:
	atom.global.add.u32 	%r2202, [%rd19], -1;

BB3_140:
	ld.param.u32 	%r2205, [m15500_m04_param_30];
	add.s32 	%r2222, %r2222, 1;
	setp.lt.u32	%p96, %r2222, %r2205;
	@%p96 bra 	BB3_3;

BB3_141:
	ret;
}

	// .globl	m15500_m08
.entry m15500_m08(
	.param .u64 .ptr .global .align 4 m15500_m08_param_0,
	.param .u64 .ptr .global .align 4 m15500_m08_param_1,
	.param .u64 .ptr .global .align 4 m15500_m08_param_2,
	.param .u64 .ptr .global .align 4 m15500_m08_param_3,
	.param .u64 .ptr .global .align 1 m15500_m08_param_4,
	.param .u64 .ptr .global .align 1 m15500_m08_param_5,
	.param .u64 .ptr .global .align 4 m15500_m08_param_6,
	.param .u64 .ptr .global .align 4 m15500_m08_param_7,
	.param .u64 .ptr .global .align 4 m15500_m08_param_8,
	.param .u64 .ptr .global .align 4 m15500_m08_param_9,
	.param .u64 .ptr .global .align 4 m15500_m08_param_10,
	.param .u64 .ptr .global .align 4 m15500_m08_param_11,
	.param .u64 .ptr .global .align 4 m15500_m08_param_12,
	.param .u64 .ptr .global .align 4 m15500_m08_param_13,
	.param .u64 .ptr .global .align 8 m15500_m08_param_14,
	.param .u64 .ptr .global .align 4 m15500_m08_param_15,
	.param .u64 .ptr .global .align 4 m15500_m08_param_16,
	.param .u64 .ptr .global .align 4 m15500_m08_param_17,
	.param .u64 .ptr .global .align 1 m15500_m08_param_18,
	.param .u64 .ptr .global .align 4 m15500_m08_param_19,
	.param .u64 .ptr .global .align 4 m15500_m08_param_20,
	.param .u64 .ptr .global .align 4 m15500_m08_param_21,
	.param .u64 .ptr .global .align 4 m15500_m08_param_22,
	.param .u64 .ptr .global .align 4 m15500_m08_param_23,
	.param .u32 m15500_m08_param_24,
	.param .u32 m15500_m08_param_25,
	.param .u32 m15500_m08_param_26,
	.param .u32 m15500_m08_param_27,
	.param .u32 m15500_m08_param_28,
	.param .u32 m15500_m08_param_29,
	.param .u32 m15500_m08_param_30,
	.param .u32 m15500_m08_param_31,
	.param .u32 m15500_m08_param_32,
	.param .u32 m15500_m08_param_33,
	.param .u64 m15500_m08_param_34
)
{



	ret;
}

	// .globl	m15500_m16
.entry m15500_m16(
	.param .u64 .ptr .global .align 4 m15500_m16_param_0,
	.param .u64 .ptr .global .align 4 m15500_m16_param_1,
	.param .u64 .ptr .global .align 4 m15500_m16_param_2,
	.param .u64 .ptr .global .align 4 m15500_m16_param_3,
	.param .u64 .ptr .global .align 1 m15500_m16_param_4,
	.param .u64 .ptr .global .align 1 m15500_m16_param_5,
	.param .u64 .ptr .global .align 4 m15500_m16_param_6,
	.param .u64 .ptr .global .align 4 m15500_m16_param_7,
	.param .u64 .ptr .global .align 4 m15500_m16_param_8,
	.param .u64 .ptr .global .align 4 m15500_m16_param_9,
	.param .u64 .ptr .global .align 4 m15500_m16_param_10,
	.param .u64 .ptr .global .align 4 m15500_m16_param_11,
	.param .u64 .ptr .global .align 4 m15500_m16_param_12,
	.param .u64 .ptr .global .align 4 m15500_m16_param_13,
	.param .u64 .ptr .global .align 8 m15500_m16_param_14,
	.param .u64 .ptr .global .align 4 m15500_m16_param_15,
	.param .u64 .ptr .global .align 4 m15500_m16_param_16,
	.param .u64 .ptr .global .align 4 m15500_m16_param_17,
	.param .u64 .ptr .global .align 1 m15500_m16_param_18,
	.param .u64 .ptr .global .align 4 m15500_m16_param_19,
	.param .u64 .ptr .global .align 4 m15500_m16_param_20,
	.param .u64 .ptr .global .align 4 m15500_m16_param_21,
	.param .u64 .ptr .global .align 4 m15500_m16_param_22,
	.param .u64 .ptr .global .align 4 m15500_m16_param_23,
	.param .u32 m15500_m16_param_24,
	.param .u32 m15500_m16_param_25,
	.param .u32 m15500_m16_param_26,
	.param .u32 m15500_m16_param_27,
	.param .u32 m15500_m16_param_28,
	.param .u32 m15500_m16_param_29,
	.param .u32 m15500_m16_param_30,
	.param .u32 m15500_m16_param_31,
	.param .u32 m15500_m16_param_32,
	.param .u32 m15500_m16_param_33,
	.param .u64 m15500_m16_param_34
)
{



	ret;
}

	// .globl	m15500_s04
.entry m15500_s04(
	.param .u64 .ptr .global .align 4 m15500_s04_param_0,
	.param .u64 .ptr .global .align 4 m15500_s04_param_1,
	.param .u64 .ptr .global .align 4 m15500_s04_param_2,
	.param .u64 .ptr .global .align 4 m15500_s04_param_3,
	.param .u64 .ptr .global .align 1 m15500_s04_param_4,
	.param .u64 .ptr .global .align 1 m15500_s04_param_5,
	.param .u64 .ptr .global .align 4 m15500_s04_param_6,
	.param .u64 .ptr .global .align 4 m15500_s04_param_7,
	.param .u64 .ptr .global .align 4 m15500_s04_param_8,
	.param .u64 .ptr .global .align 4 m15500_s04_param_9,
	.param .u64 .ptr .global .align 4 m15500_s04_param_10,
	.param .u64 .ptr .global .align 4 m15500_s04_param_11,
	.param .u64 .ptr .global .align 4 m15500_s04_param_12,
	.param .u64 .ptr .global .align 4 m15500_s04_param_13,
	.param .u64 .ptr .global .align 8 m15500_s04_param_14,
	.param .u64 .ptr .global .align 4 m15500_s04_param_15,
	.param .u64 .ptr .global .align 4 m15500_s04_param_16,
	.param .u64 .ptr .global .align 4 m15500_s04_param_17,
	.param .u64 .ptr .global .align 1 m15500_s04_param_18,
	.param .u64 .ptr .global .align 4 m15500_s04_param_19,
	.param .u64 .ptr .global .align 4 m15500_s04_param_20,
	.param .u64 .ptr .global .align 4 m15500_s04_param_21,
	.param .u64 .ptr .global .align 4 m15500_s04_param_22,
	.param .u64 .ptr .global .align 4 m15500_s04_param_23,
	.param .u32 m15500_s04_param_24,
	.param .u32 m15500_s04_param_25,
	.param .u32 m15500_s04_param_26,
	.param .u32 m15500_s04_param_27,
	.param .u32 m15500_s04_param_28,
	.param .u32 m15500_s04_param_29,
	.param .u32 m15500_s04_param_30,
	.param .u32 m15500_s04_param_31,
	.param .u32 m15500_s04_param_32,
	.param .u32 m15500_s04_param_33,
	.param .u64 m15500_s04_param_34
)
{
	.reg .pred 	%p<83>;
	.reg .b32 	%r<2170>;
	.reg .b64 	%rd<25>;


	ld.param.u64 	%rd4, [m15500_s04_param_0];
	ld.param.u64 	%rd7, [m15500_s04_param_15];
	ld.param.u64 	%rd8, [m15500_s04_param_16];
	ld.param.u64 	%rd9, [m15500_s04_param_17];
	ld.param.u64 	%rd10, [m15500_s04_param_19];
	ld.param.u32 	%r221, [m15500_s04_param_27];
	ld.param.u32 	%r222, [m15500_s04_param_30];
	ld.param.u32 	%r224, [m15500_s04_param_32];
	ld.param.u64 	%rd11, [m15500_s04_param_34];
	mov.b32	%r226, %envreg3;
	mov.u32 	%r227, %ctaid.x;
	mov.u32 	%r228, %ntid.x;
	mad.lo.s32 	%r229, %r227, %r228, %r226;
	mov.u32 	%r230, %tid.x;
	add.s32 	%r231, %r229, %r230;
	cvt.s64.s32	%rd1, %r231;
	setp.ge.u64	%p1, %rd1, %rd11;
	@%p1 bra 	BB6_118;

	mul.lo.s64 	%rd12, %rd1, 260;
	add.s64 	%rd13, %rd4, %rd12;
	ld.global.u32 	%r1, [%rd13];
	ld.global.u32 	%r2, [%rd13+4];
	ld.global.u32 	%r3, [%rd13+8];
	ld.global.u32 	%r4, [%rd13+12];
	ld.global.u32 	%r5, [%rd13+16];
	ld.global.u32 	%r6, [%rd13+20];
	ld.global.u32 	%r7, [%rd13+24];
	ld.global.u32 	%r8, [%rd13+256];
	mul.wide.u32 	%rd14, %r221, 564;
	add.s64 	%rd15, %rd9, %rd14;
	ld.global.u32 	%r9, [%rd15];
	ld.global.u32 	%r10, [%rd15+4];
	ld.global.u32 	%r11, [%rd15+8];
	ld.global.u32 	%r12, [%rd15+12];
	ld.global.u32 	%r13, [%rd15+16];
	setp.eq.s32	%p2, %r222, 0;
	@%p2 bra 	BB6_118;

	mul.wide.u32 	%rd16, %r224, 20;
	add.s64 	%rd17, %rd7, %rd16;
	ld.global.u32 	%r14, [%rd17+12];
	ld.global.u32 	%r15, [%rd17+16];
	ld.global.u32 	%r16, [%rd17+8];
	ld.global.u32 	%r17, [%rd17+4];
	and.b32  	%r233, %r8, 3;
	mov.u32 	%r234, 4;
	sub.s32 	%r235, %r234, %r233;
	shr.u32 	%r18, %r8, 2;
	shl.b32 	%r236, %r235, 2;
	mov.u32 	%r237, 1985229328;
	shr.u32 	%r238, %r237, %r236;
	and.b32  	%r19, %r238, 65535;
	mov.u32 	%r239, 1732584193;
	mov.u32 	%r240, -271733879;
	shf.l.wrap.b32 	%r21, %r240, %r240, 30;
	or.b32  	%r22, %r21, -1732584194;
	shf.l.wrap.b32 	%r23, %r239, %r239, 30;
	xor.b32  	%r24, %r23, %r21;
	mul.wide.u32 	%rd18, %r224, 4;
	add.s64 	%rd2, %rd8, %rd18;
	and.b64  	%rd3, %rd1, 4294967295;
	mov.u32 	%r2141, 0;

BB6_3:
	ld.param.u32 	%r2132, [m15500_s04_param_33];
	ld.param.u64 	%rd23, [m15500_s04_param_2];
	mul.wide.u32 	%rd19, %r2141, 260;
	add.s64 	%rd20, %rd23, %rd19;
	ld.global.u32 	%r26, [%rd20+256];
	add.s32 	%r27, %r26, %r8;
	ld.global.u32 	%r2152, [%rd20];
	ld.global.u32 	%r2151, [%rd20+4];
	ld.global.u32 	%r2150, [%rd20+8];
	ld.global.u32 	%r2149, [%rd20+12];
	ld.global.u32 	%r2155, [%rd20+16];
	ld.global.u32 	%r2154, [%rd20+20];
	ld.global.u32 	%r2153, [%rd20+24];
	setp.eq.s32	%p3, %r2132, 10001;
	@%p3 bra 	BB6_36;
	bra.uni 	BB6_4;

BB6_36:
	setp.gt.s32	%p27, %r18, 7;
	@%p27 bra 	BB6_51;

	setp.gt.s32	%p39, %r18, 3;
	@%p39 bra 	BB6_45;

	setp.gt.s32	%p45, %r18, 1;
	@%p45 bra 	BB6_42;

	setp.eq.s32	%p48, %r18, 0;
	@%p48 bra 	BB6_67;
	bra.uni 	BB6_40;

BB6_67:
	// inline asm
	prmt.b32 %r2153, %r2154, %r2153, %r19;
	// inline asm
	// inline asm
	prmt.b32 %r2154, %r2155, %r2154, %r19;
	// inline asm
	// inline asm
	prmt.b32 %r2155, %r2149, %r2155, %r19;
	// inline asm
	// inline asm
	prmt.b32 %r2149, %r2150, %r2149, %r19;
	// inline asm
	// inline asm
	prmt.b32 %r2150, %r2151, %r2150, %r19;
	// inline asm
	// inline asm
	prmt.b32 %r2151, %r2152, %r2151, %r19;
	// inline asm
	mov.u32 	%r637, 0;
	// inline asm
	prmt.b32 %r2152, %r637, %r2152, %r19;
	// inline asm
	bra.uni 	BB6_68;

BB6_4:
	and.b32  	%r242, %r26, 3;
	sub.s32 	%r244, %r234, %r242;
	shl.b32 	%r245, %r244, 2;
	shr.u32 	%r247, %r237, %r245;
	and.b32  	%r35, %r247, 65535;
	shr.u32 	%r241, %r26, 2;
	setp.gt.s32	%p4, %r241, 7;
	@%p4 bra 	BB6_19;

	setp.gt.s32	%p16, %r241, 3;
	@%p16 bra 	BB6_13;

	setp.gt.s32	%p22, %r241, 1;
	@%p22 bra 	BB6_10;

	setp.eq.s32	%p25, %r241, 0;
	@%p25 bra 	BB6_35;
	bra.uni 	BB6_8;

BB6_35:
	// inline asm
	prmt.b32 %r2146, %r6, %r7, %r35;
	// inline asm
	// inline asm
	prmt.b32 %r2147, %r5, %r6, %r35;
	// inline asm
	// inline asm
	prmt.b32 %r2148, %r4, %r5, %r35;
	// inline asm
	// inline asm
	prmt.b32 %r2142, %r3, %r4, %r35;
	// inline asm
	// inline asm
	prmt.b32 %r2143, %r2, %r3, %r35;
	// inline asm
	// inline asm
	prmt.b32 %r2144, %r1, %r2, %r35;
	// inline asm
	mov.u32 	%r441, 0;
	// inline asm
	prmt.b32 %r2145, %r441, %r1, %r35;
	// inline asm
	bra.uni 	BB6_69;

BB6_51:
	setp.gt.s32	%p28, %r18, 11;
	@%p28 bra 	BB6_57;

	setp.gt.s32	%p34, %r18, 9;
	@%p34 bra 	BB6_55;

	setp.eq.s32	%p37, %r18, 8;
	@%p37 bra 	BB6_62;

	setp.eq.s32	%p38, %r18, 9;
	mov.u32 	%r2142, %r4;
	mov.u32 	%r2143, %r3;
	mov.u32 	%r2144, %r2;
	mov.u32 	%r2145, %r1;
	mov.u32 	%r2146, %r7;
	mov.u32 	%r2147, %r6;
	mov.u32 	%r2148, %r5;
	@%p38 bra 	BB6_62;
	bra.uni 	BB6_69;

BB6_19:
	setp.gt.s32	%p5, %r241, 11;
	@%p5 bra 	BB6_25;

	setp.gt.s32	%p11, %r241, 9;
	@%p11 bra 	BB6_23;

	setp.eq.s32	%p14, %r241, 8;
	@%p14 bra 	BB6_30;

	setp.eq.s32	%p15, %r241, 9;
	@%p15 bra 	BB6_30;
	bra.uni 	BB6_68;

BB6_45:
	setp.gt.s32	%p40, %r18, 5;
	@%p40 bra 	BB6_49;

	setp.eq.s32	%p43, %r18, 4;
	@%p43 bra 	BB6_65;
	bra.uni 	BB6_47;

BB6_65:
	// inline asm
	prmt.b32 %r2153, %r2151, %r2150, %r19;
	// inline asm
	// inline asm
	prmt.b32 %r2154, %r2152, %r2151, %r19;
	// inline asm
	mov.u32 	%r2149, 0;
	// inline asm
	prmt.b32 %r2155, %r2149, %r2152, %r19;
	// inline asm
	mov.u32 	%r2142, %r4;
	mov.u32 	%r2143, %r3;
	mov.u32 	%r2144, %r2;
	mov.u32 	%r2145, %r1;
	mov.u32 	%r2146, %r7;
	mov.u32 	%r2147, %r6;
	mov.u32 	%r2148, %r5;
	mov.u32 	%r2150, %r2149;
	mov.u32 	%r2151, %r2149;
	mov.u32 	%r2152, %r2149;
	bra.uni 	BB6_69;

BB6_13:
	setp.gt.s32	%p17, %r241, 5;
	@%p17 bra 	BB6_17;

	setp.eq.s32	%p20, %r241, 4;
	@%p20 bra 	BB6_33;
	bra.uni 	BB6_15;

BB6_33:
	// inline asm
	prmt.b32 %r2146, %r2, %r3, %r35;
	// inline asm
	// inline asm
	prmt.b32 %r2147, %r1, %r2, %r35;
	// inline asm
	mov.u32 	%r2142, 0;
	// inline asm
	prmt.b32 %r2148, %r2142, %r1, %r35;
	// inline asm
	mov.u32 	%r2143, %r2142;
	mov.u32 	%r2144, %r2142;
	mov.u32 	%r2145, %r2142;
	bra.uni 	BB6_69;

BB6_57:
	setp.gt.s32	%p29, %r18, 13;
	@%p29 bra 	BB6_60;

	setp.eq.s32	%p32, %r18, 12;
	@%p32 bra 	BB6_62;

	setp.eq.s32	%p33, %r18, 13;
	mov.u32 	%r2142, %r4;
	mov.u32 	%r2143, %r3;
	mov.u32 	%r2144, %r2;
	mov.u32 	%r2145, %r1;
	mov.u32 	%r2146, %r7;
	mov.u32 	%r2147, %r6;
	mov.u32 	%r2148, %r5;
	@%p33 bra 	BB6_62;
	bra.uni 	BB6_69;

BB6_25:
	setp.gt.s32	%p6, %r241, 13;
	@%p6 bra 	BB6_28;

	setp.eq.s32	%p9, %r241, 12;
	@%p9 bra 	BB6_30;

	setp.eq.s32	%p10, %r241, 13;
	@%p10 bra 	BB6_30;
	bra.uni 	BB6_68;

BB6_42:
	setp.eq.s32	%p46, %r18, 2;
	@%p46 bra 	BB6_66;
	bra.uni 	BB6_43;

BB6_66:
	// inline asm
	prmt.b32 %r2153, %r2149, %r2155, %r19;
	// inline asm
	// inline asm
	prmt.b32 %r2154, %r2150, %r2149, %r19;
	// inline asm
	// inline asm
	prmt.b32 %r2155, %r2151, %r2150, %r19;
	// inline asm
	// inline asm
	prmt.b32 %r2149, %r2152, %r2151, %r19;
	// inline asm
	mov.u32 	%r2151, 0;
	// inline asm
	prmt.b32 %r2150, %r2151, %r2152, %r19;
	// inline asm
	mov.u32 	%r2142, %r4;
	mov.u32 	%r2143, %r3;
	mov.u32 	%r2144, %r2;
	mov.u32 	%r2145, %r1;
	mov.u32 	%r2146, %r7;
	mov.u32 	%r2147, %r6;
	mov.u32 	%r2148, %r5;
	mov.u32 	%r2152, %r2151;
	bra.uni 	BB6_69;

BB6_10:
	setp.eq.s32	%p23, %r241, 2;
	@%p23 bra 	BB6_34;
	bra.uni 	BB6_11;

BB6_34:
	// inline asm
	prmt.b32 %r2146, %r4, %r5, %r35;
	// inline asm
	// inline asm
	prmt.b32 %r2147, %r3, %r4, %r35;
	// inline asm
	// inline asm
	prmt.b32 %r2148, %r2, %r3, %r35;
	// inline asm
	// inline asm
	prmt.b32 %r2142, %r1, %r2, %r35;
	// inline asm
	mov.u32 	%r2144, 0;
	// inline asm
	prmt.b32 %r2143, %r2144, %r1, %r35;
	// inline asm
	mov.u32 	%r2145, %r2144;
	bra.uni 	BB6_69;

BB6_55:
	setp.eq.s32	%p35, %r18, 10;
	@%p35 bra 	BB6_62;

	setp.eq.s32	%p36, %r18, 11;
	mov.u32 	%r2142, %r4;
	mov.u32 	%r2143, %r3;
	mov.u32 	%r2144, %r2;
	mov.u32 	%r2145, %r1;
	mov.u32 	%r2146, %r7;
	mov.u32 	%r2147, %r6;
	mov.u32 	%r2148, %r5;
	@%p36 bra 	BB6_62;
	bra.uni 	BB6_69;

BB6_23:
	setp.eq.s32	%p12, %r241, 10;
	@%p12 bra 	BB6_30;

	setp.eq.s32	%p13, %r241, 11;
	@%p13 bra 	BB6_30;
	bra.uni 	BB6_68;

BB6_49:
	setp.eq.s32	%p41, %r18, 6;
	@%p41 bra 	BB6_64;
	bra.uni 	BB6_50;

BB6_64:
	mov.u32 	%r2149, 0;
	// inline asm
	prmt.b32 %r2153, %r2149, %r2152, %r19;
	// inline asm
	mov.u32 	%r2142, %r4;
	mov.u32 	%r2143, %r3;
	mov.u32 	%r2144, %r2;
	mov.u32 	%r2145, %r1;
	mov.u32 	%r2146, %r7;
	mov.u32 	%r2147, %r6;
	mov.u32 	%r2148, %r5;
	mov.u32 	%r2150, %r2149;
	mov.u32 	%r2151, %r2149;
	mov.u32 	%r2152, %r2149;
	bra.uni 	BB6_63;

BB6_17:
	setp.eq.s32	%p18, %r241, 6;
	@%p18 bra 	BB6_32;
	bra.uni 	BB6_18;

BB6_32:
	mov.u32 	%r2142, 0;
	// inline asm
	prmt.b32 %r2146, %r2142, %r1, %r35;
	// inline asm
	mov.u32 	%r2143, %r2142;
	mov.u32 	%r2144, %r2142;
	mov.u32 	%r2145, %r2142;
	bra.uni 	BB6_31;

BB6_60:
	setp.eq.s32	%p30, %r18, 14;
	@%p30 bra 	BB6_62;

	setp.ne.s32	%p31, %r18, 15;
	mov.u32 	%r2142, %r4;
	mov.u32 	%r2143, %r3;
	mov.u32 	%r2144, %r2;
	mov.u32 	%r2145, %r1;
	mov.u32 	%r2146, %r7;
	mov.u32 	%r2147, %r6;
	mov.u32 	%r2148, %r5;
	@%p31 bra 	BB6_69;
	bra.uni 	BB6_62;

BB6_28:
	setp.eq.s32	%p7, %r241, 14;
	@%p7 bra 	BB6_30;

	setp.ne.s32	%p8, %r241, 15;
	@%p8 bra 	BB6_68;
	bra.uni 	BB6_30;

BB6_40:
	setp.eq.s32	%p49, %r18, 1;
	@%p49 bra 	BB6_41;
	bra.uni 	BB6_68;

BB6_41:
	// inline asm
	prmt.b32 %r2153, %r2155, %r2154, %r19;
	// inline asm
	// inline asm
	prmt.b32 %r2154, %r2149, %r2155, %r19;
	// inline asm
	// inline asm
	prmt.b32 %r2155, %r2150, %r2149, %r19;
	// inline asm
	// inline asm
	prmt.b32 %r2149, %r2151, %r2150, %r19;
	// inline asm
	// inline asm
	prmt.b32 %r2150, %r2152, %r2151, %r19;
	// inline asm
	mov.u32 	%r611, 0;
	// inline asm
	prmt.b32 %r2151, %r611, %r2152, %r19;
	// inline asm
	mov.u32 	%r2142, %r4;
	mov.u32 	%r2143, %r3;
	mov.u32 	%r2144, %r2;
	mov.u32 	%r2145, %r1;
	mov.u32 	%r2146, %r7;
	mov.u32 	%r2147, %r6;
	mov.u32 	%r2148, %r5;
	mov.u32 	%r2152, %r611;
	bra.uni 	BB6_69;

BB6_8:
	setp.eq.s32	%p26, %r241, 1;
	@%p26 bra 	BB6_9;
	bra.uni 	BB6_68;

BB6_9:
	// inline asm
	prmt.b32 %r2146, %r5, %r6, %r35;
	// inline asm
	// inline asm
	prmt.b32 %r2147, %r4, %r5, %r35;
	// inline asm
	// inline asm
	prmt.b32 %r2148, %r3, %r4, %r35;
	// inline asm
	// inline asm
	prmt.b32 %r2142, %r2, %r3, %r35;
	// inline asm
	// inline asm
	prmt.b32 %r2143, %r1, %r2, %r35;
	// inline asm
	mov.u32 	%r2145, 0;
	// inline asm
	prmt.b32 %r2144, %r2145, %r1, %r35;
	// inline asm
	bra.uni 	BB6_69;

BB6_47:
	setp.eq.s32	%p44, %r18, 5;
	@%p44 bra 	BB6_48;
	bra.uni 	BB6_68;

BB6_48:
	// inline asm
	prmt.b32 %r2153, %r2152, %r2151, %r19;
	// inline asm
	mov.u32 	%r2149, 0;
	// inline asm
	prmt.b32 %r2154, %r2149, %r2152, %r19;
	// inline asm
	mov.u32 	%r2142, %r4;
	mov.u32 	%r2143, %r3;
	mov.u32 	%r2144, %r2;
	mov.u32 	%r2145, %r1;
	mov.u32 	%r2146, %r7;
	mov.u32 	%r2147, %r6;
	mov.u32 	%r2148, %r5;
	mov.u32 	%r2150, %r2149;
	mov.u32 	%r2151, %r2149;
	mov.u32 	%r2152, %r2149;
	mov.u32 	%r2155, %r2149;
	bra.uni 	BB6_69;

BB6_15:
	setp.eq.s32	%p21, %r241, 5;
	@%p21 bra 	BB6_16;
	bra.uni 	BB6_68;

BB6_16:
	// inline asm
	prmt.b32 %r2146, %r1, %r2, %r35;
	// inline asm
	mov.u32 	%r2142, 0;
	// inline asm
	prmt.b32 %r2147, %r2142, %r1, %r35;
	// inline asm
	mov.u32 	%r2143, %r2142;
	mov.u32 	%r2144, %r2142;
	mov.u32 	%r2145, %r2142;
	mov.u32 	%r2148, %r2142;
	bra.uni 	BB6_69;

BB6_43:
	setp.eq.s32	%p47, %r18, 3;
	@%p47 bra 	BB6_44;
	bra.uni 	BB6_68;

BB6_44:
	// inline asm
	prmt.b32 %r2153, %r2150, %r2149, %r19;
	// inline asm
	// inline asm
	prmt.b32 %r2154, %r2151, %r2150, %r19;
	// inline asm
	// inline asm
	prmt.b32 %r2155, %r2152, %r2151, %r19;
	// inline asm
	mov.u32 	%r2150, 0;
	// inline asm
	prmt.b32 %r2149, %r2150, %r2152, %r19;
	// inline asm
	mov.u32 	%r2142, %r4;
	mov.u32 	%r2143, %r3;
	mov.u32 	%r2144, %r2;
	mov.u32 	%r2145, %r1;
	mov.u32 	%r2146, %r7;
	mov.u32 	%r2147, %r6;
	mov.u32 	%r2148, %r5;
	mov.u32 	%r2151, %r2150;
	mov.u32 	%r2152, %r2150;
	bra.uni 	BB6_69;

BB6_11:
	setp.eq.s32	%p24, %r241, 3;
	@%p24 bra 	BB6_12;
	bra.uni 	BB6_68;

BB6_12:
	// inline asm
	prmt.b32 %r2146, %r3, %r4, %r35;
	// inline asm
	// inline asm
	prmt.b32 %r2147, %r2, %r3, %r35;
	// inline asm
	// inline asm
	prmt.b32 %r2148, %r1, %r2, %r35;
	// inline asm
	mov.u32 	%r2143, 0;
	// inline asm
	prmt.b32 %r2142, %r2143, %r1, %r35;
	// inline asm
	mov.u32 	%r2144, %r2143;
	mov.u32 	%r2145, %r2143;
	bra.uni 	BB6_69;

BB6_50:
	setp.eq.s32	%p42, %r18, 7;
	mov.u32 	%r2142, %r4;
	mov.u32 	%r2143, %r3;
	mov.u32 	%r2144, %r2;
	mov.u32 	%r2145, %r1;
	mov.u32 	%r2146, %r7;
	mov.u32 	%r2147, %r6;
	mov.u32 	%r2148, %r5;
	@%p42 bra 	BB6_62;
	bra.uni 	BB6_69;

BB6_62:
	mov.u32 	%r2149, 0;
	mov.u32 	%r2142, %r4;
	mov.u32 	%r2143, %r3;
	mov.u32 	%r2144, %r2;
	mov.u32 	%r2145, %r1;
	mov.u32 	%r2146, %r7;
	mov.u32 	%r2147, %r6;
	mov.u32 	%r2148, %r5;
	mov.u32 	%r2150, %r2149;
	mov.u32 	%r2151, %r2149;
	mov.u32 	%r2152, %r2149;
	mov.u32 	%r2153, %r2149;

BB6_63:
	mov.u32 	%r2154, %r2149;
	mov.u32 	%r2155, %r2149;
	bra.uni 	BB6_69;

BB6_18:
	setp.eq.s32	%p19, %r241, 7;
	@%p19 bra 	BB6_30;
	bra.uni 	BB6_68;

BB6_30:
	mov.u32 	%r2142, 0;
	mov.u32 	%r2143, %r2142;
	mov.u32 	%r2144, %r2142;
	mov.u32 	%r2145, %r2142;
	mov.u32 	%r2146, %r2142;

BB6_31:
	mov.u32 	%r2147, %r2142;
	mov.u32 	%r2148, %r2142;
	bra.uni 	BB6_69;

BB6_68:
	mov.u32 	%r2142, %r4;
	mov.u32 	%r2143, %r3;
	mov.u32 	%r2144, %r2;
	mov.u32 	%r2145, %r1;
	mov.u32 	%r2146, %r7;
	mov.u32 	%r2147, %r6;
	mov.u32 	%r2148, %r5;

BB6_69:
	or.b32  	%r645, %r2153, %r2146;
	mov.u32 	%r2160, 0;
	mov.u32 	%r691, 14119;
	// inline asm
	prmt.b32 %r640, %r645, %r2160, %r691;
	// inline asm
	mov.u32 	%r695, 5895;
	// inline asm
	prmt.b32 %r644, %r645, %r2160, %r695;
	// inline asm
	or.b32  	%r653, %r2154, %r2147;
	// inline asm
	prmt.b32 %r648, %r653, %r2160, %r691;
	// inline asm
	// inline asm
	prmt.b32 %r652, %r653, %r2160, %r695;
	// inline asm
	or.b32  	%r661, %r2155, %r2148;
	// inline asm
	prmt.b32 %r656, %r661, %r2160, %r691;
	// inline asm
	// inline asm
	prmt.b32 %r660, %r661, %r2160, %r695;
	// inline asm
	or.b32  	%r669, %r2149, %r2142;
	// inline asm
	prmt.b32 %r664, %r669, %r2160, %r691;
	// inline asm
	// inline asm
	prmt.b32 %r668, %r669, %r2160, %r695;
	// inline asm
	or.b32  	%r677, %r2150, %r2143;
	// inline asm
	prmt.b32 %r672, %r677, %r2160, %r691;
	// inline asm
	// inline asm
	prmt.b32 %r676, %r677, %r2160, %r695;
	// inline asm
	or.b32  	%r685, %r2151, %r2144;
	// inline asm
	prmt.b32 %r680, %r685, %r2160, %r691;
	// inline asm
	// inline asm
	prmt.b32 %r684, %r685, %r2160, %r695;
	// inline asm
	or.b32  	%r693, %r2152, %r2145;
	// inline asm
	prmt.b32 %r688, %r693, %r2160, %r691;
	// inline asm
	// inline asm
	prmt.b32 %r692, %r693, %r2160, %r695;
	// inline asm
	shl.b32 	%r706, %r27, 1;
	and.b32  	%r707, %r706, 2;
	sub.s32 	%r709, %r234, %r707;
	bfe.u32 	%r705, %r27, 1, 30;
	shl.b32 	%r710, %r709, 2;
	shr.u32 	%r712, %r237, %r710;
	and.b32  	%r120, %r712, 65535;
	mov.u32 	%r2162, 128;
	setp.gt.s32	%p50, %r705, 7;
	@%p50 bra 	BB6_85;

	setp.gt.s32	%p62, %r705, 3;
	@%p62 bra 	BB6_78;

	setp.gt.s32	%p68, %r705, 1;
	@%p68 bra 	BB6_75;

	setp.eq.s32	%p71, %r705, 0;
	@%p71 bra 	BB6_111;
	bra.uni 	BB6_73;

BB6_111:
	mov.u32 	%r1165, 0;
	// inline asm
	prmt.b32 %r2160, %r1165, %r1165, %r120;
	// inline asm
	mov.u32 	%r1146, 128;
	// inline asm
	prmt.b32 %r2161, %r1146, %r1165, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2162, %r13, %r1146, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2163, %r12, %r13, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2156, %r11, %r12, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2157, %r10, %r11, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2158, %r9, %r10, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2159, %r1165, %r9, %r120;
	// inline asm
	mov.u32 	%r2164, %r2160;
	mov.u32 	%r2165, %r2160;
	mov.u32 	%r2166, %r2160;
	mov.u32 	%r2167, %r2160;
	mov.u32 	%r2168, %r2160;
	mov.u32 	%r2169, %r2160;
	bra.uni 	BB6_112;

BB6_85:
	setp.gt.s32	%p51, %r705, 11;
	@%p51 bra 	BB6_93;

	setp.gt.s32	%p57, %r705, 9;
	@%p57 bra 	BB6_90;

	setp.eq.s32	%p60, %r705, 8;
	@%p60 bra 	BB6_104;
	bra.uni 	BB6_88;

BB6_104:
	mov.u32 	%r858, 128;
	// inline asm
	prmt.b32 %r2168, %r13, %r858, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2169, %r12, %r13, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2164, %r11, %r12, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2165, %r10, %r11, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2166, %r9, %r10, %r120;
	// inline asm
	mov.u32 	%r2156, 0;
	// inline asm
	prmt.b32 %r2167, %r2156, %r9, %r120;
	// inline asm
	mov.u32 	%r2157, %r2156;
	mov.u32 	%r2158, %r2156;
	mov.u32 	%r2159, %r2156;
	mov.u32 	%r2160, %r2156;
	bra.uni 	BB6_105;

BB6_78:
	setp.gt.s32	%p63, %r705, 5;
	@%p63 bra 	BB6_82;

	setp.eq.s32	%p66, %r705, 4;
	@%p66 bra 	BB6_108;
	bra.uni 	BB6_80;

BB6_108:
	mov.u32 	%r2156, 0;
	// inline asm
	prmt.b32 %r2164, %r2156, %r2156, %r120;
	// inline asm
	mov.u32 	%r1008, 128;
	// inline asm
	prmt.b32 %r2165, %r1008, %r2156, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2166, %r13, %r1008, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2167, %r12, %r13, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2160, %r11, %r12, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2161, %r10, %r11, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2162, %r9, %r10, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2163, %r2156, %r9, %r120;
	// inline asm
	mov.u32 	%r2157, %r2156;
	mov.u32 	%r2158, %r2156;
	mov.u32 	%r2159, %r2156;
	bra.uni 	BB6_109;

BB6_93:
	setp.gt.s32	%p52, %r705, 13;
	@%p52 bra 	BB6_97;

	setp.eq.s32	%p55, %r705, 12;
	@%p55 bra 	BB6_100;
	bra.uni 	BB6_95;

BB6_100:
	// inline asm
	prmt.b32 %r2168, %r9, %r10, %r120;
	// inline asm
	mov.u32 	%r2156, 0;
	// inline asm
	prmt.b32 %r2169, %r2156, %r9, %r120;
	// inline asm
	mov.u32 	%r2157, %r2156;
	mov.u32 	%r2158, %r2156;
	mov.u32 	%r2159, %r2156;
	mov.u32 	%r2160, %r2156;
	mov.u32 	%r2161, %r2156;
	mov.u32 	%r2162, %r2156;
	mov.u32 	%r2163, %r2156;
	mov.u32 	%r2164, %r2156;
	bra.uni 	BB6_101;

BB6_75:
	setp.eq.s32	%p69, %r705, 2;
	@%p69 bra 	BB6_110;
	bra.uni 	BB6_76;

BB6_110:
	mov.u32 	%r2158, 0;
	// inline asm
	prmt.b32 %r2164, %r2158, %r2158, %r120;
	// inline asm
	mov.u32 	%r1079, 128;
	// inline asm
	prmt.b32 %r2167, %r1079, %r2158, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2160, %r13, %r1079, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2161, %r12, %r13, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2162, %r11, %r12, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2163, %r10, %r11, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2156, %r9, %r10, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2157, %r2158, %r9, %r120;
	// inline asm
	mov.u32 	%r2159, %r2158;
	mov.u32 	%r2165, %r2164;
	mov.u32 	%r2166, %r2164;
	bra.uni 	BB6_109;

BB6_90:
	setp.eq.s32	%p58, %r705, 10;
	@%p58 bra 	BB6_103;
	bra.uni 	BB6_91;

BB6_103:
	// inline asm
	prmt.b32 %r2168, %r11, %r12, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2169, %r10, %r11, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2164, %r9, %r10, %r120;
	// inline asm
	mov.u32 	%r2156, 0;
	// inline asm
	prmt.b32 %r2165, %r2156, %r9, %r120;
	// inline asm
	mov.u32 	%r2157, %r2156;
	mov.u32 	%r2158, %r2156;
	mov.u32 	%r2159, %r2156;
	mov.u32 	%r2160, %r2156;
	mov.u32 	%r2161, %r2156;
	mov.u32 	%r2162, %r2156;
	mov.u32 	%r2163, %r2156;
	bra.uni 	BB6_102;

BB6_82:
	setp.eq.s32	%p64, %r705, 6;
	@%p64 bra 	BB6_107;
	bra.uni 	BB6_83;

BB6_107:
	mov.u32 	%r2156, 0;
	// inline asm
	prmt.b32 %r2168, %r2156, %r2156, %r120;
	// inline asm
	mov.u32 	%r933, 128;
	// inline asm
	prmt.b32 %r2169, %r933, %r2156, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2164, %r13, %r933, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2165, %r12, %r13, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2166, %r11, %r12, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2167, %r10, %r11, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2160, %r9, %r10, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2161, %r2156, %r9, %r120;
	// inline asm
	mov.u32 	%r2157, %r2156;
	mov.u32 	%r2158, %r2156;
	mov.u32 	%r2159, %r2156;
	bra.uni 	BB6_106;

BB6_97:
	setp.eq.s32	%p53, %r705, 14;
	@%p53 bra 	BB6_99;

	setp.ne.s32	%p54, %r705, 15;
	mov.u32 	%r2156, %r12;
	mov.u32 	%r2157, %r11;
	mov.u32 	%r2158, %r10;
	mov.u32 	%r2159, %r9;
	mov.u32 	%r2161, %r2160;
	mov.u32 	%r2163, %r13;
	mov.u32 	%r2164, %r2160;
	mov.u32 	%r2165, %r2160;
	mov.u32 	%r2166, %r2160;
	mov.u32 	%r2167, %r2160;
	mov.u32 	%r2168, %r2160;
	mov.u32 	%r2169, %r2160;
	@%p54 bra 	BB6_112;

BB6_99:
	mov.u32 	%r2156, 0;
	mov.u32 	%r2157, %r2156;
	mov.u32 	%r2158, %r2156;
	mov.u32 	%r2159, %r2156;
	mov.u32 	%r2160, %r2156;
	mov.u32 	%r2161, %r2156;
	mov.u32 	%r2162, %r2156;
	mov.u32 	%r2163, %r2156;
	mov.u32 	%r2164, %r2156;
	mov.u32 	%r2165, %r2156;
	mov.u32 	%r2166, %r2156;
	mov.u32 	%r2167, %r2156;
	mov.u32 	%r2168, %r2156;
	mov.u32 	%r2169, %r2156;
	bra.uni 	BB6_112;

BB6_73:
	setp.eq.s32	%p72, %r705, 1;
	mov.u32 	%r2156, %r12;
	mov.u32 	%r2157, %r11;
	mov.u32 	%r2158, %r10;
	mov.u32 	%r2159, %r9;
	mov.u32 	%r2161, %r2160;
	mov.u32 	%r2163, %r13;
	mov.u32 	%r2164, %r2160;
	mov.u32 	%r2165, %r2160;
	mov.u32 	%r2166, %r2160;
	mov.u32 	%r2167, %r2160;
	mov.u32 	%r2168, %r2160;
	mov.u32 	%r2169, %r2160;
	@%p72 bra 	BB6_74;
	bra.uni 	BB6_112;

BB6_74:
	mov.u32 	%r2159, 0;
	// inline asm
	prmt.b32 %r2164, %r2159, %r2159, %r120;
	// inline asm
	mov.u32 	%r1113, 128;
	// inline asm
	prmt.b32 %r2160, %r1113, %r2159, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2161, %r13, %r1113, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2162, %r12, %r13, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2163, %r11, %r12, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2156, %r10, %r11, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2157, %r9, %r10, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2158, %r2159, %r9, %r120;
	// inline asm
	mov.u32 	%r2165, %r2164;
	mov.u32 	%r2166, %r2164;
	mov.u32 	%r2167, %r2164;
	bra.uni 	BB6_109;

BB6_88:
	setp.eq.s32	%p61, %r705, 9;
	mov.u32 	%r2156, %r12;
	mov.u32 	%r2157, %r11;
	mov.u32 	%r2158, %r10;
	mov.u32 	%r2159, %r9;
	mov.u32 	%r2161, %r2160;
	mov.u32 	%r2163, %r13;
	mov.u32 	%r2164, %r2160;
	mov.u32 	%r2165, %r2160;
	mov.u32 	%r2166, %r2160;
	mov.u32 	%r2167, %r2160;
	mov.u32 	%r2168, %r2160;
	mov.u32 	%r2169, %r2160;
	@%p61 bra 	BB6_89;
	bra.uni 	BB6_112;

BB6_89:
	// inline asm
	prmt.b32 %r2168, %r12, %r13, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2169, %r11, %r12, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2164, %r10, %r11, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2165, %r9, %r10, %r120;
	// inline asm
	mov.u32 	%r2156, 0;
	// inline asm
	prmt.b32 %r2166, %r2156, %r9, %r120;
	// inline asm
	mov.u32 	%r2157, %r2156;
	mov.u32 	%r2158, %r2156;
	mov.u32 	%r2159, %r2156;
	mov.u32 	%r2160, %r2156;
	mov.u32 	%r2161, %r2156;
	mov.u32 	%r2162, %r2156;
	mov.u32 	%r2163, %r2156;
	mov.u32 	%r2167, %r2156;
	bra.uni 	BB6_112;

BB6_80:
	setp.eq.s32	%p67, %r705, 5;
	mov.u32 	%r2156, %r12;
	mov.u32 	%r2157, %r11;
	mov.u32 	%r2158, %r10;
	mov.u32 	%r2159, %r9;
	mov.u32 	%r2161, %r2160;
	mov.u32 	%r2163, %r13;
	mov.u32 	%r2164, %r2160;
	mov.u32 	%r2165, %r2160;
	mov.u32 	%r2166, %r2160;
	mov.u32 	%r2167, %r2160;
	mov.u32 	%r2168, %r2160;
	mov.u32 	%r2169, %r2160;
	@%p67 bra 	BB6_81;
	bra.uni 	BB6_112;

BB6_81:
	mov.u32 	%r2156, 0;
	// inline asm
	prmt.b32 %r2168, %r2156, %r2156, %r120;
	// inline asm
	mov.u32 	%r971, 128;
	// inline asm
	prmt.b32 %r2164, %r971, %r2156, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2165, %r13, %r971, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2166, %r12, %r13, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2167, %r11, %r12, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2160, %r10, %r11, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2161, %r9, %r10, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2162, %r2156, %r9, %r120;
	// inline asm
	mov.u32 	%r2157, %r2156;
	mov.u32 	%r2158, %r2156;
	mov.u32 	%r2159, %r2156;
	mov.u32 	%r2163, %r2156;
	mov.u32 	%r2169, %r2168;
	bra.uni 	BB6_112;

BB6_95:
	setp.eq.s32	%p56, %r705, 13;
	mov.u32 	%r2156, %r12;
	mov.u32 	%r2157, %r11;
	mov.u32 	%r2158, %r10;
	mov.u32 	%r2159, %r9;
	mov.u32 	%r2161, %r2160;
	mov.u32 	%r2163, %r13;
	mov.u32 	%r2164, %r2160;
	mov.u32 	%r2165, %r2160;
	mov.u32 	%r2166, %r2160;
	mov.u32 	%r2167, %r2160;
	mov.u32 	%r2168, %r2160;
	mov.u32 	%r2169, %r2160;
	@%p56 bra 	BB6_96;
	bra.uni 	BB6_112;

BB6_96:
	mov.u32 	%r2156, 0;
	// inline asm
	prmt.b32 %r2168, %r2156, %r9, %r120;
	// inline asm
	mov.u32 	%r2157, %r2156;
	mov.u32 	%r2158, %r2156;
	mov.u32 	%r2159, %r2156;
	mov.u32 	%r2160, %r2156;
	mov.u32 	%r2161, %r2156;
	mov.u32 	%r2162, %r2156;
	mov.u32 	%r2163, %r2156;
	mov.u32 	%r2164, %r2156;
	mov.u32 	%r2165, %r2156;
	mov.u32 	%r2166, %r2156;
	mov.u32 	%r2167, %r2156;
	mov.u32 	%r2169, %r2156;
	bra.uni 	BB6_112;

BB6_76:
	setp.eq.s32	%p70, %r705, 3;
	mov.u32 	%r2156, %r12;
	mov.u32 	%r2157, %r11;
	mov.u32 	%r2158, %r10;
	mov.u32 	%r2159, %r9;
	mov.u32 	%r2161, %r2160;
	mov.u32 	%r2163, %r13;
	mov.u32 	%r2164, %r2160;
	mov.u32 	%r2165, %r2160;
	mov.u32 	%r2166, %r2160;
	mov.u32 	%r2167, %r2160;
	mov.u32 	%r2168, %r2160;
	mov.u32 	%r2169, %r2160;
	@%p70 bra 	BB6_77;
	bra.uni 	BB6_112;

BB6_77:
	mov.u32 	%r2157, 0;
	// inline asm
	prmt.b32 %r2164, %r2157, %r2157, %r120;
	// inline asm
	mov.u32 	%r1044, 128;
	// inline asm
	prmt.b32 %r2166, %r1044, %r2157, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2167, %r13, %r1044, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2160, %r12, %r13, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2161, %r11, %r12, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2162, %r10, %r11, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2163, %r9, %r10, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2156, %r2157, %r9, %r120;
	// inline asm
	mov.u32 	%r2158, %r2157;
	mov.u32 	%r2159, %r2157;
	mov.u32 	%r2165, %r2164;

BB6_109:
	mov.u32 	%r2168, %r2164;
	mov.u32 	%r2169, %r2164;
	bra.uni 	BB6_112;

BB6_91:
	setp.eq.s32	%p59, %r705, 11;
	mov.u32 	%r2156, %r12;
	mov.u32 	%r2157, %r11;
	mov.u32 	%r2158, %r10;
	mov.u32 	%r2159, %r9;
	mov.u32 	%r2161, %r2160;
	mov.u32 	%r2163, %r13;
	mov.u32 	%r2164, %r2160;
	mov.u32 	%r2165, %r2160;
	mov.u32 	%r2166, %r2160;
	mov.u32 	%r2167, %r2160;
	mov.u32 	%r2168, %r2160;
	mov.u32 	%r2169, %r2160;
	@%p59 bra 	BB6_92;
	bra.uni 	BB6_112;

BB6_92:
	// inline asm
	prmt.b32 %r2168, %r10, %r11, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2169, %r9, %r10, %r120;
	// inline asm
	mov.u32 	%r2156, 0;
	// inline asm
	prmt.b32 %r2164, %r2156, %r9, %r120;
	// inline asm
	mov.u32 	%r2157, %r2156;
	mov.u32 	%r2158, %r2156;
	mov.u32 	%r2159, %r2156;
	mov.u32 	%r2160, %r2156;
	mov.u32 	%r2161, %r2156;
	mov.u32 	%r2162, %r2156;
	mov.u32 	%r2163, %r2156;

BB6_101:
	mov.u32 	%r2165, %r2156;

BB6_102:
	mov.u32 	%r2166, %r2156;
	mov.u32 	%r2167, %r2156;
	bra.uni 	BB6_112;

BB6_83:
	setp.eq.s32	%p65, %r705, 7;
	mov.u32 	%r2156, %r12;
	mov.u32 	%r2157, %r11;
	mov.u32 	%r2158, %r10;
	mov.u32 	%r2159, %r9;
	mov.u32 	%r2161, %r2160;
	mov.u32 	%r2163, %r13;
	mov.u32 	%r2164, %r2160;
	mov.u32 	%r2165, %r2160;
	mov.u32 	%r2166, %r2160;
	mov.u32 	%r2167, %r2160;
	mov.u32 	%r2168, %r2160;
	mov.u32 	%r2169, %r2160;
	@%p65 bra 	BB6_84;
	bra.uni 	BB6_112;

BB6_84:
	mov.u32 	%r894, 128;
	mov.u32 	%r2156, 0;
	// inline asm
	prmt.b32 %r2168, %r894, %r2156, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2169, %r13, %r894, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2164, %r12, %r13, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2165, %r11, %r12, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2166, %r10, %r11, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2167, %r9, %r10, %r120;
	// inline asm
	// inline asm
	prmt.b32 %r2160, %r2156, %r9, %r120;
	// inline asm
	mov.u32 	%r2157, %r2156;
	mov.u32 	%r2158, %r2156;
	mov.u32 	%r2159, %r2156;

BB6_105:
	mov.u32 	%r2161, %r2156;

BB6_106:
	mov.u32 	%r2162, %r2156;
	mov.u32 	%r2163, %r2156;

BB6_112:
	mov.u32 	%r2137, 1732584193;
	shf.l.wrap.b32 	%r2136, %r2137, %r2137, 30;
	mov.u32 	%r2135, -271733879;
	shf.l.wrap.b32 	%r2134, %r2135, %r2135, 30;
	shf.l.wrap.b32 	%r2133, %r2137, %r2137, 5;
	or.b32  	%r1169, %r2159, %r692;
	// inline asm
	prmt.b32 %r1168, %r1169, 0, 0x0123;
	// inline asm
	or.b32  	%r1171, %r2158, %r688;
	// inline asm
	prmt.b32 %r1170, %r1171, 0, 0x0123;
	// inline asm
	or.b32  	%r1173, %r2157, %r684;
	// inline asm
	prmt.b32 %r1172, %r1173, 0, 0x0123;
	// inline asm
	or.b32  	%r1175, %r2156, %r680;
	// inline asm
	prmt.b32 %r1174, %r1175, 0, 0x0123;
	// inline asm
	or.b32  	%r1177, %r2163, %r676;
	// inline asm
	prmt.b32 %r1176, %r1177, 0, 0x0123;
	// inline asm
	or.b32  	%r1179, %r2162, %r672;
	// inline asm
	prmt.b32 %r1178, %r1179, 0, 0x0123;
	// inline asm
	or.b32  	%r1181, %r2161, %r668;
	// inline asm
	prmt.b32 %r1180, %r1181, 0, 0x0123;
	// inline asm
	or.b32  	%r1183, %r2160, %r664;
	// inline asm
	prmt.b32 %r1182, %r1183, 0, 0x0123;
	// inline asm
	or.b32  	%r1185, %r2167, %r660;
	// inline asm
	prmt.b32 %r1184, %r1185, 0, 0x0123;
	// inline asm
	or.b32  	%r1187, %r2166, %r656;
	// inline asm
	prmt.b32 %r1186, %r1187, 0, 0x0123;
	// inline asm
	or.b32  	%r1189, %r2165, %r652;
	// inline asm
	prmt.b32 %r1188, %r1189, 0, 0x0123;
	// inline asm
	or.b32  	%r1191, %r2164, %r648;
	// inline asm
	prmt.b32 %r1190, %r1191, 0, 0x0123;
	// inline asm
	or.b32  	%r1193, %r2169, %r644;
	// inline asm
	prmt.b32 %r1192, %r1193, 0, 0x0123;
	// inline asm
	or.b32  	%r1195, %r2168, %r640;
	// inline asm
	prmt.b32 %r1194, %r1195, 0, 0x0123;
	// inline asm
	shl.b32 	%r1196, %r27, 4;
	add.s32 	%r1197, %r1196, 160;
	add.s32 	%r1198, %r1168, %r2133;
	add.s32 	%r1199, %r1198, -1223673721;
	shf.l.wrap.b32 	%r1200, %r1199, %r1199, 5;
	add.s32 	%r1201, %r1170, %r1200;
	add.s32 	%r1202, %r1201, %r22;
	add.s32 	%r1203, %r1202, 1790234127;
	and.b32  	%r1204, %r24, %r1199;
	xor.b32  	%r1205, %r1204, %r2134;
	shf.l.wrap.b32 	%r1206, %r1203, %r1203, 5;
	add.s32 	%r1207, %r1172, %r1206;
	add.s32 	%r1208, %r1207, %r1205;
	add.s32 	%r1209, %r1208, -214083945;
	shf.l.wrap.b32 	%r1210, %r1199, %r1199, 30;
	xor.b32  	%r1211, %r1210, %r2136;
	and.b32  	%r1212, %r1211, %r1203;
	xor.b32  	%r1213, %r1212, %r2136;
	shf.l.wrap.b32 	%r1214, %r1209, %r1209, 5;
	add.s32 	%r1215, %r1174, %r2134;
	add.s32 	%r1216, %r1215, %r1214;
	add.s32 	%r1217, %r1216, %r1213;
	add.s32 	%r1218, %r1217, 1518500249;
	shf.l.wrap.b32 	%r1219, %r1203, %r1203, 30;
	xor.b32  	%r1220, %r1219, %r1210;
	and.b32  	%r1221, %r1220, %r1209;
	xor.b32  	%r1222, %r1221, %r1210;
	shf.l.wrap.b32 	%r1223, %r1218, %r1218, 5;
	add.s32 	%r1224, %r1176, %r2136;
	add.s32 	%r1225, %r1224, %r1223;
	add.s32 	%r1226, %r1225, %r1222;
	add.s32 	%r1227, %r1226, 1518500249;
	shf.l.wrap.b32 	%r1228, %r1209, %r1209, 30;
	xor.b32  	%r1229, %r1228, %r1219;
	and.b32  	%r1230, %r1229, %r1218;
	xor.b32  	%r1231, %r1230, %r1219;
	shf.l.wrap.b32 	%r1232, %r1227, %r1227, 5;
	add.s32 	%r1233, %r1178, %r1210;
	add.s32 	%r1234, %r1233, %r1232;
	add.s32 	%r1235, %r1234, %r1231;
	add.s32 	%r1236, %r1235, 1518500249;
	shf.l.wrap.b32 	%r1237, %r1218, %r1218, 30;
	xor.b32  	%r1238, %r1237, %r1228;
	and.b32  	%r1239, %r1238, %r1227;
	xor.b32  	%r1240, %r1239, %r1228;
	shf.l.wrap.b32 	%r1241, %r1236, %r1236, 5;
	add.s32 	%r1242, %r1180, %r1219;
	add.s32 	%r1243, %r1242, %r1241;
	add.s32 	%r1244, %r1243, %r1240;
	add.s32 	%r1245, %r1244, 1518500249;
	shf.l.wrap.b32 	%r1246, %r1227, %r1227, 30;
	xor.b32  	%r1247, %r1246, %r1237;
	and.b32  	%r1248, %r1247, %r1236;
	xor.b32  	%r1249, %r1248, %r1237;
	shf.l.wrap.b32 	%r1250, %r1245, %r1245, 5;
	add.s32 	%r1251, %r1182, %r1228;
	add.s32 	%r1252, %r1251, %r1250;
	add.s32 	%r1253, %r1252, %r1249;
	add.s32 	%r1254, %r1253, 1518500249;
	shf.l.wrap.b32 	%r1255, %r1236, %r1236, 30;
	xor.b32  	%r1256, %r1255, %r1246;
	and.b32  	%r1257, %r1256, %r1245;
	xor.b32  	%r1258, %r1257, %r1246;
	shf.l.wrap.b32 	%r1259, %r1254, %r1254, 5;
	add.s32 	%r1260, %r1184, %r1237;
	add.s32 	%r1261, %r1260, %r1259;
	add.s32 	%r1262, %r1261, %r1258;
	add.s32 	%r1263, %r1262, 1518500249;
	shf.l.wrap.b32 	%r1264, %r1245, %r1245, 30;
	xor.b32  	%r1265, %r1264, %r1255;
	and.b32  	%r1266, %r1265, %r1254;
	xor.b32  	%r1267, %r1266, %r1255;
	shf.l.wrap.b32 	%r1268, %r1263, %r1263, 5;
	add.s32 	%r1269, %r1186, %r1246;
	add.s32 	%r1270, %r1269, %r1268;
	add.s32 	%r1271, %r1270, %r1267;
	add.s32 	%r1272, %r1271, 1518500249;
	shf.l.wrap.b32 	%r1273, %r1254, %r1254, 30;
	xor.b32  	%r1274, %r1273, %r1264;
	and.b32  	%r1275, %r1274, %r1263;
	xor.b32  	%r1276, %r1275, %r1264;
	shf.l.wrap.b32 	%r1277, %r1272, %r1272, 5;
	add.s32 	%r1278, %r1188, %r1255;
	add.s32 	%r1279, %r1278, %r1277;
	add.s32 	%r1280, %r1279, %r1276;
	add.s32 	%r1281, %r1280, 1518500249;
	shf.l.wrap.b32 	%r1282, %r1263, %r1263, 30;
	xor.b32  	%r1283, %r1282, %r1273;
	and.b32  	%r1284, %r1283, %r1272;
	xor.b32  	%r1285, %r1284, %r1273;
	shf.l.wrap.b32 	%r1286, %r1281, %r1281, 5;
	add.s32 	%r1287, %r1190, %r1264;
	add.s32 	%r1288, %r1287, %r1286;
	add.s32 	%r1289, %r1288, %r1285;
	add.s32 	%r1290, %r1289, 1518500249;
	shf.l.wrap.b32 	%r1291, %r1272, %r1272, 30;
	xor.b32  	%r1292, %r1291, %r1282;
	and.b32  	%r1293, %r1292, %r1281;
	xor.b32  	%r1294, %r1293, %r1282;
	shf.l.wrap.b32 	%r1295, %r1290, %r1290, 5;
	add.s32 	%r1296, %r1192, %r1273;
	add.s32 	%r1297, %r1296, %r1295;
	add.s32 	%r1298, %r1297, %r1294;
	add.s32 	%r1299, %r1298, 1518500249;
	shf.l.wrap.b32 	%r1300, %r1281, %r1281, 30;
	xor.b32  	%r1301, %r1300, %r1291;
	and.b32  	%r1302, %r1301, %r1290;
	xor.b32  	%r1303, %r1302, %r1291;
	shf.l.wrap.b32 	%r1304, %r1299, %r1299, 5;
	add.s32 	%r1305, %r1194, %r1282;
	add.s32 	%r1306, %r1305, %r1304;
	add.s32 	%r1307, %r1306, %r1303;
	add.s32 	%r1308, %r1307, 1518500249;
	shf.l.wrap.b32 	%r1309, %r1290, %r1290, 30;
	shf.l.wrap.b32 	%r1310, %r1308, %r1308, 5;
	add.s32 	%r1311, %r1291, %r1310;
	xor.b32  	%r1312, %r1309, %r1300;
	and.b32  	%r1313, %r1312, %r1299;
	xor.b32  	%r1314, %r1313, %r1300;
	add.s32 	%r1315, %r1311, %r1314;
	add.s32 	%r1316, %r1315, 1518500249;
	shf.l.wrap.b32 	%r1317, %r1299, %r1299, 30;
	xor.b32  	%r1318, %r1317, %r1309;
	and.b32  	%r1319, %r1318, %r1308;
	xor.b32  	%r1320, %r1319, %r1309;
	shf.l.wrap.b32 	%r1321, %r1316, %r1316, 5;
	add.s32 	%r1322, %r1196, %r1300;
	add.s32 	%r1323, %r1322, %r1321;
	add.s32 	%r1324, %r1323, %r1320;
	add.s32 	%r1325, %r1324, 1518500409;
	shf.l.wrap.b32 	%r1326, %r1308, %r1308, 30;
	xor.b32  	%r1327, %r1172, %r1168;
	xor.b32  	%r1328, %r1327, %r1184;
	xor.b32  	%r1329, %r1328, %r1194;
	shf.l.wrap.b32 	%r1330, %r1329, %r1329, 1;
	add.s32 	%r1331, %r1309, %r1330;
	xor.b32  	%r1332, %r1326, %r1317;
	and.b32  	%r1333, %r1332, %r1316;
	xor.b32  	%r1334, %r1333, %r1317;
	shf.l.wrap.b32 	%r1335, %r1325, %r1325, 5;
	add.s32 	%r1336, %r1331, %r1335;
	add.s32 	%r1337, %r1336, %r1334;
	add.s32 	%r1338, %r1337, 1518500249;
	shf.l.wrap.b32 	%r1339, %r1316, %r1316, 30;
	xor.b32  	%r1340, %r1174, %r1170;
	xor.b32  	%r1341, %r1340, %r1186;
	shf.l.wrap.b32 	%r1342, %r1341, %r1341, 1;
	add.s32 	%r1343, %r1317, %r1342;
	xor.b32  	%r1344, %r1339, %r1326;
	and.b32  	%r1345, %r1344, %r1325;
	xor.b32  	%r1346, %r1345, %r1326;
	shf.l.wrap.b32 	%r1347, %r1338, %r1338, 5;
	add.s32 	%r1348, %r1343, %r1347;
	add.s32 	%r1349, %r1348, %r1346;
	add.s32 	%r1350, %r1349, 1518500249;
	shf.l.wrap.b32 	%r1351, %r1325, %r1325, 30;
	xor.b32  	%r1352, %r1172, %r1197;
	xor.b32  	%r1353, %r1352, %r1176;
	xor.b32  	%r1354, %r1353, %r1188;
	shf.l.wrap.b32 	%r1355, %r1354, %r1354, 1;
	add.s32 	%r1356, %r1326, %r1355;
	xor.b32  	%r1357, %r1351, %r1339;
	and.b32  	%r1358, %r1357, %r1338;
	xor.b32  	%r1359, %r1358, %r1339;
	shf.l.wrap.b32 	%r1360, %r1350, %r1350, 5;
	add.s32 	%r1361, %r1356, %r1360;
	add.s32 	%r1362, %r1361, %r1359;
	add.s32 	%r1363, %r1362, 1518500249;
	shf.l.wrap.b32 	%r1364, %r1338, %r1338, 30;
	xor.b32  	%r1365, %r1178, %r1174;
	xor.b32  	%r1366, %r1365, %r1190;
	xor.b32  	%r1367, %r1366, %r1330;
	shf.l.wrap.b32 	%r1368, %r1367, %r1367, 1;
	add.s32 	%r1369, %r1339, %r1368;
	xor.b32  	%r1370, %r1364, %r1351;
	and.b32  	%r1371, %r1370, %r1350;
	xor.b32  	%r1372, %r1371, %r1351;
	shf.l.wrap.b32 	%r1373, %r1363, %r1363, 5;
	add.s32 	%r1374, %r1369, %r1373;
	add.s32 	%r1375, %r1374, %r1372;
	add.s32 	%r1376, %r1375, 1518500249;
	shf.l.wrap.b32 	%r1377, %r1350, %r1350, 30;
	xor.b32  	%r1378, %r1180, %r1176;
	xor.b32  	%r1379, %r1378, %r1192;
	xor.b32  	%r1380, %r1379, %r1342;
	shf.l.wrap.b32 	%r1381, %r1380, %r1380, 1;
	add.s32 	%r1382, %r1351, %r1381;
	xor.b32  	%r1383, %r1363, %r1364;
	xor.b32  	%r1384, %r1383, %r1377;
	add.s32 	%r1385, %r1382, %r1384;
	shf.l.wrap.b32 	%r1386, %r1376, %r1376, 5;
	add.s32 	%r1387, %r1385, %r1386;
	add.s32 	%r1388, %r1387, 1859775393;
	shf.l.wrap.b32 	%r1389, %r1363, %r1363, 30;
	xor.b32  	%r1390, %r1182, %r1178;
	xor.b32  	%r1391, %r1390, %r1194;
	xor.b32  	%r1392, %r1391, %r1355;
	shf.l.wrap.b32 	%r1393, %r1392, %r1392, 1;
	add.s32 	%r1394, %r1364, %r1393;
	xor.b32  	%r1395, %r1376, %r1377;
	xor.b32  	%r1396, %r1395, %r1389;
	add.s32 	%r1397, %r1394, %r1396;
	shf.l.wrap.b32 	%r1398, %r1388, %r1388, 5;
	add.s32 	%r1399, %r1397, %r1398;
	add.s32 	%r1400, %r1399, 1859775393;
	shf.l.wrap.b32 	%r1401, %r1376, %r1376, 30;
	xor.b32  	%r1402, %r1184, %r1180;
	xor.b32  	%r1403, %r1402, %r1368;
	shf.l.wrap.b32 	%r1404, %r1403, %r1403, 1;
	add.s32 	%r1405, %r1377, %r1404;
	xor.b32  	%r1406, %r1388, %r1389;
	xor.b32  	%r1407, %r1406, %r1401;
	add.s32 	%r1408, %r1405, %r1407;
	shf.l.wrap.b32 	%r1409, %r1400, %r1400, 5;
	add.s32 	%r1410, %r1408, %r1409;
	add.s32 	%r1411, %r1410, 1859775393;
	shf.l.wrap.b32 	%r1412, %r1388, %r1388, 30;
	xor.b32  	%r1413, %r1182, %r1197;
	xor.b32  	%r1414, %r1413, %r1186;
	xor.b32  	%r1415, %r1414, %r1381;
	shf.l.wrap.b32 	%r1416, %r1415, %r1415, 1;
	add.s32 	%r1417, %r1389, %r1416;
	xor.b32  	%r1418, %r1400, %r1401;
	xor.b32  	%r1419, %r1418, %r1412;
	add.s32 	%r1420, %r1417, %r1419;
	shf.l.wrap.b32 	%r1421, %r1411, %r1411, 5;
	add.s32 	%r1422, %r1420, %r1421;
	add.s32 	%r1423, %r1422, 1859775393;
	shf.l.wrap.b32 	%r1424, %r1400, %r1400, 30;
	xor.b32  	%r1425, %r1188, %r1184;
	xor.b32  	%r1426, %r1425, %r1330;
	xor.b32  	%r1427, %r1426, %r1393;
	shf.l.wrap.b32 	%r1428, %r1427, %r1427, 1;
	add.s32 	%r1429, %r1401, %r1428;
	xor.b32  	%r1430, %r1411, %r1412;
	xor.b32  	%r1431, %r1430, %r1424;
	add.s32 	%r1432, %r1429, %r1431;
	shf.l.wrap.b32 	%r1433, %r1423, %r1423, 5;
	add.s32 	%r1434, %r1432, %r1433;
	add.s32 	%r1435, %r1434, 1859775393;
	shf.l.wrap.b32 	%r1436, %r1411, %r1411, 30;
	xor.b32  	%r1437, %r1190, %r1186;
	xor.b32  	%r1438, %r1437, %r1342;
	xor.b32  	%r1439, %r1438, %r1404;
	shf.l.wrap.b32 	%r1440, %r1439, %r1439, 1;
	add.s32 	%r1441, %r1412, %r1440;
	xor.b32  	%r1442, %r1423, %r1424;
	xor.b32  	%r1443, %r1442, %r1436;
	add.s32 	%r1444, %r1441, %r1443;
	shf.l.wrap.b32 	%r1445, %r1435, %r1435, 5;
	add.s32 	%r1446, %r1444, %r1445;
	add.s32 	%r1447, %r1446, 1859775393;
	shf.l.wrap.b32 	%r1448, %r1423, %r1423, 30;
	xor.b32  	%r1449, %r1192, %r1188;
	xor.b32  	%r1450, %r1449, %r1355;
	xor.b32  	%r1451, %r1450, %r1416;
	shf.l.wrap.b32 	%r1452, %r1451, %r1451, 1;
	add.s32 	%r1453, %r1424, %r1452;
	xor.b32  	%r1454, %r1435, %r1436;
	xor.b32  	%r1455, %r1454, %r1448;
	add.s32 	%r1456, %r1453, %r1455;
	shf.l.wrap.b32 	%r1457, %r1447, %r1447, 5;
	add.s32 	%r1458, %r1456, %r1457;
	add.s32 	%r1459, %r1458, 1859775393;
	shf.l.wrap.b32 	%r1460, %r1435, %r1435, 30;
	xor.b32  	%r1461, %r1194, %r1190;
	xor.b32  	%r1462, %r1461, %r1368;
	xor.b32  	%r1463, %r1462, %r1428;
	shf.l.wrap.b32 	%r1464, %r1463, %r1463, 1;
	add.s32 	%r1465, %r1436, %r1464;
	xor.b32  	%r1466, %r1447, %r1448;
	xor.b32  	%r1467, %r1466, %r1460;
	add.s32 	%r1468, %r1465, %r1467;
	shf.l.wrap.b32 	%r1469, %r1459, %r1459, 5;
	add.s32 	%r1470, %r1468, %r1469;
	add.s32 	%r1471, %r1470, 1859775393;
	shf.l.wrap.b32 	%r1472, %r1447, %r1447, 30;
	xor.b32  	%r1473, %r1381, %r1192;
	xor.b32  	%r1474, %r1473, %r1440;
	shf.l.wrap.b32 	%r1475, %r1474, %r1474, 1;
	add.s32 	%r1476, %r1448, %r1475;
	xor.b32  	%r1477, %r1459, %r1460;
	xor.b32  	%r1478, %r1477, %r1472;
	add.s32 	%r1479, %r1476, %r1478;
	shf.l.wrap.b32 	%r1480, %r1471, %r1471, 5;
	add.s32 	%r1481, %r1479, %r1480;
	add.s32 	%r1482, %r1481, 1859775393;
	shf.l.wrap.b32 	%r1483, %r1459, %r1459, 30;
	xor.b32  	%r1484, %r1194, %r1197;
	xor.b32  	%r1485, %r1484, %r1393;
	xor.b32  	%r1486, %r1485, %r1452;
	shf.l.wrap.b32 	%r1487, %r1486, %r1486, 1;
	add.s32 	%r1488, %r1460, %r1487;
	xor.b32  	%r1489, %r1471, %r1472;
	xor.b32  	%r1490, %r1489, %r1483;
	add.s32 	%r1491, %r1488, %r1490;
	shf.l.wrap.b32 	%r1492, %r1482, %r1482, 5;
	add.s32 	%r1493, %r1491, %r1492;
	add.s32 	%r1494, %r1493, 1859775393;
	shf.l.wrap.b32 	%r1495, %r1471, %r1471, 30;
	xor.b32  	%r1496, %r1404, %r1330;
	xor.b32  	%r1497, %r1496, %r1464;
	shf.l.wrap.b32 	%r1498, %r1497, %r1497, 1;
	add.s32 	%r1499, %r1472, %r1498;
	xor.b32  	%r1500, %r1482, %r1483;
	xor.b32  	%r1501, %r1500, %r1495;
	add.s32 	%r1502, %r1499, %r1501;
	shf.l.wrap.b32 	%r1503, %r1494, %r1494, 5;
	add.s32 	%r1504, %r1502, %r1503;
	add.s32 	%r1505, %r1504, 1859775393;
	shf.l.wrap.b32 	%r1506, %r1482, %r1482, 30;
	xor.b32  	%r1507, %r1342, %r1197;
	xor.b32  	%r1508, %r1507, %r1416;
	xor.b32  	%r1509, %r1508, %r1475;
	shf.l.wrap.b32 	%r1510, %r1509, %r1509, 1;
	add.s32 	%r1511, %r1483, %r1510;
	xor.b32  	%r1512, %r1494, %r1495;
	xor.b32  	%r1513, %r1512, %r1506;
	add.s32 	%r1514, %r1511, %r1513;
	shf.l.wrap.b32 	%r1515, %r1505, %r1505, 5;
	add.s32 	%r1516, %r1514, %r1515;
	add.s32 	%r1517, %r1516, 1859775393;
	shf.l.wrap.b32 	%r1518, %r1494, %r1494, 30;
	xor.b32  	%r1519, %r1355, %r1330;
	xor.b32  	%r1520, %r1519, %r1428;
	xor.b32  	%r1521, %r1520, %r1487;
	shf.l.wrap.b32 	%r1522, %r1521, %r1521, 1;
	add.s32 	%r1523, %r1495, %r1522;
	xor.b32  	%r1524, %r1505, %r1506;
	xor.b32  	%r1525, %r1524, %r1518;
	add.s32 	%r1526, %r1523, %r1525;
	shf.l.wrap.b32 	%r1527, %r1517, %r1517, 5;
	add.s32 	%r1528, %r1526, %r1527;
	add.s32 	%r1529, %r1528, 1859775393;
	shf.l.wrap.b32 	%r1530, %r1505, %r1505, 30;
	xor.b32  	%r1531, %r1368, %r1342;
	xor.b32  	%r1532, %r1531, %r1440;
	xor.b32  	%r1533, %r1532, %r1498;
	shf.l.wrap.b32 	%r1534, %r1533, %r1533, 1;
	add.s32 	%r1535, %r1506, %r1534;
	xor.b32  	%r1536, %r1517, %r1518;
	xor.b32  	%r1537, %r1536, %r1530;
	add.s32 	%r1538, %r1535, %r1537;
	shf.l.wrap.b32 	%r1539, %r1529, %r1529, 5;
	add.s32 	%r1540, %r1538, %r1539;
	add.s32 	%r1541, %r1540, 1859775393;
	shf.l.wrap.b32 	%r1542, %r1517, %r1517, 30;
	xor.b32  	%r1543, %r1381, %r1355;
	xor.b32  	%r1544, %r1543, %r1452;
	xor.b32  	%r1545, %r1544, %r1510;
	shf.l.wrap.b32 	%r1546, %r1545, %r1545, 1;
	add.s32 	%r1547, %r1518, %r1546;
	xor.b32  	%r1548, %r1529, %r1530;
	xor.b32  	%r1549, %r1548, %r1542;
	add.s32 	%r1550, %r1547, %r1549;
	shf.l.wrap.b32 	%r1551, %r1541, %r1541, 5;
	add.s32 	%r1552, %r1550, %r1551;
	add.s32 	%r1553, %r1552, 1859775393;
	shf.l.wrap.b32 	%r1554, %r1529, %r1529, 30;
	xor.b32  	%r1555, %r1393, %r1368;
	xor.b32  	%r1556, %r1555, %r1464;
	xor.b32  	%r1557, %r1556, %r1522;
	shf.l.wrap.b32 	%r1558, %r1557, %r1557, 1;
	add.s32 	%r1559, %r1530, %r1558;
	xor.b32  	%r1560, %r1541, %r1542;
	xor.b32  	%r1561, %r1560, %r1554;
	add.s32 	%r1562, %r1559, %r1561;
	shf.l.wrap.b32 	%r1563, %r1553, %r1553, 5;
	add.s32 	%r1564, %r1562, %r1563;
	add.s32 	%r1565, %r1564, 1859775393;
	shf.l.wrap.b32 	%r1566, %r1541, %r1541, 30;
	xor.b32  	%r1567, %r1404, %r1381;
	xor.b32  	%r1568, %r1567, %r1475;
	xor.b32  	%r1569, %r1568, %r1534;
	shf.l.wrap.b32 	%r1570, %r1569, %r1569, 1;
	add.s32 	%r1571, %r1542, %r1570;
	xor.b32  	%r1572, %r1553, %r1554;
	xor.b32  	%r1573, %r1572, %r1566;
	add.s32 	%r1574, %r1571, %r1573;
	shf.l.wrap.b32 	%r1575, %r1565, %r1565, 5;
	add.s32 	%r1576, %r1574, %r1575;
	add.s32 	%r1577, %r1576, 1859775393;
	shf.l.wrap.b32 	%r1578, %r1553, %r1553, 30;
	xor.b32  	%r1579, %r1416, %r1393;
	xor.b32  	%r1580, %r1579, %r1487;
	xor.b32  	%r1581, %r1580, %r1546;
	shf.l.wrap.b32 	%r1582, %r1581, %r1581, 1;
	add.s32 	%r1583, %r1554, %r1582;
	xor.b32  	%r1584, %r1565, %r1566;
	xor.b32  	%r1585, %r1584, %r1578;
	add.s32 	%r1586, %r1583, %r1585;
	shf.l.wrap.b32 	%r1587, %r1577, %r1577, 5;
	add.s32 	%r1588, %r1586, %r1587;
	add.s32 	%r1589, %r1588, 1859775393;
	shf.l.wrap.b32 	%r1590, %r1565, %r1565, 30;
	xor.b32  	%r1591, %r1428, %r1404;
	xor.b32  	%r1592, %r1591, %r1498;
	xor.b32  	%r1593, %r1592, %r1558;
	shf.l.wrap.b32 	%r1594, %r1593, %r1593, 1;
	add.s32 	%r1595, %r1566, %r1594;
	xor.b32  	%r1596, %r1577, %r1578;
	xor.b32  	%r1597, %r1596, %r1590;
	add.s32 	%r1598, %r1595, %r1597;
	shf.l.wrap.b32 	%r1599, %r1589, %r1589, 5;
	add.s32 	%r1600, %r1598, %r1599;
	add.s32 	%r1601, %r1600, 1859775393;
	shf.l.wrap.b32 	%r1602, %r1577, %r1577, 30;
	xor.b32  	%r1603, %r1440, %r1416;
	xor.b32  	%r1604, %r1603, %r1510;
	xor.b32  	%r1605, %r1604, %r1570;
	shf.l.wrap.b32 	%r1606, %r1605, %r1605, 1;
	add.s32 	%r1607, %r1578, %r1606;
	xor.b32  	%r1608, %r1589, %r1590;
	xor.b32  	%r1609, %r1608, %r1602;
	add.s32 	%r1610, %r1607, %r1609;
	shf.l.wrap.b32 	%r1611, %r1601, %r1601, 5;
	add.s32 	%r1612, %r1610, %r1611;
	add.s32 	%r1613, %r1612, 1859775393;
	shf.l.wrap.b32 	%r1614, %r1589, %r1589, 30;
	xor.b32  	%r1615, %r1452, %r1428;
	xor.b32  	%r1616, %r1615, %r1522;
	xor.b32  	%r1617, %r1616, %r1582;
	shf.l.wrap.b32 	%r1618, %r1617, %r1617, 1;
	add.s32 	%r1619, %r1590, %r1618;
	xor.b32  	%r1620, %r1601, %r1602;
	xor.b32  	%r1621, %r1614, %r1601;
	and.b32  	%r1622, %r1621, %r1620;
	xor.b32  	%r1623, %r1622, %r1601;
	shf.l.wrap.b32 	%r1624, %r1613, %r1613, 5;
	add.s32 	%r1625, %r1619, %r1624;
	add.s32 	%r1626, %r1625, %r1623;
	add.s32 	%r1627, %r1626, -1894007588;
	shf.l.wrap.b32 	%r1628, %r1601, %r1601, 30;
	xor.b32  	%r1629, %r1464, %r1440;
	xor.b32  	%r1630, %r1629, %r1534;
	xor.b32  	%r1631, %r1630, %r1594;
	shf.l.wrap.b32 	%r1632, %r1631, %r1631, 1;
	add.s32 	%r1633, %r1602, %r1632;
	xor.b32  	%r1634, %r1613, %r1614;
	xor.b32  	%r1635, %r1628, %r1613;
	and.b32  	%r1636, %r1635, %r1634;
	xor.b32  	%r1637, %r1636, %r1613;
	shf.l.wrap.b32 	%r1638, %r1627, %r1627, 5;
	add.s32 	%r1639, %r1633, %r1638;
	add.s32 	%r1640, %r1639, %r1637;
	add.s32 	%r1641, %r1640, -1894007588;
	shf.l.wrap.b32 	%r1642, %r1613, %r1613, 30;
	xor.b32  	%r1643, %r1475, %r1452;
	xor.b32  	%r1644, %r1643, %r1546;
	xor.b32  	%r1645, %r1644, %r1606;
	shf.l.wrap.b32 	%r1646, %r1645, %r1645, 1;
	add.s32 	%r1647, %r1614, %r1646;
	xor.b32  	%r1648, %r1627, %r1628;
	xor.b32  	%r1649, %r1642, %r1627;
	and.b32  	%r1650, %r1649, %r1648;
	xor.b32  	%r1651, %r1650, %r1627;
	shf.l.wrap.b32 	%r1652, %r1641, %r1641, 5;
	add.s32 	%r1653, %r1647, %r1652;
	add.s32 	%r1654, %r1653, %r1651;
	add.s32 	%r1655, %r1654, -1894007588;
	shf.l.wrap.b32 	%r1656, %r1627, %r1627, 30;
	xor.b32  	%r1657, %r1487, %r1464;
	xor.b32  	%r1658, %r1657, %r1558;
	xor.b32  	%r1659, %r1658, %r1618;
	shf.l.wrap.b32 	%r1660, %r1659, %r1659, 1;
	add.s32 	%r1661, %r1628, %r1660;
	xor.b32  	%r1662, %r1641, %r1642;
	xor.b32  	%r1663, %r1656, %r1641;
	and.b32  	%r1664, %r1663, %r1662;
	xor.b32  	%r1665, %r1664, %r1641;
	shf.l.wrap.b32 	%r1666, %r1655, %r1655, 5;
	add.s32 	%r1667, %r1661, %r1666;
	add.s32 	%r1668, %r1667, %r1665;
	add.s32 	%r1669, %r1668, -1894007588;
	shf.l.wrap.b32 	%r1670, %r1641, %r1641, 30;
	xor.b32  	%r1671, %r1498, %r1475;
	xor.b32  	%r1672, %r1671, %r1570;
	xor.b32  	%r1673, %r1672, %r1632;
	shf.l.wrap.b32 	%r1674, %r1673, %r1673, 1;
	add.s32 	%r1675, %r1642, %r1674;
	xor.b32  	%r1676, %r1655, %r1656;
	xor.b32  	%r1677, %r1670, %r1655;
	and.b32  	%r1678, %r1677, %r1676;
	xor.b32  	%r1679, %r1678, %r1655;
	shf.l.wrap.b32 	%r1680, %r1669, %r1669, 5;
	add.s32 	%r1681, %r1675, %r1680;
	add.s32 	%r1682, %r1681, %r1679;
	add.s32 	%r1683, %r1682, -1894007588;
	shf.l.wrap.b32 	%r1684, %r1655, %r1655, 30;
	xor.b32  	%r1685, %r1510, %r1487;
	xor.b32  	%r1686, %r1685, %r1582;
	xor.b32  	%r1687, %r1686, %r1646;
	shf.l.wrap.b32 	%r1688, %r1687, %r1687, 1;
	add.s32 	%r1689, %r1656, %r1688;
	xor.b32  	%r1690, %r1669, %r1670;
	xor.b32  	%r1691, %r1684, %r1669;
	and.b32  	%r1692, %r1691, %r1690;
	xor.b32  	%r1693, %r1692, %r1669;
	shf.l.wrap.b32 	%r1694, %r1683, %r1683, 5;
	add.s32 	%r1695, %r1689, %r1694;
	add.s32 	%r1696, %r1695, %r1693;
	add.s32 	%r1697, %r1696, -1894007588;
	shf.l.wrap.b32 	%r1698, %r1669, %r1669, 30;
	xor.b32  	%r1699, %r1522, %r1498;
	xor.b32  	%r1700, %r1699, %r1594;
	xor.b32  	%r1701, %r1700, %r1660;
	shf.l.wrap.b32 	%r1702, %r1701, %r1701, 1;
	add.s32 	%r1703, %r1670, %r1702;
	xor.b32  	%r1704, %r1683, %r1684;
	xor.b32  	%r1705, %r1698, %r1683;
	and.b32  	%r1706, %r1705, %r1704;
	xor.b32  	%r1707, %r1706, %r1683;
	shf.l.wrap.b32 	%r1708, %r1697, %r1697, 5;
	add.s32 	%r1709, %r1703, %r1708;
	add.s32 	%r1710, %r1709, %r1707;
	add.s32 	%r1711, %r1710, -1894007588;
	shf.l.wrap.b32 	%r1712, %r1683, %r1683, 30;
	xor.b32  	%r1713, %r1534, %r1510;
	xor.b32  	%r1714, %r1713, %r1606;
	xor.b32  	%r1715, %r1714, %r1674;
	shf.l.wrap.b32 	%r1716, %r1715, %r1715, 1;
	add.s32 	%r1717, %r1684, %r1716;
	xor.b32  	%r1718, %r1697, %r1698;
	xor.b32  	%r1719, %r1712, %r1697;
	and.b32  	%r1720, %r1719, %r1718;
	xor.b32  	%r1721, %r1720, %r1697;
	shf.l.wrap.b32 	%r1722, %r1711, %r1711, 5;
	add.s32 	%r1723, %r1717, %r1722;
	add.s32 	%r1724, %r1723, %r1721;
	add.s32 	%r1725, %r1724, -1894007588;
	shf.l.wrap.b32 	%r1726, %r1697, %r1697, 30;
	xor.b32  	%r1727, %r1546, %r1522;
	xor.b32  	%r1728, %r1727, %r1618;
	xor.b32  	%r1729, %r1728, %r1688;
	shf.l.wrap.b32 	%r1730, %r1729, %r1729, 1;
	add.s32 	%r1731, %r1698, %r1730;
	xor.b32  	%r1732, %r1711, %r1712;
	xor.b32  	%r1733, %r1726, %r1711;
	and.b32  	%r1734, %r1733, %r1732;
	xor.b32  	%r1735, %r1734, %r1711;
	shf.l.wrap.b32 	%r1736, %r1725, %r1725, 5;
	add.s32 	%r1737, %r1731, %r1736;
	add.s32 	%r1738, %r1737, %r1735;
	add.s32 	%r1739, %r1738, -1894007588;
	shf.l.wrap.b32 	%r1740, %r1711, %r1711, 30;
	xor.b32  	%r1741, %r1558, %r1534;
	xor.b32  	%r1742, %r1741, %r1632;
	xor.b32  	%r1743, %r1742, %r1702;
	shf.l.wrap.b32 	%r1744, %r1743, %r1743, 1;
	add.s32 	%r1745, %r1712, %r1744;
	xor.b32  	%r1746, %r1725, %r1726;
	xor.b32  	%r1747, %r1740, %r1725;
	and.b32  	%r1748, %r1747, %r1746;
	xor.b32  	%r1749, %r1748, %r1725;
	shf.l.wrap.b32 	%r1750, %r1739, %r1739, 5;
	add.s32 	%r1751, %r1745, %r1750;
	add.s32 	%r1752, %r1751, %r1749;
	add.s32 	%r1753, %r1752, -1894007588;
	shf.l.wrap.b32 	%r1754, %r1725, %r1725, 30;
	xor.b32  	%r1755, %r1570, %r1546;
	xor.b32  	%r1756, %r1755, %r1646;
	xor.b32  	%r1757, %r1756, %r1716;
	shf.l.wrap.b32 	%r1758, %r1757, %r1757, 1;
	add.s32 	%r1759, %r1726, %r1758;
	xor.b32  	%r1760, %r1739, %r1740;
	xor.b32  	%r1761, %r1754, %r1739;
	and.b32  	%r1762, %r1761, %r1760;
	xor.b32  	%r1763, %r1762, %r1739;
	shf.l.wrap.b32 	%r1764, %r1753, %r1753, 5;
	add.s32 	%r1765, %r1759, %r1764;
	add.s32 	%r1766, %r1765, %r1763;
	add.s32 	%r1767, %r1766, -1894007588;
	shf.l.wrap.b32 	%r1768, %r1739, %r1739, 30;
	xor.b32  	%r1769, %r1582, %r1558;
	xor.b32  	%r1770, %r1769, %r1660;
	xor.b32  	%r1771, %r1770, %r1730;
	shf.l.wrap.b32 	%r1772, %r1771, %r1771, 1;
	add.s32 	%r1773, %r1740, %r1772;
	xor.b32  	%r1774, %r1753, %r1754;
	xor.b32  	%r1775, %r1768, %r1753;
	and.b32  	%r1776, %r1775, %r1774;
	xor.b32  	%r1777, %r1776, %r1753;
	shf.l.wrap.b32 	%r1778, %r1767, %r1767, 5;
	add.s32 	%r1779, %r1773, %r1778;
	add.s32 	%r1780, %r1779, %r1777;
	add.s32 	%r1781, %r1780, -1894007588;
	shf.l.wrap.b32 	%r1782, %r1753, %r1753, 30;
	xor.b32  	%r1783, %r1594, %r1570;
	xor.b32  	%r1784, %r1783, %r1674;
	xor.b32  	%r1785, %r1784, %r1744;
	shf.l.wrap.b32 	%r1786, %r1785, %r1785, 1;
	add.s32 	%r1787, %r1754, %r1786;
	xor.b32  	%r1788, %r1767, %r1768;
	xor.b32  	%r1789, %r1782, %r1767;
	and.b32  	%r1790, %r1789, %r1788;
	xor.b32  	%r1791, %r1790, %r1767;
	shf.l.wrap.b32 	%r1792, %r1781, %r1781, 5;
	add.s32 	%r1793, %r1787, %r1792;
	add.s32 	%r1794, %r1793, %r1791;
	add.s32 	%r1795, %r1794, -1894007588;
	shf.l.wrap.b32 	%r1796, %r1767, %r1767, 30;
	xor.b32  	%r1797, %r1606, %r1582;
	xor.b32  	%r1798, %r1797, %r1688;
	xor.b32  	%r1799, %r1798, %r1758;
	shf.l.wrap.b32 	%r1800, %r1799, %r1799, 1;
	add.s32 	%r1801, %r1768, %r1800;
	xor.b32  	%r1802, %r1781, %r1782;
	xor.b32  	%r1803, %r1796, %r1781;
	and.b32  	%r1804, %r1803, %r1802;
	xor.b32  	%r1805, %r1804, %r1781;
	shf.l.wrap.b32 	%r1806, %r1795, %r1795, 5;
	add.s32 	%r1807, %r1801, %r1806;
	add.s32 	%r1808, %r1807, %r1805;
	add.s32 	%r1809, %r1808, -1894007588;
	shf.l.wrap.b32 	%r1810, %r1781, %r1781, 30;
	xor.b32  	%r1811, %r1618, %r1594;
	xor.b32  	%r1812, %r1811, %r1702;
	xor.b32  	%r1813, %r1812, %r1772;
	shf.l.wrap.b32 	%r1814, %r1813, %r1813, 1;
	add.s32 	%r1815, %r1782, %r1814;
	xor.b32  	%r1816, %r1795, %r1796;
	xor.b32  	%r1817, %r1810, %r1795;
	and.b32  	%r1818, %r1817, %r1816;
	xor.b32  	%r1819, %r1818, %r1795;
	shf.l.wrap.b32 	%r1820, %r1809, %r1809, 5;
	add.s32 	%r1821, %r1815, %r1820;
	add.s32 	%r1822, %r1821, %r1819;
	add.s32 	%r1823, %r1822, -1894007588;
	shf.l.wrap.b32 	%r1824, %r1795, %r1795, 30;
	xor.b32  	%r1825, %r1632, %r1606;
	xor.b32  	%r1826, %r1825, %r1716;
	xor.b32  	%r1827, %r1826, %r1786;
	shf.l.wrap.b32 	%r1828, %r1827, %r1827, 1;
	add.s32 	%r1829, %r1796, %r1828;
	xor.b32  	%r1830, %r1809, %r1810;
	xor.b32  	%r1831, %r1824, %r1809;
	and.b32  	%r1832, %r1831, %r1830;
	xor.b32  	%r1833, %r1832, %r1809;
	shf.l.wrap.b32 	%r1834, %r1823, %r1823, 5;
	add.s32 	%r1835, %r1829, %r1834;
	add.s32 	%r1836, %r1835, %r1833;
	add.s32 	%r1837, %r1836, -1894007588;
	shf.l.wrap.b32 	%r1838, %r1809, %r1809, 30;
	xor.b32  	%r1839, %r1646, %r1618;
	xor.b32  	%r1840, %r1839, %r1730;
	xor.b32  	%r1841, %r1840, %r1800;
	shf.l.wrap.b32 	%r1842, %r1841, %r1841, 1;
	add.s32 	%r1843, %r1810, %r1842;
	xor.b32  	%r1844, %r1823, %r1824;
	xor.b32  	%r1845, %r1838, %r1823;
	and.b32  	%r1846, %r1845, %r1844;
	xor.b32  	%r1847, %r1846, %r1823;
	shf.l.wrap.b32 	%r1848, %r1837, %r1837, 5;
	add.s32 	%r1849, %r1843, %r1848;
	add.s32 	%r1850, %r1849, %r1847;
	add.s32 	%r1851, %r1850, -1894007588;
	shf.l.wrap.b32 	%r1852, %r1823, %r1823, 30;
	xor.b32  	%r1853, %r1660, %r1632;
	xor.b32  	%r1854, %r1853, %r1744;
	xor.b32  	%r1855, %r1854, %r1814;
	shf.l.wrap.b32 	%r1856, %r1855, %r1855, 1;
	add.s32 	%r1857, %r1824, %r1856;
	xor.b32  	%r1858, %r1837, %r1838;
	xor.b32  	%r1859, %r1852, %r1837;
	and.b32  	%r1860, %r1859, %r1858;
	xor.b32  	%r1861, %r1860, %r1837;
	shf.l.wrap.b32 	%r1862, %r1851, %r1851, 5;
	add.s32 	%r1863, %r1857, %r1862;
	add.s32 	%r1864, %r1863, %r1861;
	add.s32 	%r1865, %r1864, -1894007588;
	shf.l.wrap.b32 	%r1866, %r1837, %r1837, 30;
	xor.b32  	%r1867, %r1674, %r1646;
	xor.b32  	%r1868, %r1867, %r1758;
	xor.b32  	%r1869, %r1868, %r1828;
	shf.l.wrap.b32 	%r1870, %r1869, %r1869, 1;
	add.s32 	%r1871, %r1838, %r1870;
	xor.b32  	%r1872, %r1851, %r1852;
	xor.b32  	%r1873, %r1866, %r1851;
	and.b32  	%r1874, %r1873, %r1872;
	xor.b32  	%r1875, %r1874, %r1851;
	shf.l.wrap.b32 	%r1876, %r1865, %r1865, 5;
	add.s32 	%r1877, %r1871, %r1876;
	add.s32 	%r1878, %r1877, %r1875;
	add.s32 	%r1879, %r1878, -1894007588;
	shf.l.wrap.b32 	%r1880, %r1851, %r1851, 30;
	xor.b32  	%r1881, %r1688, %r1660;
	xor.b32  	%r1882, %r1881, %r1772;
	xor.b32  	%r1883, %r1882, %r1842;
	shf.l.wrap.b32 	%r1884, %r1883, %r1883, 1;
	add.s32 	%r1885, %r1852, %r1884;
	xor.b32  	%r1886, %r1865, %r1866;
	xor.b32  	%r1887, %r1880, %r1865;
	and.b32  	%r1888, %r1887, %r1886;
	xor.b32  	%r1889, %r1888, %r1865;
	shf.l.wrap.b32 	%r1890, %r1879, %r1879, 5;
	add.s32 	%r1891, %r1885, %r1890;
	add.s32 	%r1892, %r1891, %r1889;
	add.s32 	%r1893, %r1892, -1894007588;
	shf.l.wrap.b32 	%r1894, %r1865, %r1865, 30;
	xor.b32  	%r1895, %r1702, %r1674;
	xor.b32  	%r1896, %r1895, %r1786;
	xor.b32  	%r1897, %r1896, %r1856;
	shf.l.wrap.b32 	%r1898, %r1897, %r1897, 1;
	add.s32 	%r1899, %r1866, %r1898;
	xor.b32  	%r1900, %r1879, %r1880;
	xor.b32  	%r1901, %r1900, %r1894;
	add.s32 	%r1902, %r1899, %r1901;
	shf.l.wrap.b32 	%r1903, %r1893, %r1893, 5;
	add.s32 	%r1904, %r1902, %r1903;
	add.s32 	%r1905, %r1904, -899497514;
	shf.l.wrap.b32 	%r1906, %r1879, %r1879, 30;
	xor.b32  	%r1907, %r1716, %r1688;
	xor.b32  	%r1908, %r1907, %r1800;
	xor.b32  	%r1909, %r1908, %r1870;
	shf.l.wrap.b32 	%r1910, %r1909, %r1909, 1;
	add.s32 	%r1911, %r1880, %r1910;
	xor.b32  	%r1912, %r1893, %r1894;
	xor.b32  	%r1913, %r1912, %r1906;
	add.s32 	%r1914, %r1911, %r1913;
	shf.l.wrap.b32 	%r1915, %r1905, %r1905, 5;
	add.s32 	%r1916, %r1914, %r1915;
	add.s32 	%r1917, %r1916, -899497514;
	shf.l.wrap.b32 	%r1918, %r1893, %r1893, 30;
	xor.b32  	%r1919, %r1730, %r1702;
	xor.b32  	%r1920, %r1919, %r1814;
	xor.b32  	%r1921, %r1920, %r1884;
	shf.l.wrap.b32 	%r1922, %r1921, %r1921, 1;
	add.s32 	%r1923, %r1894, %r1922;
	xor.b32  	%r1924, %r1905, %r1906;
	xor.b32  	%r1925, %r1924, %r1918;
	add.s32 	%r1926, %r1923, %r1925;
	shf.l.wrap.b32 	%r1927, %r1917, %r1917, 5;
	add.s32 	%r1928, %r1926, %r1927;
	add.s32 	%r1929, %r1928, -899497514;
	shf.l.wrap.b32 	%r1930, %r1905, %r1905, 30;
	xor.b32  	%r1931, %r1744, %r1716;
	xor.b32  	%r1932, %r1931, %r1828;
	xor.b32  	%r1933, %r1932, %r1898;
	shf.l.wrap.b32 	%r1934, %r1933, %r1933, 1;
	add.s32 	%r1935, %r1906, %r1934;
	xor.b32  	%r1936, %r1917, %r1918;
	xor.b32  	%r1937, %r1936, %r1930;
	add.s32 	%r1938, %r1935, %r1937;
	shf.l.wrap.b32 	%r1939, %r1929, %r1929, 5;
	add.s32 	%r1940, %r1938, %r1939;
	add.s32 	%r1941, %r1940, -899497514;
	shf.l.wrap.b32 	%r1942, %r1917, %r1917, 30;
	xor.b32  	%r1943, %r1758, %r1730;
	xor.b32  	%r1944, %r1943, %r1842;
	xor.b32  	%r1945, %r1944, %r1910;
	shf.l.wrap.b32 	%r1946, %r1945, %r1945, 1;
	add.s32 	%r1947, %r1918, %r1946;
	xor.b32  	%r1948, %r1929, %r1930;
	xor.b32  	%r1949, %r1948, %r1942;
	add.s32 	%r1950, %r1947, %r1949;
	shf.l.wrap.b32 	%r1951, %r1941, %r1941, 5;
	add.s32 	%r1952, %r1950, %r1951;
	add.s32 	%r1953, %r1952, -899497514;
	shf.l.wrap.b32 	%r1954, %r1929, %r1929, 30;
	xor.b32  	%r1955, %r1772, %r1744;
	xor.b32  	%r1956, %r1955, %r1856;
	xor.b32  	%r1957, %r1956, %r1922;
	shf.l.wrap.b32 	%r1958, %r1957, %r1957, 1;
	add.s32 	%r1959, %r1930, %r1958;
	xor.b32  	%r1960, %r1941, %r1942;
	xor.b32  	%r1961, %r1960, %r1954;
	add.s32 	%r1962, %r1959, %r1961;
	shf.l.wrap.b32 	%r1963, %r1953, %r1953, 5;
	add.s32 	%r1964, %r1962, %r1963;
	add.s32 	%r1965, %r1964, -899497514;
	shf.l.wrap.b32 	%r1966, %r1941, %r1941, 30;
	xor.b32  	%r1967, %r1786, %r1758;
	xor.b32  	%r1968, %r1967, %r1870;
	xor.b32  	%r1969, %r1968, %r1934;
	shf.l.wrap.b32 	%r1970, %r1969, %r1969, 1;
	add.s32 	%r1971, %r1942, %r1970;
	xor.b32  	%r1972, %r1953, %r1954;
	xor.b32  	%r1973, %r1972, %r1966;
	add.s32 	%r1974, %r1971, %r1973;
	shf.l.wrap.b32 	%r1975, %r1965, %r1965, 5;
	add.s32 	%r1976, %r1974, %r1975;
	add.s32 	%r1977, %r1976, -899497514;
	shf.l.wrap.b32 	%r1978, %r1953, %r1953, 30;
	xor.b32  	%r1979, %r1800, %r1772;
	xor.b32  	%r1980, %r1979, %r1884;
	xor.b32  	%r1981, %r1980, %r1946;
	shf.l.wrap.b32 	%r1982, %r1981, %r1981, 1;
	add.s32 	%r1983, %r1954, %r1982;
	xor.b32  	%r1984, %r1965, %r1966;
	xor.b32  	%r1985, %r1984, %r1978;
	add.s32 	%r1986, %r1983, %r1985;
	shf.l.wrap.b32 	%r1987, %r1977, %r1977, 5;
	add.s32 	%r1988, %r1986, %r1987;
	add.s32 	%r1989, %r1988, -899497514;
	shf.l.wrap.b32 	%r1990, %r1965, %r1965, 30;
	xor.b32  	%r1991, %r1814, %r1786;
	xor.b32  	%r1992, %r1991, %r1898;
	xor.b32  	%r1993, %r1992, %r1958;
	shf.l.wrap.b32 	%r1994, %r1993, %r1993, 1;
	add.s32 	%r1995, %r1966, %r1994;
	xor.b32  	%r1996, %r1977, %r1978;
	xor.b32  	%r1997, %r1996, %r1990;
	add.s32 	%r1998, %r1995, %r1997;
	shf.l.wrap.b32 	%r1999, %r1989, %r1989, 5;
	add.s32 	%r2000, %r1998, %r1999;
	add.s32 	%r2001, %r2000, -899497514;
	shf.l.wrap.b32 	%r2002, %r1977, %r1977, 30;
	xor.b32  	%r2003, %r1828, %r1800;
	xor.b32  	%r2004, %r2003, %r1910;
	xor.b32  	%r2005, %r2004, %r1970;
	shf.l.wrap.b32 	%r2006, %r2005, %r2005, 1;
	add.s32 	%r2007, %r1978, %r2006;
	xor.b32  	%r2008, %r1989, %r1990;
	xor.b32  	%r2009, %r2008, %r2002;
	add.s32 	%r2010, %r2007, %r2009;
	shf.l.wrap.b32 	%r2011, %r2001, %r2001, 5;
	add.s32 	%r2012, %r2010, %r2011;
	add.s32 	%r2013, %r2012, -899497514;
	shf.l.wrap.b32 	%r2014, %r1989, %r1989, 30;
	xor.b32  	%r2015, %r1842, %r1814;
	xor.b32  	%r2016, %r2015, %r1922;
	xor.b32  	%r2017, %r2016, %r1982;
	shf.l.wrap.b32 	%r2018, %r2017, %r2017, 1;
	add.s32 	%r2019, %r1990, %r2018;
	xor.b32  	%r2020, %r2001, %r2002;
	xor.b32  	%r2021, %r2020, %r2014;
	add.s32 	%r2022, %r2019, %r2021;
	shf.l.wrap.b32 	%r2023, %r2013, %r2013, 5;
	add.s32 	%r2024, %r2022, %r2023;
	add.s32 	%r2025, %r2024, -899497514;
	shf.l.wrap.b32 	%r2026, %r2001, %r2001, 30;
	xor.b32  	%r2027, %r1856, %r1828;
	xor.b32  	%r2028, %r2027, %r1934;
	xor.b32  	%r2029, %r2028, %r1994;
	shf.l.wrap.b32 	%r2030, %r2029, %r2029, 1;
	add.s32 	%r2031, %r2002, %r2030;
	xor.b32  	%r2032, %r2013, %r2014;
	xor.b32  	%r2033, %r2032, %r2026;
	add.s32 	%r2034, %r2031, %r2033;
	shf.l.wrap.b32 	%r2035, %r2025, %r2025, 5;
	add.s32 	%r2036, %r2034, %r2035;
	add.s32 	%r2037, %r2036, -899497514;
	shf.l.wrap.b32 	%r2038, %r2013, %r2013, 30;
	xor.b32  	%r2039, %r1870, %r1842;
	xor.b32  	%r2040, %r2039, %r1946;
	xor.b32  	%r2041, %r2040, %r2006;
	shf.l.wrap.b32 	%r2042, %r2041, %r2041, 1;
	add.s32 	%r2043, %r2014, %r2042;
	xor.b32  	%r2044, %r2025, %r2026;
	xor.b32  	%r2045, %r2044, %r2038;
	add.s32 	%r2046, %r2043, %r2045;
	shf.l.wrap.b32 	%r2047, %r2037, %r2037, 5;
	add.s32 	%r2048, %r2046, %r2047;
	add.s32 	%r2049, %r2048, -899497514;
	shf.l.wrap.b32 	%r2050, %r2025, %r2025, 30;
	xor.b32  	%r2051, %r1884, %r1856;
	xor.b32  	%r2052, %r2051, %r1958;
	xor.b32  	%r2053, %r2052, %r2018;
	shf.l.wrap.b32 	%r2054, %r2053, %r2053, 1;
	add.s32 	%r2055, %r2026, %r2054;
	xor.b32  	%r2056, %r2037, %r2038;
	xor.b32  	%r2057, %r2056, %r2050;
	add.s32 	%r2058, %r2055, %r2057;
	shf.l.wrap.b32 	%r2059, %r2049, %r2049, 5;
	add.s32 	%r2060, %r2058, %r2059;
	add.s32 	%r2061, %r2060, -899497514;
	shf.l.wrap.b32 	%r2062, %r2037, %r2037, 30;
	xor.b32  	%r2063, %r1898, %r1870;
	xor.b32  	%r2064, %r2063, %r1970;
	xor.b32  	%r2065, %r2064, %r2030;
	shf.l.wrap.b32 	%r2066, %r2065, %r2065, 1;
	add.s32 	%r2067, %r2038, %r2066;
	xor.b32  	%r2068, %r2049, %r2050;
	xor.b32  	%r2069, %r2068, %r2062;
	add.s32 	%r2070, %r2067, %r2069;
	shf.l.wrap.b32 	%r2071, %r2061, %r2061, 5;
	add.s32 	%r2072, %r2070, %r2071;
	add.s32 	%r2073, %r2072, -899497514;
	shf.l.wrap.b32 	%r2074, %r2049, %r2049, 30;
	xor.b32  	%r2075, %r1910, %r1884;
	xor.b32  	%r2076, %r2075, %r1982;
	xor.b32  	%r2077, %r2076, %r2042;
	shf.l.wrap.b32 	%r2078, %r2077, %r2077, 1;
	add.s32 	%r2079, %r2050, %r2078;
	xor.b32  	%r2080, %r2061, %r2062;
	xor.b32  	%r2081, %r2080, %r2074;
	add.s32 	%r2082, %r2079, %r2081;
	shf.l.wrap.b32 	%r2083, %r2073, %r2073, 5;
	add.s32 	%r2084, %r2082, %r2083;
	add.s32 	%r2085, %r2084, -899497514;
	shf.l.wrap.b32 	%r2086, %r2061, %r2061, 30;
	xor.b32  	%r2087, %r1922, %r1898;
	xor.b32  	%r2088, %r2087, %r1994;
	xor.b32  	%r2089, %r2088, %r2054;
	shf.l.wrap.b32 	%r2090, %r2089, %r2089, 1;
	add.s32 	%r2091, %r2062, %r2090;
	xor.b32  	%r2092, %r2073, %r2074;
	xor.b32  	%r2093, %r2092, %r2086;
	add.s32 	%r2094, %r2091, %r2093;
	shf.l.wrap.b32 	%r2095, %r2085, %r2085, 5;
	add.s32 	%r2096, %r2094, %r2095;
	add.s32 	%r2097, %r2096, -899497514;
	shf.l.wrap.b32 	%r2098, %r2073, %r2073, 30;
	xor.b32  	%r2099, %r1934, %r1910;
	xor.b32  	%r2100, %r2099, %r2006;
	xor.b32  	%r2101, %r2100, %r2066;
	shf.l.wrap.b32 	%r2102, %r2101, %r2101, 1;
	add.s32 	%r2103, %r2074, %r2102;
	xor.b32  	%r2104, %r2085, %r2086;
	xor.b32  	%r2105, %r2104, %r2098;
	add.s32 	%r2106, %r2103, %r2105;
	shf.l.wrap.b32 	%r2107, %r2097, %r2097, 5;
	add.s32 	%r2108, %r2106, %r2107;
	add.s32 	%r2109, %r2108, -899497514;
	shf.l.wrap.b32 	%r2110, %r2085, %r2085, 30;
	xor.b32  	%r2111, %r1946, %r1922;
	xor.b32  	%r2112, %r2111, %r2018;
	xor.b32  	%r2113, %r2112, %r2078;
	shf.l.wrap.b32 	%r2114, %r2113, %r2113, 1;
	xor.b32  	%r2115, %r2097, %r2098;
	xor.b32  	%r2116, %r2115, %r2110;
	shf.l.wrap.b32 	%r2117, %r2109, %r2109, 5;
	shf.l.wrap.b32 	%r2118, %r2097, %r2097, 30;
	shf.l.wrap.b32 	%r2119, %r2109, %r2109, 30;
	add.s32 	%r2120, %r2086, %r2114;
	add.s32 	%r2121, %r2120, %r2116;
	add.s32 	%r2122, %r2121, %r2117;
	add.s32 	%r2123, %r2122, 27999;
	add.s32 	%r2124, %r2119, -1732584194;
	add.s32 	%r2125, %r2118, 271733878;
	and.b32  	%r2126, %r2123, 65535;
	setp.eq.s32	%p73, %r2125, %r14;
	add.s32 	%r2127, %r2110, -1009589776;
	setp.eq.s32	%p74, %r2127, %r15;
	and.pred  	%p75, %p73, %p74;
	setp.eq.s32	%p76, %r2124, %r16;
	and.pred  	%p77, %p75, %p76;
	setp.eq.s32	%p78, %r2126, %r17;
	and.pred  	%p79, %p77, %p78;
	@!%p79 bra 	BB6_117;
	bra.uni 	BB6_113;

BB6_113:
	atom.global.add.u32 	%r2128, [%rd2], 1;
	setp.ne.s32	%p80, %r2128, 0;
	@%p80 bra 	BB6_117;

	ld.param.u32 	%r2138, [m15500_s04_param_31];
	atom.global.add.u32 	%r219, [%rd10], 1;
	setp.lt.u32	%p81, %r219, %r2138;
	@%p81 bra 	BB6_116;
	bra.uni 	BB6_115;

BB6_116:
	ld.param.u64 	%rd24, [m15500_s04_param_14];
	ld.param.u32 	%r2140, [m15500_s04_param_32];
	ld.param.u32 	%r2139, [m15500_s04_param_27];
	mul.wide.u32 	%rd21, %r219, 32;
	add.s64 	%rd22, %rd24, %rd21;
	mov.u32 	%r2130, 0;
	st.global.v2.u32 	[%rd22], {%r2139, %r2130};
	st.global.u32 	[%rd22+8], %r2140;
	st.global.u32 	[%rd22+24], %r2141;
	st.global.u64 	[%rd22+16], %rd3;
	bra.uni 	BB6_117;

BB6_115:
	atom.global.add.u32 	%r2129, [%rd10], -1;

BB6_117:
	ld.param.u32 	%r2131, [m15500_s04_param_30];
	add.s32 	%r2141, %r2141, 1;
	setp.lt.u32	%p82, %r2141, %r2131;
	@%p82 bra 	BB6_3;

BB6_118:
	ret;
}

	// .globl	m15500_s08
.entry m15500_s08(
	.param .u64 .ptr .global .align 4 m15500_s08_param_0,
	.param .u64 .ptr .global .align 4 m15500_s08_param_1,
	.param .u64 .ptr .global .align 4 m15500_s08_param_2,
	.param .u64 .ptr .global .align 4 m15500_s08_param_3,
	.param .u64 .ptr .global .align 1 m15500_s08_param_4,
	.param .u64 .ptr .global .align 1 m15500_s08_param_5,
	.param .u64 .ptr .global .align 4 m15500_s08_param_6,
	.param .u64 .ptr .global .align 4 m15500_s08_param_7,
	.param .u64 .ptr .global .align 4 m15500_s08_param_8,
	.param .u64 .ptr .global .align 4 m15500_s08_param_9,
	.param .u64 .ptr .global .align 4 m15500_s08_param_10,
	.param .u64 .ptr .global .align 4 m15500_s08_param_11,
	.param .u64 .ptr .global .align 4 m15500_s08_param_12,
	.param .u64 .ptr .global .align 4 m15500_s08_param_13,
	.param .u64 .ptr .global .align 8 m15500_s08_param_14,
	.param .u64 .ptr .global .align 4 m15500_s08_param_15,
	.param .u64 .ptr .global .align 4 m15500_s08_param_16,
	.param .u64 .ptr .global .align 4 m15500_s08_param_17,
	.param .u64 .ptr .global .align 1 m15500_s08_param_18,
	.param .u64 .ptr .global .align 4 m15500_s08_param_19,
	.param .u64 .ptr .global .align 4 m15500_s08_param_20,
	.param .u64 .ptr .global .align 4 m15500_s08_param_21,
	.param .u64 .ptr .global .align 4 m15500_s08_param_22,
	.param .u64 .ptr .global .align 4 m15500_s08_param_23,
	.param .u32 m15500_s08_param_24,
	.param .u32 m15500_s08_param_25,
	.param .u32 m15500_s08_param_26,
	.param .u32 m15500_s08_param_27,
	.param .u32 m15500_s08_param_28,
	.param .u32 m15500_s08_param_29,
	.param .u32 m15500_s08_param_30,
	.param .u32 m15500_s08_param_31,
	.param .u32 m15500_s08_param_32,
	.param .u32 m15500_s08_param_33,
	.param .u64 m15500_s08_param_34
)
{



	ret;
}

	// .globl	m15500_s16
.entry m15500_s16(
	.param .u64 .ptr .global .align 4 m15500_s16_param_0,
	.param .u64 .ptr .global .align 4 m15500_s16_param_1,
	.param .u64 .ptr .global .align 4 m15500_s16_param_2,
	.param .u64 .ptr .global .align 4 m15500_s16_param_3,
	.param .u64 .ptr .global .align 1 m15500_s16_param_4,
	.param .u64 .ptr .global .align 1 m15500_s16_param_5,
	.param .u64 .ptr .global .align 4 m15500_s16_param_6,
	.param .u64 .ptr .global .align 4 m15500_s16_param_7,
	.param .u64 .ptr .global .align 4 m15500_s16_param_8,
	.param .u64 .ptr .global .align 4 m15500_s16_param_9,
	.param .u64 .ptr .global .align 4 m15500_s16_param_10,
	.param .u64 .ptr .global .align 4 m15500_s16_param_11,
	.param .u64 .ptr .global .align 4 m15500_s16_param_12,
	.param .u64 .ptr .global .align 4 m15500_s16_param_13,
	.param .u64 .ptr .global .align 8 m15500_s16_param_14,
	.param .u64 .ptr .global .align 4 m15500_s16_param_15,
	.param .u64 .ptr .global .align 4 m15500_s16_param_16,
	.param .u64 .ptr .global .align 4 m15500_s16_param_17,
	.param .u64 .ptr .global .align 1 m15500_s16_param_18,
	.param .u64 .ptr .global .align 4 m15500_s16_param_19,
	.param .u64 .ptr .global .align 4 m15500_s16_param_20,
	.param .u64 .ptr .global .align 4 m15500_s16_param_21,
	.param .u64 .ptr .global .align 4 m15500_s16_param_22,
	.param .u64 .ptr .global .align 4 m15500_s16_param_23,
	.param .u32 m15500_s16_param_24,
	.param .u32 m15500_s16_param_25,
	.param .u32 m15500_s16_param_26,
	.param .u32 m15500_s16_param_27,
	.param .u32 m15500_s16_param_28,
	.param .u32 m15500_s16_param_29,
	.param .u32 m15500_s16_param_30,
	.param .u32 m15500_s16_param_31,
	.param .u32 m15500_s16_param_32,
	.param .u32 m15500_s16_param_33,
	.param .u64 m15500_s16_param_34
)
{



	ret;
}


  