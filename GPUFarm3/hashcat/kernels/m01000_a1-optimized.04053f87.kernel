//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: UNKNOWN
// Driver 
// Based on LLVM 3.4svn
//

.version 6.1
.target sm_61, texmode_independent
.address_size 64

	// .globl	gpu_memset
.const .align 4 .b8 c_append_helper[4096] = {255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255};

.entry gpu_memset(
	.param .u64 .ptr .global .align 16 gpu_memset_param_0,
	.param .u32 gpu_memset_param_1,
	.param .u64 gpu_memset_param_2
)
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<8>;
	.reg .b64 	%rd<6>;


	ld.param.u64 	%rd1, [gpu_memset_param_0];
	ld.param.u32 	%r2, [gpu_memset_param_1];
	ld.param.u64 	%rd2, [gpu_memset_param_2];
	mov.b32	%r3, %envreg3;
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %ntid.x;
	mad.lo.s32 	%r6, %r4, %r5, %r3;
	mov.u32 	%r7, %tid.x;
	add.s32 	%r1, %r6, %r7;
	cvt.s64.s32	%rd3, %r1;
	setp.ge.u64	%p1, %rd3, %rd2;
	@%p1 bra 	BB0_2;

	mul.wide.s32 	%rd4, %r1, 16;
	add.s64 	%rd5, %rd1, %rd4;
	st.global.v4.u32 	[%rd5], {%r2, %r2, %r2, %r2};

BB0_2:
	ret;
}

	// .globl	m01000_m04
.entry m01000_m04(
	.param .u64 .ptr .global .align 4 m01000_m04_param_0,
	.param .u64 .ptr .global .align 4 m01000_m04_param_1,
	.param .u64 .ptr .global .align 4 m01000_m04_param_2,
	.param .u64 .ptr .global .align 4 m01000_m04_param_3,
	.param .u64 .ptr .global .align 1 m01000_m04_param_4,
	.param .u64 .ptr .global .align 1 m01000_m04_param_5,
	.param .u64 .ptr .global .align 4 m01000_m04_param_6,
	.param .u64 .ptr .global .align 4 m01000_m04_param_7,
	.param .u64 .ptr .global .align 4 m01000_m04_param_8,
	.param .u64 .ptr .global .align 4 m01000_m04_param_9,
	.param .u64 .ptr .global .align 4 m01000_m04_param_10,
	.param .u64 .ptr .global .align 4 m01000_m04_param_11,
	.param .u64 .ptr .global .align 4 m01000_m04_param_12,
	.param .u64 .ptr .global .align 4 m01000_m04_param_13,
	.param .u64 .ptr .global .align 4 m01000_m04_param_14,
	.param .u64 .ptr .global .align 4 m01000_m04_param_15,
	.param .u64 .ptr .global .align 4 m01000_m04_param_16,
	.param .u64 .ptr .global .align 4 m01000_m04_param_17,
	.param .u64 .ptr .global .align 1 m01000_m04_param_18,
	.param .u64 .ptr .global .align 4 m01000_m04_param_19,
	.param .u64 .ptr .global .align 4 m01000_m04_param_20,
	.param .u64 .ptr .global .align 4 m01000_m04_param_21,
	.param .u64 .ptr .global .align 4 m01000_m04_param_22,
	.param .u64 .ptr .global .align 4 m01000_m04_param_23,
	.param .u32 m01000_m04_param_24,
	.param .u32 m01000_m04_param_25,
	.param .u32 m01000_m04_param_26,
	.param .u32 m01000_m04_param_27,
	.param .u32 m01000_m04_param_28,
	.param .u32 m01000_m04_param_29,
	.param .u32 m01000_m04_param_30,
	.param .u32 m01000_m04_param_31,
	.param .u32 m01000_m04_param_32,
	.param .u32 m01000_m04_param_33,
	.param .u64 m01000_m04_param_34
)
{
	.reg .pred 	%p<74>;
	.reg .b32 	%r<1904>;
	.reg .b64 	%rd<58>;


	ld.param.u64 	%rd3, [m01000_m04_param_0];
	ld.param.u64 	%rd16, [m01000_m04_param_19];
	ld.param.u32 	%r138, [m01000_m04_param_24];
	ld.param.u32 	%r139, [m01000_m04_param_25];
	ld.param.u32 	%r140, [m01000_m04_param_26];
	ld.param.u32 	%r142, [m01000_m04_param_30];
	ld.param.u32 	%r143, [m01000_m04_param_31];
	ld.param.u32 	%r144, [m01000_m04_param_32];
	ld.param.u64 	%rd17, [m01000_m04_param_34];
	mov.b32	%r146, %envreg3;
	mov.u32 	%r147, %ctaid.x;
	mov.u32 	%r148, %ntid.x;
	mad.lo.s32 	%r149, %r147, %r148, %r146;
	mov.u32 	%r150, %tid.x;
	add.s32 	%r1, %r149, %r150;
	cvt.s64.s32	%rd18, %r1;
	setp.ge.u64	%p1, %rd18, %rd17;
	@%p1 bra 	BB1_114;

	mul.wide.s32 	%rd19, %r1, 260;
	add.s64 	%rd20, %rd3, %rd19;
	ld.global.u32 	%r2, [%rd20];
	ld.global.u32 	%r3, [%rd20+4];
	ld.global.u32 	%r4, [%rd20+8];
	ld.global.u32 	%r5, [%rd20+12];
	ld.global.u32 	%r6, [%rd20+16];
	ld.global.u32 	%r7, [%rd20+20];
	ld.global.u32 	%r8, [%rd20+24];
	ld.global.u32 	%r9, [%rd20+28];
	ld.global.u32 	%r10, [%rd20+256];
	setp.eq.s32	%p2, %r142, 0;
	@%p2 bra 	BB1_114;

	and.b32  	%r152, %r10, 3;
	mov.u32 	%r153, 4;
	sub.s32 	%r154, %r153, %r152;
	shr.u32 	%r11, %r10, 2;
	shl.b32 	%r155, %r154, 2;
	mov.u32 	%r156, 1985229328;
	shr.u32 	%r157, %r156, %r155;
	and.b32  	%r12, %r157, 65535;
	and.b32  	%r13, %r139, 31;
	and.b32  	%r14, %r140, 31;
	cvt.u64.u32	%rd1, %r144;
	mov.u32 	%r1883, 0;

BB1_3:
	ld.param.u32 	%r1868, [m01000_m04_param_33];
	ld.param.u64 	%rd53, [m01000_m04_param_2];
	mul.wide.u32 	%rd21, %r1883, 260;
	add.s64 	%rd22, %rd53, %rd21;
	ld.global.u32 	%r16, [%rd22+256];
	ld.global.u32 	%r1888, [%rd22];
	ld.global.u32 	%r1889, [%rd22+4];
	ld.global.u32 	%r1890, [%rd22+8];
	ld.global.u32 	%r1891, [%rd22+12];
	ld.global.u32 	%r1887, [%rd22+16];
	ld.global.u32 	%r1886, [%rd22+20];
	ld.global.u32 	%r1885, [%rd22+24];
	ld.global.u32 	%r1884, [%rd22+28];
	setp.eq.s32	%p3, %r1868, 10001;
	@%p3 bra 	BB1_45;
	bra.uni 	BB1_4;

BB1_45:
	setp.gt.s32	%p27, %r11, 7;
	@%p27 bra 	BB1_61;

	setp.gt.s32	%p39, %r11, 3;
	@%p39 bra 	BB1_54;

	setp.gt.s32	%p45, %r11, 1;
	@%p45 bra 	BB1_51;

	setp.eq.s32	%p48, %r11, 0;
	@%p48 bra 	BB1_84;
	bra.uni 	BB1_49;

BB1_84:
	mov.u32 	%r1434, 0;
	// inline asm
	prmt.b32 %r1373, %r1434, %r1434, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1377, %r1434, %r1434, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1381, %r1434, %r1434, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1385, %r1434, %r1434, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1389, %r1434, %r1434, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1393, %r1434, %r1434, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1397, %r1434, %r1434, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1401, %r1884, %r1434, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1884, %r1885, %r1884, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1885, %r1886, %r1885, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1886, %r1887, %r1886, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1887, %r1891, %r1887, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1891, %r1890, %r1891, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1890, %r1889, %r1890, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1889, %r1888, %r1889, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1888, %r1434, %r1888, %r12;
	// inline asm
	bra.uni 	BB1_85;

BB1_4:
	mov.u32 	%r1870, 1985229328;
	mov.u32 	%r1869, 4;
	and.b32  	%r159, %r16, 3;
	sub.s32 	%r161, %r1869, %r159;
	shl.b32 	%r162, %r161, 2;
	shr.u32 	%r164, %r1870, %r162;
	and.b32  	%r25, %r164, 65535;
	shr.u32 	%r158, %r16, 2;
	setp.gt.s32	%p4, %r158, 7;
	@%p4 bra 	BB1_20;

	setp.gt.s32	%p16, %r158, 3;
	@%p16 bra 	BB1_13;

	setp.gt.s32	%p22, %r158, 1;
	@%p22 bra 	BB1_10;

	setp.eq.s32	%p25, %r158, 0;
	@%p25 bra 	BB1_44;
	bra.uni 	BB1_8;

BB1_44:
	mov.u32 	%r798, 0;
	// inline asm
	prmt.b32 %r737, %r798, %r798, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r741, %r798, %r798, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r745, %r798, %r798, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r749, %r798, %r798, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r753, %r798, %r798, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r757, %r798, %r798, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r761, %r798, %r798, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r765, %r9, %r798, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1895, %r8, %r9, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1894, %r7, %r8, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1893, %r6, %r7, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1892, %r5, %r6, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1899, %r4, %r5, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1898, %r3, %r4, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1897, %r2, %r3, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1896, %r798, %r2, %r25;
	// inline asm
	bra.uni 	BB1_86;

BB1_61:
	setp.gt.s32	%p28, %r11, 11;
	@%p28 bra 	BB1_69;

	setp.gt.s32	%p34, %r11, 9;
	@%p34 bra 	BB1_66;

	setp.eq.s32	%p37, %r11, 8;
	@%p37 bra 	BB1_80;
	bra.uni 	BB1_64;

BB1_80:
	// inline asm
	prmt.b32 %r969, %r1885, %r1884, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r973, %r1886, %r1885, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r977, %r1887, %r1886, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r981, %r1891, %r1887, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r985, %r1890, %r1891, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r989, %r1889, %r1890, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r993, %r1888, %r1889, %r12;
	// inline asm
	mov.u32 	%r1884, 0;
	// inline asm
	prmt.b32 %r997, %r1884, %r1888, %r12;
	// inline asm
	bra.uni 	BB1_76;

BB1_20:
	setp.gt.s32	%p5, %r158, 11;
	@%p5 bra 	BB1_28;

	setp.gt.s32	%p11, %r158, 9;
	@%p11 bra 	BB1_25;

	setp.eq.s32	%p14, %r158, 8;
	@%p14 bra 	BB1_40;
	bra.uni 	BB1_23;

BB1_40:
	// inline asm
	prmt.b32 %r333, %r8, %r9, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r337, %r7, %r8, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r341, %r6, %r7, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r345, %r5, %r6, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r349, %r4, %r5, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r353, %r3, %r4, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r357, %r2, %r3, %r25;
	// inline asm
	mov.u32 	%r1892, 0;
	// inline asm
	prmt.b32 %r361, %r1892, %r2, %r25;
	// inline asm
	bra.uni 	BB1_35;

BB1_54:
	setp.gt.s32	%p40, %r11, 5;
	@%p40 bra 	BB1_58;

	setp.eq.s32	%p43, %r11, 4;
	@%p43 bra 	BB1_82;
	bra.uni 	BB1_56;

BB1_82:
	mov.u32 	%r1198, 0;
	// inline asm
	prmt.b32 %r1147, %r1198, %r1198, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1151, %r1198, %r1198, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1155, %r1198, %r1198, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1159, %r1884, %r1198, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1163, %r1885, %r1884, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1167, %r1886, %r1885, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1171, %r1887, %r1886, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1175, %r1891, %r1887, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1884, %r1890, %r1891, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1885, %r1889, %r1890, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1886, %r1888, %r1889, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1887, %r1198, %r1888, %r12;
	// inline asm
	mov.u32 	%r1888, %r1198;
	mov.u32 	%r1889, %r1198;
	mov.u32 	%r1890, %r1198;
	mov.u32 	%r1891, %r1198;
	bra.uni 	BB1_85;

BB1_13:
	setp.gt.s32	%p17, %r158, 5;
	@%p17 bra 	BB1_17;

	setp.eq.s32	%p20, %r158, 4;
	@%p20 bra 	BB1_42;
	bra.uni 	BB1_15;

BB1_42:
	mov.u32 	%r1896, 0;
	// inline asm
	prmt.b32 %r511, %r1896, %r1896, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r515, %r1896, %r1896, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r519, %r1896, %r1896, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r523, %r9, %r1896, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r527, %r8, %r9, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r531, %r7, %r8, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r535, %r6, %r7, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r539, %r5, %r6, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1895, %r4, %r5, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1894, %r3, %r4, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1893, %r2, %r3, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1892, %r1896, %r2, %r25;
	// inline asm
	mov.u32 	%r1897, %r1896;
	mov.u32 	%r1898, %r1896;
	mov.u32 	%r1899, %r1896;
	bra.uni 	BB1_86;

BB1_69:
	setp.gt.s32	%p29, %r11, 13;
	@%p29 bra 	BB1_73;

	setp.eq.s32	%p32, %r11, 12;
	@%p32 bra 	BB1_78;
	bra.uni 	BB1_71;

BB1_78:
	// inline asm
	prmt.b32 %r849, %r1890, %r1891, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r853, %r1889, %r1890, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r857, %r1888, %r1889, %r12;
	// inline asm
	mov.u32 	%r1884, 0;
	// inline asm
	prmt.b32 %r861, %r1884, %r1888, %r12;
	// inline asm
	bra.uni 	BB1_76;

BB1_28:
	setp.gt.s32	%p6, %r158, 13;
	@%p6 bra 	BB1_32;

	setp.eq.s32	%p9, %r158, 12;
	@%p9 bra 	BB1_38;
	bra.uni 	BB1_30;

BB1_38:
	// inline asm
	prmt.b32 %r213, %r4, %r5, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r217, %r3, %r4, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r221, %r2, %r3, %r25;
	// inline asm
	mov.u32 	%r1892, 0;
	// inline asm
	prmt.b32 %r225, %r1892, %r2, %r25;
	// inline asm
	bra.uni 	BB1_35;

BB1_51:
	setp.eq.s32	%p46, %r11, 2;
	@%p46 bra 	BB1_83;
	bra.uni 	BB1_52;

BB1_83:
	mov.u32 	%r1311, 0;
	// inline asm
	prmt.b32 %r1254, %r1311, %r1311, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1258, %r1311, %r1311, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1262, %r1311, %r1311, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1266, %r1311, %r1311, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1270, %r1311, %r1311, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1274, %r1884, %r1311, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1278, %r1885, %r1884, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1282, %r1886, %r1885, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1884, %r1887, %r1886, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1885, %r1891, %r1887, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1886, %r1890, %r1891, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1887, %r1889, %r1890, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1891, %r1888, %r1889, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1890, %r1311, %r1888, %r12;
	// inline asm
	mov.u32 	%r1888, %r1311;
	mov.u32 	%r1889, %r1311;
	bra.uni 	BB1_85;

BB1_10:
	setp.eq.s32	%p23, %r158, 2;
	@%p23 bra 	BB1_43;
	bra.uni 	BB1_11;

BB1_43:
	mov.u32 	%r1896, 0;
	// inline asm
	prmt.b32 %r618, %r1896, %r1896, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r622, %r1896, %r1896, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r626, %r1896, %r1896, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r630, %r1896, %r1896, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r634, %r1896, %r1896, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r638, %r9, %r1896, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r642, %r8, %r9, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r646, %r7, %r8, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1895, %r6, %r7, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1894, %r5, %r6, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1893, %r4, %r5, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1892, %r3, %r4, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1899, %r2, %r3, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1898, %r1896, %r2, %r25;
	// inline asm
	mov.u32 	%r1897, %r1896;
	bra.uni 	BB1_86;

BB1_66:
	setp.eq.s32	%p35, %r11, 10;
	@%p35 bra 	BB1_79;
	bra.uni 	BB1_67;

BB1_79:
	// inline asm
	prmt.b32 %r901, %r1887, %r1886, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r905, %r1891, %r1887, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r909, %r1890, %r1891, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r913, %r1889, %r1890, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r917, %r1888, %r1889, %r12;
	// inline asm
	mov.u32 	%r1884, 0;
	// inline asm
	prmt.b32 %r921, %r1884, %r1888, %r12;
	// inline asm
	bra.uni 	BB1_76;

BB1_25:
	setp.eq.s32	%p12, %r158, 10;
	@%p12 bra 	BB1_39;
	bra.uni 	BB1_26;

BB1_39:
	// inline asm
	prmt.b32 %r265, %r6, %r7, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r269, %r5, %r6, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r273, %r4, %r5, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r277, %r3, %r4, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r281, %r2, %r3, %r25;
	// inline asm
	mov.u32 	%r1892, 0;
	// inline asm
	prmt.b32 %r285, %r1892, %r2, %r25;
	// inline asm
	bra.uni 	BB1_35;

BB1_58:
	setp.eq.s32	%p41, %r11, 6;
	@%p41 bra 	BB1_81;
	bra.uni 	BB1_59;

BB1_81:
	mov.u32 	%r1097, 0;
	// inline asm
	prmt.b32 %r1052, %r1097, %r1097, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1056, %r1884, %r1097, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1060, %r1885, %r1884, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1064, %r1886, %r1885, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1068, %r1887, %r1886, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1072, %r1891, %r1887, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1076, %r1890, %r1891, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1080, %r1889, %r1890, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1884, %r1888, %r1889, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1885, %r1097, %r1888, %r12;
	// inline asm
	mov.u32 	%r1886, %r1097;
	mov.u32 	%r1887, %r1097;
	mov.u32 	%r1888, %r1097;
	mov.u32 	%r1889, %r1097;
	mov.u32 	%r1890, %r1097;
	mov.u32 	%r1891, %r1097;
	bra.uni 	BB1_85;

BB1_17:
	setp.eq.s32	%p18, %r158, 6;
	@%p18 bra 	BB1_41;
	bra.uni 	BB1_18;

BB1_41:
	mov.u32 	%r1892, 0;
	// inline asm
	prmt.b32 %r416, %r1892, %r1892, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r420, %r9, %r1892, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r424, %r8, %r9, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r428, %r7, %r8, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r432, %r6, %r7, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r436, %r5, %r6, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r440, %r4, %r5, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r444, %r3, %r4, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1895, %r2, %r3, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1894, %r1892, %r2, %r25;
	// inline asm
	mov.u32 	%r1893, %r1892;
	bra.uni 	BB1_36;

BB1_73:
	setp.eq.s32	%p30, %r11, 14;
	@%p30 bra 	BB1_77;
	bra.uni 	BB1_74;

BB1_77:
	// inline asm
	prmt.b32 %r813, %r1888, %r1889, %r12;
	// inline asm
	mov.u32 	%r1884, 0;
	// inline asm
	prmt.b32 %r817, %r1884, %r1888, %r12;
	// inline asm
	bra.uni 	BB1_76;

BB1_32:
	setp.eq.s32	%p7, %r158, 14;
	@%p7 bra 	BB1_37;
	bra.uni 	BB1_33;

BB1_37:
	// inline asm
	prmt.b32 %r177, %r2, %r3, %r25;
	// inline asm
	mov.u32 	%r1892, 0;
	// inline asm
	prmt.b32 %r181, %r1892, %r2, %r25;
	// inline asm
	bra.uni 	BB1_35;

BB1_49:
	setp.eq.s32	%p49, %r11, 1;
	@%p49 bra 	BB1_50;
	bra.uni 	BB1_85;

BB1_50:
	mov.u32 	%r1372, 0;
	// inline asm
	prmt.b32 %r1312, %r1372, %r1372, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1316, %r1372, %r1372, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1320, %r1372, %r1372, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1324, %r1372, %r1372, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1328, %r1372, %r1372, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1332, %r1372, %r1372, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1336, %r1884, %r1372, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1340, %r1885, %r1884, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1884, %r1886, %r1885, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1885, %r1887, %r1886, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1886, %r1891, %r1887, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1887, %r1890, %r1891, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1891, %r1889, %r1890, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1890, %r1888, %r1889, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1889, %r1372, %r1888, %r12;
	// inline asm
	mov.u32 	%r1888, %r1372;
	bra.uni 	BB1_85;

BB1_8:
	setp.eq.s32	%p26, %r158, 1;
	@%p26 bra 	BB1_9;
	bra.uni 	BB1_85;

BB1_9:
	mov.u32 	%r1896, 0;
	// inline asm
	prmt.b32 %r676, %r1896, %r1896, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r680, %r1896, %r1896, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r684, %r1896, %r1896, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r688, %r1896, %r1896, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r692, %r1896, %r1896, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r696, %r1896, %r1896, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r700, %r9, %r1896, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r704, %r8, %r9, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1895, %r7, %r8, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1894, %r6, %r7, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1893, %r5, %r6, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1892, %r4, %r5, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1899, %r3, %r4, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1898, %r2, %r3, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1897, %r1896, %r2, %r25;
	// inline asm
	bra.uni 	BB1_86;

BB1_64:
	setp.eq.s32	%p38, %r11, 9;
	@%p38 bra 	BB1_65;
	bra.uni 	BB1_85;

BB1_65:
	// inline asm
	prmt.b32 %r933, %r1886, %r1885, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r937, %r1887, %r1886, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r941, %r1891, %r1887, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r945, %r1890, %r1891, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r949, %r1889, %r1890, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r953, %r1888, %r1889, %r12;
	// inline asm
	mov.u32 	%r1884, 0;
	// inline asm
	prmt.b32 %r957, %r1884, %r1888, %r12;
	// inline asm
	bra.uni 	BB1_76;

BB1_23:
	setp.eq.s32	%p15, %r158, 9;
	@%p15 bra 	BB1_24;
	bra.uni 	BB1_85;

BB1_24:
	// inline asm
	prmt.b32 %r297, %r7, %r8, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r301, %r6, %r7, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r305, %r5, %r6, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r309, %r4, %r5, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r313, %r3, %r4, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r317, %r2, %r3, %r25;
	// inline asm
	mov.u32 	%r1892, 0;
	// inline asm
	prmt.b32 %r321, %r1892, %r2, %r25;
	// inline asm
	bra.uni 	BB1_35;

BB1_56:
	setp.eq.s32	%p44, %r11, 5;
	@%p44 bra 	BB1_57;
	bra.uni 	BB1_85;

BB1_57:
	mov.u32 	%r1146, 0;
	// inline asm
	prmt.b32 %r1098, %r1146, %r1146, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1102, %r1146, %r1146, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1106, %r1884, %r1146, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1110, %r1885, %r1884, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1114, %r1886, %r1885, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1118, %r1887, %r1886, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1122, %r1891, %r1887, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1126, %r1890, %r1891, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1884, %r1889, %r1890, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1885, %r1888, %r1889, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1886, %r1146, %r1888, %r12;
	// inline asm
	mov.u32 	%r1887, %r1146;
	mov.u32 	%r1888, %r1146;
	mov.u32 	%r1889, %r1146;
	mov.u32 	%r1890, %r1146;
	mov.u32 	%r1891, %r1146;
	bra.uni 	BB1_85;

BB1_15:
	setp.eq.s32	%p21, %r158, 5;
	@%p21 bra 	BB1_16;
	bra.uni 	BB1_85;

BB1_16:
	mov.u32 	%r1892, 0;
	// inline asm
	prmt.b32 %r462, %r1892, %r1892, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r466, %r1892, %r1892, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r470, %r9, %r1892, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r474, %r8, %r9, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r478, %r7, %r8, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r482, %r6, %r7, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r486, %r5, %r6, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r490, %r4, %r5, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1895, %r3, %r4, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1894, %r2, %r3, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1893, %r1892, %r2, %r25;
	// inline asm
	bra.uni 	BB1_36;

BB1_71:
	setp.eq.s32	%p33, %r11, 13;
	@%p33 bra 	BB1_72;
	bra.uni 	BB1_85;

BB1_72:
	// inline asm
	prmt.b32 %r829, %r1889, %r1890, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r833, %r1888, %r1889, %r12;
	// inline asm
	mov.u32 	%r1884, 0;
	// inline asm
	prmt.b32 %r837, %r1884, %r1888, %r12;
	// inline asm
	bra.uni 	BB1_76;

BB1_30:
	setp.eq.s32	%p10, %r158, 13;
	@%p10 bra 	BB1_31;
	bra.uni 	BB1_85;

BB1_31:
	// inline asm
	prmt.b32 %r193, %r3, %r4, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r197, %r2, %r3, %r25;
	// inline asm
	mov.u32 	%r1892, 0;
	// inline asm
	prmt.b32 %r201, %r1892, %r2, %r25;
	// inline asm
	bra.uni 	BB1_35;

BB1_52:
	setp.eq.s32	%p47, %r11, 3;
	@%p47 bra 	BB1_53;
	bra.uni 	BB1_85;

BB1_53:
	mov.u32 	%r1253, 0;
	// inline asm
	prmt.b32 %r1199, %r1253, %r1253, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1203, %r1253, %r1253, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1207, %r1253, %r1253, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1211, %r1253, %r1253, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1215, %r1884, %r1253, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1219, %r1885, %r1884, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1223, %r1886, %r1885, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1227, %r1887, %r1886, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1884, %r1891, %r1887, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1885, %r1890, %r1891, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1886, %r1889, %r1890, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1887, %r1888, %r1889, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1891, %r1253, %r1888, %r12;
	// inline asm
	mov.u32 	%r1888, %r1253;
	mov.u32 	%r1889, %r1253;
	mov.u32 	%r1890, %r1253;
	bra.uni 	BB1_85;

BB1_11:
	setp.eq.s32	%p24, %r158, 3;
	@%p24 bra 	BB1_12;
	bra.uni 	BB1_85;

BB1_12:
	mov.u32 	%r1896, 0;
	// inline asm
	prmt.b32 %r563, %r1896, %r1896, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r567, %r1896, %r1896, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r571, %r1896, %r1896, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r575, %r1896, %r1896, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r579, %r9, %r1896, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r583, %r8, %r9, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r587, %r7, %r8, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r591, %r6, %r7, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1895, %r5, %r6, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1894, %r4, %r5, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1893, %r3, %r4, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1892, %r2, %r3, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1899, %r1896, %r2, %r25;
	// inline asm
	mov.u32 	%r1897, %r1896;
	mov.u32 	%r1898, %r1896;
	bra.uni 	BB1_86;

BB1_67:
	setp.eq.s32	%p36, %r11, 11;
	@%p36 bra 	BB1_68;
	bra.uni 	BB1_85;

BB1_68:
	// inline asm
	prmt.b32 %r873, %r1891, %r1887, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r877, %r1890, %r1891, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r881, %r1889, %r1890, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r885, %r1888, %r1889, %r12;
	// inline asm
	mov.u32 	%r1884, 0;
	// inline asm
	prmt.b32 %r889, %r1884, %r1888, %r12;
	// inline asm
	bra.uni 	BB1_76;

BB1_26:
	setp.eq.s32	%p13, %r158, 11;
	@%p13 bra 	BB1_27;
	bra.uni 	BB1_85;

BB1_27:
	// inline asm
	prmt.b32 %r237, %r5, %r6, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r241, %r4, %r5, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r245, %r3, %r4, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r249, %r2, %r3, %r25;
	// inline asm
	mov.u32 	%r1892, 0;
	// inline asm
	prmt.b32 %r253, %r1892, %r2, %r25;
	// inline asm
	bra.uni 	BB1_35;

BB1_59:
	setp.eq.s32	%p42, %r11, 7;
	@%p42 bra 	BB1_60;
	bra.uni 	BB1_85;

BB1_60:
	mov.u32 	%r1051, 0;
	// inline asm
	prmt.b32 %r1009, %r1884, %r1051, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1013, %r1885, %r1884, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1017, %r1886, %r1885, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1021, %r1887, %r1886, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1025, %r1891, %r1887, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1029, %r1890, %r1891, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1033, %r1889, %r1890, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1037, %r1888, %r1889, %r12;
	// inline asm
	// inline asm
	prmt.b32 %r1884, %r1051, %r1888, %r12;
	// inline asm
	mov.u32 	%r1885, %r1051;
	mov.u32 	%r1886, %r1051;
	mov.u32 	%r1887, %r1051;
	mov.u32 	%r1888, %r1051;
	mov.u32 	%r1889, %r1051;
	mov.u32 	%r1890, %r1051;
	mov.u32 	%r1891, %r1051;
	bra.uni 	BB1_85;

BB1_18:
	setp.eq.s32	%p19, %r158, 7;
	@%p19 bra 	BB1_19;
	bra.uni 	BB1_85;

BB1_19:
	mov.u32 	%r1892, 0;
	// inline asm
	prmt.b32 %r373, %r9, %r1892, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r377, %r8, %r9, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r381, %r7, %r8, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r385, %r6, %r7, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r389, %r5, %r6, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r393, %r4, %r5, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r397, %r3, %r4, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r401, %r2, %r3, %r25;
	// inline asm
	// inline asm
	prmt.b32 %r1895, %r1892, %r2, %r25;
	// inline asm
	mov.u32 	%r1893, %r1892;
	mov.u32 	%r1894, %r1892;
	bra.uni 	BB1_36;

BB1_74:
	setp.ne.s32	%p31, %r11, 15;
	@%p31 bra 	BB1_85;

	mov.u32 	%r1884, 0;
	// inline asm
	prmt.b32 %r801, %r1884, %r1888, %r12;
	// inline asm

BB1_76:
	mov.u32 	%r1885, %r1884;
	mov.u32 	%r1886, %r1884;
	mov.u32 	%r1887, %r1884;
	mov.u32 	%r1888, %r1884;
	mov.u32 	%r1889, %r1884;
	mov.u32 	%r1890, %r1884;
	mov.u32 	%r1891, %r1884;

BB1_85:
	mov.u32 	%r1892, %r6;
	mov.u32 	%r1893, %r7;
	mov.u32 	%r1894, %r8;
	mov.u32 	%r1895, %r9;
	mov.u32 	%r1896, %r2;
	mov.u32 	%r1897, %r3;
	mov.u32 	%r1898, %r4;
	mov.u32 	%r1899, %r5;
	bra.uni 	BB1_86;

BB1_33:
	setp.ne.s32	%p8, %r158, 15;
	@%p8 bra 	BB1_85;

	mov.u32 	%r1892, 0;
	// inline asm
	prmt.b32 %r165, %r1892, %r2, %r25;
	// inline asm

BB1_35:
	mov.u32 	%r1893, %r1892;
	mov.u32 	%r1894, %r1892;
	mov.u32 	%r1895, %r1892;

BB1_36:
	mov.u32 	%r1896, %r1892;
	mov.u32 	%r1897, %r1892;
	mov.u32 	%r1898, %r1892;
	mov.u32 	%r1899, %r1892;

BB1_86:
	ld.param.u64 	%rd54, [m01000_m04_param_6];
	or.b32  	%r1442, %r1895, %r1884;
	mov.u32 	%r1499, 0;
	mov.u32 	%r1496, 29554;
	// inline asm
	prmt.b32 %r1437, %r1442, %r1499, %r1496;
	// inline asm
	mov.u32 	%r1500, 29040;
	// inline asm
	prmt.b32 %r1441, %r1442, %r1499, %r1500;
	// inline asm
	or.b32  	%r1450, %r1894, %r1885;
	// inline asm
	prmt.b32 %r1445, %r1450, %r1499, %r1496;
	// inline asm
	// inline asm
	prmt.b32 %r1449, %r1450, %r1499, %r1500;
	// inline asm
	or.b32  	%r1458, %r1893, %r1886;
	// inline asm
	prmt.b32 %r1453, %r1458, %r1499, %r1496;
	// inline asm
	// inline asm
	prmt.b32 %r1457, %r1458, %r1499, %r1500;
	// inline asm
	or.b32  	%r1466, %r1892, %r1887;
	// inline asm
	prmt.b32 %r1461, %r1466, %r1499, %r1496;
	// inline asm
	// inline asm
	prmt.b32 %r1465, %r1466, %r1499, %r1500;
	// inline asm
	or.b32  	%r1474, %r1899, %r1891;
	// inline asm
	prmt.b32 %r1469, %r1474, %r1499, %r1496;
	// inline asm
	// inline asm
	prmt.b32 %r1473, %r1474, %r1499, %r1500;
	// inline asm
	or.b32  	%r1482, %r1898, %r1890;
	// inline asm
	prmt.b32 %r1477, %r1482, %r1499, %r1496;
	// inline asm
	// inline asm
	prmt.b32 %r1481, %r1482, %r1499, %r1500;
	// inline asm
	or.b32  	%r1490, %r1897, %r1889;
	// inline asm
	prmt.b32 %r1485, %r1490, %r1499, %r1496;
	// inline asm
	// inline asm
	prmt.b32 %r1489, %r1490, %r1499, %r1500;
	// inline asm
	or.b32  	%r1498, %r1896, %r1888;
	// inline asm
	prmt.b32 %r1493, %r1498, %r1499, %r1496;
	// inline asm
	// inline asm
	prmt.b32 %r1497, %r1498, %r1499, %r1500;
	// inline asm
	add.s32 	%r1501, %r1497, -1;
	shf.l.wrap.b32 	%r1502, %r1501, %r1501, 3;
	and.b32  	%r1503, %r1502, 2004318071;
	xor.b32  	%r1504, %r1503, -1732584194;
	add.s32 	%r1505, %r1493, %r1504;
	add.s32 	%r1506, %r1505, 271733878;
	shf.l.wrap.b32 	%r1507, %r1506, %r1506, 7;
	xor.b32  	%r1508, %r1502, -271733879;
	and.b32  	%r1509, %r1508, %r1507;
	xor.b32  	%r1510, %r1509, -271733879;
	add.s32 	%r1511, %r1489, %r1510;
	add.s32 	%r1512, %r1511, -1732584194;
	shf.l.wrap.b32 	%r1513, %r1512, %r1512, 11;
	xor.b32  	%r1514, %r1507, %r1502;
	and.b32  	%r1515, %r1514, %r1513;
	xor.b32  	%r1516, %r1515, %r1502;
	add.s32 	%r1517, %r1485, %r1516;
	add.s32 	%r1518, %r1517, -271733879;
	shf.l.wrap.b32 	%r1519, %r1518, %r1518, 19;
	xor.b32  	%r1520, %r1513, %r1507;
	and.b32  	%r1521, %r1520, %r1519;
	xor.b32  	%r1522, %r1521, %r1507;
	add.s32 	%r1523, %r1502, %r1481;
	add.s32 	%r1524, %r1523, %r1522;
	shf.l.wrap.b32 	%r1525, %r1524, %r1524, 3;
	xor.b32  	%r1526, %r1519, %r1513;
	and.b32  	%r1527, %r1526, %r1525;
	xor.b32  	%r1528, %r1527, %r1513;
	add.s32 	%r1529, %r1507, %r1477;
	add.s32 	%r1530, %r1529, %r1528;
	shf.l.wrap.b32 	%r1531, %r1530, %r1530, 7;
	xor.b32  	%r1532, %r1525, %r1519;
	and.b32  	%r1533, %r1532, %r1531;
	xor.b32  	%r1534, %r1533, %r1519;
	add.s32 	%r1535, %r1513, %r1473;
	add.s32 	%r1536, %r1535, %r1534;
	shf.l.wrap.b32 	%r1537, %r1536, %r1536, 11;
	xor.b32  	%r1538, %r1531, %r1525;
	and.b32  	%r1539, %r1538, %r1537;
	xor.b32  	%r1540, %r1539, %r1525;
	add.s32 	%r1541, %r1519, %r1469;
	add.s32 	%r1542, %r1541, %r1540;
	shf.l.wrap.b32 	%r1543, %r1542, %r1542, 19;
	xor.b32  	%r1544, %r1537, %r1531;
	and.b32  	%r1545, %r1544, %r1543;
	xor.b32  	%r1546, %r1545, %r1531;
	add.s32 	%r1547, %r1525, %r1465;
	add.s32 	%r1548, %r1547, %r1546;
	shf.l.wrap.b32 	%r1549, %r1548, %r1548, 3;
	xor.b32  	%r1550, %r1543, %r1537;
	and.b32  	%r1551, %r1550, %r1549;
	xor.b32  	%r1552, %r1551, %r1537;
	add.s32 	%r1553, %r1531, %r1461;
	add.s32 	%r1554, %r1553, %r1552;
	shf.l.wrap.b32 	%r1555, %r1554, %r1554, 7;
	xor.b32  	%r1556, %r1549, %r1543;
	and.b32  	%r1557, %r1556, %r1555;
	xor.b32  	%r1558, %r1557, %r1543;
	add.s32 	%r1559, %r1537, %r1457;
	add.s32 	%r1560, %r1559, %r1558;
	shf.l.wrap.b32 	%r1561, %r1560, %r1560, 11;
	xor.b32  	%r1562, %r1555, %r1549;
	and.b32  	%r1563, %r1562, %r1561;
	xor.b32  	%r1564, %r1563, %r1549;
	add.s32 	%r1565, %r1543, %r1453;
	add.s32 	%r1566, %r1565, %r1564;
	shf.l.wrap.b32 	%r1567, %r1566, %r1566, 19;
	xor.b32  	%r1568, %r1561, %r1555;
	and.b32  	%r1569, %r1568, %r1567;
	xor.b32  	%r1570, %r1569, %r1555;
	add.s32 	%r1571, %r1549, %r1449;
	add.s32 	%r1572, %r1571, %r1570;
	shf.l.wrap.b32 	%r1573, %r1572, %r1572, 3;
	xor.b32  	%r1574, %r1567, %r1561;
	and.b32  	%r1575, %r1574, %r1573;
	xor.b32  	%r1576, %r1575, %r1561;
	add.s32 	%r1577, %r1555, %r1445;
	add.s32 	%r1578, %r1577, %r1576;
	shf.l.wrap.b32 	%r1579, %r1578, %r1578, 7;
	xor.b32  	%r1580, %r1573, %r1567;
	and.b32  	%r1581, %r1580, %r1579;
	xor.b32  	%r1582, %r1581, %r1567;
	add.s32 	%r1583, %r16, %r10;
	shl.b32 	%r1584, %r1583, 4;
	add.s32 	%r1585, %r1561, %r1584;
	add.s32 	%r1586, %r1585, %r1582;
	shf.l.wrap.b32 	%r1587, %r1586, %r1586, 11;
	xor.b32  	%r1588, %r1579, %r1573;
	and.b32  	%r1589, %r1588, %r1587;
	xor.b32  	%r1590, %r1589, %r1573;
	add.s32 	%r1591, %r1590, %r1567;
	shf.l.wrap.b32 	%r1592, %r1591, %r1591, 19;
	xor.b32  	%r1593, %r1592, %r1579;
	xor.b32  	%r1594, %r1592, %r1587;
	and.b32  	%r1595, %r1594, %r1593;
	xor.b32  	%r1596, %r1595, %r1592;
	add.s32 	%r1597, %r1497, %r1573;
	add.s32 	%r1598, %r1597, %r1596;
	add.s32 	%r1599, %r1598, 1518500249;
	shf.l.wrap.b32 	%r1600, %r1599, %r1599, 3;
	xor.b32  	%r1601, %r1600, %r1587;
	xor.b32  	%r1602, %r1600, %r1592;
	and.b32  	%r1603, %r1602, %r1601;
	xor.b32  	%r1604, %r1603, %r1600;
	add.s32 	%r1605, %r1481, %r1579;
	add.s32 	%r1606, %r1605, %r1604;
	add.s32 	%r1607, %r1606, 1518500249;
	shf.l.wrap.b32 	%r1608, %r1607, %r1607, 5;
	xor.b32  	%r1609, %r1608, %r1592;
	xor.b32  	%r1610, %r1608, %r1600;
	and.b32  	%r1611, %r1610, %r1609;
	xor.b32  	%r1612, %r1611, %r1608;
	add.s32 	%r1613, %r1465, %r1587;
	add.s32 	%r1614, %r1613, %r1612;
	add.s32 	%r1615, %r1614, 1518500249;
	shf.l.wrap.b32 	%r1616, %r1615, %r1615, 9;
	xor.b32  	%r1617, %r1616, %r1600;
	xor.b32  	%r1618, %r1616, %r1608;
	and.b32  	%r1619, %r1618, %r1617;
	xor.b32  	%r1620, %r1619, %r1616;
	add.s32 	%r1621, %r1449, %r1592;
	add.s32 	%r1622, %r1621, %r1620;
	add.s32 	%r1623, %r1622, 1518500249;
	shf.l.wrap.b32 	%r1624, %r1623, %r1623, 13;
	xor.b32  	%r1625, %r1624, %r1608;
	xor.b32  	%r1626, %r1624, %r1616;
	and.b32  	%r1627, %r1626, %r1625;
	xor.b32  	%r1628, %r1627, %r1624;
	add.s32 	%r1629, %r1493, %r1600;
	add.s32 	%r1630, %r1629, %r1628;
	add.s32 	%r1631, %r1630, 1518500249;
	shf.l.wrap.b32 	%r1632, %r1631, %r1631, 3;
	xor.b32  	%r1633, %r1632, %r1616;
	xor.b32  	%r1634, %r1632, %r1624;
	and.b32  	%r1635, %r1634, %r1633;
	xor.b32  	%r1636, %r1635, %r1632;
	add.s32 	%r1637, %r1477, %r1608;
	add.s32 	%r1638, %r1637, %r1636;
	add.s32 	%r1639, %r1638, 1518500249;
	shf.l.wrap.b32 	%r1640, %r1639, %r1639, 5;
	xor.b32  	%r1641, %r1640, %r1624;
	xor.b32  	%r1642, %r1640, %r1632;
	and.b32  	%r1643, %r1642, %r1641;
	xor.b32  	%r1644, %r1643, %r1640;
	add.s32 	%r1645, %r1461, %r1616;
	add.s32 	%r1646, %r1645, %r1644;
	add.s32 	%r1647, %r1646, 1518500249;
	shf.l.wrap.b32 	%r1648, %r1647, %r1647, 9;
	xor.b32  	%r1649, %r1648, %r1632;
	xor.b32  	%r1650, %r1648, %r1640;
	and.b32  	%r1651, %r1650, %r1649;
	xor.b32  	%r1652, %r1651, %r1648;
	add.s32 	%r1653, %r1445, %r1624;
	add.s32 	%r1654, %r1653, %r1652;
	add.s32 	%r1655, %r1654, 1518500249;
	shf.l.wrap.b32 	%r1656, %r1655, %r1655, 13;
	xor.b32  	%r1657, %r1656, %r1640;
	xor.b32  	%r1658, %r1656, %r1648;
	and.b32  	%r1659, %r1658, %r1657;
	xor.b32  	%r1660, %r1659, %r1656;
	add.s32 	%r1661, %r1489, %r1632;
	add.s32 	%r1662, %r1661, %r1660;
	add.s32 	%r1663, %r1662, 1518500249;
	shf.l.wrap.b32 	%r1664, %r1663, %r1663, 3;
	xor.b32  	%r1665, %r1664, %r1648;
	xor.b32  	%r1666, %r1664, %r1656;
	and.b32  	%r1667, %r1666, %r1665;
	xor.b32  	%r1668, %r1667, %r1664;
	add.s32 	%r1669, %r1473, %r1640;
	add.s32 	%r1670, %r1669, %r1668;
	add.s32 	%r1671, %r1670, 1518500249;
	shf.l.wrap.b32 	%r1672, %r1671, %r1671, 5;
	xor.b32  	%r1673, %r1672, %r1656;
	xor.b32  	%r1674, %r1672, %r1664;
	and.b32  	%r1675, %r1674, %r1673;
	xor.b32  	%r1676, %r1675, %r1672;
	add.s32 	%r1677, %r1457, %r1648;
	add.s32 	%r1678, %r1677, %r1676;
	add.s32 	%r1679, %r1678, 1518500249;
	shf.l.wrap.b32 	%r1680, %r1679, %r1679, 9;
	xor.b32  	%r1681, %r1680, %r1664;
	xor.b32  	%r1682, %r1680, %r1672;
	and.b32  	%r1683, %r1682, %r1681;
	xor.b32  	%r1684, %r1683, %r1680;
	add.s32 	%r1685, %r1584, %r1656;
	add.s32 	%r1686, %r1685, %r1684;
	add.s32 	%r1687, %r1686, 1518500249;
	shf.l.wrap.b32 	%r1688, %r1687, %r1687, 13;
	xor.b32  	%r1689, %r1688, %r1672;
	xor.b32  	%r1690, %r1688, %r1680;
	and.b32  	%r1691, %r1690, %r1689;
	xor.b32  	%r1692, %r1691, %r1688;
	add.s32 	%r1693, %r1485, %r1664;
	add.s32 	%r1694, %r1693, %r1692;
	add.s32 	%r1695, %r1694, 1518500249;
	shf.l.wrap.b32 	%r1696, %r1695, %r1695, 3;
	xor.b32  	%r1697, %r1696, %r1680;
	xor.b32  	%r1698, %r1696, %r1688;
	and.b32  	%r1699, %r1698, %r1697;
	xor.b32  	%r1700, %r1699, %r1696;
	add.s32 	%r1701, %r1469, %r1672;
	add.s32 	%r1702, %r1701, %r1700;
	add.s32 	%r1703, %r1702, 1518500249;
	shf.l.wrap.b32 	%r1704, %r1703, %r1703, 5;
	xor.b32  	%r1705, %r1704, %r1688;
	xor.b32  	%r1706, %r1704, %r1696;
	and.b32  	%r1707, %r1706, %r1705;
	xor.b32  	%r1708, %r1707, %r1704;
	add.s32 	%r1709, %r1453, %r1680;
	add.s32 	%r1710, %r1709, %r1708;
	add.s32 	%r1711, %r1710, 1518500249;
	shf.l.wrap.b32 	%r1712, %r1711, %r1711, 9;
	xor.b32  	%r1713, %r1712, %r1696;
	xor.b32  	%r1714, %r1712, %r1704;
	and.b32  	%r1715, %r1714, %r1713;
	xor.b32  	%r1716, %r1715, %r1712;
	add.s32 	%r1717, %r1688, %r1716;
	add.s32 	%r1718, %r1717, 1518500249;
	shf.l.wrap.b32 	%r1719, %r1718, %r1718, 13;
	xor.b32  	%r1720, %r1714, %r1719;
	add.s32 	%r1721, %r1497, %r1696;
	add.s32 	%r1722, %r1721, %r1720;
	add.s32 	%r1723, %r1722, 1859775393;
	shf.l.wrap.b32 	%r1724, %r1723, %r1723, 3;
	xor.b32  	%r1725, %r1719, %r1712;
	xor.b32  	%r1726, %r1725, %r1724;
	add.s32 	%r1727, %r1465, %r1704;
	add.s32 	%r1728, %r1727, %r1726;
	add.s32 	%r1729, %r1728, 1859775393;
	shf.l.wrap.b32 	%r1730, %r1729, %r1729, 9;
	xor.b32  	%r1731, %r1724, %r1719;
	xor.b32  	%r1732, %r1731, %r1730;
	add.s32 	%r1733, %r1481, %r1712;
	add.s32 	%r1734, %r1733, %r1732;
	add.s32 	%r1735, %r1734, 1859775393;
	shf.l.wrap.b32 	%r1736, %r1735, %r1735, 11;
	xor.b32  	%r1737, %r1730, %r1724;
	xor.b32  	%r1738, %r1737, %r1736;
	add.s32 	%r1739, %r1449, %r1719;
	add.s32 	%r1740, %r1739, %r1738;
	add.s32 	%r1741, %r1740, 1859775393;
	shf.l.wrap.b32 	%r1742, %r1741, %r1741, 15;
	xor.b32  	%r1743, %r1736, %r1730;
	xor.b32  	%r1744, %r1743, %r1742;
	add.s32 	%r1745, %r1489, %r1724;
	add.s32 	%r1746, %r1745, %r1744;
	add.s32 	%r1747, %r1746, 1859775393;
	shf.l.wrap.b32 	%r1748, %r1747, %r1747, 3;
	xor.b32  	%r1749, %r1742, %r1736;
	xor.b32  	%r1750, %r1749, %r1748;
	add.s32 	%r1751, %r1457, %r1730;
	add.s32 	%r1752, %r1751, %r1750;
	add.s32 	%r1753, %r1752, 1859775393;
	shf.l.wrap.b32 	%r1754, %r1753, %r1753, 9;
	xor.b32  	%r1755, %r1748, %r1742;
	xor.b32  	%r1756, %r1755, %r1754;
	add.s32 	%r1757, %r1473, %r1736;
	add.s32 	%r1758, %r1757, %r1756;
	add.s32 	%r1759, %r1758, 1859775393;
	shf.l.wrap.b32 	%r1760, %r1759, %r1759, 11;
	xor.b32  	%r1761, %r1754, %r1748;
	xor.b32  	%r1762, %r1761, %r1760;
	add.s32 	%r1763, %r1584, %r1742;
	add.s32 	%r1764, %r1763, %r1762;
	add.s32 	%r1765, %r1764, 1859775393;
	shf.l.wrap.b32 	%r1766, %r1765, %r1765, 15;
	xor.b32  	%r1767, %r1760, %r1754;
	xor.b32  	%r1768, %r1767, %r1766;
	add.s32 	%r1769, %r1493, %r1748;
	add.s32 	%r1770, %r1769, %r1768;
	add.s32 	%r1771, %r1770, 1859775393;
	shf.l.wrap.b32 	%r1772, %r1771, %r1771, 3;
	xor.b32  	%r1773, %r1766, %r1760;
	xor.b32  	%r1774, %r1773, %r1772;
	add.s32 	%r1775, %r1461, %r1754;
	add.s32 	%r1776, %r1775, %r1774;
	add.s32 	%r1777, %r1776, 1859775393;
	shf.l.wrap.b32 	%r1778, %r1777, %r1777, 9;
	xor.b32  	%r1779, %r1772, %r1766;
	xor.b32  	%r1780, %r1779, %r1778;
	add.s32 	%r1781, %r1477, %r1760;
	add.s32 	%r1782, %r1781, %r1780;
	add.s32 	%r1783, %r1782, 1859775393;
	shf.l.wrap.b32 	%r1784, %r1783, %r1783, 11;
	xor.b32  	%r1785, %r1778, %r1772;
	xor.b32  	%r1786, %r1785, %r1784;
	add.s32 	%r1787, %r1445, %r1766;
	add.s32 	%r1788, %r1787, %r1786;
	add.s32 	%r1789, %r1788, 1859775393;
	shf.l.wrap.b32 	%r1790, %r1789, %r1789, 15;
	xor.b32  	%r1791, %r1784, %r1778;
	xor.b32  	%r1792, %r1791, %r1790;
	add.s32 	%r1793, %r1485, %r1772;
	add.s32 	%r1794, %r1793, %r1792;
	add.s32 	%r1795, %r1794, 1859775393;
	shf.l.wrap.b32 	%r114, %r1795, %r1795, 3;
	xor.b32  	%r1796, %r1790, %r1784;
	xor.b32  	%r1797, %r1796, %r114;
	add.s32 	%r1798, %r1453, %r1778;
	add.s32 	%r1799, %r1798, %r1797;
	add.s32 	%r1800, %r1799, 1859775393;
	shf.l.wrap.b32 	%r115, %r1800, %r1800, 9;
	xor.b32  	%r1801, %r114, %r1790;
	xor.b32  	%r1802, %r1801, %r115;
	add.s32 	%r1803, %r1469, %r1784;
	add.s32 	%r1804, %r1803, %r1802;
	add.s32 	%r1805, %r1804, 1859775393;
	shf.l.wrap.b32 	%r116, %r1805, %r1805, 11;
	xor.b32  	%r1806, %r115, %r114;
	xor.b32  	%r1807, %r1806, %r116;
	add.s32 	%r1808, %r1790, %r1807;
	add.s32 	%r1809, %r1808, 1859775393;
	shf.l.wrap.b32 	%r117, %r1809, %r1809, 15;
	shr.u32 	%r1810, %r114, %r13;
	and.b32  	%r1811, %r1810, %r138;
	mul.wide.u32 	%rd23, %r1811, 4;
	add.s64 	%rd24, %rd54, %rd23;
	and.b32  	%r1812, %r114, 31;
	mov.u32 	%r1813, 1;
	shl.b32 	%r118, %r1813, %r1812;
	ld.global.u32 	%r1814, [%rd24];
	and.b32  	%r1815, %r1814, %r118;
	setp.eq.s32	%p50, %r1815, 0;
	@%p50 bra 	BB1_113;

	mov.u32 	%r1876, 1;
	ld.param.u64 	%rd46, [m01000_m04_param_7];
	shr.u32 	%r1816, %r115, %r13;
	and.b32  	%r1817, %r1816, %r138;
	mul.wide.u32 	%rd25, %r1817, 4;
	add.s64 	%rd26, %rd46, %rd25;
	and.b32  	%r1818, %r115, 31;
	shl.b32 	%r119, %r1876, %r1818;
	ld.global.u32 	%r1820, [%rd26];
	and.b32  	%r1821, %r1820, %r119;
	setp.eq.s32	%p51, %r1821, 0;
	@%p51 bra 	BB1_113;

	mov.u32 	%r1877, 1;
	ld.param.u64 	%rd47, [m01000_m04_param_8];
	shr.u32 	%r1822, %r116, %r13;
	and.b32  	%r1823, %r1822, %r138;
	mul.wide.u32 	%rd27, %r1823, 4;
	add.s64 	%rd28, %rd47, %rd27;
	and.b32  	%r1824, %r116, 31;
	shl.b32 	%r120, %r1877, %r1824;
	ld.global.u32 	%r1826, [%rd28];
	and.b32  	%r1827, %r1826, %r120;
	setp.eq.s32	%p52, %r1827, 0;
	@%p52 bra 	BB1_113;

	mov.u32 	%r1878, 1;
	ld.param.u64 	%rd48, [m01000_m04_param_9];
	shr.u32 	%r1828, %r117, %r13;
	and.b32  	%r1829, %r1828, %r138;
	mul.wide.u32 	%rd29, %r1829, 4;
	add.s64 	%rd30, %rd48, %rd29;
	and.b32  	%r1830, %r117, 31;
	shl.b32 	%r121, %r1878, %r1830;
	ld.global.u32 	%r1832, [%rd30];
	and.b32  	%r1833, %r1832, %r121;
	setp.eq.s32	%p53, %r1833, 0;
	@%p53 bra 	BB1_113;

	and.b32  	%r1873, %r114, 31;
	mov.u32 	%r1872, 1;
	shl.b32 	%r1871, %r1872, %r1873;
	ld.param.u64 	%rd49, [m01000_m04_param_10];
	shr.u32 	%r1834, %r114, %r14;
	and.b32  	%r1835, %r1834, %r138;
	mul.wide.u32 	%rd31, %r1835, 4;
	add.s64 	%rd32, %rd49, %rd31;
	ld.global.u32 	%r1836, [%rd32];
	and.b32  	%r1837, %r1836, %r1871;
	setp.eq.s32	%p54, %r1837, 0;
	@%p54 bra 	BB1_113;

	ld.param.u64 	%rd50, [m01000_m04_param_11];
	shr.u32 	%r1838, %r115, %r14;
	and.b32  	%r1839, %r1838, %r138;
	mul.wide.u32 	%rd33, %r1839, 4;
	add.s64 	%rd34, %rd50, %rd33;
	ld.global.u32 	%r1840, [%rd34];
	and.b32  	%r1841, %r1840, %r119;
	setp.eq.s32	%p55, %r1841, 0;
	@%p55 bra 	BB1_113;

	ld.param.u64 	%rd51, [m01000_m04_param_12];
	shr.u32 	%r1842, %r116, %r14;
	and.b32  	%r1843, %r1842, %r138;
	mul.wide.u32 	%rd35, %r1843, 4;
	add.s64 	%rd36, %rd51, %rd35;
	ld.global.u32 	%r1844, [%rd36];
	and.b32  	%r1845, %r1844, %r120;
	setp.eq.s32	%p56, %r1845, 0;
	@%p56 bra 	BB1_113;

	ld.param.u64 	%rd52, [m01000_m04_param_13];
	shr.u32 	%r1846, %r117, %r14;
	and.b32  	%r1847, %r1846, %r138;
	mul.wide.u32 	%rd37, %r1847, 4;
	add.s64 	%rd38, %rd52, %rd37;
	ld.global.u32 	%r1848, [%rd38];
	and.b32  	%r1849, %r1848, %r121;
	setp.eq.s32	%p57, %r1849, 0;
	@%p57 bra 	BB1_113;

	mov.u32 	%r1901, 0;
	setp.eq.s32	%p58, %r143, 0;
	mov.u32 	%r1850, -1;
	mov.u32 	%r1900, %r143;
	@%p58 bra 	BB1_107;

BB1_95:
	mov.u32 	%r1902, 1;
	ld.param.u64 	%rd55, [m01000_m04_param_15];
	shr.u32 	%r124, %r1900, 1;
	add.s32 	%r1903, %r124, %r1901;
	cvt.u64.u32	%rd39, %r1903;
	add.s64 	%rd40, %rd39, %rd1;
	shl.b64 	%rd41, %rd40, 4;
	add.s64 	%rd2, %rd55, %rd41;
	ld.global.u32 	%r126, [%rd2+4];
	setp.gt.u32	%p59, %r117, %r126;
	@%p59 bra 	BB1_105;

	setp.lt.u32	%p60, %r117, %r126;
	mov.u32 	%r1853, -1;
	@%p60 bra 	BB1_97;
	bra.uni 	BB1_98;

BB1_97:
	mov.u32 	%r1902, %r1853;
	bra.uni 	BB1_105;

BB1_98:
	mov.u32 	%r1902, 1;
	ld.global.u32 	%r127, [%rd2+8];
	setp.gt.u32	%p61, %r116, %r127;
	@%p61 bra 	BB1_105;

	setp.lt.u32	%p62, %r116, %r127;
	@%p62 bra 	BB1_100;
	bra.uni 	BB1_101;

BB1_100:
	mov.u32 	%r1902, %r1853;
	bra.uni 	BB1_105;

BB1_101:
	mov.u32 	%r1902, 1;
	ld.global.u32 	%r128, [%rd2+12];
	setp.gt.u32	%p63, %r115, %r128;
	@%p63 bra 	BB1_105;

	setp.lt.u32	%p64, %r115, %r128;
	mov.u32 	%r1902, %r1853;
	@%p64 bra 	BB1_105;

	mov.u32 	%r1902, 1;
	ld.global.u32 	%r129, [%rd2];
	setp.gt.u32	%p65, %r114, %r129;
	@%p65 bra 	BB1_105;

	setp.lt.u32	%p66, %r114, %r129;
	selp.b32	%r1902, -1, 0, %p66;

BB1_105:
	add.s32 	%r1859, %r124, 1;
	setp.gt.s32	%p67, %r1902, 0;
	selp.b32	%r1860, %r1859, 0, %p67;
	add.s32 	%r1901, %r1860, %r1901;
	selp.b32	%r1861, -1, 0, %p67;
	add.s32 	%r1862, %r1861, %r1900;
	shr.u32 	%r1900, %r1862, 1;
	setp.eq.s32	%p68, %r1902, 0;
	@%p68 bra 	BB1_108;

	setp.ne.s32	%p69, %r1900, 0;
	@%p69 bra 	BB1_95;

BB1_107:
	mov.u32 	%r1903, %r1850;

BB1_108:
	setp.eq.s32	%p70, %r1903, -1;
	@%p70 bra 	BB1_113;

	ld.param.u64 	%rd56, [m01000_m04_param_16];
	ld.param.u32 	%r1867, [m01000_m04_param_32];
	add.s32 	%r135, %r1903, %r1867;
	mul.wide.u32 	%rd42, %r135, 4;
	add.s64 	%rd43, %rd56, %rd42;
	atom.global.add.u32 	%r1864, [%rd43], 1;
	setp.ne.s32	%p71, %r1864, 0;
	@%p71 bra 	BB1_113;

	atom.global.add.u32 	%r136, [%rd16], 1;
	setp.lt.u32	%p72, %r136, %r143;
	@%p72 bra 	BB1_112;
	bra.uni 	BB1_111;

BB1_112:
	ld.param.u32 	%r1874, [m01000_m04_param_27];
	ld.param.u64 	%rd57, [m01000_m04_param_14];
	mul.wide.u32 	%rd44, %r136, 20;
	add.s64 	%rd45, %rd57, %rd44;
	st.global.u32 	[%rd45], %r1874;
	st.global.u32 	[%rd45+4], %r1903;
	st.global.u32 	[%rd45+8], %r135;
	st.global.u32 	[%rd45+12], %r1;
	st.global.u32 	[%rd45+16], %r1883;
	bra.uni 	BB1_113;

BB1_111:
	atom.global.add.u32 	%r1865, [%rd16], -1;

BB1_113:
	ld.param.u32 	%r1875, [m01000_m04_param_30];
	add.s32 	%r1883, %r1883, 1;
	setp.lt.u32	%p73, %r1883, %r1875;
	@%p73 bra 	BB1_3;

BB1_114:
	ret;
}

	// .globl	m01000_m08
.entry m01000_m08(
	.param .u64 .ptr .global .align 4 m01000_m08_param_0,
	.param .u64 .ptr .global .align 4 m01000_m08_param_1,
	.param .u64 .ptr .global .align 4 m01000_m08_param_2,
	.param .u64 .ptr .global .align 4 m01000_m08_param_3,
	.param .u64 .ptr .global .align 1 m01000_m08_param_4,
	.param .u64 .ptr .global .align 1 m01000_m08_param_5,
	.param .u64 .ptr .global .align 4 m01000_m08_param_6,
	.param .u64 .ptr .global .align 4 m01000_m08_param_7,
	.param .u64 .ptr .global .align 4 m01000_m08_param_8,
	.param .u64 .ptr .global .align 4 m01000_m08_param_9,
	.param .u64 .ptr .global .align 4 m01000_m08_param_10,
	.param .u64 .ptr .global .align 4 m01000_m08_param_11,
	.param .u64 .ptr .global .align 4 m01000_m08_param_12,
	.param .u64 .ptr .global .align 4 m01000_m08_param_13,
	.param .u64 .ptr .global .align 4 m01000_m08_param_14,
	.param .u64 .ptr .global .align 4 m01000_m08_param_15,
	.param .u64 .ptr .global .align 4 m01000_m08_param_16,
	.param .u64 .ptr .global .align 4 m01000_m08_param_17,
	.param .u64 .ptr .global .align 1 m01000_m08_param_18,
	.param .u64 .ptr .global .align 4 m01000_m08_param_19,
	.param .u64 .ptr .global .align 4 m01000_m08_param_20,
	.param .u64 .ptr .global .align 4 m01000_m08_param_21,
	.param .u64 .ptr .global .align 4 m01000_m08_param_22,
	.param .u64 .ptr .global .align 4 m01000_m08_param_23,
	.param .u32 m01000_m08_param_24,
	.param .u32 m01000_m08_param_25,
	.param .u32 m01000_m08_param_26,
	.param .u32 m01000_m08_param_27,
	.param .u32 m01000_m08_param_28,
	.param .u32 m01000_m08_param_29,
	.param .u32 m01000_m08_param_30,
	.param .u32 m01000_m08_param_31,
	.param .u32 m01000_m08_param_32,
	.param .u32 m01000_m08_param_33,
	.param .u64 m01000_m08_param_34
)
{



	ret;
}

	// .globl	m01000_m16
.entry m01000_m16(
	.param .u64 .ptr .global .align 4 m01000_m16_param_0,
	.param .u64 .ptr .global .align 4 m01000_m16_param_1,
	.param .u64 .ptr .global .align 4 m01000_m16_param_2,
	.param .u64 .ptr .global .align 4 m01000_m16_param_3,
	.param .u64 .ptr .global .align 1 m01000_m16_param_4,
	.param .u64 .ptr .global .align 1 m01000_m16_param_5,
	.param .u64 .ptr .global .align 4 m01000_m16_param_6,
	.param .u64 .ptr .global .align 4 m01000_m16_param_7,
	.param .u64 .ptr .global .align 4 m01000_m16_param_8,
	.param .u64 .ptr .global .align 4 m01000_m16_param_9,
	.param .u64 .ptr .global .align 4 m01000_m16_param_10,
	.param .u64 .ptr .global .align 4 m01000_m16_param_11,
	.param .u64 .ptr .global .align 4 m01000_m16_param_12,
	.param .u64 .ptr .global .align 4 m01000_m16_param_13,
	.param .u64 .ptr .global .align 4 m01000_m16_param_14,
	.param .u64 .ptr .global .align 4 m01000_m16_param_15,
	.param .u64 .ptr .global .align 4 m01000_m16_param_16,
	.param .u64 .ptr .global .align 4 m01000_m16_param_17,
	.param .u64 .ptr .global .align 1 m01000_m16_param_18,
	.param .u64 .ptr .global .align 4 m01000_m16_param_19,
	.param .u64 .ptr .global .align 4 m01000_m16_param_20,
	.param .u64 .ptr .global .align 4 m01000_m16_param_21,
	.param .u64 .ptr .global .align 4 m01000_m16_param_22,
	.param .u64 .ptr .global .align 4 m01000_m16_param_23,
	.param .u32 m01000_m16_param_24,
	.param .u32 m01000_m16_param_25,
	.param .u32 m01000_m16_param_26,
	.param .u32 m01000_m16_param_27,
	.param .u32 m01000_m16_param_28,
	.param .u32 m01000_m16_param_29,
	.param .u32 m01000_m16_param_30,
	.param .u32 m01000_m16_param_31,
	.param .u32 m01000_m16_param_32,
	.param .u32 m01000_m16_param_33,
	.param .u64 m01000_m16_param_34
)
{



	ret;
}

	// .globl	m01000_s04
.entry m01000_s04(
	.param .u64 .ptr .global .align 4 m01000_s04_param_0,
	.param .u64 .ptr .global .align 4 m01000_s04_param_1,
	.param .u64 .ptr .global .align 4 m01000_s04_param_2,
	.param .u64 .ptr .global .align 4 m01000_s04_param_3,
	.param .u64 .ptr .global .align 1 m01000_s04_param_4,
	.param .u64 .ptr .global .align 1 m01000_s04_param_5,
	.param .u64 .ptr .global .align 4 m01000_s04_param_6,
	.param .u64 .ptr .global .align 4 m01000_s04_param_7,
	.param .u64 .ptr .global .align 4 m01000_s04_param_8,
	.param .u64 .ptr .global .align 4 m01000_s04_param_9,
	.param .u64 .ptr .global .align 4 m01000_s04_param_10,
	.param .u64 .ptr .global .align 4 m01000_s04_param_11,
	.param .u64 .ptr .global .align 4 m01000_s04_param_12,
	.param .u64 .ptr .global .align 4 m01000_s04_param_13,
	.param .u64 .ptr .global .align 4 m01000_s04_param_14,
	.param .u64 .ptr .global .align 4 m01000_s04_param_15,
	.param .u64 .ptr .global .align 4 m01000_s04_param_16,
	.param .u64 .ptr .global .align 4 m01000_s04_param_17,
	.param .u64 .ptr .global .align 1 m01000_s04_param_18,
	.param .u64 .ptr .global .align 4 m01000_s04_param_19,
	.param .u64 .ptr .global .align 4 m01000_s04_param_20,
	.param .u64 .ptr .global .align 4 m01000_s04_param_21,
	.param .u64 .ptr .global .align 4 m01000_s04_param_22,
	.param .u64 .ptr .global .align 4 m01000_s04_param_23,
	.param .u32 m01000_s04_param_24,
	.param .u32 m01000_s04_param_25,
	.param .u32 m01000_s04_param_26,
	.param .u32 m01000_s04_param_27,
	.param .u32 m01000_s04_param_28,
	.param .u32 m01000_s04_param_29,
	.param .u32 m01000_s04_param_30,
	.param .u32 m01000_s04_param_31,
	.param .u32 m01000_s04_param_32,
	.param .u32 m01000_s04_param_33,
	.param .u64 m01000_s04_param_34
)
{
	.reg .pred 	%p<59>;
	.reg .b32 	%r<1821>;
	.reg .b64 	%rd<22>;


	ld.param.u64 	%rd4, [m01000_s04_param_0];
	ld.param.u64 	%rd7, [m01000_s04_param_15];
	ld.param.u64 	%rd8, [m01000_s04_param_16];
	ld.param.u64 	%rd9, [m01000_s04_param_19];
	ld.param.u32 	%r124, [m01000_s04_param_30];
	ld.param.u32 	%r126, [m01000_s04_param_32];
	ld.param.u64 	%rd10, [m01000_s04_param_34];
	mov.b32	%r128, %envreg3;
	mov.u32 	%r129, %ctaid.x;
	mov.u32 	%r130, %ntid.x;
	mad.lo.s32 	%r131, %r129, %r130, %r128;
	mov.u32 	%r132, %tid.x;
	add.s32 	%r1, %r131, %r132;
	cvt.s64.s32	%rd11, %r1;
	setp.ge.u64	%p1, %rd11, %rd10;
	@%p1 bra 	BB4_93;

	mul.wide.s32 	%rd12, %r1, 260;
	add.s64 	%rd13, %rd4, %rd12;
	ld.global.u32 	%r2, [%rd13];
	ld.global.u32 	%r3, [%rd13+4];
	ld.global.u32 	%r4, [%rd13+8];
	ld.global.u32 	%r5, [%rd13+12];
	ld.global.u32 	%r6, [%rd13+16];
	ld.global.u32 	%r7, [%rd13+20];
	ld.global.u32 	%r8, [%rd13+24];
	ld.global.u32 	%r9, [%rd13+28];
	ld.global.u32 	%r10, [%rd13+256];
	cvt.u64.u32	%rd1, %r126;
	mul.wide.u32 	%rd14, %r126, 16;
	add.s64 	%rd2, %rd7, %rd14;
	ld.global.u32 	%r11, [%rd2];
	setp.eq.s32	%p2, %r124, 0;
	@%p2 bra 	BB4_93;

	ld.global.u32 	%r12, [%rd2+12];
	ld.global.u32 	%r13, [%rd2+8];
	ld.global.u32 	%r14, [%rd2+4];
	and.b32  	%r134, %r10, 3;
	mov.u32 	%r135, 4;
	sub.s32 	%r136, %r135, %r134;
	shr.u32 	%r15, %r10, 2;
	shl.b32 	%r137, %r136, 2;
	mov.u32 	%r138, 1985229328;
	shr.u32 	%r139, %r138, %r137;
	and.b32  	%r16, %r139, 65535;
	shl.b64 	%rd15, %rd1, 2;
	add.s64 	%rd3, %rd8, %rd15;
	mov.u32 	%r1804, 0;

BB4_3:
	ld.param.u32 	%r1797, [m01000_s04_param_33];
	ld.param.u64 	%rd20, [m01000_s04_param_2];
	mul.wide.u32 	%rd16, %r1804, 260;
	add.s64 	%rd17, %rd20, %rd16;
	ld.global.u32 	%r18, [%rd17+256];
	ld.global.u32 	%r1808, [%rd17];
	ld.global.u32 	%r1807, [%rd17+4];
	ld.global.u32 	%r1806, [%rd17+8];
	ld.global.u32 	%r1805, [%rd17+12];
	ld.global.u32 	%r1812, [%rd17+16];
	ld.global.u32 	%r1811, [%rd17+20];
	ld.global.u32 	%r1810, [%rd17+24];
	ld.global.u32 	%r1809, [%rd17+28];
	setp.eq.s32	%p3, %r1797, 10001;
	@%p3 bra 	BB4_45;
	bra.uni 	BB4_4;

BB4_45:
	setp.gt.s32	%p27, %r15, 7;
	@%p27 bra 	BB4_61;

	setp.gt.s32	%p39, %r15, 3;
	@%p39 bra 	BB4_54;

	setp.gt.s32	%p45, %r15, 1;
	@%p45 bra 	BB4_51;

	setp.eq.s32	%p48, %r15, 0;
	@%p48 bra 	BB4_84;
	bra.uni 	BB4_49;

BB4_84:
	mov.u32 	%r1416, 0;
	// inline asm
	prmt.b32 %r1355, %r1416, %r1416, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1359, %r1416, %r1416, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1363, %r1416, %r1416, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1367, %r1416, %r1416, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1371, %r1416, %r1416, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1375, %r1416, %r1416, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1379, %r1416, %r1416, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1383, %r1809, %r1416, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1809, %r1810, %r1809, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1810, %r1811, %r1810, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1811, %r1812, %r1811, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1812, %r1805, %r1812, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1805, %r1806, %r1805, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1806, %r1807, %r1806, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1807, %r1808, %r1807, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1808, %r1416, %r1808, %r16;
	// inline asm
	bra.uni 	BB4_85;

BB4_4:
	mov.u32 	%r1799, 1985229328;
	mov.u32 	%r1798, 4;
	and.b32  	%r141, %r18, 3;
	sub.s32 	%r143, %r1798, %r141;
	shl.b32 	%r144, %r143, 2;
	shr.u32 	%r146, %r1799, %r144;
	and.b32  	%r27, %r146, 65535;
	shr.u32 	%r140, %r18, 2;
	setp.gt.s32	%p4, %r140, 7;
	@%p4 bra 	BB4_20;

	setp.gt.s32	%p16, %r140, 3;
	@%p16 bra 	BB4_13;

	setp.gt.s32	%p22, %r140, 1;
	@%p22 bra 	BB4_10;

	setp.eq.s32	%p25, %r140, 0;
	@%p25 bra 	BB4_44;
	bra.uni 	BB4_8;

BB4_44:
	mov.u32 	%r780, 0;
	// inline asm
	prmt.b32 %r719, %r780, %r780, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r723, %r780, %r780, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r727, %r780, %r780, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r731, %r780, %r780, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r735, %r780, %r780, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r739, %r780, %r780, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r743, %r780, %r780, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r747, %r9, %r780, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1816, %r8, %r9, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1815, %r7, %r8, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1814, %r6, %r7, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1813, %r5, %r6, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1820, %r4, %r5, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1819, %r3, %r4, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1818, %r2, %r3, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1817, %r780, %r2, %r27;
	// inline asm
	bra.uni 	BB4_86;

BB4_61:
	setp.gt.s32	%p28, %r15, 11;
	@%p28 bra 	BB4_69;

	setp.gt.s32	%p34, %r15, 9;
	@%p34 bra 	BB4_66;

	setp.eq.s32	%p37, %r15, 8;
	@%p37 bra 	BB4_80;
	bra.uni 	BB4_64;

BB4_80:
	// inline asm
	prmt.b32 %r951, %r1810, %r1809, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r955, %r1811, %r1810, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r959, %r1812, %r1811, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r963, %r1805, %r1812, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r967, %r1806, %r1805, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r971, %r1807, %r1806, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r975, %r1808, %r1807, %r16;
	// inline asm
	mov.u32 	%r1805, 0;
	// inline asm
	prmt.b32 %r979, %r1805, %r1808, %r16;
	// inline asm
	bra.uni 	BB4_76;

BB4_20:
	setp.gt.s32	%p5, %r140, 11;
	@%p5 bra 	BB4_28;

	setp.gt.s32	%p11, %r140, 9;
	@%p11 bra 	BB4_25;

	setp.eq.s32	%p14, %r140, 8;
	@%p14 bra 	BB4_40;
	bra.uni 	BB4_23;

BB4_40:
	// inline asm
	prmt.b32 %r315, %r8, %r9, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r319, %r7, %r8, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r323, %r6, %r7, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r327, %r5, %r6, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r331, %r4, %r5, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r335, %r3, %r4, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r339, %r2, %r3, %r27;
	// inline asm
	mov.u32 	%r1813, 0;
	// inline asm
	prmt.b32 %r343, %r1813, %r2, %r27;
	// inline asm
	bra.uni 	BB4_35;

BB4_54:
	setp.gt.s32	%p40, %r15, 5;
	@%p40 bra 	BB4_58;

	setp.eq.s32	%p43, %r15, 4;
	@%p43 bra 	BB4_82;
	bra.uni 	BB4_56;

BB4_82:
	mov.u32 	%r1180, 0;
	// inline asm
	prmt.b32 %r1129, %r1180, %r1180, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1133, %r1180, %r1180, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1137, %r1180, %r1180, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1141, %r1809, %r1180, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1145, %r1810, %r1809, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1149, %r1811, %r1810, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1153, %r1812, %r1811, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1157, %r1805, %r1812, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1809, %r1806, %r1805, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1810, %r1807, %r1806, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1811, %r1808, %r1807, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1812, %r1180, %r1808, %r16;
	// inline asm
	mov.u32 	%r1805, %r1180;
	mov.u32 	%r1806, %r1180;
	mov.u32 	%r1807, %r1180;
	mov.u32 	%r1808, %r1180;
	bra.uni 	BB4_85;

BB4_13:
	setp.gt.s32	%p17, %r140, 5;
	@%p17 bra 	BB4_17;

	setp.eq.s32	%p20, %r140, 4;
	@%p20 bra 	BB4_42;
	bra.uni 	BB4_15;

BB4_42:
	mov.u32 	%r1817, 0;
	// inline asm
	prmt.b32 %r493, %r1817, %r1817, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r497, %r1817, %r1817, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r501, %r1817, %r1817, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r505, %r9, %r1817, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r509, %r8, %r9, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r513, %r7, %r8, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r517, %r6, %r7, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r521, %r5, %r6, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1816, %r4, %r5, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1815, %r3, %r4, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1814, %r2, %r3, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1813, %r1817, %r2, %r27;
	// inline asm
	mov.u32 	%r1818, %r1817;
	mov.u32 	%r1819, %r1817;
	mov.u32 	%r1820, %r1817;
	bra.uni 	BB4_86;

BB4_69:
	setp.gt.s32	%p29, %r15, 13;
	@%p29 bra 	BB4_73;

	setp.eq.s32	%p32, %r15, 12;
	@%p32 bra 	BB4_78;
	bra.uni 	BB4_71;

BB4_78:
	// inline asm
	prmt.b32 %r831, %r1806, %r1805, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r835, %r1807, %r1806, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r839, %r1808, %r1807, %r16;
	// inline asm
	mov.u32 	%r1805, 0;
	// inline asm
	prmt.b32 %r843, %r1805, %r1808, %r16;
	// inline asm
	bra.uni 	BB4_76;

BB4_28:
	setp.gt.s32	%p6, %r140, 13;
	@%p6 bra 	BB4_32;

	setp.eq.s32	%p9, %r140, 12;
	@%p9 bra 	BB4_38;
	bra.uni 	BB4_30;

BB4_38:
	// inline asm
	prmt.b32 %r195, %r4, %r5, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r199, %r3, %r4, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r203, %r2, %r3, %r27;
	// inline asm
	mov.u32 	%r1813, 0;
	// inline asm
	prmt.b32 %r207, %r1813, %r2, %r27;
	// inline asm
	bra.uni 	BB4_35;

BB4_51:
	setp.eq.s32	%p46, %r15, 2;
	@%p46 bra 	BB4_83;
	bra.uni 	BB4_52;

BB4_83:
	mov.u32 	%r1293, 0;
	// inline asm
	prmt.b32 %r1236, %r1293, %r1293, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1240, %r1293, %r1293, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1244, %r1293, %r1293, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1248, %r1293, %r1293, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1252, %r1293, %r1293, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1256, %r1809, %r1293, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1260, %r1810, %r1809, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1264, %r1811, %r1810, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1809, %r1812, %r1811, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1810, %r1805, %r1812, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1811, %r1806, %r1805, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1812, %r1807, %r1806, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1805, %r1808, %r1807, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1806, %r1293, %r1808, %r16;
	// inline asm
	mov.u32 	%r1807, %r1293;
	mov.u32 	%r1808, %r1293;
	bra.uni 	BB4_85;

BB4_10:
	setp.eq.s32	%p23, %r140, 2;
	@%p23 bra 	BB4_43;
	bra.uni 	BB4_11;

BB4_43:
	mov.u32 	%r1817, 0;
	// inline asm
	prmt.b32 %r600, %r1817, %r1817, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r604, %r1817, %r1817, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r608, %r1817, %r1817, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r612, %r1817, %r1817, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r616, %r1817, %r1817, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r620, %r9, %r1817, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r624, %r8, %r9, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r628, %r7, %r8, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1816, %r6, %r7, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1815, %r5, %r6, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1814, %r4, %r5, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1813, %r3, %r4, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1820, %r2, %r3, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1819, %r1817, %r2, %r27;
	// inline asm
	mov.u32 	%r1818, %r1817;
	bra.uni 	BB4_86;

BB4_66:
	setp.eq.s32	%p35, %r15, 10;
	@%p35 bra 	BB4_79;
	bra.uni 	BB4_67;

BB4_79:
	// inline asm
	prmt.b32 %r883, %r1812, %r1811, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r887, %r1805, %r1812, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r891, %r1806, %r1805, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r895, %r1807, %r1806, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r899, %r1808, %r1807, %r16;
	// inline asm
	mov.u32 	%r1805, 0;
	// inline asm
	prmt.b32 %r903, %r1805, %r1808, %r16;
	// inline asm
	bra.uni 	BB4_76;

BB4_25:
	setp.eq.s32	%p12, %r140, 10;
	@%p12 bra 	BB4_39;
	bra.uni 	BB4_26;

BB4_39:
	// inline asm
	prmt.b32 %r247, %r6, %r7, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r251, %r5, %r6, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r255, %r4, %r5, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r259, %r3, %r4, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r263, %r2, %r3, %r27;
	// inline asm
	mov.u32 	%r1813, 0;
	// inline asm
	prmt.b32 %r267, %r1813, %r2, %r27;
	// inline asm
	bra.uni 	BB4_35;

BB4_58:
	setp.eq.s32	%p41, %r15, 6;
	@%p41 bra 	BB4_81;
	bra.uni 	BB4_59;

BB4_81:
	mov.u32 	%r1079, 0;
	// inline asm
	prmt.b32 %r1034, %r1079, %r1079, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1038, %r1809, %r1079, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1042, %r1810, %r1809, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1046, %r1811, %r1810, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1050, %r1812, %r1811, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1054, %r1805, %r1812, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1058, %r1806, %r1805, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1062, %r1807, %r1806, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1809, %r1808, %r1807, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1810, %r1079, %r1808, %r16;
	// inline asm
	mov.u32 	%r1805, %r1079;
	mov.u32 	%r1806, %r1079;
	mov.u32 	%r1807, %r1079;
	mov.u32 	%r1808, %r1079;
	mov.u32 	%r1811, %r1079;
	mov.u32 	%r1812, %r1079;
	bra.uni 	BB4_85;

BB4_17:
	setp.eq.s32	%p18, %r140, 6;
	@%p18 bra 	BB4_41;
	bra.uni 	BB4_18;

BB4_41:
	mov.u32 	%r1813, 0;
	// inline asm
	prmt.b32 %r398, %r1813, %r1813, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r402, %r9, %r1813, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r406, %r8, %r9, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r410, %r7, %r8, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r414, %r6, %r7, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r418, %r5, %r6, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r422, %r4, %r5, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r426, %r3, %r4, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1816, %r2, %r3, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1815, %r1813, %r2, %r27;
	// inline asm
	mov.u32 	%r1814, %r1813;
	bra.uni 	BB4_36;

BB4_73:
	setp.eq.s32	%p30, %r15, 14;
	@%p30 bra 	BB4_77;
	bra.uni 	BB4_74;

BB4_77:
	// inline asm
	prmt.b32 %r795, %r1808, %r1807, %r16;
	// inline asm
	mov.u32 	%r1805, 0;
	// inline asm
	prmt.b32 %r799, %r1805, %r1808, %r16;
	// inline asm
	bra.uni 	BB4_76;

BB4_32:
	setp.eq.s32	%p7, %r140, 14;
	@%p7 bra 	BB4_37;
	bra.uni 	BB4_33;

BB4_37:
	// inline asm
	prmt.b32 %r159, %r2, %r3, %r27;
	// inline asm
	mov.u32 	%r1813, 0;
	// inline asm
	prmt.b32 %r163, %r1813, %r2, %r27;
	// inline asm
	bra.uni 	BB4_35;

BB4_49:
	setp.eq.s32	%p49, %r15, 1;
	@%p49 bra 	BB4_50;
	bra.uni 	BB4_85;

BB4_50:
	mov.u32 	%r1354, 0;
	// inline asm
	prmt.b32 %r1294, %r1354, %r1354, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1298, %r1354, %r1354, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1302, %r1354, %r1354, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1306, %r1354, %r1354, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1310, %r1354, %r1354, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1314, %r1354, %r1354, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1318, %r1809, %r1354, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1322, %r1810, %r1809, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1809, %r1811, %r1810, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1810, %r1812, %r1811, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1811, %r1805, %r1812, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1812, %r1806, %r1805, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1805, %r1807, %r1806, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1806, %r1808, %r1807, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1807, %r1354, %r1808, %r16;
	// inline asm
	mov.u32 	%r1808, %r1354;
	bra.uni 	BB4_85;

BB4_8:
	setp.eq.s32	%p26, %r140, 1;
	@%p26 bra 	BB4_9;
	bra.uni 	BB4_85;

BB4_9:
	mov.u32 	%r1817, 0;
	// inline asm
	prmt.b32 %r658, %r1817, %r1817, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r662, %r1817, %r1817, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r666, %r1817, %r1817, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r670, %r1817, %r1817, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r674, %r1817, %r1817, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r678, %r1817, %r1817, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r682, %r9, %r1817, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r686, %r8, %r9, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1816, %r7, %r8, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1815, %r6, %r7, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1814, %r5, %r6, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1813, %r4, %r5, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1820, %r3, %r4, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1819, %r2, %r3, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1818, %r1817, %r2, %r27;
	// inline asm
	bra.uni 	BB4_86;

BB4_64:
	setp.eq.s32	%p38, %r15, 9;
	@%p38 bra 	BB4_65;
	bra.uni 	BB4_85;

BB4_65:
	// inline asm
	prmt.b32 %r915, %r1811, %r1810, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r919, %r1812, %r1811, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r923, %r1805, %r1812, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r927, %r1806, %r1805, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r931, %r1807, %r1806, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r935, %r1808, %r1807, %r16;
	// inline asm
	mov.u32 	%r1805, 0;
	// inline asm
	prmt.b32 %r939, %r1805, %r1808, %r16;
	// inline asm
	bra.uni 	BB4_76;

BB4_23:
	setp.eq.s32	%p15, %r140, 9;
	@%p15 bra 	BB4_24;
	bra.uni 	BB4_85;

BB4_24:
	// inline asm
	prmt.b32 %r279, %r7, %r8, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r283, %r6, %r7, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r287, %r5, %r6, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r291, %r4, %r5, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r295, %r3, %r4, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r299, %r2, %r3, %r27;
	// inline asm
	mov.u32 	%r1813, 0;
	// inline asm
	prmt.b32 %r303, %r1813, %r2, %r27;
	// inline asm
	bra.uni 	BB4_35;

BB4_56:
	setp.eq.s32	%p44, %r15, 5;
	@%p44 bra 	BB4_57;
	bra.uni 	BB4_85;

BB4_57:
	mov.u32 	%r1128, 0;
	// inline asm
	prmt.b32 %r1080, %r1128, %r1128, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1084, %r1128, %r1128, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1088, %r1809, %r1128, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1092, %r1810, %r1809, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1096, %r1811, %r1810, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1100, %r1812, %r1811, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1104, %r1805, %r1812, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1108, %r1806, %r1805, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1809, %r1807, %r1806, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1810, %r1808, %r1807, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1811, %r1128, %r1808, %r16;
	// inline asm
	mov.u32 	%r1805, %r1128;
	mov.u32 	%r1806, %r1128;
	mov.u32 	%r1807, %r1128;
	mov.u32 	%r1808, %r1128;
	mov.u32 	%r1812, %r1128;
	bra.uni 	BB4_85;

BB4_15:
	setp.eq.s32	%p21, %r140, 5;
	@%p21 bra 	BB4_16;
	bra.uni 	BB4_85;

BB4_16:
	mov.u32 	%r1813, 0;
	// inline asm
	prmt.b32 %r444, %r1813, %r1813, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r448, %r1813, %r1813, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r452, %r9, %r1813, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r456, %r8, %r9, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r460, %r7, %r8, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r464, %r6, %r7, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r468, %r5, %r6, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r472, %r4, %r5, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1816, %r3, %r4, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1815, %r2, %r3, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1814, %r1813, %r2, %r27;
	// inline asm
	bra.uni 	BB4_36;

BB4_71:
	setp.eq.s32	%p33, %r15, 13;
	@%p33 bra 	BB4_72;
	bra.uni 	BB4_85;

BB4_72:
	// inline asm
	prmt.b32 %r811, %r1807, %r1806, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r815, %r1808, %r1807, %r16;
	// inline asm
	mov.u32 	%r1805, 0;
	// inline asm
	prmt.b32 %r819, %r1805, %r1808, %r16;
	// inline asm
	bra.uni 	BB4_76;

BB4_30:
	setp.eq.s32	%p10, %r140, 13;
	@%p10 bra 	BB4_31;
	bra.uni 	BB4_85;

BB4_31:
	// inline asm
	prmt.b32 %r175, %r3, %r4, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r179, %r2, %r3, %r27;
	// inline asm
	mov.u32 	%r1813, 0;
	// inline asm
	prmt.b32 %r183, %r1813, %r2, %r27;
	// inline asm
	bra.uni 	BB4_35;

BB4_52:
	setp.eq.s32	%p47, %r15, 3;
	@%p47 bra 	BB4_53;
	bra.uni 	BB4_85;

BB4_53:
	mov.u32 	%r1235, 0;
	// inline asm
	prmt.b32 %r1181, %r1235, %r1235, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1185, %r1235, %r1235, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1189, %r1235, %r1235, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1193, %r1235, %r1235, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1197, %r1809, %r1235, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1201, %r1810, %r1809, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1205, %r1811, %r1810, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1209, %r1812, %r1811, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1809, %r1805, %r1812, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1810, %r1806, %r1805, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1811, %r1807, %r1806, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1812, %r1808, %r1807, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1805, %r1235, %r1808, %r16;
	// inline asm
	mov.u32 	%r1806, %r1235;
	mov.u32 	%r1807, %r1235;
	mov.u32 	%r1808, %r1235;
	bra.uni 	BB4_85;

BB4_11:
	setp.eq.s32	%p24, %r140, 3;
	@%p24 bra 	BB4_12;
	bra.uni 	BB4_85;

BB4_12:
	mov.u32 	%r1817, 0;
	// inline asm
	prmt.b32 %r545, %r1817, %r1817, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r549, %r1817, %r1817, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r553, %r1817, %r1817, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r557, %r1817, %r1817, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r561, %r9, %r1817, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r565, %r8, %r9, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r569, %r7, %r8, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r573, %r6, %r7, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1816, %r5, %r6, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1815, %r4, %r5, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1814, %r3, %r4, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1813, %r2, %r3, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1820, %r1817, %r2, %r27;
	// inline asm
	mov.u32 	%r1818, %r1817;
	mov.u32 	%r1819, %r1817;
	bra.uni 	BB4_86;

BB4_67:
	setp.eq.s32	%p36, %r15, 11;
	@%p36 bra 	BB4_68;
	bra.uni 	BB4_85;

BB4_68:
	// inline asm
	prmt.b32 %r855, %r1805, %r1812, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r859, %r1806, %r1805, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r863, %r1807, %r1806, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r867, %r1808, %r1807, %r16;
	// inline asm
	mov.u32 	%r1805, 0;
	// inline asm
	prmt.b32 %r871, %r1805, %r1808, %r16;
	// inline asm
	bra.uni 	BB4_76;

BB4_26:
	setp.eq.s32	%p13, %r140, 11;
	@%p13 bra 	BB4_27;
	bra.uni 	BB4_85;

BB4_27:
	// inline asm
	prmt.b32 %r219, %r5, %r6, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r223, %r4, %r5, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r227, %r3, %r4, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r231, %r2, %r3, %r27;
	// inline asm
	mov.u32 	%r1813, 0;
	// inline asm
	prmt.b32 %r235, %r1813, %r2, %r27;
	// inline asm
	bra.uni 	BB4_35;

BB4_59:
	setp.eq.s32	%p42, %r15, 7;
	@%p42 bra 	BB4_60;
	bra.uni 	BB4_85;

BB4_60:
	mov.u32 	%r1033, 0;
	// inline asm
	prmt.b32 %r991, %r1809, %r1033, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r995, %r1810, %r1809, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r999, %r1811, %r1810, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1003, %r1812, %r1811, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1007, %r1805, %r1812, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1011, %r1806, %r1805, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1015, %r1807, %r1806, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1019, %r1808, %r1807, %r16;
	// inline asm
	// inline asm
	prmt.b32 %r1809, %r1033, %r1808, %r16;
	// inline asm
	mov.u32 	%r1805, %r1033;
	mov.u32 	%r1806, %r1033;
	mov.u32 	%r1807, %r1033;
	mov.u32 	%r1808, %r1033;
	mov.u32 	%r1810, %r1033;
	mov.u32 	%r1811, %r1033;
	mov.u32 	%r1812, %r1033;
	bra.uni 	BB4_85;

BB4_18:
	setp.eq.s32	%p19, %r140, 7;
	@%p19 bra 	BB4_19;
	bra.uni 	BB4_85;

BB4_19:
	mov.u32 	%r1813, 0;
	// inline asm
	prmt.b32 %r355, %r9, %r1813, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r359, %r8, %r9, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r363, %r7, %r8, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r367, %r6, %r7, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r371, %r5, %r6, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r375, %r4, %r5, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r379, %r3, %r4, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r383, %r2, %r3, %r27;
	// inline asm
	// inline asm
	prmt.b32 %r1816, %r1813, %r2, %r27;
	// inline asm
	mov.u32 	%r1814, %r1813;
	mov.u32 	%r1815, %r1813;
	bra.uni 	BB4_36;

BB4_74:
	setp.ne.s32	%p31, %r15, 15;
	@%p31 bra 	BB4_85;

	mov.u32 	%r1805, 0;
	// inline asm
	prmt.b32 %r783, %r1805, %r1808, %r16;
	// inline asm

BB4_76:
	mov.u32 	%r1806, %r1805;
	mov.u32 	%r1807, %r1805;
	mov.u32 	%r1808, %r1805;
	mov.u32 	%r1809, %r1805;
	mov.u32 	%r1810, %r1805;
	mov.u32 	%r1811, %r1805;
	mov.u32 	%r1812, %r1805;

BB4_85:
	mov.u32 	%r1813, %r6;
	mov.u32 	%r1814, %r7;
	mov.u32 	%r1815, %r8;
	mov.u32 	%r1816, %r9;
	mov.u32 	%r1817, %r2;
	mov.u32 	%r1818, %r3;
	mov.u32 	%r1819, %r4;
	mov.u32 	%r1820, %r5;
	bra.uni 	BB4_86;

BB4_33:
	setp.ne.s32	%p8, %r140, 15;
	@%p8 bra 	BB4_85;

	mov.u32 	%r1813, 0;
	// inline asm
	prmt.b32 %r147, %r1813, %r2, %r27;
	// inline asm

BB4_35:
	mov.u32 	%r1814, %r1813;
	mov.u32 	%r1815, %r1813;
	mov.u32 	%r1816, %r1813;

BB4_36:
	mov.u32 	%r1817, %r1813;
	mov.u32 	%r1818, %r1813;
	mov.u32 	%r1819, %r1813;
	mov.u32 	%r1820, %r1813;

BB4_86:
	or.b32  	%r1424, %r1816, %r1809;
	mov.u32 	%r1481, 0;
	mov.u32 	%r1478, 29554;
	// inline asm
	prmt.b32 %r1419, %r1424, %r1481, %r1478;
	// inline asm
	mov.u32 	%r1482, 29040;
	// inline asm
	prmt.b32 %r1423, %r1424, %r1481, %r1482;
	// inline asm
	or.b32  	%r1432, %r1815, %r1810;
	// inline asm
	prmt.b32 %r1427, %r1432, %r1481, %r1478;
	// inline asm
	// inline asm
	prmt.b32 %r1431, %r1432, %r1481, %r1482;
	// inline asm
	or.b32  	%r1440, %r1814, %r1811;
	// inline asm
	prmt.b32 %r1435, %r1440, %r1481, %r1478;
	// inline asm
	// inline asm
	prmt.b32 %r1439, %r1440, %r1481, %r1482;
	// inline asm
	or.b32  	%r1448, %r1813, %r1812;
	// inline asm
	prmt.b32 %r1443, %r1448, %r1481, %r1478;
	// inline asm
	// inline asm
	prmt.b32 %r1447, %r1448, %r1481, %r1482;
	// inline asm
	or.b32  	%r1456, %r1820, %r1805;
	// inline asm
	prmt.b32 %r1451, %r1456, %r1481, %r1478;
	// inline asm
	// inline asm
	prmt.b32 %r1455, %r1456, %r1481, %r1482;
	// inline asm
	or.b32  	%r1464, %r1819, %r1806;
	// inline asm
	prmt.b32 %r1459, %r1464, %r1481, %r1478;
	// inline asm
	// inline asm
	prmt.b32 %r1463, %r1464, %r1481, %r1482;
	// inline asm
	or.b32  	%r1472, %r1818, %r1807;
	// inline asm
	prmt.b32 %r1467, %r1472, %r1481, %r1478;
	// inline asm
	// inline asm
	prmt.b32 %r1471, %r1472, %r1481, %r1482;
	// inline asm
	or.b32  	%r1480, %r1817, %r1808;
	// inline asm
	prmt.b32 %r1475, %r1480, %r1481, %r1478;
	// inline asm
	// inline asm
	prmt.b32 %r1479, %r1480, %r1481, %r1482;
	// inline asm
	add.s32 	%r1483, %r1479, -1;
	shf.l.wrap.b32 	%r1484, %r1483, %r1483, 3;
	and.b32  	%r1485, %r1484, 2004318071;
	xor.b32  	%r1486, %r1485, -1732584194;
	add.s32 	%r1487, %r1475, %r1486;
	add.s32 	%r1488, %r1487, 271733878;
	shf.l.wrap.b32 	%r1489, %r1488, %r1488, 7;
	xor.b32  	%r1490, %r1484, -271733879;
	and.b32  	%r1491, %r1490, %r1489;
	xor.b32  	%r1492, %r1491, -271733879;
	add.s32 	%r1493, %r1471, %r1492;
	add.s32 	%r1494, %r1493, -1732584194;
	shf.l.wrap.b32 	%r1495, %r1494, %r1494, 11;
	xor.b32  	%r1496, %r1489, %r1484;
	and.b32  	%r1497, %r1496, %r1495;
	xor.b32  	%r1498, %r1497, %r1484;
	add.s32 	%r1499, %r1467, %r1498;
	add.s32 	%r1500, %r1499, -271733879;
	shf.l.wrap.b32 	%r1501, %r1500, %r1500, 19;
	xor.b32  	%r1502, %r1495, %r1489;
	and.b32  	%r1503, %r1502, %r1501;
	xor.b32  	%r1504, %r1503, %r1489;
	add.s32 	%r1505, %r1484, %r1463;
	add.s32 	%r1506, %r1505, %r1504;
	shf.l.wrap.b32 	%r1507, %r1506, %r1506, 3;
	xor.b32  	%r1508, %r1501, %r1495;
	and.b32  	%r1509, %r1508, %r1507;
	xor.b32  	%r1510, %r1509, %r1495;
	add.s32 	%r1511, %r1489, %r1459;
	add.s32 	%r1512, %r1511, %r1510;
	shf.l.wrap.b32 	%r1513, %r1512, %r1512, 7;
	xor.b32  	%r1514, %r1507, %r1501;
	and.b32  	%r1515, %r1514, %r1513;
	xor.b32  	%r1516, %r1515, %r1501;
	add.s32 	%r1517, %r1495, %r1455;
	add.s32 	%r1518, %r1517, %r1516;
	shf.l.wrap.b32 	%r1519, %r1518, %r1518, 11;
	xor.b32  	%r1520, %r1513, %r1507;
	and.b32  	%r1521, %r1520, %r1519;
	xor.b32  	%r1522, %r1521, %r1507;
	add.s32 	%r1523, %r1501, %r1451;
	add.s32 	%r1524, %r1523, %r1522;
	shf.l.wrap.b32 	%r1525, %r1524, %r1524, 19;
	xor.b32  	%r1526, %r1519, %r1513;
	and.b32  	%r1527, %r1526, %r1525;
	xor.b32  	%r1528, %r1527, %r1513;
	add.s32 	%r1529, %r1507, %r1447;
	add.s32 	%r1530, %r1529, %r1528;
	shf.l.wrap.b32 	%r1531, %r1530, %r1530, 3;
	xor.b32  	%r1532, %r1525, %r1519;
	and.b32  	%r1533, %r1532, %r1531;
	xor.b32  	%r1534, %r1533, %r1519;
	add.s32 	%r1535, %r1513, %r1443;
	add.s32 	%r1536, %r1535, %r1534;
	shf.l.wrap.b32 	%r1537, %r1536, %r1536, 7;
	xor.b32  	%r1538, %r1531, %r1525;
	and.b32  	%r1539, %r1538, %r1537;
	xor.b32  	%r1540, %r1539, %r1525;
	add.s32 	%r1541, %r1519, %r1439;
	add.s32 	%r1542, %r1541, %r1540;
	shf.l.wrap.b32 	%r1543, %r1542, %r1542, 11;
	xor.b32  	%r1544, %r1537, %r1531;
	and.b32  	%r1545, %r1544, %r1543;
	xor.b32  	%r1546, %r1545, %r1531;
	add.s32 	%r1547, %r1525, %r1435;
	add.s32 	%r1548, %r1547, %r1546;
	shf.l.wrap.b32 	%r1549, %r1548, %r1548, 19;
	xor.b32  	%r1550, %r1543, %r1537;
	and.b32  	%r1551, %r1550, %r1549;
	xor.b32  	%r1552, %r1551, %r1537;
	add.s32 	%r1553, %r1531, %r1431;
	add.s32 	%r1554, %r1553, %r1552;
	shf.l.wrap.b32 	%r1555, %r1554, %r1554, 3;
	xor.b32  	%r1556, %r1549, %r1543;
	and.b32  	%r1557, %r1556, %r1555;
	xor.b32  	%r1558, %r1557, %r1543;
	add.s32 	%r1559, %r1537, %r1427;
	add.s32 	%r1560, %r1559, %r1558;
	shf.l.wrap.b32 	%r1561, %r1560, %r1560, 7;
	xor.b32  	%r1562, %r1555, %r1549;
	and.b32  	%r1563, %r1562, %r1561;
	xor.b32  	%r1564, %r1563, %r1549;
	add.s32 	%r1565, %r18, %r10;
	shl.b32 	%r1566, %r1565, 4;
	add.s32 	%r1567, %r1543, %r1566;
	add.s32 	%r1568, %r1567, %r1564;
	shf.l.wrap.b32 	%r1569, %r1568, %r1568, 11;
	xor.b32  	%r1570, %r1561, %r1555;
	and.b32  	%r1571, %r1570, %r1569;
	xor.b32  	%r1572, %r1571, %r1555;
	add.s32 	%r1573, %r1572, %r1549;
	shf.l.wrap.b32 	%r1574, %r1573, %r1573, 19;
	xor.b32  	%r1575, %r1574, %r1561;
	xor.b32  	%r1576, %r1574, %r1569;
	and.b32  	%r1577, %r1576, %r1575;
	xor.b32  	%r1578, %r1577, %r1574;
	add.s32 	%r1579, %r1479, %r1555;
	add.s32 	%r1580, %r1579, %r1578;
	add.s32 	%r1581, %r1580, 1518500249;
	shf.l.wrap.b32 	%r1582, %r1581, %r1581, 3;
	xor.b32  	%r1583, %r1582, %r1569;
	xor.b32  	%r1584, %r1582, %r1574;
	and.b32  	%r1585, %r1584, %r1583;
	xor.b32  	%r1586, %r1585, %r1582;
	add.s32 	%r1587, %r1463, %r1561;
	add.s32 	%r1588, %r1587, %r1586;
	add.s32 	%r1589, %r1588, 1518500249;
	shf.l.wrap.b32 	%r1590, %r1589, %r1589, 5;
	xor.b32  	%r1591, %r1590, %r1574;
	xor.b32  	%r1592, %r1590, %r1582;
	and.b32  	%r1593, %r1592, %r1591;
	xor.b32  	%r1594, %r1593, %r1590;
	add.s32 	%r1595, %r1447, %r1569;
	add.s32 	%r1596, %r1595, %r1594;
	add.s32 	%r1597, %r1596, 1518500249;
	shf.l.wrap.b32 	%r1598, %r1597, %r1597, 9;
	xor.b32  	%r1599, %r1598, %r1582;
	xor.b32  	%r1600, %r1598, %r1590;
	and.b32  	%r1601, %r1600, %r1599;
	xor.b32  	%r1602, %r1601, %r1598;
	add.s32 	%r1603, %r1431, %r1574;
	add.s32 	%r1604, %r1603, %r1602;
	add.s32 	%r1605, %r1604, 1518500249;
	shf.l.wrap.b32 	%r1606, %r1605, %r1605, 13;
	xor.b32  	%r1607, %r1606, %r1590;
	xor.b32  	%r1608, %r1606, %r1598;
	and.b32  	%r1609, %r1608, %r1607;
	xor.b32  	%r1610, %r1609, %r1606;
	add.s32 	%r1611, %r1475, %r1582;
	add.s32 	%r1612, %r1611, %r1610;
	add.s32 	%r1613, %r1612, 1518500249;
	shf.l.wrap.b32 	%r1614, %r1613, %r1613, 3;
	xor.b32  	%r1615, %r1614, %r1598;
	xor.b32  	%r1616, %r1614, %r1606;
	and.b32  	%r1617, %r1616, %r1615;
	xor.b32  	%r1618, %r1617, %r1614;
	add.s32 	%r1619, %r1459, %r1590;
	add.s32 	%r1620, %r1619, %r1618;
	add.s32 	%r1621, %r1620, 1518500249;
	shf.l.wrap.b32 	%r1622, %r1621, %r1621, 5;
	xor.b32  	%r1623, %r1622, %r1606;
	xor.b32  	%r1624, %r1622, %r1614;
	and.b32  	%r1625, %r1624, %r1623;
	xor.b32  	%r1626, %r1625, %r1622;
	add.s32 	%r1627, %r1443, %r1598;
	add.s32 	%r1628, %r1627, %r1626;
	add.s32 	%r1629, %r1628, 1518500249;
	shf.l.wrap.b32 	%r1630, %r1629, %r1629, 9;
	xor.b32  	%r1631, %r1630, %r1614;
	xor.b32  	%r1632, %r1630, %r1622;
	and.b32  	%r1633, %r1632, %r1631;
	xor.b32  	%r1634, %r1633, %r1630;
	add.s32 	%r1635, %r1427, %r1606;
	add.s32 	%r1636, %r1635, %r1634;
	add.s32 	%r1637, %r1636, 1518500249;
	shf.l.wrap.b32 	%r1638, %r1637, %r1637, 13;
	xor.b32  	%r1639, %r1638, %r1622;
	xor.b32  	%r1640, %r1638, %r1630;
	and.b32  	%r1641, %r1640, %r1639;
	xor.b32  	%r1642, %r1641, %r1638;
	add.s32 	%r1643, %r1471, %r1614;
	add.s32 	%r1644, %r1643, %r1642;
	add.s32 	%r1645, %r1644, 1518500249;
	shf.l.wrap.b32 	%r1646, %r1645, %r1645, 3;
	xor.b32  	%r1647, %r1646, %r1630;
	xor.b32  	%r1648, %r1646, %r1638;
	and.b32  	%r1649, %r1648, %r1647;
	xor.b32  	%r1650, %r1649, %r1646;
	add.s32 	%r1651, %r1455, %r1622;
	add.s32 	%r1652, %r1651, %r1650;
	add.s32 	%r1653, %r1652, 1518500249;
	shf.l.wrap.b32 	%r1654, %r1653, %r1653, 5;
	xor.b32  	%r1655, %r1654, %r1638;
	xor.b32  	%r1656, %r1654, %r1646;
	and.b32  	%r1657, %r1656, %r1655;
	xor.b32  	%r1658, %r1657, %r1654;
	add.s32 	%r1659, %r1439, %r1630;
	add.s32 	%r1660, %r1659, %r1658;
	add.s32 	%r1661, %r1660, 1518500249;
	shf.l.wrap.b32 	%r1662, %r1661, %r1661, 9;
	xor.b32  	%r1663, %r1662, %r1646;
	xor.b32  	%r1664, %r1662, %r1654;
	and.b32  	%r1665, %r1664, %r1663;
	xor.b32  	%r1666, %r1665, %r1662;
	add.s32 	%r1667, %r1566, %r1638;
	add.s32 	%r1668, %r1667, %r1666;
	add.s32 	%r1669, %r1668, 1518500249;
	shf.l.wrap.b32 	%r1670, %r1669, %r1669, 13;
	xor.b32  	%r1671, %r1670, %r1654;
	xor.b32  	%r1672, %r1670, %r1662;
	and.b32  	%r1673, %r1672, %r1671;
	xor.b32  	%r1674, %r1673, %r1670;
	add.s32 	%r1675, %r1467, %r1646;
	add.s32 	%r1676, %r1675, %r1674;
	add.s32 	%r1677, %r1676, 1518500249;
	shf.l.wrap.b32 	%r1678, %r1677, %r1677, 3;
	xor.b32  	%r1679, %r1678, %r1662;
	xor.b32  	%r1680, %r1678, %r1670;
	and.b32  	%r1681, %r1680, %r1679;
	xor.b32  	%r1682, %r1681, %r1678;
	add.s32 	%r1683, %r1451, %r1654;
	add.s32 	%r1684, %r1683, %r1682;
	add.s32 	%r1685, %r1684, 1518500249;
	shf.l.wrap.b32 	%r1686, %r1685, %r1685, 5;
	xor.b32  	%r1687, %r1686, %r1670;
	xor.b32  	%r1688, %r1686, %r1678;
	and.b32  	%r1689, %r1688, %r1687;
	xor.b32  	%r1690, %r1689, %r1686;
	add.s32 	%r1691, %r1435, %r1662;
	add.s32 	%r1692, %r1691, %r1690;
	add.s32 	%r1693, %r1692, 1518500249;
	shf.l.wrap.b32 	%r1694, %r1693, %r1693, 9;
	xor.b32  	%r1695, %r1694, %r1678;
	xor.b32  	%r1696, %r1694, %r1686;
	and.b32  	%r1697, %r1696, %r1695;
	xor.b32  	%r1698, %r1697, %r1694;
	add.s32 	%r1699, %r1670, %r1698;
	add.s32 	%r1700, %r1699, 1518500249;
	shf.l.wrap.b32 	%r1701, %r1700, %r1700, 13;
	xor.b32  	%r1702, %r1696, %r1701;
	add.s32 	%r1703, %r1479, %r1678;
	add.s32 	%r1704, %r1703, %r1702;
	add.s32 	%r1705, %r1704, 1859775393;
	shf.l.wrap.b32 	%r1706, %r1705, %r1705, 3;
	xor.b32  	%r1707, %r1701, %r1694;
	xor.b32  	%r1708, %r1707, %r1706;
	add.s32 	%r1709, %r1447, %r1686;
	add.s32 	%r1710, %r1709, %r1708;
	add.s32 	%r1711, %r1710, 1859775393;
	shf.l.wrap.b32 	%r1712, %r1711, %r1711, 9;
	xor.b32  	%r1713, %r1706, %r1701;
	xor.b32  	%r1714, %r1713, %r1712;
	add.s32 	%r1715, %r1463, %r1694;
	add.s32 	%r1716, %r1715, %r1714;
	add.s32 	%r1717, %r1716, 1859775393;
	shf.l.wrap.b32 	%r1718, %r1717, %r1717, 11;
	xor.b32  	%r1719, %r1712, %r1706;
	xor.b32  	%r1720, %r1719, %r1718;
	add.s32 	%r1721, %r1431, %r1701;
	add.s32 	%r1722, %r1721, %r1720;
	add.s32 	%r1723, %r1722, 1859775393;
	shf.l.wrap.b32 	%r1724, %r1723, %r1723, 15;
	xor.b32  	%r1725, %r1718, %r1712;
	xor.b32  	%r1726, %r1725, %r1724;
	add.s32 	%r1727, %r1471, %r1706;
	add.s32 	%r1728, %r1727, %r1726;
	add.s32 	%r1729, %r1728, 1859775393;
	shf.l.wrap.b32 	%r1730, %r1729, %r1729, 3;
	xor.b32  	%r1731, %r1724, %r1718;
	xor.b32  	%r1732, %r1731, %r1730;
	add.s32 	%r1733, %r1439, %r1712;
	add.s32 	%r1734, %r1733, %r1732;
	add.s32 	%r1735, %r1734, 1859775393;
	shf.l.wrap.b32 	%r1736, %r1735, %r1735, 9;
	xor.b32  	%r1737, %r1730, %r1724;
	xor.b32  	%r1738, %r1737, %r1736;
	add.s32 	%r1739, %r1455, %r1718;
	add.s32 	%r1740, %r1739, %r1738;
	add.s32 	%r1741, %r1740, 1859775393;
	shf.l.wrap.b32 	%r1742, %r1741, %r1741, 11;
	xor.b32  	%r1743, %r1736, %r1730;
	xor.b32  	%r1744, %r1743, %r1742;
	add.s32 	%r1745, %r1566, %r1724;
	add.s32 	%r1746, %r1745, %r1744;
	add.s32 	%r1747, %r1746, 1859775393;
	shf.l.wrap.b32 	%r1748, %r1747, %r1747, 15;
	xor.b32  	%r1749, %r1742, %r1736;
	xor.b32  	%r1750, %r1749, %r1748;
	add.s32 	%r1751, %r1475, %r1730;
	add.s32 	%r1752, %r1751, %r1750;
	add.s32 	%r1753, %r1752, 1859775393;
	shf.l.wrap.b32 	%r1754, %r1753, %r1753, 3;
	xor.b32  	%r1755, %r1748, %r1742;
	xor.b32  	%r1756, %r1755, %r1754;
	add.s32 	%r1757, %r1443, %r1736;
	add.s32 	%r1758, %r1757, %r1756;
	add.s32 	%r1759, %r1758, 1859775393;
	shf.l.wrap.b32 	%r118, %r1759, %r1759, 9;
	xor.b32  	%r1760, %r1754, %r1748;
	xor.b32  	%r1761, %r1760, %r118;
	add.s32 	%r1762, %r1459, %r1742;
	add.s32 	%r1763, %r1762, %r1761;
	add.s32 	%r1764, %r1763, 1859775393;
	shf.l.wrap.b32 	%r119, %r1764, %r1764, 11;
	xor.b32  	%r1765, %r118, %r1754;
	xor.b32  	%r1766, %r1765, %r119;
	add.s32 	%r1767, %r1427, %r1748;
	add.s32 	%r1768, %r1767, %r1766;
	add.s32 	%r1769, %r1768, 1859775393;
	shf.l.wrap.b32 	%r120, %r1769, %r1769, 15;
	xor.b32  	%r1770, %r119, %r118;
	xor.b32  	%r1771, %r1770, %r120;
	add.s32 	%r1772, %r1467, %r1754;
	add.s32 	%r1773, %r1772, %r1771;
	add.s32 	%r1774, %r1773, 1859775393;
	shf.l.wrap.b32 	%r1775, %r1774, %r1774, 3;
	setp.ne.s32	%p50, %r1775, %r11;
	@%p50 bra 	BB4_92;

	xor.b32  	%r1776, %r119, %r11;
	xor.b32  	%r1777, %r1776, %r120;
	add.s32 	%r1778, %r1435, %r118;
	add.s32 	%r1779, %r1778, %r1777;
	add.s32 	%r1780, %r1779, 1859775393;
	shf.l.wrap.b32 	%r1781, %r1780, %r1780, 9;
	xor.b32  	%r1782, %r120, %r11;
	xor.b32  	%r1783, %r1782, %r1781;
	add.s32 	%r1784, %r1451, %r119;
	add.s32 	%r1785, %r1784, %r1783;
	add.s32 	%r1786, %r1785, 1859775393;
	shf.l.wrap.b32 	%r1787, %r1786, %r1786, 11;
	xor.b32  	%r1788, %r1781, %r11;
	xor.b32  	%r1789, %r1788, %r1787;
	add.s32 	%r1790, %r120, %r1789;
	add.s32 	%r1791, %r1790, 1859775393;
	shf.l.wrap.b32 	%r1792, %r1791, %r1791, 15;
	setp.eq.s32	%p51, %r1781, %r12;
	setp.eq.s32	%p52, %r1787, %r13;
	and.pred  	%p53, %p51, %p52;
	setp.eq.s32	%p54, %r1792, %r14;
	and.pred  	%p55, %p53, %p54;
	@!%p55 bra 	BB4_92;
	bra.uni 	BB4_88;

BB4_88:
	atom.global.add.u32 	%r1793, [%rd3], 1;
	setp.ne.s32	%p56, %r1793, 0;
	@%p56 bra 	BB4_92;

	ld.param.u32 	%r1800, [m01000_s04_param_31];
	atom.global.add.u32 	%r121, [%rd9], 1;
	setp.lt.u32	%p57, %r121, %r1800;
	@%p57 bra 	BB4_91;
	bra.uni 	BB4_90;

BB4_91:
	ld.param.u32 	%r1803, [m01000_s04_param_32];
	mov.u32 	%r1802, 0;
	ld.param.u32 	%r1801, [m01000_s04_param_27];
	ld.param.u64 	%rd21, [m01000_s04_param_14];
	mul.wide.u32 	%rd18, %r121, 20;
	add.s64 	%rd19, %rd21, %rd18;
	st.global.u32 	[%rd19], %r1801;
	st.global.u32 	[%rd19+4], %r1802;
	st.global.u32 	[%rd19+8], %r1803;
	st.global.u32 	[%rd19+12], %r1;
	st.global.u32 	[%rd19+16], %r1804;
	bra.uni 	BB4_92;

BB4_90:
	atom.global.add.u32 	%r1794, [%rd9], -1;

BB4_92:
	ld.param.u32 	%r1796, [m01000_s04_param_30];
	add.s32 	%r1804, %r1804, 1;
	setp.lt.u32	%p58, %r1804, %r1796;
	@%p58 bra 	BB4_3;

BB4_93:
	ret;
}

	// .globl	m01000_s08
.entry m01000_s08(
	.param .u64 .ptr .global .align 4 m01000_s08_param_0,
	.param .u64 .ptr .global .align 4 m01000_s08_param_1,
	.param .u64 .ptr .global .align 4 m01000_s08_param_2,
	.param .u64 .ptr .global .align 4 m01000_s08_param_3,
	.param .u64 .ptr .global .align 1 m01000_s08_param_4,
	.param .u64 .ptr .global .align 1 m01000_s08_param_5,
	.param .u64 .ptr .global .align 4 m01000_s08_param_6,
	.param .u64 .ptr .global .align 4 m01000_s08_param_7,
	.param .u64 .ptr .global .align 4 m01000_s08_param_8,
	.param .u64 .ptr .global .align 4 m01000_s08_param_9,
	.param .u64 .ptr .global .align 4 m01000_s08_param_10,
	.param .u64 .ptr .global .align 4 m01000_s08_param_11,
	.param .u64 .ptr .global .align 4 m01000_s08_param_12,
	.param .u64 .ptr .global .align 4 m01000_s08_param_13,
	.param .u64 .ptr .global .align 4 m01000_s08_param_14,
	.param .u64 .ptr .global .align 4 m01000_s08_param_15,
	.param .u64 .ptr .global .align 4 m01000_s08_param_16,
	.param .u64 .ptr .global .align 4 m01000_s08_param_17,
	.param .u64 .ptr .global .align 1 m01000_s08_param_18,
	.param .u64 .ptr .global .align 4 m01000_s08_param_19,
	.param .u64 .ptr .global .align 4 m01000_s08_param_20,
	.param .u64 .ptr .global .align 4 m01000_s08_param_21,
	.param .u64 .ptr .global .align 4 m01000_s08_param_22,
	.param .u64 .ptr .global .align 4 m01000_s08_param_23,
	.param .u32 m01000_s08_param_24,
	.param .u32 m01000_s08_param_25,
	.param .u32 m01000_s08_param_26,
	.param .u32 m01000_s08_param_27,
	.param .u32 m01000_s08_param_28,
	.param .u32 m01000_s08_param_29,
	.param .u32 m01000_s08_param_30,
	.param .u32 m01000_s08_param_31,
	.param .u32 m01000_s08_param_32,
	.param .u32 m01000_s08_param_33,
	.param .u64 m01000_s08_param_34
)
{



	ret;
}

	// .globl	m01000_s16
.entry m01000_s16(
	.param .u64 .ptr .global .align 4 m01000_s16_param_0,
	.param .u64 .ptr .global .align 4 m01000_s16_param_1,
	.param .u64 .ptr .global .align 4 m01000_s16_param_2,
	.param .u64 .ptr .global .align 4 m01000_s16_param_3,
	.param .u64 .ptr .global .align 1 m01000_s16_param_4,
	.param .u64 .ptr .global .align 1 m01000_s16_param_5,
	.param .u64 .ptr .global .align 4 m01000_s16_param_6,
	.param .u64 .ptr .global .align 4 m01000_s16_param_7,
	.param .u64 .ptr .global .align 4 m01000_s16_param_8,
	.param .u64 .ptr .global .align 4 m01000_s16_param_9,
	.param .u64 .ptr .global .align 4 m01000_s16_param_10,
	.param .u64 .ptr .global .align 4 m01000_s16_param_11,
	.param .u64 .ptr .global .align 4 m01000_s16_param_12,
	.param .u64 .ptr .global .align 4 m01000_s16_param_13,
	.param .u64 .ptr .global .align 4 m01000_s16_param_14,
	.param .u64 .ptr .global .align 4 m01000_s16_param_15,
	.param .u64 .ptr .global .align 4 m01000_s16_param_16,
	.param .u64 .ptr .global .align 4 m01000_s16_param_17,
	.param .u64 .ptr .global .align 1 m01000_s16_param_18,
	.param .u64 .ptr .global .align 4 m01000_s16_param_19,
	.param .u64 .ptr .global .align 4 m01000_s16_param_20,
	.param .u64 .ptr .global .align 4 m01000_s16_param_21,
	.param .u64 .ptr .global .align 4 m01000_s16_param_22,
	.param .u64 .ptr .global .align 4 m01000_s16_param_23,
	.param .u32 m01000_s16_param_24,
	.param .u32 m01000_s16_param_25,
	.param .u32 m01000_s16_param_26,
	.param .u32 m01000_s16_param_27,
	.param .u32 m01000_s16_param_28,
	.param .u32 m01000_s16_param_29,
	.param .u32 m01000_s16_param_30,
	.param .u32 m01000_s16_param_31,
	.param .u32 m01000_s16_param_32,
	.param .u32 m01000_s16_param_33,
	.param .u64 m01000_s16_param_34
)
{



	ret;
}


  